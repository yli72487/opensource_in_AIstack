[
  {
    "number": 84,
    "title": "Multiples Imges allowed in Multimodal request. Fix some issues reported by users.",
    "user": "danielferr85",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-25T16:24:39Z",
    "closed_at": "2025-10-25T17:33:12Z",
    "merged_at": "2025-10-25T17:33:12Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/84"
  },
  {
    "number": 74,
    "title": "Fix Docker Compose configuration",
    "user": "goetzc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-05T22:09:17Z",
    "closed_at": "2025-10-06T15:30:21Z",
    "merged_at": "2025-10-06T15:30:21Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/74"
  },
  {
    "number": 73,
    "title": "OpenAI endpoint for Image Generation (Stable Diffusion LCM)",
    "user": "danielferr85",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-02T16:06:25Z",
    "closed_at": "2025-10-04T17:34:42Z",
    "merged_at": "2025-10-04T17:34:42Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/73"
  },
  {
    "number": 72,
    "title": "New library version rkllm 1.2.2",
    "user": "danielferr85",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-30T11:55:14Z",
    "closed_at": "2025-10-02T13:05:15Z",
    "merged_at": "2025-10-02T13:05:15Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/72"
  },
  {
    "number": 71,
    "title": "Fix python package setuptools (pyproject.toml) and location of lib foâ€¦",
    "user": "danielferr85",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-28T19:13:16Z",
    "closed_at": "2025-09-28T20:19:13Z",
    "merged_at": "2025-09-28T20:19:13Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/71"
  },
  {
    "number": 68,
    "title": "Packaging support",
    "user": "phkrl",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-20T09:33:48Z",
    "closed_at": "2025-09-26T18:08:51Z",
    "merged_at": "2025-09-26T18:08:51Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/68"
  },
  {
    "number": 66,
    "title": "FIx in streaming and tool calls for a particular use case.",
    "user": "danielferr85",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-06T03:24:59Z",
    "closed_at": "2025-09-09T15:03:46Z",
    "merged_at": "2025-09-09T15:03:46Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/66"
  },
  {
    "number": 65,
    "title": "Multimodal Support (BETA)!!!!!. Added parameter think for compatibility with new version of Ollama for thinking models",
    "user": "danielferr85",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-04T05:30:14Z",
    "closed_at": "2025-09-05T08:58:40Z",
    "merged_at": "2025-09-05T08:58:40Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/65"
  },
  {
    "number": 63,
    "title": "Multiload RKLLM models in memory for parallelism inference and Embedding support. Other improvements",
    "user": "danielferr85",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-27T15:55:44Z",
    "closed_at": "2025-09-02T13:43:26Z",
    "merged_at": "2025-09-02T13:43:26Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/63"
  },
  {
    "number": 59,
    "title": "New library version and new changes and features",
    "user": "danielferr85",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-25T22:58:09Z",
    "closed_at": "2025-08-01T12:15:28Z",
    "merged_at": "2025-08-01T12:15:28Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/59"
  },
  {
    "number": 57,
    "title": "Add comprehensive tool/function calling documentation",
    "user": "akaoio",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-21T06:43:48Z",
    "closed_at": "2025-06-22T13:55:46Z",
    "merged_at": "2025-06-22T13:55:46Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/57"
  },
  {
    "number": 56,
    "title": "Update model mappings after pulling a new model",
    "user": "atiltman",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-13T06:01:16Z",
    "closed_at": "2025-06-14T18:04:44Z",
    "merged_at": "2025-06-14T18:04:44Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/56"
  },
  {
    "number": 52,
    "title": "Now support Tool Call with Streaming. Option to disable thinking in models  that suport it.",
    "user": "danielferr85",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-24T15:52:52Z",
    "closed_at": "2025-05-24T16:43:13Z",
    "merged_at": "2025-05-24T16:43:13Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/52"
  },
  {
    "number": 49,
    "title": "Tool Calling support. Fix context length for  RKLLM 1.1.4.",
    "user": "danielferr85",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-15T23:25:30Z",
    "closed_at": "2025-05-16T11:27:22Z",
    "merged_at": "2025-05-16T11:27:22Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/49"
  },
  {
    "number": 45,
    "title": "update librkllmrt.so to v1.2.1b1",
    "user": "feilongfl",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-11T22:43:35Z",
    "closed_at": "2025-05-17T18:24:03Z",
    "merged_at": "2025-05-17T18:24:03Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/45"
  },
  {
    "number": 44,
    "title": "fix: use sudo for sed command to modify rkllama executable",
    "user": "feilongfl",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-11T22:39:42Z",
    "closed_at": "2025-05-12T07:39:15Z",
    "merged_at": "2025-05-12T07:39:15Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/44"
  },
  {
    "number": 43,
    "title": "fix: correct indentation in pull_model function",
    "user": "feilongfl",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-11T01:32:55Z",
    "closed_at": "2025-05-11T13:48:06Z",
    "merged_at": "2025-05-11T13:48:06Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/43"
  },
  {
    "number": 40,
    "title": "feat: Add HuggingFace to RKLLM converter and improve Docker support",
    "user": "maltyxx",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-03T17:53:26Z",
    "closed_at": "2025-05-05T08:54:17Z",
    "merged_at": "2025-05-05T08:54:17Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/40"
  },
  {
    "number": 36,
    "title": "Docker: container improvements",
    "user": "goetzc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-20T19:04:40Z",
    "closed_at": "2025-04-21T13:06:25Z",
    "merged_at": "2025-04-21T13:06:25Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/36"
  },
  {
    "number": 33,
    "title": "Support tag names as model aliases in Ollama API",
    "user": "alexeyvolkoff",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-16T11:05:52Z",
    "closed_at": "2025-04-16T15:17:04Z",
    "merged_at": "2025-04-16T15:17:04Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/33"
  },
  {
    "number": 29,
    "title": "Beta",
    "user": "NotPunchnox",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-12T14:59:22Z",
    "closed_at": "2025-04-12T15:01:20Z",
    "merged_at": "2025-04-12T15:01:20Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/29"
  },
  {
    "number": 24,
    "title": "add docker compose",
    "user": "thanhtantran",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-21T09:51:06Z",
    "closed_at": "2025-03-21T17:25:46Z",
    "merged_at": "2025-03-21T17:25:46Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/24"
  },
  {
    "number": 19,
    "title": "Flexible configuration system for RKLLAMA",
    "user": "TomJacobsUK",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-14T00:30:10Z",
    "closed_at": "2025-03-15T14:57:16Z",
    "merged_at": "2025-03-15T14:57:16Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/19"
  },
  {
    "number": 17,
    "title": "Ollama api",
    "user": "TomJacobsUK",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-08T12:07:46Z",
    "closed_at": "2025-03-08T19:11:14Z",
    "merged_at": "2025-03-08T19:11:14Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/17"
  },
  {
    "number": 16,
    "title": "CPU selection",
    "user": "TomJacobsUK",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-07T19:40:05Z",
    "closed_at": "2025-03-07T22:32:44Z",
    "merged_at": "2025-03-07T22:32:44Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/16"
  },
  {
    "number": 14,
    "title": "Add CPU model selection prompt in server.sh",
    "user": "TomJacobsUK",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-01T00:04:24Z",
    "closed_at": "2025-03-01T17:56:17Z",
    "merged_at": "2025-03-01T17:56:17Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/14"
  },
  {
    "number": 11,
    "title": "Minor PR: Update process.py to fix non-stream text generation stuck bug.",
    "user": "ichlaffterlalu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-18T06:59:07Z",
    "closed_at": "2025-02-18T23:13:07Z",
    "merged_at": "2025-02-18T23:13:07Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/11"
  },
  {
    "number": 10,
    "title": "Rkllama docker",
    "user": "NotPunchnox",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-16T13:05:26Z",
    "closed_at": "2025-02-16T13:28:18Z",
    "merged_at": "2025-02-16T13:28:18Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/10"
  },
  {
    "number": 9,
    "title": "Docker version of RKLLAMA",
    "user": "ichlaffterlalu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-14T23:51:31Z",
    "closed_at": "2025-02-15T11:25:48Z",
    "merged_at": "2025-02-15T11:25:48Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/9"
  },
  {
    "number": 6,
    "title": "Support all models",
    "user": "NotPunchnox",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-04T23:10:08Z",
    "closed_at": "2025-02-04T23:10:24Z",
    "merged_at": "2025-02-04T23:10:24Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/6"
  },
  {
    "number": 5,
    "title": "Support all models",
    "user": "NotPunchnox",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-04T21:05:05Z",
    "closed_at": "2025-02-04T21:05:19Z",
    "merged_at": "2025-02-04T21:05:19Z",
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/5"
  },
  {
    "number": 3,
    "title": "Init new branche",
    "user": "NotPunchnox",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-17T08:41:43Z",
    "closed_at": "2025-01-17T08:45:40Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/NotPunchnox/rkllama/pull/3"
  }
]