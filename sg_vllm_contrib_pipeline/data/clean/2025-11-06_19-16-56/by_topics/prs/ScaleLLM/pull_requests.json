[
  {
    "number": 505,
    "title": "chore: added kernel_only option for fast build",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-06T17:05:36Z",
    "closed_at": "2025-11-06T18:46:53Z",
    "merged_at": "2025-11-06T18:46:53Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/505"
  },
  {
    "number": 504,
    "title": "refactor: clean up load_state_dict for quant linear",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-08T05:45:33Z",
    "closed_at": "2025-11-06T19:31:47Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/504"
  },
  {
    "number": 503,
    "title": "refactor: clean up legacy load_state_dict for linear layers",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-24T06:26:03Z",
    "closed_at": "2025-10-08T00:21:06Z",
    "merged_at": "2025-10-08T00:21:06Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/503"
  },
  {
    "number": 502,
    "title": "feat: added state dict load and verify support in module",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-23T01:54:03Z",
    "closed_at": "2025-09-24T04:54:53Z",
    "merged_at": "2025-09-24T04:54:53Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/502"
  },
  {
    "number": 501,
    "title": "feat: clean up module for inference use only",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-22T20:30:54Z",
    "closed_at": "2025-09-22T23:18:03Z",
    "merged_at": "2025-09-22T23:18:03Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/501"
  },
  {
    "number": 500,
    "title": "feat: port torch::nn::module as llm::nn::module",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-22T18:06:27Z",
    "closed_at": "2025-09-22T19:20:42Z",
    "merged_at": "2025-09-22T19:20:42Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/500"
  },
  {
    "number": 499,
    "title": "ci: fix package test workflow",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-15T04:20:05Z",
    "closed_at": "2025-09-15T05:00:48Z",
    "merged_at": "2025-09-15T05:00:48Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/499"
  },
  {
    "number": 498,
    "title": "ci: added python 13",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-13T00:11:46Z",
    "closed_at": "2025-09-13T00:53:44Z",
    "merged_at": "2025-09-13T00:53:44Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/498"
  },
  {
    "number": 497,
    "title": "ci: fix nccl related build error",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-12T21:18:42Z",
    "closed_at": "2025-09-12T21:42:46Z",
    "merged_at": "2025-09-12T21:42:46Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/497"
  },
  {
    "number": 496,
    "title": "upgrade torch to 12.8",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-12T17:31:25Z",
    "closed_at": "2025-09-12T20:24:28Z",
    "merged_at": "2025-09-12T20:24:28Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/496"
  },
  {
    "number": 495,
    "title": "refactor: keep problem shape in fmha block for q/k/v shape",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-25T20:43:41Z",
    "closed_at": "2025-07-25T21:11:08Z",
    "merged_at": "2025-07-25T21:11:08Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/495"
  },
  {
    "number": 494,
    "title": "refactor: change stride for Q/K/V to MNKL",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-25T17:47:59Z",
    "closed_at": "2025-07-25T19:33:05Z",
    "merged_at": "2025-07-25T19:33:05Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/494"
  },
  {
    "number": 493,
    "title": "feat: added kernel builder for attn",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-23T17:34:56Z",
    "closed_at": "2025-07-23T17:46:14Z",
    "merged_at": "2025-07-23T17:46:14Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/493"
  },
  {
    "number": 492,
    "title": "feat: added universal fmha runner",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-23T06:09:26Z",
    "closed_at": "2025-07-23T06:28:29Z",
    "merged_at": "2025-07-23T06:28:29Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/492"
  },
  {
    "number": 491,
    "title": "feat: added args and params for attn kernels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-22T05:05:17Z",
    "closed_at": "2025-07-22T05:29:37Z",
    "merged_at": "2025-07-22T05:29:37Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/491"
  },
  {
    "number": 490,
    "title": "feat: added smem and gmem layout selector for attn kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-21T05:25:35Z",
    "closed_at": "2025-07-22T00:32:27Z",
    "merged_at": "2025-07-22T00:32:27Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/490"
  },
  {
    "number": 489,
    "title": "feat: added KV multi-stages support for attn sm120",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-17T23:43:03Z",
    "closed_at": "2025-07-17T23:53:36Z",
    "merged_at": "2025-07-17T23:53:36Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/489"
  },
  {
    "number": 488,
    "title": "refactor: simplify mha block tiling logic",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-17T21:29:45Z",
    "closed_at": "2025-07-18T19:49:25Z",
    "merged_at": "2025-07-18T19:49:25Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/488"
  },
  {
    "number": 487,
    "title": "refactor: move kernel code into different folders",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-17T20:38:21Z",
    "closed_at": "2025-07-17T21:10:52Z",
    "merged_at": "2025-07-17T21:10:52Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/487"
  },
  {
    "number": 486,
    "title": "feat: [2/n] added warp specialization kernel for sm120 fmha",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-17T07:03:37Z",
    "closed_at": "2025-07-17T18:14:22Z",
    "merged_at": "2025-07-17T18:14:22Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/486"
  },
  {
    "number": 485,
    "title": "feat: added fast StaticPersistentTileScheduler for 1d tma multicast",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-12T00:20:12Z",
    "closed_at": "2025-07-12T00:27:06Z",
    "merged_at": "2025-07-12T00:27:06Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/485"
  },
  {
    "number": 484,
    "title": "feat: use aggressive compress-mode for fatbin",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-10T06:44:12Z",
    "closed_at": "2025-07-10T07:04:54Z",
    "merged_at": "2025-07-10T07:04:54Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/484"
  },
  {
    "number": 483,
    "title": "feat: [1/n] added sm120 fmha using collective async copy",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-10T03:56:58Z",
    "closed_at": "2025-07-17T02:18:39Z",
    "merged_at": "2025-07-17T02:18:39Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/483"
  },
  {
    "number": 482,
    "title": "feat: added gather tma copy to control smem box size",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-08T00:45:04Z",
    "closed_at": "2025-07-08T01:43:53Z",
    "merged_at": "2025-07-08T01:43:53Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/482"
  },
  {
    "number": 481,
    "title": "ci: upgrade cutlass to v4.1 and switch to forked repo",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-03T20:12:33Z",
    "closed_at": "2025-07-03T20:47:58Z",
    "merged_at": "2025-07-03T20:47:58Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/481"
  },
  {
    "number": 480,
    "title": "feat: add tma copy for paged kv ",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-03T00:09:40Z",
    "closed_at": "2025-07-07T23:16:24Z",
    "merged_at": "2025-07-07T23:16:24Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/480"
  },
  {
    "number": 479,
    "title": "feat: added gtest_main with filters based on compute_capabilities",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-02T19:55:36Z",
    "closed_at": "2025-07-02T21:25:24Z",
    "merged_at": "2025-07-02T21:25:24Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/479"
  },
  {
    "number": 478,
    "title": "feat: added static permistent tile scheduler with swizzle and rasterize",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-01T06:05:54Z",
    "closed_at": "2025-07-01T06:49:54Z",
    "merged_at": "2025-07-01T06:49:54Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/478"
  },
  {
    "number": 477,
    "title": "feat: simplify mask logic to avoid manual index computation",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-25T20:24:09Z",
    "closed_at": "2025-06-25T21:37:25Z",
    "merged_at": "2025-06-25T21:37:25Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/477"
  },
  {
    "number": 476,
    "title": "feat: use global residue_mnk for oob handling",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-25T05:11:04Z",
    "closed_at": "2025-06-25T05:40:38Z",
    "merged_at": "2025-06-25T05:40:38Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/476"
  },
  {
    "number": 475,
    "title": "refactor: split mla kernels into collective_mla collective_epilogue",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-22T01:42:48Z",
    "closed_at": "2025-06-25T04:39:17Z",
    "merged_at": "2025-06-25T04:39:17Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/475"
  },
  {
    "number": 474,
    "title": "feat: add tile scheduler for grouped gemm and refactor gemm kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-21T19:14:41Z",
    "closed_at": "2025-06-21T22:00:33Z",
    "merged_at": "2025-06-21T22:00:33Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/474"
  },
  {
    "number": 473,
    "title": "feat: added single tile scheduler for attn kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-20T06:33:16Z",
    "closed_at": "2025-06-20T07:32:31Z",
    "merged_at": "2025-06-20T07:32:31Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/473"
  },
  {
    "number": 472,
    "title": "fix: skip failed unittests for blackwell gpus",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-19T06:19:44Z",
    "closed_at": "2025-06-19T06:59:45Z",
    "merged_at": "2025-06-19T06:59:44Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/472"
  },
  {
    "number": 471,
    "title": "ci: use cuda 12.9 for devel and 12.8 for test",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-19T02:10:57Z",
    "closed_at": "2025-06-19T05:06:41Z",
    "merged_at": "2025-06-19T05:06:41Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/471"
  },
  {
    "number": 470,
    "title": "ci: refactor cuda install script and upgrade to latest version",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-18T19:20:20Z",
    "closed_at": "2025-06-18T20:15:36Z",
    "merged_at": "2025-06-18T20:15:36Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/470"
  },
  {
    "number": 469,
    "title": "refactor: split attention kernel into collective mainloop, collective epilogue and kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-18T05:29:12Z",
    "closed_at": "2025-06-19T01:51:21Z",
    "merged_at": "2025-06-19T01:51:21Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/469"
  },
  {
    "number": 468,
    "title": "refactor: move TileShape into launch_mha_kernel_sm80",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-18T05:17:59Z",
    "closed_at": "2025-06-18T05:28:10Z",
    "merged_at": "2025-06-18T05:28:10Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/468"
  },
  {
    "number": 467,
    "title": "ci: set cuda arch to native for ci workflows",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-17T18:33:12Z",
    "closed_at": "2025-06-17T19:05:17Z",
    "merged_at": "2025-06-17T19:05:17Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/467"
  },
  {
    "number": 466,
    "title": "refactor: add _1 into stride for contiguous dim",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-16T06:14:46Z",
    "closed_at": "2025-06-16T06:23:21Z",
    "merged_at": "2025-06-16T06:23:21Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/466"
  },
  {
    "number": 465,
    "title": "kernel: added oob handling for grouped gemm kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-14T03:21:06Z",
    "closed_at": "2025-06-15T19:45:55Z",
    "merged_at": "2025-06-15T19:45:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/465"
  },
  {
    "number": 464,
    "title": "fix: clean up existing whl files",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-27T06:15:00Z",
    "closed_at": "2025-05-27T06:31:05Z",
    "merged_at": "2025-05-27T06:31:05Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/464"
  },
  {
    "number": 463,
    "title": "fix: choose cuda arthitectures based on cuda version",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-27T04:43:50Z",
    "closed_at": "2025-05-27T05:41:32Z",
    "merged_at": "2025-05-27T05:41:32Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/463"
  },
  {
    "number": 462,
    "title": "ci: use old version of setuptools to avoid Metadata-Version issue",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-27T02:31:26Z",
    "closed_at": "2025-05-27T02:33:39Z",
    "merged_at": "2025-05-27T02:33:39Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/462"
  },
  {
    "number": 461,
    "title": "ci: change self-hosted runner tags",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-26T18:58:55Z",
    "closed_at": "2025-05-26T19:15:35Z",
    "merged_at": "2025-05-26T19:15:35Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/461"
  },
  {
    "number": 460,
    "title": "chore: upgrade cutlass to v4.0",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-15T03:25:56Z",
    "closed_at": "2025-05-15T04:47:23Z",
    "merged_at": "2025-05-15T04:47:22Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/460"
  },
  {
    "number": 459,
    "title": "build: added build for blackwell",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-15T00:09:09Z",
    "closed_at": "2025-05-15T02:00:57Z",
    "merged_at": "2025-05-15T02:00:57Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/459"
  },
  {
    "number": 458,
    "title": "kernel: add grouped gemm support for moe",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-10T00:14:42Z",
    "closed_at": "2025-06-13T05:59:37Z",
    "merged_at": "2025-06-13T05:59:37Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/458"
  },
  {
    "number": 442,
    "title": "kernel: added align block permutation kernel for moe",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-01T05:59:13Z",
    "closed_at": "2025-05-08T03:45:03Z",
    "merged_at": "2025-05-08T03:45:03Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/442"
  },
  {
    "number": 441,
    "title": "ci: enable docker cache",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-29T06:14:57Z",
    "closed_at": "2025-04-29T15:33:15Z",
    "merged_at": "2025-04-29T15:33:15Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/441"
  },
  {
    "number": 440,
    "title": "ci: switch to arc-runners",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-28T20:02:38Z",
    "closed_at": "2025-04-29T05:46:38Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/440"
  },
  {
    "number": 439,
    "title": "chore: add script to install zsh for devbox",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-27T04:27:45Z",
    "closed_at": "2025-04-27T04:28:24Z",
    "merged_at": "2025-04-27T04:28:24Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/439"
  },
  {
    "number": 438,
    "title": "chore: add option to install py module into scalellm folder",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T04:36:18Z",
    "closed_at": "2025-04-24T04:40:55Z",
    "merged_at": "2025-04-24T04:40:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/438"
  },
  {
    "number": 437,
    "title": "upgrade vcpkg after switch to manylinux_2_28",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T22:27:23Z",
    "closed_at": "2025-04-24T00:26:29Z",
    "merged_at": "2025-04-24T00:26:29Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/437"
  },
  {
    "number": 436,
    "title": "fix: fix manylinux2_28 build",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T21:27:55Z",
    "closed_at": "2025-04-23T22:08:34Z",
    "merged_at": "2025-04-23T22:08:34Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/436"
  },
  {
    "number": 435,
    "title": "chore: build manylinux2_28 builder image",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T20:52:12Z",
    "closed_at": "2025-04-23T20:55:40Z",
    "merged_at": "2025-04-23T20:55:40Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/435"
  },
  {
    "number": 434,
    "title": "upgrade pytorch to 2.7",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T19:55:15Z",
    "closed_at": "2025-04-23T20:33:18Z",
    "merged_at": "2025-04-23T20:33:18Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/434"
  },
  {
    "number": 433,
    "title": "kenerl: add kernel for moe permutation with mask map",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T18:14:21Z",
    "closed_at": "2025-04-30T20:26:36Z",
    "merged_at": "2025-04-30T20:26:36Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/433"
  },
  {
    "number": 432,
    "title": "refactor: use __ldlu to load/store data and refactor code for moe permute kernels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T17:28:23Z",
    "closed_at": "2025-04-23T18:05:05Z",
    "merged_at": "2025-04-23T18:05:05Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/432"
  },
  {
    "number": 431,
    "title": "test: added different dtype unittests for moe permute kernels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T04:48:40Z",
    "closed_at": "2025-04-23T05:00:13Z",
    "merged_at": "2025-04-23T05:00:13Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/431"
  },
  {
    "number": 430,
    "title": "chore: clean up JinjaChatTemplate",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T03:27:12Z",
    "closed_at": "2025-04-23T03:33:23Z",
    "merged_at": "2025-04-23T03:33:23Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/430"
  },
  {
    "number": 429,
    "title": "chore: clean up attn dependencies",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T03:14:48Z",
    "closed_at": "2025-04-23T03:23:09Z",
    "merged_at": "2025-04-23T03:23:09Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/429"
  },
  {
    "number": 428,
    "title": "kernel: added moe permute kernels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T00:59:10Z",
    "closed_at": "2025-04-23T01:37:31Z",
    "merged_at": "2025-04-23T01:37:31Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/428"
  },
  {
    "number": 427,
    "title": "chore: added pre-commit-config",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T01:40:16Z",
    "closed_at": "2025-04-21T04:21:25Z",
    "merged_at": "2025-04-21T04:21:25Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/427"
  },
  {
    "number": 426,
    "title": "kernel: added fused gate for moe",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-16T01:13:03Z",
    "closed_at": "2025-04-19T05:38:27Z",
    "merged_at": "2025-04-19T05:38:27Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/426"
  },
  {
    "number": 425,
    "title": "upgrade cutlass to 3.9",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-14T23:04:36Z",
    "closed_at": "2025-04-15T00:54:47Z",
    "merged_at": "2025-04-15T00:54:47Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/425"
  },
  {
    "number": 424,
    "title": "moe: added all to all token dispatcher pytorch implementation",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-11T02:55:20Z",
    "closed_at": "2025-04-12T18:53:03Z",
    "merged_at": "2025-04-12T18:53:03Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/424"
  },
  {
    "number": 423,
    "title": "nccl: added all2all for nccl process group",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-19T03:52:12Z",
    "closed_at": "2025-04-09T03:14:27Z",
    "merged_at": "2025-04-09T03:14:27Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/423"
  },
  {
    "number": 422,
    "title": "moe: added local token dispatcher pytorch implementation for testing",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-18T01:05:52Z",
    "closed_at": "2025-03-18T03:49:50Z",
    "merged_at": "2025-03-18T03:49:50Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/422"
  },
  {
    "number": 421,
    "title": "moe: added token dispatcher interface for MOE layer.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-14T05:50:15Z",
    "closed_at": "2025-03-14T06:01:34Z",
    "merged_at": "2025-03-14T06:01:34Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/421"
  },
  {
    "number": 420,
    "title": "kernel: refactor and added more unittests for attn combine kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-12T18:39:40Z",
    "closed_at": "2025-03-12T20:54:13Z",
    "merged_at": "2025-03-12T20:54:13Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/420"
  },
  {
    "number": 419,
    "title": "kernel: added attention combine kernel to support split kv",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-11T05:19:39Z",
    "closed_at": "2025-03-12T04:20:11Z",
    "merged_at": "2025-03-12T04:20:11Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/419"
  },
  {
    "number": 418,
    "title": "ci: fix whell build script",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-01T20:01:49Z",
    "closed_at": "2025-03-02T01:57:10Z",
    "merged_at": "2025-03-02T01:57:10Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/418"
  },
  {
    "number": 417,
    "title": "kernel: use FastDivmod in attention kernels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-01T00:07:54Z",
    "closed_at": "2025-03-01T00:31:53Z",
    "merged_at": "2025-03-01T00:31:53Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/417"
  },
  {
    "number": 416,
    "title": "kernel: fix kv oob issue and added more unittests for paged MLA",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-28T20:22:56Z",
    "closed_at": "2025-02-28T20:32:51Z",
    "merged_at": "2025-02-28T20:32:51Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/416"
  },
  {
    "number": 415,
    "title": "kernel: added paged kv support for MLA kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-27T06:24:16Z",
    "closed_at": "2025-02-28T19:38:06Z",
    "merged_at": "2025-02-28T19:38:06Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/415"
  },
  {
    "number": 414,
    "title": "kernel: optimize mask loop for MLA kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-27T04:48:54Z",
    "closed_at": "2025-02-27T05:33:30Z",
    "merged_at": "2025-02-27T05:33:30Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/414"
  },
  {
    "number": 413,
    "title": "kernel: added q and kv oob handling for MLA kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-26T23:54:46Z",
    "closed_at": "2025-02-27T04:11:54Z",
    "merged_at": "2025-02-27T04:11:54Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/413"
  },
  {
    "number": 412,
    "title": "misc: upgrade cuda version and add devcontainer for manylinux",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-26T00:15:39Z",
    "closed_at": "2025-02-26T00:41:52Z",
    "merged_at": "2025-02-26T00:41:52Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/412"
  },
  {
    "number": 411,
    "title": "upgrade vcpkg to 2025.02.14",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-24T23:59:52Z",
    "closed_at": "2025-02-26T00:15:49Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/411"
  },
  {
    "number": 410,
    "title": "kernel: added stage support for MLA kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-16T00:19:50Z",
    "closed_at": "2025-02-16T01:35:10Z",
    "merged_at": "2025-02-16T01:35:10Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/410"
  },
  {
    "number": 409,
    "title": "kernel: use differnt TiledMma for GEMM qk and pv",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-15T19:34:09Z",
    "closed_at": "2025-02-15T19:50:53Z",
    "merged_at": "2025-02-15T19:50:53Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/409"
  },
  {
    "number": 408,
    "title": "kernel: fix mask bugs for MLA",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-15T18:38:31Z",
    "closed_at": "2025-02-15T19:13:27Z",
    "merged_at": "2025-02-15T19:13:27Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/408"
  },
  {
    "number": 407,
    "title": "kernel: added blk_n=16 for MLA to support sm_86/sm_89 with only 100kb smem",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-15T06:29:12Z",
    "closed_at": "2025-02-15T06:34:03Z",
    "merged_at": "2025-02-15T06:34:03Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/407"
  },
  {
    "number": 406,
    "title": "kernel: added causal mask for MLA kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-14T21:22:41Z",
    "closed_at": "2025-02-14T21:32:13Z",
    "merged_at": "2025-02-14T21:32:13Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/406"
  },
  {
    "number": 405,
    "title": "kernel: refactor mask logic to avoid using hard-coded stride.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-14T20:07:58Z",
    "closed_at": "2025-02-14T20:32:06Z",
    "merged_at": "2025-02-14T20:32:06Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/405"
  },
  {
    "number": 404,
    "title": "kernel: revert mla ping-pong rmem change",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-14T05:51:48Z",
    "closed_at": "2025-02-14T06:05:14Z",
    "merged_at": "2025-02-14T06:05:14Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/404"
  },
  {
    "number": 403,
    "title": "kernel: use 8 warps to avoid register spilling for mla with hdim=512",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-13T20:11:30Z",
    "closed_at": "2025-02-14T01:37:55Z",
    "merged_at": "2025-02-14T01:37:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/403"
  },
  {
    "number": 402,
    "title": "kernel: put query alwasy in registers for mha",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-13T04:16:34Z",
    "closed_at": "2025-02-13T04:30:01Z",
    "merged_at": "2025-02-13T04:30:01Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/402"
  },
  {
    "number": 401,
    "title": "kernel: revert experimental TiledMMA separation change.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-13T03:43:57Z",
    "closed_at": "2025-02-13T03:47:50Z",
    "merged_at": "2025-02-13T03:47:50Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/401"
  },
  {
    "number": 400,
    "title": "kernel: added ping-pong rmem support for MLA",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-12T20:59:41Z",
    "closed_at": "2025-02-13T03:25:24Z",
    "merged_at": "2025-02-13T03:25:24Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/400"
  },
  {
    "number": 399,
    "title": "kernel: added pipeline support for mla",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-10T22:05:20Z",
    "closed_at": "2025-02-12T04:30:34Z",
    "merged_at": "2025-02-12T04:30:34Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/399"
  },
  {
    "number": 398,
    "title": "upgrade libtorch to 2.6.0 and cutlass to 3.8.0",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-07T01:52:35Z",
    "closed_at": "2025-02-07T03:24:40Z",
    "merged_at": "2025-02-07T03:24:40Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/398"
  },
  {
    "number": 397,
    "title": "kernel: fix register spilling issue for attention head_dim=256",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-06T20:47:07Z",
    "closed_at": "2025-02-07T01:37:52Z",
    "merged_at": "2025-02-07T01:37:52Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/397"
  },
  {
    "number": 396,
    "title": "kernel: added simple MLA kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-05T00:04:23Z",
    "closed_at": "2025-02-08T06:39:02Z",
    "merged_at": "2025-02-08T06:39:02Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/396"
  },
  {
    "number": 395,
    "title": "kernel: generate smaller kernel instantiations",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-04T20:43:35Z",
    "closed_at": "2025-02-04T21:45:02Z",
    "merged_at": "2025-02-04T21:45:02Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/395"
  },
  {
    "number": 394,
    "title": "kernel: added triton aot compiler",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-04T07:46:16Z",
    "closed_at": "2025-02-04T08:58:20Z",
    "merged_at": "2025-02-04T08:58:20Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/394"
  },
  {
    "number": 393,
    "title": "refactor: rename attention to mha to differentiate it from mla",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-31T18:13:05Z",
    "closed_at": "2025-01-31T18:40:55Z",
    "merged_at": "2025-01-31T18:40:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/393"
  },
  {
    "number": 392,
    "title": "kernel: added query packing support for attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-27T18:52:42Z",
    "closed_at": "2025-01-28T01:24:16Z",
    "merged_at": "2025-01-28T01:24:16Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/392"
  },
  {
    "number": 391,
    "title": "ci: build devel image with cuda 12.8 for blackwell",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-26T22:58:08Z",
    "closed_at": "2025-01-26T23:26:13Z",
    "merged_at": "2025-01-26T23:26:13Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/391"
  },
  {
    "number": 390,
    "title": "ci: add option to skip nvbench build",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-26T21:20:47Z",
    "closed_at": "2025-01-26T21:30:28Z",
    "merged_at": "2025-01-26T21:30:27Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/390"
  },
  {
    "number": 389,
    "title": "refactor: clean up kv cache set/get apis and improve slot id calculation perf",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-26T00:56:08Z",
    "closed_at": "2025-01-26T18:36:42Z",
    "merged_at": "2025-01-26T18:36:42Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/389"
  },
  {
    "number": 388,
    "title": "refactor: skip flash_attn build",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-25T22:06:27Z",
    "closed_at": "2025-01-25T22:14:36Z",
    "merged_at": "2025-01-25T22:14:36Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/388"
  },
  {
    "number": 387,
    "title": "kernel: only zfill k once to improve perf for attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-25T20:15:48Z",
    "closed_at": "2025-01-25T20:22:39Z",
    "merged_at": "2025-01-25T20:22:39Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/387"
  },
  {
    "number": 386,
    "title": "refactor: stop build flash_infer kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-24T19:33:57Z",
    "closed_at": "2025-01-24T20:07:09Z",
    "merged_at": "2025-01-24T20:07:09Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/386"
  },
  {
    "number": 385,
    "title": "refactor: remove batch_prefill interface",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-24T19:00:46Z",
    "closed_at": "2025-01-24T19:17:38Z",
    "merged_at": "2025-01-24T19:17:38Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/385"
  },
  {
    "number": 384,
    "title": "kernel: seperate oob iterations for better performance.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-24T03:48:52Z",
    "closed_at": "2025-01-24T04:59:46Z",
    "merged_at": "2025-01-24T04:59:46Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/384"
  },
  {
    "number": 383,
    "title": "kernel: use cp_async_zfill instead of cute::clear for oob handling",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-23T23:59:59Z",
    "closed_at": "2025-01-24T00:31:50Z",
    "merged_at": "2025-01-24T00:31:50Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/383"
  },
  {
    "number": 382,
    "title": "kernel: handle kv block range for attention kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-23T22:42:24Z",
    "closed_at": "2025-01-23T23:23:48Z",
    "merged_at": "2025-01-23T23:23:48Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/382"
  },
  {
    "number": 381,
    "title": "kernel: support fp8 kv cache",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-21T07:06:18Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/381"
  },
  {
    "number": 380,
    "title": "feat: integrate in-house scale attention and use it by default",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-21T04:44:19Z",
    "closed_at": "2025-01-25T00:25:10Z",
    "merged_at": "2025-01-25T00:25:09Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/380"
  },
  {
    "number": 379,
    "title": "upgrade cutlass to 3.7.0",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-21T01:27:32Z",
    "closed_at": "2025-01-21T01:36:08Z",
    "merged_at": "2025-01-21T01:36:08Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/379"
  },
  {
    "number": 378,
    "title": "[WIP] kernel: added fp8/int8 kv cache support",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-19T07:47:30Z",
    "closed_at": "2025-01-21T07:03:33Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/378"
  },
  {
    "number": 377,
    "title": "kernel: optimize attention kernel performance",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-17T22:22:57Z",
    "closed_at": "2025-01-18T01:15:05Z",
    "merged_at": "2025-01-18T01:15:05Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/377"
  },
  {
    "number": 376,
    "title": "kernel: added head_dim=96 support for attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-17T04:34:28Z",
    "closed_at": "2025-01-17T05:18:04Z",
    "merged_at": "2025-01-17T05:18:04Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/376"
  },
  {
    "number": 375,
    "title": "kernel: change attention input shape from [head, seq, dim] to [seq, head, dim]",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-16T20:59:02Z",
    "closed_at": "2025-01-16T21:08:19Z",
    "merged_at": "2025-01-16T21:08:19Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/375"
  },
  {
    "number": 374,
    "title": "kernel: added build script to generate kernel instantiations for attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-16T19:20:38Z",
    "closed_at": "2025-01-16T19:36:23Z",
    "merged_at": "2025-01-16T19:36:23Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/374"
  },
  {
    "number": 373,
    "title": "kernel: added attention kernel launch",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-16T06:38:14Z",
    "closed_at": "2025-01-16T06:43:36Z",
    "merged_at": "2025-01-16T06:43:36Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/373"
  },
  {
    "number": 372,
    "title": "kernel: added varlen and pagedkv unittests for attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-15T06:35:54Z",
    "closed_at": "2025-01-15T06:55:44Z",
    "merged_at": "2025-01-15T06:55:44Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/372"
  },
  {
    "number": 371,
    "title": "kernel: added var len and paged kv cache support for attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-14T19:51:10Z",
    "closed_at": "2025-01-15T03:42:33Z",
    "merged_at": "2025-01-15T03:42:33Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/371"
  },
  {
    "number": 370,
    "title": "kernel: added mqa and gqa support for attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-14T05:46:06Z",
    "closed_at": "2025-01-14T05:49:40Z",
    "merged_at": "2025-01-14T05:49:40Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/370"
  },
  {
    "number": 369,
    "title": "kernel: Added attention params and tile for different input types.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-14T05:15:38Z",
    "closed_at": "2025-01-14T05:34:00Z",
    "merged_at": "2025-01-14T05:34:00Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/369"
  },
  {
    "number": 368,
    "title": "tools: update svg build to generate small file",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-12T19:38:08Z",
    "closed_at": "2025-01-12T19:42:21Z",
    "merged_at": "2025-01-12T19:42:21Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/368"
  },
  {
    "number": 367,
    "title": "kernel: added M/N OOB handling for attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-12T02:38:15Z",
    "closed_at": "2025-01-12T02:53:21Z",
    "merged_at": "2025-01-12T02:53:21Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/367"
  },
  {
    "number": 366,
    "title": "kernel: refactor attention kernel and add more unittests",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-09T19:38:49Z",
    "closed_at": "2025-01-09T20:13:21Z",
    "merged_at": "2025-01-09T20:13:21Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/366"
  },
  {
    "number": 365,
    "title": "kernel: added causal, alibi, sliding window mask for attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-08T05:13:23Z",
    "closed_at": "2025-01-09T04:04:31Z",
    "merged_at": "2025-01-09T04:04:31Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/365"
  },
  {
    "number": 364,
    "title": "kernel: added swizzle for shared memory to avoid bank conflict",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-07T19:57:45Z",
    "closed_at": "2025-01-07T20:02:11Z",
    "merged_at": "2025-01-07T20:02:11Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/364"
  },
  {
    "number": 363,
    "title": "tools: added attention traits viewer",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-06T23:40:16Z",
    "closed_at": "2025-01-07T05:11:20Z",
    "merged_at": "2025-01-07T05:11:19Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/363"
  },
  {
    "number": 362,
    "title": "kernel: added logits soft cap support for attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-04T20:51:35Z",
    "closed_at": "2025-01-04T20:58:42Z",
    "merged_at": "2025-01-04T20:58:42Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/362"
  },
  {
    "number": 361,
    "title": "kernel: added logits soft cap support for attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-04T20:42:17Z",
    "closed_at": "2025-01-04T20:51:21Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/361"
  },
  {
    "number": 360,
    "title": "kernel: added attention bench for profiling before optimization",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-04T01:26:12Z",
    "closed_at": "2025-01-04T02:10:55Z",
    "merged_at": "2025-01-04T02:10:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/360"
  },
  {
    "number": 359,
    "title": "dev: config dev container with proper extensions",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-02T23:13:22Z",
    "closed_at": "2025-01-03T00:04:17Z",
    "merged_at": "2025-01-03T00:04:17Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/359"
  },
  {
    "number": 358,
    "title": "kernel: refactor attention kernel for readibility",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-02T05:48:55Z",
    "closed_at": "2025-01-02T07:41:16Z",
    "merged_at": "2025-01-02T07:41:16Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/358"
  },
  {
    "number": 357,
    "title": "ci: fix package test workflow",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-01T19:40:08Z",
    "closed_at": "2025-01-01T20:18:42Z",
    "merged_at": "2025-01-01T20:18:42Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/357"
  },
  {
    "number": 355,
    "title": "kernel: added attention kernel for sm80 (Happy new year!)",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-31T20:05:34Z",
    "closed_at": "2025-01-01T04:10:45Z",
    "merged_at": "2025-01-01T04:10:45Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/355"
  },
  {
    "number": 354,
    "title": "fix cmake version issue for manylinux image",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-21T05:53:54Z",
    "closed_at": "2024-11-21T08:34:55Z",
    "merged_at": "2024-11-21T08:34:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/354"
  },
  {
    "number": 353,
    "title": "added cuda 12.6 build image",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-20T20:55:58Z",
    "closed_at": "2024-11-20T23:20:48Z",
    "merged_at": "2024-11-20T23:20:47Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/353"
  },
  {
    "number": 352,
    "title": "[WIP] Llava support",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-20T19:44:17Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/352"
  },
  {
    "number": 351,
    "title": "upgrade pytorch to 2.5.1",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-20T19:18:29Z",
    "closed_at": "2024-11-20T19:43:08Z",
    "merged_at": "2024-11-20T19:43:08Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/351"
  },
  {
    "number": 350,
    "title": "misc: remove legacy logic to support quantization for other types.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-07T17:14:40Z",
    "closed_at": "2024-11-07T17:24:14Z",
    "merged_at": "2024-11-07T17:24:14Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/350"
  },
  {
    "number": 347,
    "title": "Upgrade pytorch to 2.5.0",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-17T17:43:42Z",
    "closed_at": "2024-10-17T18:28:01Z",
    "merged_at": "2024-10-17T18:28:00Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/347"
  },
  {
    "number": 346,
    "title": "ci: build cuda 12.4 for scalellm cpp images",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-15T04:40:27Z",
    "closed_at": "2024-10-15T04:56:43Z",
    "merged_at": "2024-10-15T04:56:43Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/346"
  },
  {
    "number": 345,
    "title": "ci: run package test in docker",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-14T23:24:37Z",
    "closed_at": "2024-10-15T04:05:44Z",
    "merged_at": "2024-10-15T04:05:44Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/345"
  },
  {
    "number": 344,
    "title": "ci: use venv instead of conda in package test",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-14T17:52:42Z",
    "closed_at": "2024-10-14T18:23:54Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/344"
  },
  {
    "number": 343,
    "title": "Revert \"port cuda changes\"",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-14T03:13:34Z",
    "closed_at": "2024-10-14T03:25:21Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/343"
  },
  {
    "number": 342,
    "title": "ci: update python version for package test",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-14T02:15:33Z",
    "closed_at": "2024-10-14T03:25:35Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/342"
  },
  {
    "number": 341,
    "title": "upgrade pytorch to 2.4.1",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-13T04:57:59Z",
    "closed_at": "2024-10-13T18:35:25Z",
    "merged_at": "2024-10-13T18:35:25Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/341"
  },
  {
    "number": 340,
    "title": "ut: add more tests for different warp layout",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-22T21:52:08Z",
    "closed_at": "2024-10-18T06:09:07Z",
    "merged_at": "2024-10-18T06:09:07Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/340"
  },
  {
    "number": 339,
    "title": "misc: attention kernel refactoring",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-20T06:29:37Z",
    "closed_at": "2024-10-23T18:43:46Z",
    "merged_at": "2024-10-23T18:43:46Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/339"
  },
  {
    "number": 338,
    "title": "[misc] read flashinfer kernel code and add comments",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-18T16:49:02Z",
    "closed_at": "2024-09-20T06:19:55Z",
    "merged_at": "2024-09-20T06:19:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/338"
  },
  {
    "number": 337,
    "title": "ci: added pip cache to avoid redownloading",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-11T05:10:22Z",
    "closed_at": "2024-09-11T05:27:55Z",
    "merged_at": "2024-09-11T05:27:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/337"
  },
  {
    "number": 336,
    "title": "ut: added fp8 kv unittests for flash infer kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-11T04:55:28Z",
    "closed_at": "2024-09-11T05:06:50Z",
    "merged_at": "2024-09-11T05:06:50Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/336"
  },
  {
    "number": 335,
    "title": "refactor: move paged kv related logic into paged_kv_t",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-10T22:56:39Z",
    "closed_at": "2024-09-10T23:25:26Z",
    "merged_at": "2024-09-10T23:25:26Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/335"
  },
  {
    "number": 334,
    "title": "feat: added pass-in alibi slopes support for flash infer kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-10T05:17:33Z",
    "closed_at": "2024-09-10T05:26:04Z",
    "merged_at": "2024-09-10T05:26:04Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/334"
  },
  {
    "number": 333,
    "title": "refactor: replaced last_page_len with kv_indptr for flash infer kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-10T03:41:23Z",
    "closed_at": "2024-09-10T04:08:24Z",
    "merged_at": "2024-09-10T04:08:24Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/333"
  },
  {
    "number": 332,
    "title": "ut: added unittests for flash infer kernels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-07T19:01:42Z",
    "closed_at": "2024-09-09T23:30:10Z",
    "merged_at": "2024-09-09T23:30:10Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/332"
  },
  {
    "number": 331,
    "title": "kernel: port flash infer handler + wrapper logics",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-07T04:47:27Z",
    "closed_at": "2024-09-07T05:30:50Z",
    "merged_at": "2024-09-07T05:30:50Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/331"
  },
  {
    "number": 330,
    "title": "refactor: move flash attn and flash infer into attention folder",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-07T01:12:50Z",
    "closed_at": "2024-09-07T01:22:36Z",
    "merged_at": "2024-09-07T01:22:36Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/330"
  },
  {
    "number": 329,
    "title": "kernel: added script to generate instantiation for flashinfer kernels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-05T23:00:03Z",
    "closed_at": "2024-09-05T23:07:37Z",
    "merged_at": "2024-09-05T23:07:37Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/329"
  },
  {
    "number": 328,
    "title": "refactor: flatten block tables to 1d tensor",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-05T02:25:24Z",
    "closed_at": "2024-09-05T03:41:25Z",
    "merged_at": "2024-09-05T03:41:25Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/328"
  },
  {
    "number": 327,
    "title": "kernel: added flash infer attention impl",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T23:02:39Z",
    "closed_at": "2024-09-04T23:14:31Z",
    "merged_at": "2024-09-04T23:14:31Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/327"
  },
  {
    "number": 326,
    "title": "feat: fix and use marlin kernel for awq by default",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T18:16:08Z",
    "closed_at": "2024-09-04T18:40:30Z",
    "merged_at": "2024-09-04T18:40:30Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/326"
  },
  {
    "number": 325,
    "title": "refactor: added static switch for marlin kernel dispatch",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-31T17:47:17Z",
    "closed_at": "2024-09-03T18:58:27Z",
    "merged_at": "2024-09-03T18:58:27Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/325"
  },
  {
    "number": 324,
    "title": "fix: put item into asyncio.Queue in a thread-safe way",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-30T05:32:33Z",
    "closed_at": "2024-08-30T05:51:54Z",
    "merged_at": "2024-08-30T05:51:54Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/324"
  },
  {
    "number": 321,
    "title": "ci: allow build without requiring a physical gpu device",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-29T00:02:49Z",
    "closed_at": "2024-08-29T00:36:51Z",
    "merged_at": "2024-08-29T00:36:51Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/321"
  },
  {
    "number": 320,
    "title": "cmake: make includes private and disable jinja2cpp build",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-28T19:00:23Z",
    "closed_at": "2024-08-28T19:34:20Z",
    "merged_at": "2024-08-28T19:34:20Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/320"
  },
  {
    "number": 319,
    "title": "fix: clean up build warnings: \"LOG\" redefined",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-28T01:22:17Z",
    "closed_at": "2024-08-28T01:36:36Z",
    "merged_at": "2024-08-28T01:36:36Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/319"
  },
  {
    "number": 318,
    "title": "refactor: clean up build warnings and refactor marlin kernels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-27T22:48:08Z",
    "closed_at": "2024-08-28T01:19:07Z",
    "merged_at": "2024-08-28T01:19:07Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/318"
  },
  {
    "number": 317,
    "title": "test: added unittests for marlin kernels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-27T05:09:17Z",
    "closed_at": "2024-08-27T18:17:31Z",
    "merged_at": "2024-08-27T18:17:31Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/317"
  },
  {
    "number": 316,
    "title": "build: speed up compilation for marlin kernels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-24T18:08:06Z",
    "closed_at": "2024-08-25T19:45:50Z",
    "merged_at": "2024-08-25T19:45:50Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/316"
  },
  {
    "number": 315,
    "title": "feat: added awq marlin qlinear",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-20T04:20:01Z",
    "closed_at": "2024-08-24T04:32:29Z",
    "merged_at": "2024-08-24T04:32:29Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/315"
  },
  {
    "number": 314,
    "title": "kernel: port awq repack kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-20T03:41:03Z",
    "closed_at": "2024-08-20T04:08:21Z",
    "merged_at": "2024-08-20T04:08:21Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/314"
  },
  {
    "number": 313,
    "title": "feat: added fused column parallel linear",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-19T05:14:59Z",
    "closed_at": "2024-08-19T20:18:44Z",
    "merged_at": "2024-08-19T20:18:44Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/313"
  },
  {
    "number": 312,
    "title": "feat: added gptq marlin qlinear layer",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-17T18:13:29Z",
    "closed_at": "2024-08-19T21:32:24Z",
    "merged_at": "2024-08-19T21:32:24Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/312"
  },
  {
    "number": 311,
    "title": "refactor: remove the logic loading individual weight from shared partitions",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-17T02:08:07Z",
    "closed_at": "2024-08-17T15:23:19Z",
    "merged_at": "2024-08-17T15:23:19Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/311"
  },
  {
    "number": 309,
    "title": "rust: upgrade rust libs to latest version",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-14T16:31:37Z",
    "closed_at": "2024-08-14T16:43:45Z",
    "merged_at": "2024-08-14T16:43:45Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/309"
  },
  {
    "number": 307,
    "title": "kernel: port gptq marlin kernel and fp8 marlin kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-12T20:29:18Z",
    "closed_at": "2024-08-14T03:57:01Z",
    "merged_at": "2024-08-14T03:57:01Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/307"
  },
  {
    "number": 306,
    "title": "refactor: move models to upper folder",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-09T17:51:43Z",
    "closed_at": "2024-08-09T17:58:18Z",
    "merged_at": "2024-08-09T17:58:18Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/306"
  },
  {
    "number": 305,
    "title": "fix: move eos out of stop token list to honor ignore_eos option",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-09T17:20:26Z",
    "closed_at": "2024-08-09T17:28:51Z",
    "merged_at": "2024-08-09T17:28:51Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/305"
  },
  {
    "number": 303,
    "title": "feat: added marlin qlinear support",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-09T00:34:48Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/303"
  },
  {
    "number": 302,
    "title": "test: added unittests for marlin fp16xint4 gemm",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-08T04:48:14Z",
    "closed_at": "2024-08-08T04:54:45Z",
    "merged_at": "2024-08-08T04:54:45Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/302"
  },
  {
    "number": 301,
    "title": "kernel: support kernel test in python via pybind",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-07T18:57:31Z",
    "closed_at": "2024-08-07T19:13:01Z",
    "merged_at": "2024-08-07T19:13:01Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/301"
  },
  {
    "number": 300,
    "title": "model: added gemma2 with softcap and sliding window support",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T19:08:15Z",
    "closed_at": "2024-08-06T21:34:31Z",
    "merged_at": "2024-08-06T21:34:31Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/300"
  },
  {
    "number": 299,
    "title": "test: added unittests for attention sliding window",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T05:45:09Z",
    "closed_at": "2024-08-06T05:53:33Z",
    "merged_at": "2024-08-06T05:53:33Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/299"
  },
  {
    "number": 298,
    "title": "kernel: port softcap support for flash attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-05T20:43:19Z",
    "closed_at": "2024-08-06T05:16:15Z",
    "merged_at": "2024-08-06T05:16:15Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/298"
  },
  {
    "number": 297,
    "title": "ci: fix pytest version to avoid flakiness",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-03T17:29:48Z",
    "closed_at": "2024-08-03T18:14:41Z",
    "merged_at": "2024-08-03T18:14:41Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/297"
  },
  {
    "number": 296,
    "title": "feat: added sliding window support for QWen2",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-02T23:44:13Z",
    "closed_at": "2024-08-02T23:55:10Z",
    "merged_at": "2024-08-02T23:55:10Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/296"
  },
  {
    "number": 295,
    "title": "model: added qwen2 support",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-02T22:42:29Z",
    "closed_at": "2024-08-02T23:04:32Z",
    "merged_at": "2024-08-02T23:04:32Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/295"
  },
  {
    "number": 294,
    "title": "triton: fix build error and add example with unittest",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-02T19:24:10Z",
    "closed_at": "2024-08-02T21:22:58Z",
    "merged_at": "2024-08-02T21:22:58Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/294"
  },
  {
    "number": 293,
    "title": "fix: handle unfinished utf8 bytes for tiktoken tokenizer",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-02T06:05:44Z",
    "closed_at": "2024-08-02T06:16:24Z",
    "merged_at": "2024-08-02T06:16:24Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/293"
  },
  {
    "number": 292,
    "title": "feat: added THUDM/glm-4* support",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-01T18:51:22Z",
    "closed_at": "2024-08-02T05:22:48Z",
    "merged_at": "2024-08-02T05:22:48Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/292"
  },
  {
    "number": 290,
    "title": "ci: added clang-format-ignore file to exclude generated files",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-01T08:03:44Z",
    "closed_at": "2024-08-01T08:38:24Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/290"
  },
  {
    "number": 289,
    "title": "kernel: added triton kernel build support",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-01T07:38:43Z",
    "closed_at": "2024-08-01T07:51:20Z",
    "merged_at": "2024-08-01T07:51:20Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/289"
  },
  {
    "number": 288,
    "title": "debug: added environment collection script.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-31T16:50:09Z",
    "closed_at": "2024-07-31T17:23:19Z",
    "merged_at": "2024-07-31T17:23:19Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/288"
  },
  {
    "number": 287,
    "title": "kernel: added marlin dense and sparse kernels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-30T17:51:31Z",
    "closed_at": "2024-07-30T18:29:57Z",
    "merged_at": "2024-07-30T18:29:57Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/287"
  },
  {
    "number": 286,
    "title": "ci: disable pip cache to avoid hash mismatch error",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-30T17:01:44Z",
    "closed_at": "2024-07-30T17:18:04Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/286"
  },
  {
    "number": 285,
    "title": "refactor: remove exllama kernels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-29T23:01:15Z",
    "closed_at": "2024-07-29T23:53:20Z",
    "merged_at": "2024-07-29T23:53:20Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/285"
  },
  {
    "number": 284,
    "title": "pypi: fix invalid classifier",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-25T14:34:26Z",
    "closed_at": "2024-07-25T18:33:20Z",
    "merged_at": "2024-07-25T18:33:20Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/284"
  },
  {
    "number": 283,
    "title": "ci: cancel all previous runs if a new one is triggered",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-25T02:52:05Z",
    "closed_at": "2024-07-25T02:56:46Z",
    "merged_at": "2024-07-25T02:56:46Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/283"
  },
  {
    "number": 282,
    "title": "ci: fix  cuda version for wheel build workflow",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-25T01:55:30Z",
    "closed_at": "2024-07-25T01:58:03Z",
    "merged_at": "2024-07-25T01:58:02Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/282"
  },
  {
    "number": 281,
    "title": "default use cuda 12.1 for wheel package",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-24T23:52:09Z",
    "closed_at": "2024-07-25T00:59:09Z",
    "merged_at": "2024-07-25T00:59:09Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/281"
  },
  {
    "number": 280,
    "title": "upgrade torch to 2.4.0",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-24T17:41:32Z",
    "closed_at": "2024-07-24T18:29:34Z",
    "merged_at": "2024-07-24T18:29:34Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/280"
  },
  {
    "number": 279,
    "title": "ci: increase ccache max size from 5GB(default) to 25GB",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-24T05:06:49Z",
    "closed_at": "2024-07-24T05:10:32Z",
    "merged_at": "2024-07-24T05:10:32Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/279"
  },
  {
    "number": 278,
    "title": "update docs for llama3.1 support and bump up version",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-23T22:37:17Z",
    "closed_at": "2024-07-23T23:15:51Z",
    "merged_at": "2024-07-23T23:15:51Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/278"
  },
  {
    "number": 277,
    "title": "feat: added rope scaling support for llama3.1",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-23T20:37:39Z",
    "closed_at": "2024-07-23T20:47:55Z",
    "merged_at": "2024-07-23T20:47:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/277"
  },
  {
    "number": 274,
    "title": "kernel: added playground for learning and experimenting cute.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-12T20:58:54Z",
    "closed_at": "2024-07-12T21:34:46Z",
    "merged_at": "2024-07-12T21:34:46Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/274"
  },
  {
    "number": 273,
    "title": "attention: added tile logic using cute::local_tile into cpu attention",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-12T06:36:21Z",
    "closed_at": "2024-07-12T06:39:46Z",
    "merged_at": "2024-07-12T06:39:46Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/273"
  },
  {
    "number": 272,
    "title": "ci: build and test in devel docker image",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-11T06:36:38Z",
    "closed_at": "2024-07-11T07:16:17Z",
    "merged_at": "2024-07-11T07:16:17Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/272"
  },
  {
    "number": 271,
    "title": "ci: use manylinux image to build wheel and run pytest",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-11T04:56:11Z",
    "closed_at": "2024-07-11T07:49:56Z",
    "merged_at": "2024-07-11T07:49:56Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/271"
  },
  {
    "number": 270,
    "title": "build: upgrade cmake required version from 3.18 to 3.26",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-11T04:27:34Z",
    "closed_at": "2024-07-11T05:08:36Z",
    "merged_at": "2024-07-11T05:08:36Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/270"
  },
  {
    "number": 269,
    "title": "build: added nvbench as submodule",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-10T23:34:44Z",
    "closed_at": "2024-07-10T23:56:51Z",
    "merged_at": "2024-07-10T23:56:51Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/269"
  },
  {
    "number": 268,
    "title": "kernel: added attention cpu implementation for testing",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T16:36:38Z",
    "closed_at": "2024-07-09T17:36:09Z",
    "merged_at": "2024-07-09T17:36:09Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/268"
  },
  {
    "number": 267,
    "title": "feat: added range to support Range-for loops",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T06:33:24Z",
    "closed_at": "2024-07-09T06:48:38Z",
    "merged_at": "2024-07-09T06:48:38Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/267"
  },
  {
    "number": 266,
    "title": "cmake: define header only library instead of symbol link for cutlass and flashinfer",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T05:28:42Z",
    "closed_at": "2024-07-09T05:44:00Z",
    "merged_at": "2024-07-09T05:44:00Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/266"
  },
  {
    "number": 265,
    "title": "kernel: upgrade cutlass to 3.5.0 + cuda 12.4 for sm89 fp8 support",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-08T01:01:35Z",
    "closed_at": "2024-07-08T05:24:32Z",
    "merged_at": "2024-07-08T05:24:32Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/265"
  },
  {
    "number": 264,
    "title": "build: fix build error with gcc-13",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-07T06:23:56Z",
    "closed_at": "2024-07-07T06:43:19Z",
    "merged_at": "2024-07-07T06:43:19Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/264"
  },
  {
    "number": 263,
    "title": "ci: fail test if not all tests were passed successfully",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-03T17:11:32Z",
    "closed_at": "2024-07-03T17:33:39Z",
    "merged_at": "2024-07-03T17:33:39Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/263"
  },
  {
    "number": 262,
    "title": "Revert \"[model] support vision language model llava. (#178)\"",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-03T16:57:22Z",
    "closed_at": "2024-07-03T17:39:32Z",
    "merged_at": "2024-07-03T17:39:32Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/262"
  },
  {
    "number": 261,
    "title": "bugfix: fix multiple definition issue.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-03T10:45:33Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/261"
  },
  {
    "number": 260,
    "title": "build: fix multiple definition issue.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-02T08:27:58Z",
    "closed_at": "2024-07-03T02:02:56Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/260"
  },
  {
    "number": 259,
    "title": "bugfix: fix invalid max_cache_size when device is cpu.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-02T06:23:22Z",
    "closed_at": "2024-07-02T15:50:00Z",
    "merged_at": "2024-07-02T15:50:00Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/259"
  },
  {
    "number": 257,
    "title": "fix: check against num_tokens instead of num_prompt_tokens for shared blocks",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-01T07:49:22Z",
    "closed_at": "2024-07-01T08:17:37Z",
    "merged_at": "2024-07-01T08:17:37Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/257"
  },
  {
    "number": 256,
    "title": "build: fix multiple definition issue",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-01T07:40:01Z",
    "closed_at": "2024-07-01T07:52:30Z",
    "merged_at": "2024-07-01T07:52:30Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/256"
  },
  {
    "number": 255,
    "title": "dev: added cuda 12.4 build support",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-30T05:48:09Z",
    "closed_at": "2024-06-30T06:11:36Z",
    "merged_at": "2024-06-30T06:11:36Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/255"
  },
  {
    "number": 254,
    "title": "dev: fix issues in run_in_docker script",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-29T04:36:01Z",
    "closed_at": "2024-06-29T04:41:40Z",
    "merged_at": "2024-06-29T04:41:40Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/254"
  },
  {
    "number": 253,
    "title": "alllow deploy docs when triggered on demand",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T23:23:08Z",
    "closed_at": "2024-06-21T23:33:35Z",
    "merged_at": "2024-06-21T23:33:35Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/253"
  },
  {
    "number": 252,
    "title": "fix: pass in secrets for workflow calls.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T20:49:55Z",
    "closed_at": "2024-06-21T21:10:01Z",
    "merged_at": "2024-06-21T21:10:01Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/252"
  },
  {
    "number": 251,
    "title": "fix workflow",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T18:17:22Z",
    "closed_at": "2024-06-21T18:59:11Z",
    "merged_at": "2024-06-21T18:59:11Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/251"
  },
  {
    "number": 250,
    "title": "ci: added release workflow",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T17:59:54Z",
    "closed_at": "2024-06-21T18:06:54Z",
    "merged_at": "2024-06-21T18:06:54Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/250"
  },
  {
    "number": 249,
    "title": "revert torch.cuda.empty_cache change",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T06:32:39Z",
    "closed_at": "2024-06-21T06:47:21Z",
    "merged_at": "2024-06-21T06:47:21Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/249"
  },
  {
    "number": 248,
    "title": "fix multiple devices cuda graph capture issue",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T05:36:47Z",
    "closed_at": "2024-06-21T05:55:47Z",
    "merged_at": "2024-06-21T05:55:47Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/248"
  },
  {
    "number": 247,
    "title": "refactor: only do sampling in driver worker (rank=0)",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T00:15:10Z",
    "closed_at": "2024-06-21T00:18:30Z",
    "merged_at": "2024-06-21T00:18:30Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/247"
  },
  {
    "number": 246,
    "title": "[wip] feat: add embeddings support",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-20T18:15:50Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/246"
  },
  {
    "number": 245,
    "title": "[minor] use available memory to caculate cache_size by default.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-19T10:22:31Z",
    "closed_at": "2024-06-20T02:04:53Z",
    "merged_at": "2024-06-20T02:04:53Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/245"
  },
  {
    "number": 244,
    "title": "feat: added unittests for openai server",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-17T19:14:38Z",
    "closed_at": "2024-06-17T23:31:42Z",
    "merged_at": "2024-06-17T23:31:42Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/244"
  },
  {
    "number": 243,
    "title": "feat: added include_usage into stream options for stream scenarios",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-17T16:46:32Z",
    "closed_at": "2024-06-17T18:20:19Z",
    "merged_at": "2024-06-17T18:20:19Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/243"
  },
  {
    "number": 242,
    "title": "feat: added '__repr__' function for scalellm package",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T06:29:23Z",
    "closed_at": "2024-06-13T06:34:48Z",
    "merged_at": "2024-06-13T06:34:48Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/242"
  },
  {
    "number": 241,
    "title": "feat: added synchronization for batch inference",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T03:49:12Z",
    "closed_at": "2024-06-13T04:09:39Z",
    "merged_at": "2024-06-13T04:09:39Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/241"
  },
  {
    "number": 240,
    "title": "feat: added logprobs support for speculative decoding",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-12T21:28:13Z",
    "closed_at": "2024-06-13T00:00:31Z",
    "merged_at": "2024-06-13T00:00:31Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/240"
  },
  {
    "number": 239,
    "title": "refactor: split pybind11 binding definitions into seperate files",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-12T05:38:45Z",
    "closed_at": "2024-06-12T05:43:00Z",
    "merged_at": "2024-06-12T05:43:00Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/239"
  },
  {
    "number": 238,
    "title": "feat: added id_to_token for tokenizer to handle unfinished byte sequence, ending with \"\"",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-12T01:11:49Z",
    "closed_at": "2024-06-12T04:04:01Z",
    "merged_at": "2024-06-12T04:04:01Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/238"
  },
  {
    "number": 237,
    "title": "feat: added token_ids into sequence output for better debuggability.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-11T21:25:08Z",
    "closed_at": "2024-06-11T22:31:42Z",
    "merged_at": "2024-06-11T22:31:42Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/237"
  },
  {
    "number": 236,
    "title": "feat: added best_of functionality for completion apis",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-09T03:20:33Z",
    "closed_at": "2024-06-11T00:46:34Z",
    "merged_at": "2024-06-11T00:46:34Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/236"
  },
  {
    "number": 235,
    "title": "[wip] feat: added logprobs support for speculative decoding",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-08T21:47:31Z",
    "closed_at": "2024-06-12T21:25:42Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/235"
  },
  {
    "number": 234,
    "title": "feat: added logprobs for grpc server",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-08T21:31:10Z",
    "closed_at": "2024-06-09T00:09:40Z",
    "merged_at": "2024-06-09T00:09:40Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/234"
  },
  {
    "number": 233,
    "title": "feat: added logprobs support for legacy completion api",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-08T18:38:36Z",
    "closed_at": "2024-06-08T20:27:34Z",
    "merged_at": "2024-06-08T20:27:34Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/233"
  },
  {
    "number": 232,
    "title": "feat: added openai compatible logprobs support",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-07T23:09:04Z",
    "closed_at": "2024-06-08T08:18:08Z",
    "merged_at": "2024-06-08T08:18:08Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/232"
  },
  {
    "number": 231,
    "title": "feat: added with statement support to release memory and exposed help function for tokenizer",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-06T23:51:43Z",
    "closed_at": "2024-06-07T00:21:33Z",
    "merged_at": "2024-06-07T00:21:33Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/231"
  },
  {
    "number": 230,
    "title": "fix: load vocab_size first then use it to decide model type for model sharing between llama3, llama2 and Yi.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-06T18:58:18Z",
    "closed_at": "2024-06-06T19:11:32Z",
    "merged_at": "2024-06-06T19:11:32Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/230"
  },
  {
    "number": 229,
    "title": "fix: decode ending tokens one by one to handle unfinished tokens",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-06T07:20:36Z",
    "closed_at": "2024-06-06T07:30:11Z",
    "merged_at": "2024-06-06T07:30:11Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/229"
  },
  {
    "number": 228,
    "title": "fix: avoid tensor convertion for converted ones.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-06T00:20:56Z",
    "closed_at": "2024-06-06T00:31:38Z",
    "merged_at": "2024-06-06T00:31:38Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/228"
  },
  {
    "number": 227,
    "title": "feat: added time_to_first_token and inter_token metrics for both stream and non-stream requests",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-06T00:19:18Z",
    "closed_at": "2024-06-06T00:31:52Z",
    "merged_at": "2024-06-06T00:31:52Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/227"
  },
  {
    "number": 226,
    "title": "fix: use error instead of CHECK when prompt input is empty",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T19:40:28Z",
    "closed_at": "2024-06-05T19:48:06Z",
    "merged_at": "2024-06-05T19:48:06Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/226"
  },
  {
    "number": 225,
    "title": "docs: add livehtml for docs development",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T18:58:41Z",
    "closed_at": "2024-06-05T19:13:59Z",
    "merged_at": "2024-06-05T19:13:59Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/225"
  },
  {
    "number": 224,
    "title": "feat: convert pickle to safetensors for fast loading",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T08:24:42Z",
    "closed_at": "2024-06-05T08:39:23Z",
    "merged_at": "2024-06-05T08:39:23Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/224"
  },
  {
    "number": 223,
    "title": "fix: set correct default value of rope_theta for llama2",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T07:10:41Z",
    "closed_at": "2024-06-05T07:25:35Z",
    "merged_at": "2024-06-05T07:25:35Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/223"
  },
  {
    "number": 219,
    "title": "added missing changes for carrying over prompt",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T02:55:54Z",
    "closed_at": "2024-06-05T03:12:25Z",
    "merged_at": "2024-06-05T03:12:25Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/219"
  },
  {
    "number": 218,
    "title": "feat: carry over prompt to output for feature parity",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T00:53:54Z",
    "closed_at": "2024-06-05T02:34:41Z",
    "merged_at": "2024-06-05T02:34:41Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/218"
  },
  {
    "number": 217,
    "title": "refactor: move setup.py to top level",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T00:13:04Z",
    "closed_at": "2024-06-05T00:37:09Z",
    "merged_at": "2024-06-05T00:37:09Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/217"
  },
  {
    "number": 216,
    "title": "[feat] add prompt in RequestOutput.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-04T11:08:50Z",
    "closed_at": "2024-06-05T02:04:04Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/216"
  },
  {
    "number": 214,
    "title": "fix: use a consistent version for whl",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-03T21:49:48Z",
    "closed_at": "2024-06-03T21:59:05Z",
    "merged_at": "2024-06-03T21:59:05Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/214"
  },
  {
    "number": 213,
    "title": "fix: fix weight load issue for fused qkv and added more unittests for weight loading",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-03T19:03:19Z",
    "closed_at": "2024-06-03T19:07:23Z",
    "merged_at": "2024-06-03T19:07:23Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/213"
  },
  {
    "number": 211,
    "title": "feat: added token related latency metrics",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-31T06:51:21Z",
    "closed_at": "2024-05-31T08:02:13Z",
    "merged_at": "2024-05-31T08:02:13Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/211"
  },
  {
    "number": 210,
    "title": "feat: Added prometheus metrics",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-30T05:52:25Z",
    "closed_at": "2024-05-30T23:47:45Z",
    "merged_at": "2024-05-30T23:47:45Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/210"
  },
  {
    "number": 209,
    "title": "feat: added monitoring docker compose for prometheus and grafana",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-29T22:35:24Z",
    "closed_at": "2024-05-29T22:51:36Z",
    "merged_at": "2024-05-29T22:51:36Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/209"
  },
  {
    "number": 208,
    "title": "docs: fixed source directory and added announcement",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-25T05:57:15Z",
    "closed_at": "2024-05-25T05:59:26Z",
    "merged_at": "2024-05-25T05:59:26Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/208"
  },
  {
    "number": 207,
    "title": "docs: added docs skeleton",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-25T00:52:43Z",
    "closed_at": "2024-05-25T00:54:49Z",
    "merged_at": "2024-05-25T00:54:49Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/207"
  },
  {
    "number": 206,
    "title": "ci: added workflow to publish docs to GitHub Pages",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T17:03:48Z",
    "closed_at": "2024-05-24T17:11:35Z",
    "merged_at": "2024-05-24T17:11:35Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/206"
  },
  {
    "number": 205,
    "title": "ci: publish wheels to whl index repo",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-23T18:56:47Z",
    "closed_at": "2024-05-23T19:18:34Z",
    "merged_at": "2024-05-23T19:18:34Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/205"
  },
  {
    "number": 204,
    "title": "feat: added batch support for llm handler",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-22T16:33:30Z",
    "closed_at": "2024-05-22T16:36:25Z",
    "merged_at": "2024-05-22T16:36:25Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/204"
  },
  {
    "number": 203,
    "title": "[wip] feat: added benchmarks for scalellm package",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-22T05:51:26Z",
    "closed_at": "2024-06-13T21:30:40Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/203"
  },
  {
    "number": 202,
    "title": "fix: use a proper epsilon to avoid division by zero error for rejection sampler",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-22T05:46:26Z",
    "closed_at": "2024-05-22T05:49:17Z",
    "merged_at": "2024-05-22T05:49:17Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/202"
  },
  {
    "number": 201,
    "title": "feat: added multiple threads support for LLMHandler",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-22T04:22:40Z",
    "closed_at": "2024-05-22T04:32:08Z",
    "merged_at": "2024-05-22T04:32:08Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/201"
  },
  {
    "number": 200,
    "title": "feat: moved scheduler wait logic from python into scheduler run_until_complete function",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-21T20:04:43Z",
    "closed_at": "2024-05-21T20:35:03Z",
    "merged_at": "2024-05-21T20:35:03Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/200"
  },
  {
    "number": 199,
    "title": "[python] added more examples and fix requirments version",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T22:44:33Z",
    "closed_at": "2024-05-20T22:53:34Z",
    "merged_at": "2024-05-20T22:53:34Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/199"
  },
  {
    "number": 198,
    "title": "ci: bump version and build with new manylinux image (gcc-9)",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T19:29:13Z",
    "closed_at": "2024-05-20T20:57:06Z",
    "merged_at": "2024-05-20T20:57:06Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/198"
  },
  {
    "number": 197,
    "title": "fix: make build pass with gcc-9",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T17:46:14Z",
    "closed_at": "2024-05-20T18:22:26Z",
    "merged_at": "2024-05-20T18:22:26Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/197"
  },
  {
    "number": 196,
    "title": "[CI] fix docker run options",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-19T17:13:52Z",
    "closed_at": "2024-05-19T18:15:45Z",
    "merged_at": "2024-05-19T18:15:45Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/196"
  },
  {
    "number": 195,
    "title": "[fix] fix workflow format",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T21:51:57Z",
    "closed_at": "2024-05-19T04:10:56Z",
    "merged_at": "2024-05-19T04:10:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/195"
  },
  {
    "number": 194,
    "title": "[feat] added cuda 11.8 devel image to build cpp release image",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T20:28:47Z",
    "closed_at": "2024-05-17T21:50:09Z",
    "merged_at": "2024-05-17T21:50:09Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/194"
  },
  {
    "number": 193,
    "title": "[Release] added workflow to publish whls to PyPI",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T08:11:00Z",
    "closed_at": "2024-05-17T08:13:38Z",
    "merged_at": "2024-05-17T08:13:38Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/193"
  },
  {
    "number": 192,
    "title": "[Release] prepare 0.1.0 release",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T07:07:34Z",
    "closed_at": "2024-05-17T07:28:29Z",
    "merged_at": "2024-05-17T07:28:29Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/192"
  },
  {
    "number": 191,
    "title": "[python] added requirements into package",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T03:27:12Z",
    "closed_at": "2024-05-17T03:29:18Z",
    "merged_at": "2024-05-17T03:29:18Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/191"
  },
  {
    "number": 190,
    "title": "[python] added LLM for offline inference and stream examples for chat and complete",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-16T18:41:34Z",
    "closed_at": "2024-05-16T20:03:22Z",
    "merged_at": "2024-05-16T20:03:22Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/190"
  },
  {
    "number": 189,
    "title": "[fix] fix extension typo for wheel publish workflow",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-15T00:55:41Z",
    "closed_at": "2024-05-15T01:19:25Z",
    "merged_at": "2024-05-15T01:19:25Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/189"
  },
  {
    "number": 188,
    "title": "[CI] Upload wheels to release as asserts",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-14T23:01:54Z",
    "closed_at": "2024-05-15T00:04:50Z",
    "merged_at": "2024-05-15T00:04:50Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/188"
  },
  {
    "number": 187,
    "title": "[feat] added version suffix to include cuda and torch version",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-14T22:43:26Z",
    "closed_at": "2024-05-14T22:44:31Z",
    "merged_at": "2024-05-14T22:44:31Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/187"
  },
  {
    "number": 186,
    "title": "[fix] added cuda 11.8 support for manylinux",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-14T20:41:34Z",
    "closed_at": "2024-05-14T21:45:35Z",
    "merged_at": "2024-05-14T21:45:35Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/186"
  },
  {
    "number": 185,
    "title": "[fix] added manylinux support",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-14T05:04:32Z",
    "closed_at": "2024-05-14T19:40:04Z",
    "merged_at": "2024-05-14T19:40:04Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/185"
  },
  {
    "number": 184,
    "title": "[CI] fix docker image issues and build wheel for different python, pytorch versions",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-13T21:08:23Z",
    "closed_at": "2024-05-14T04:42:20Z",
    "merged_at": "2024-05-14T04:42:20Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/184"
  },
  {
    "number": 183,
    "title": "[ci] build python wheels",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-13T17:11:25Z",
    "closed_at": "2024-05-13T19:48:41Z",
    "merged_at": "2024-05-13T19:48:41Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/183"
  },
  {
    "number": 182,
    "title": "[CI] added base docker image for python wheel build",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-12T08:30:36Z",
    "closed_at": "2024-05-13T16:58:11Z",
    "merged_at": "2024-05-13T16:58:11Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/182"
  },
  {
    "number": 181,
    "title": "[kernle] change head_dim list to reduce binary size",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-11T07:12:51Z",
    "closed_at": "2024-05-11T07:45:18Z",
    "merged_at": "2024-05-11T07:45:18Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/181"
  },
  {
    "number": 180,
    "title": "[misc] some changes to cmake file",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-11T05:13:12Z",
    "closed_at": "2024-05-11T07:05:26Z",
    "merged_at": "2024-05-11T07:05:26Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/180"
  },
  {
    "number": 179,
    "title": "[python] reduce whl size",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-10T17:21:12Z",
    "closed_at": "2024-05-11T05:13:25Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/179"
  },
  {
    "number": 178,
    "title": "[model] support vision language model llava.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-10T10:58:23Z",
    "closed_at": "2024-06-28T08:37:35Z",
    "merged_at": "2024-06-28T08:37:35Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/178"
  },
  {
    "number": 177,
    "title": "[feat] added status handling for grpc server",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-09T20:50:53Z",
    "closed_at": "2024-05-09T21:21:56Z",
    "merged_at": "2024-05-09T21:21:56Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/177"
  },
  {
    "number": 176,
    "title": "[python] added model check for rest api",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-09T19:18:03Z",
    "closed_at": "2024-05-09T19:19:27Z",
    "merged_at": "2024-05-09T19:19:27Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/176"
  },
  {
    "number": 175,
    "title": "[python] move request handling logic into seperate file from api server",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-09T02:01:17Z",
    "closed_at": "2024-05-09T06:14:47Z",
    "merged_at": "2024-05-09T06:14:47Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/175"
  },
  {
    "number": 174,
    "title": "[refactor] consolidate handlers to share llm_handler between python rest api server and grpc server",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-07T23:08:55Z",
    "closed_at": "2024-05-09T01:12:00Z",
    "merged_at": "2024-05-09T01:12:00Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/174"
  },
  {
    "number": 173,
    "title": "[refactor] move proto definitions into proto namespace",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-06T22:28:36Z",
    "closed_at": "2024-05-06T22:36:01Z",
    "merged_at": "2024-05-06T22:36:01Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/173"
  },
  {
    "number": 172,
    "title": "[feat] implement async llm engine for python wrapper",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-05T07:32:10Z",
    "closed_at": "2024-05-07T22:07:02Z",
    "merged_at": "2024-05-07T22:07:02Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/172"
  },
  {
    "number": 171,
    "title": "[feat] added python LLMEngine skeleton",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-02T22:51:26Z",
    "closed_at": "2024-05-05T04:54:04Z",
    "merged_at": "2024-05-05T04:54:03Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/171"
  },
  {
    "number": 170,
    "title": "[refactor] combine sequence and request outputs",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-01T22:57:24Z",
    "closed_at": "2024-05-02T20:01:58Z",
    "merged_at": "2024-05-02T20:01:58Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/170"
  },
  {
    "number": 169,
    "title": "[feat] added python rest api server skeleton",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-01T16:49:44Z",
    "closed_at": "2024-05-01T19:08:11Z",
    "merged_at": "2024-05-01T19:08:11Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/169"
  },
  {
    "number": 168,
    "title": "[misc] upgrade torch to 2.3 and use gcc-12",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-30T03:59:13Z",
    "closed_at": "2024-04-30T05:23:42Z",
    "merged_at": "2024-04-30T05:23:42Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/168"
  },
  {
    "number": 167,
    "title": "[fix] use the pybind11 from libtorch and fix model download issue.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-29T07:14:05Z",
    "closed_at": "2024-04-29T07:20:16Z",
    "merged_at": "2024-04-29T07:20:16Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/167"
  },
  {
    "number": 145,
    "title": "[feat] enable speculative decoding and update readme",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-28T03:34:53Z",
    "closed_at": "2024-04-28T03:46:46Z",
    "merged_at": "2024-04-28T03:46:46Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/145"
  },
  {
    "number": 143,
    "title": "[feat] added support for kv_cache with different strides.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T23:23:57Z",
    "closed_at": "2024-04-26T23:32:24Z",
    "merged_at": "2024-04-26T23:32:24Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/143"
  },
  {
    "number": 142,
    "title": "[unittest] added more unittests for pos_embedding, sampler and rejection_sampler.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T17:37:01Z",
    "closed_at": "2024-04-26T17:39:36Z",
    "merged_at": "2024-04-26T17:39:36Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/142"
  },
  {
    "number": 141,
    "title": "[unittest] added more unittests for speculative decoding",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-23T17:46:10Z",
    "closed_at": "2024-04-23T18:52:55Z",
    "merged_at": "2024-04-23T18:52:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/141"
  },
  {
    "number": 140,
    "title": "[refactor] refactoring for sequence",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-22T22:32:24Z",
    "closed_at": "2024-04-22T23:40:34Z",
    "merged_at": "2024-04-22T23:40:34Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/140"
  },
  {
    "number": 139,
    "title": "[kernel] added half2 specialization for layernorm kernel",
    "user": "dongxianzhe",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-22T06:14:10Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/139"
  },
  {
    "number": 138,
    "title": "[op] layernorm kernel",
    "user": "dongxianzhe",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-22T05:42:01Z",
    "closed_at": "2024-04-22T05:57:57Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/138"
  },
  {
    "number": 137,
    "title": "[feat] support tensor parallelism for MQA/GQA models when num_kv_heads < world_size",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-20T18:38:43Z",
    "closed_at": "2024-04-20T19:37:44Z",
    "merged_at": "2024-04-20T19:37:44Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/137"
  },
  {
    "number": 136,
    "title": "[op] layernorm kernel",
    "user": "dongxianzhe",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-20T05:26:46Z",
    "closed_at": "2024-04-22T05:40:59Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/136"
  },
  {
    "number": 135,
    "title": "[refactor] change tokenizer special tokens from token to token + id.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-19T23:56:01Z",
    "closed_at": "2024-04-20T00:20:04Z",
    "merged_at": "2024-04-20T00:20:04Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/135"
  },
  {
    "number": 134,
    "title": "[refactor] add implicit conversion between slice and vector",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-19T21:58:16Z",
    "closed_at": "2024-04-19T22:21:40Z",
    "merged_at": "2024-04-19T22:21:40Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/134"
  },
  {
    "number": 133,
    "title": "[build] build with half cores to use less memory",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-19T07:07:43Z",
    "closed_at": "2024-04-19T15:44:12Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/133"
  },
  {
    "number": 132,
    "title": "[feat] optimize batch size for cuda graph",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-19T03:37:48Z",
    "closed_at": "2024-04-19T03:45:55Z",
    "merged_at": "2024-04-19T03:45:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/132"
  },
  {
    "number": 130,
    "title": "[bugfix] fix cuda graph capture issue for tensor parallelism",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-18T10:08:00Z",
    "closed_at": "2024-04-18T21:43:56Z",
    "merged_at": "2024-04-18T21:43:56Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/130"
  },
  {
    "number": 129,
    "title": "[feat] enable cuda graph for decoding",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-17T00:09:34Z",
    "closed_at": "2024-04-17T23:33:15Z",
    "merged_at": "2024-04-17T23:33:15Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/129"
  },
  {
    "number": 128,
    "title": "[model] add support for mixtral moe model ",
    "user": "936187425",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-16T02:57:13Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/128"
  },
  {
    "number": 127,
    "title": "[refactor] added options for LLMEngine, SpeculativeEngine and Scheduler.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-15T23:34:20Z",
    "closed_at": "2024-04-15T23:43:04Z",
    "merged_at": "2024-04-15T23:43:04Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/127"
  },
  {
    "number": 126,
    "title": "[fix] fix data accuracy issue for gemma",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-15T21:07:15Z",
    "closed_at": "2024-04-15T21:31:00Z",
    "merged_at": "2024-04-15T21:31:00Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/126"
  },
  {
    "number": 125,
    "title": "[feat] added rms norm residual kernel",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-15T17:58:54Z",
    "closed_at": "2024-04-15T21:02:21Z",
    "merged_at": "2024-04-15T21:02:21Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/125"
  },
  {
    "number": 124,
    "title": "benchmark test script",
    "user": "ShijiaTang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-13T13:56:03Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/124"
  },
  {
    "number": 123,
    "title": "Op/layernorm kernel",
    "user": "dongxianzhe",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-13T13:18:53Z",
    "closed_at": "2024-04-22T06:05:02Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/123"
  },
  {
    "number": 122,
    "title": "Op/layernorm kernel",
    "user": "dongxianzhe",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-13T12:51:11Z",
    "closed_at": "2024-04-13T12:52:37Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/122"
  },
  {
    "number": 120,
    "title": "[feat] added skip_special_tokens support for tokenizers",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-06T03:18:53Z",
    "closed_at": "2024-04-06T03:48:32Z",
    "merged_at": "2024-04-06T03:48:32Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/120"
  },
  {
    "number": 119,
    "title": "[fix] put finish reason into a separate response",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-06T02:20:34Z",
    "closed_at": "2024-04-06T02:32:39Z",
    "merged_at": "2024-04-06T02:32:39Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/119"
  },
  {
    "number": 118,
    "title": "[feat] cancel request if rpc is not ok",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-05T07:46:46Z",
    "closed_at": "2024-04-05T07:52:32Z",
    "merged_at": "2024-04-05T07:52:32Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/118"
  },
  {
    "number": 117,
    "title": "[feat] enable speculative decoding for scalellm.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-05T05:27:05Z",
    "closed_at": "2024-04-05T05:37:58Z",
    "merged_at": "2024-04-05T05:37:58Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/117"
  },
  {
    "number": 116,
    "title": "[feat] added stream support for n > 1 scenarios",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-04T08:06:10Z",
    "closed_at": "2024-04-04T08:09:55Z",
    "merged_at": "2024-04-04T08:09:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/116"
  },
  {
    "number": 115,
    "title": "[feat] added sampling support for multiple query decoding",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-04T03:14:48Z",
    "closed_at": "2024-04-04T04:24:21Z",
    "merged_at": "2024-04-04T04:24:21Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/115"
  },
  {
    "number": 114,
    "title": "[feat] mask out rejected tokens with -1 in Rejection Sampler",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-03T06:06:45Z",
    "closed_at": "2024-04-03T06:12:04Z",
    "merged_at": "2024-04-03T06:12:04Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/114"
  },
  {
    "number": 113,
    "title": "[feat] enable speculative decoding for simple server",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-01T18:14:19Z",
    "closed_at": "2024-04-02T05:31:20Z",
    "merged_at": "2024-04-02T05:31:20Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/113"
  },
  {
    "number": 112,
    "title": "[feat] added rejection sampler for speculative decoding.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-30T06:27:34Z",
    "closed_at": "2024-03-30T19:21:24Z",
    "merged_at": "2024-03-30T19:21:24Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/112"
  },
  {
    "number": 111,
    "title": "added half2 for reduce_kernel_utils",
    "user": "dongxianzhe",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-30T02:04:11Z",
    "closed_at": "2024-04-15T14:40:24Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/111"
  },
  {
    "number": 110,
    "title": "[op] added support for half2 reduce_kernel_utils",
    "user": "dongxianzhe",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-29T11:17:30Z",
    "closed_at": "2024-03-30T01:57:19Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/110"
  },
  {
    "number": 109,
    "title": "[feat] Added selected tokens to return logits from model execution.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-29T07:21:37Z",
    "closed_at": "2024-03-29T07:58:18Z",
    "merged_at": "2024-03-29T07:58:18Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/109"
  },
  {
    "number": 108,
    "title": "[op] optimize layernorm kernels",
    "user": "dongxianzhe",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-28T13:45:55Z",
    "closed_at": "2024-03-29T11:04:29Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/108"
  },
  {
    "number": 107,
    "title": "[feat] added prompt blocks sharing across n sequences",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T23:33:09Z",
    "closed_at": "2024-03-28T04:48:49Z",
    "merged_at": "2024-03-28T04:48:49Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/107"
  },
  {
    "number": 106,
    "title": "[fix] only run git-clang-format agains c/c++ files",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T20:19:52Z",
    "closed_at": "2024-03-27T20:27:38Z",
    "merged_at": "2024-03-27T20:27:38Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/106"
  },
  {
    "number": 105,
    "title": "[workflow] added clang-format workflow",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T17:24:39Z",
    "closed_at": "2024-03-27T19:58:40Z",
    "merged_at": "2024-03-27T19:58:40Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/105"
  },
  {
    "number": 104,
    "title": "[workflow] added clang-format for pull_requests",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T16:35:43Z",
    "closed_at": "2024-03-27T17:21:46Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/104"
  },
  {
    "number": 103,
    "title": "[model] added support for google Gemma-2b model",
    "user": "936187425",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T06:21:25Z",
    "closed_at": "2024-04-15T07:21:10Z",
    "merged_at": "2024-04-15T07:21:10Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/103"
  },
  {
    "number": 102,
    "title": "[refactor] moved top_k and top_p from sampler to logits process.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T05:54:58Z",
    "closed_at": "2024-03-27T05:59:01Z",
    "merged_at": "2024-03-27T05:59:01Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/102"
  },
  {
    "number": 101,
    "title": "[feat] added speculative engine class without implementation.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-25T23:42:50Z",
    "closed_at": "2024-03-25T23:50:38Z",
    "merged_at": "2024-03-25T23:50:37Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/101"
  },
  {
    "number": 100,
    "title": "[feat] added engine type to allow LLM and SSM share sequence.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-25T18:39:05Z",
    "closed_at": "2024-03-25T19:30:00Z",
    "merged_at": "2024-03-25T19:30:00Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/100"
  },
  {
    "number": 99,
    "title": "[refactor] move model output process logic into batch",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-24T05:04:07Z",
    "closed_at": "2024-03-24T05:51:14Z",
    "merged_at": "2024-03-24T05:51:13Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/99"
  },
  {
    "number": 98,
    "title": "[feat] added dynamic split-fuse support in continuous scheduler",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-23T23:40:48Z",
    "closed_at": "2024-03-24T02:03:36Z",
    "merged_at": "2024-03-24T02:03:36Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/98"
  },
  {
    "number": 97,
    "title": "added layernorm benchmark",
    "user": "dongxianzhe",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-23T13:53:21Z",
    "closed_at": "2024-03-23T16:54:20Z",
    "merged_at": "2024-03-23T16:54:20Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/97"
  },
  {
    "number": 96,
    "title": "[fix] adjust kv_cache_pos to give at least one token to generate logits",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-22T21:40:25Z",
    "closed_at": "2024-03-22T22:23:03Z",
    "merged_at": "2024-03-22T22:23:03Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/96"
  },
  {
    "number": 95,
    "title": "[fix] added small page size support for flash attention.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-22T16:59:28Z",
    "closed_at": "2024-03-22T18:10:55Z",
    "merged_at": "2024-03-22T18:10:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/95"
  },
  {
    "number": 94,
    "title": "[feat] return prompt string directly in echo mode to avoid decode cost and avoid showing appended prefix tokens.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-22T16:17:28Z",
    "closed_at": "2024-03-22T17:03:28Z",
    "merged_at": "2024-03-22T17:03:28Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/94"
  },
  {
    "number": 93,
    "title": "[feat] add max tokens to process to support dynamic split-fuse",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T21:54:33Z",
    "closed_at": "2024-03-22T00:15:07Z",
    "merged_at": "2024-03-22T00:15:07Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/93"
  },
  {
    "number": 92,
    "title": "[fix] replace submodules git path with https path to avoid permission issue.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T17:45:00Z",
    "closed_at": "2024-03-21T17:48:12Z",
    "merged_at": "2024-03-21T17:48:12Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/92"
  },
  {
    "number": 91,
    "title": "[fix] use https instead of git to avoid permission issue.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T17:32:02Z",
    "closed_at": "2024-03-21T17:39:41Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/91"
  },
  {
    "number": 90,
    "title": "[refactor] move batch related logic into a class",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T00:13:35Z",
    "closed_at": "2024-03-21T00:50:13Z",
    "merged_at": "2024-03-21T00:50:13Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/90"
  },
  {
    "number": 89,
    "title": "[feat] added LRU policy into prefix cache.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-19T22:49:34Z",
    "closed_at": "2024-03-20T05:37:45Z",
    "merged_at": "2024-03-20T05:37:45Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/89"
  },
  {
    "number": 88,
    "title": "[refactor] avoid name conflict with torch::indexing::Slice",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-19T21:01:20Z",
    "closed_at": "2024-03-19T21:02:44Z",
    "merged_at": "2024-03-19T21:02:44Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/88"
  },
  {
    "number": 87,
    "title": "[feat] enable prefix cache in block manager",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-19T18:29:09Z",
    "closed_at": "2024-03-19T22:02:16Z",
    "merged_at": "2024-03-19T22:02:16Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/87"
  },
  {
    "number": 86,
    "title": "[feat] added prefix cache to share kv cache across sequences.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-18T05:29:13Z",
    "closed_at": "2024-03-19T06:21:13Z",
    "merged_at": "2024-03-19T06:21:13Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/86"
  },
  {
    "number": 85,
    "title": "[feat] add block id lifecycle management for block sharing scenarios.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-18T00:25:08Z",
    "closed_at": "2024-03-18T02:20:20Z",
    "merged_at": "2024-03-18T02:20:20Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/85"
  },
  {
    "number": 82,
    "title": "[models] fix chatglm model issue. ",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-13T05:28:22Z",
    "closed_at": "2024-03-13T06:08:25Z",
    "merged_at": "2024-03-13T06:08:25Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/82"
  },
  {
    "number": 81,
    "title": "[models] support both baichuan and baichuan2",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-13T00:00:51Z",
    "closed_at": "2024-03-13T01:30:10Z",
    "merged_at": "2024-03-13T01:30:10Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/81"
  },
  {
    "number": 80,
    "title": "[refactor] split model forward function into two: 1> get hidden states 2> get logits from hidden states",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-12T20:30:47Z",
    "closed_at": "2024-03-12T20:39:50Z",
    "merged_at": "2024-03-12T20:39:50Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/80"
  },
  {
    "number": 79,
    "title": "[feat] add support for cudagraph and its unit test.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-12T13:52:20Z",
    "closed_at": "2024-03-16T20:06:50Z",
    "merged_at": "2024-03-16T20:06:50Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/79"
  },
  {
    "number": 78,
    "title": "[refactor] move cutlass and flashinfer into third_party folder",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-12T04:01:17Z",
    "closed_at": "2024-03-12T04:16:05Z",
    "merged_at": "2024-03-12T04:16:05Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/78"
  },
  {
    "number": 77,
    "title": "[refactor] replace dtype and device with options since they are used together usually",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-11T22:49:25Z",
    "closed_at": "2024-03-11T23:01:15Z",
    "merged_at": "2024-03-11T23:01:15Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/77"
  },
  {
    "number": 76,
    "title": "[feat] moved rope logic into attention handler to support apply positional embeding on the fly",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-11T20:45:57Z",
    "closed_at": "2024-03-11T21:06:52Z",
    "merged_at": "2024-03-11T21:06:52Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/76"
  },
  {
    "number": 74,
    "title": "[minor] cleanup redundant code for models.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-11T08:35:22Z",
    "closed_at": "2024-03-11T08:48:20Z",
    "merged_at": "2024-03-11T08:48:20Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/74"
  },
  {
    "number": 73,
    "title": "[perf] use a seperate cuda stream for kv cache",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-11T04:49:56Z",
    "closed_at": "2024-03-11T05:21:11Z",
    "merged_at": "2024-03-11T05:21:11Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/73"
  },
  {
    "number": 72,
    "title": "[perf] enabled speed up for gpa and mqa decoding.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-10T22:36:53Z",
    "closed_at": "2024-03-10T22:40:54Z",
    "merged_at": "2024-03-10T22:40:54Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/72"
  },
  {
    "number": 71,
    "title": "[feat] added attention handler for different implementations",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-08T00:39:01Z",
    "closed_at": "2024-03-10T02:00:32Z",
    "merged_at": "2024-03-10T02:00:32Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/71"
  },
  {
    "number": 70,
    "title": "[models] added baichuan/baichuan2 model support.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-07T14:25:34Z",
    "closed_at": "2024-03-11T07:57:29Z",
    "merged_at": "2024-03-11T07:57:29Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/70"
  },
  {
    "number": 68,
    "title": "more changes to support python wrapper",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-07T07:53:44Z",
    "closed_at": "2024-03-07T10:00:28Z",
    "merged_at": "2024-03-07T10:00:28Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/68"
  },
  {
    "number": 67,
    "title": "merge huggingface tokenizers and safetensors rust projects into one.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-07T04:00:44Z",
    "closed_at": "2024-03-07T04:05:58Z",
    "merged_at": "2024-03-07T04:05:58Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/67"
  },
  {
    "number": 66,
    "title": "added support to build python wrapper with installed pytorch ( pre-cxx11 abi)",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-06T10:11:25Z",
    "closed_at": "2024-03-06T18:09:12Z",
    "merged_at": "2024-03-06T18:09:12Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/66"
  },
  {
    "number": 65,
    "title": "moved attention related files into attention subfolder",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T21:11:32Z",
    "closed_at": "2024-03-04T22:04:16Z",
    "merged_at": "2024-03-04T22:04:16Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/65"
  },
  {
    "number": 64,
    "title": "add pybind11 to support python user interface.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T13:08:17Z",
    "closed_at": "2024-03-05T16:00:12Z",
    "merged_at": "2024-03-05T16:00:12Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/64"
  },
  {
    "number": 63,
    "title": "added gpu memory profiling to decided kv cache size precisely.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-02T00:49:48Z",
    "closed_at": "2024-03-02T00:56:29Z",
    "merged_at": "2024-03-02T00:56:29Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/63"
  },
  {
    "number": 62,
    "title": "add custom command to generate instantiation for flash-attn",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-01T19:56:13Z",
    "closed_at": "2024-03-01T20:24:58Z",
    "merged_at": "2024-03-01T20:24:57Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/62"
  },
  {
    "number": 61,
    "title": "added a custom command to generate instantiation for flashinfer",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-01T06:40:41Z",
    "closed_at": "2024-03-01T07:19:34Z",
    "merged_at": "2024-03-01T07:19:34Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/61"
  },
  {
    "number": 60,
    "title": "benchmark test",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-01T03:37:50Z",
    "closed_at": "2024-03-30T01:58:18Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/60"
  },
  {
    "number": 59,
    "title": "enable split-k for flash decoding and fix bugs.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-29T06:23:59Z",
    "closed_at": "2024-02-29T06:29:39Z",
    "merged_at": "2024-02-29T06:29:39Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/59"
  },
  {
    "number": 58,
    "title": "[test] benchmark test",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-29T00:51:10Z",
    "closed_at": "2024-03-01T03:36:54Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/58"
  },
  {
    "number": 57,
    "title": "[ut] add unit tests for speculative scheduler.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-28T09:08:17Z",
    "closed_at": "2024-02-29T10:11:05Z",
    "merged_at": "2024-02-29T10:11:05Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/57"
  },
  {
    "number": 56,
    "title": "[WIP] fused kernel to append k/v into cache",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-27T21:31:43Z",
    "closed_at": "2024-03-04T21:16:38Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/56"
  },
  {
    "number": 55,
    "title": "[ut] add unit tests for speculative scheduler.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-27T13:07:06Z",
    "closed_at": "2024-02-28T09:08:06Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/55"
  },
  {
    "number": 54,
    "title": "enable flash decoding for both prefill and decode phase.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-27T05:26:36Z",
    "closed_at": "2024-02-28T05:00:41Z",
    "merged_at": "2024-02-28T05:00:41Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/54"
  },
  {
    "number": 53,
    "title": "added support for small page size.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-27T04:45:33Z",
    "closed_at": "2024-02-27T04:46:56Z",
    "merged_at": "2024-02-27T04:46:56Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/53"
  },
  {
    "number": 52,
    "title": "added a new attention kernel for speculative decoding",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-26T22:22:26Z",
    "closed_at": "2024-02-26T22:33:59Z",
    "merged_at": "2024-02-26T22:33:59Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/52"
  },
  {
    "number": 51,
    "title": "added a new attention kernel for speculative decoding",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-24T21:40:44Z",
    "closed_at": "2024-02-26T07:33:13Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/51"
  },
  {
    "number": 50,
    "title": "[feat] add speculative decoding.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-19T14:51:40Z",
    "closed_at": "2024-02-22T04:03:52Z",
    "merged_at": "2024-02-22T04:03:51Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/50"
  },
  {
    "number": 47,
    "title": "upgrade paged_atten kernel to v0.2.7",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-30T11:48:05Z",
    "closed_at": "2024-01-30T12:13:32Z",
    "merged_at": "2024-01-30T12:13:32Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/47"
  },
  {
    "number": 46,
    "title": "encapsulate class of time for performance tracking.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-30T04:13:42Z",
    "closed_at": "2024-01-30T04:56:34Z",
    "merged_at": "2024-01-30T04:56:34Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/46"
  },
  {
    "number": 45,
    "title": "pick up new changes",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-09T15:23:55Z",
    "closed_at": "2024-01-09T15:24:22Z",
    "merged_at": "2024-01-09T15:24:22Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/45"
  },
  {
    "number": 44,
    "title": "replace GITHUB_SHA with ${{ github.sha }}",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-06T00:49:26Z",
    "closed_at": "2024-01-06T00:52:23Z",
    "merged_at": "2024-01-06T00:52:23Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/44"
  },
  {
    "number": 43,
    "title": "use ${GITHUB_SHA} in cache key",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-05T15:47:45Z",
    "closed_at": "2024-01-05T19:50:08Z",
    "merged_at": "2024-01-05T19:50:08Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/43"
  },
  {
    "number": 42,
    "title": "add timestamp into ccache cache key",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-05T15:32:02Z",
    "closed_at": "2024-01-05T15:40:53Z",
    "merged_at": "2024-01-05T15:40:53Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/42"
  },
  {
    "number": 36,
    "title": "[refactor] rename Executor to ThreadPool.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-21T10:07:34Z",
    "closed_at": "2023-12-22T03:09:30Z",
    "merged_at": "2023-12-22T03:09:30Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/36"
  },
  {
    "number": 35,
    "title": "[docs] add devel image in CONTRIBUTING.md.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-21T08:57:57Z",
    "closed_at": "2023-12-22T03:08:26Z",
    "merged_at": "2023-12-22T03:08:26Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/35"
  },
  {
    "number": 33,
    "title": "[docs] add speculative decoding design docs.",
    "user": "liutongxuan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-19T11:09:22Z",
    "closed_at": "2023-12-19T11:14:04Z",
    "merged_at": "2023-12-19T11:14:04Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/33"
  },
  {
    "number": 18,
    "title": "sync from main",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-09T06:36:37Z",
    "closed_at": "2023-11-09T06:36:55Z",
    "merged_at": "2023-11-09T06:36:55Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/18"
  },
  {
    "number": 15,
    "title": "fixed top_k tensor type and added unittests.",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-08T01:23:34Z",
    "closed_at": "2023-11-08T01:24:21Z",
    "merged_at": "2023-11-08T01:24:21Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/15"
  },
  {
    "number": 14,
    "title": "load dtype from config",
    "user": "guocuimi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-07T19:24:57Z",
    "closed_at": "2023-11-07T19:34:56Z",
    "merged_at": "2023-11-07T19:34:56Z",
    "state": "closed",
    "html_url": "https://github.com/vectorch-ai/ScaleLLM/pull/14"
  }
]