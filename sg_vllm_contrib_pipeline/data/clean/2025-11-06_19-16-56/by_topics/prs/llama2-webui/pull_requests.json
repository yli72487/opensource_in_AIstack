[
  {
    "number": 87,
    "title": "Supports accepting network requests, listening on specific ports and running GPTQ models on multiple GPUs",
    "user": "Arondight",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-22T09:50:23Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/87"
  },
  {
    "number": 86,
    "title": "Update README.md",
    "user": "RISHIKREDDYL",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-05T18:05:09Z",
    "closed_at": "2024-02-14T07:50:36Z",
    "merged_at": "2024-02-14T07:50:36Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/86"
  },
  {
    "number": 78,
    "title": "multi gpu, llama2-70b",
    "user": "fo40225",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-27T00:31:11Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/78"
  },
  {
    "number": 76,
    "title": "[FEATURE] added prompts templates.",
    "user": "BobCN2017",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-31T08:42:07Z",
    "closed_at": "2023-11-08T06:11:40Z",
    "merged_at": "2023-11-08T06:11:40Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/76"
  },
  {
    "number": 73,
    "title": "[FEATURE] add support for GGUF models",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-03T23:38:53Z",
    "closed_at": "2023-10-04T05:31:10Z",
    "merged_at": "2023-10-04T05:31:10Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/73"
  },
  {
    "number": 65,
    "title": "[DOCUMENT] update readme",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-02T06:52:27Z",
    "closed_at": "2023-09-02T06:52:34Z",
    "merged_at": "2023-09-02T06:52:34Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/65"
  },
  {
    "number": 64,
    "title": "[DOCUMENT] update readme",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-02T06:44:14Z",
    "closed_at": "2023-09-02T06:45:59Z",
    "merged_at": "2023-09-02T06:45:59Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/64"
  },
  {
    "number": 63,
    "title": "[FEATURE] Add code llama, add code completion ",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-01T03:11:19Z",
    "closed_at": "2023-09-01T03:13:44Z",
    "merged_at": "2023-09-01T03:13:44Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/63"
  },
  {
    "number": 61,
    "title": "[FEATURE] Add model downloading script",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-26T06:58:54Z",
    "closed_at": "2023-08-26T07:00:43Z",
    "merged_at": "2023-08-26T07:00:43Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/61"
  },
  {
    "number": 60,
    "title": "[FEATURE] update app.py with args, test codellama",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-26T06:19:20Z",
    "closed_at": "2023-08-26T06:22:22Z",
    "merged_at": "2023-08-26T06:22:22Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/60"
  },
  {
    "number": 58,
    "title": "[BUG] bug resolved on fast api",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-24T01:00:23Z",
    "closed_at": "2023-08-24T01:01:40Z",
    "merged_at": "2023-08-24T01:01:40Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/58"
  },
  {
    "number": 57,
    "title": "[BUILD] Create release.yml for PYPI",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-23T07:55:22Z",
    "closed_at": "2023-08-23T07:57:52Z",
    "merged_at": "2023-08-23T07:57:52Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/57"
  },
  {
    "number": 56,
    "title": "[FEATURE] add OpenAI compatible API",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-23T07:14:39Z",
    "closed_at": "2023-08-23T07:15:14Z",
    "merged_at": "2023-08-23T07:15:14Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/56"
  },
  {
    "number": 55,
    "title": "[BUILD] Create branch.yml for CI",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-23T07:12:06Z",
    "closed_at": "2023-08-23T07:46:38Z",
    "merged_at": "2023-08-23T07:46:38Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/55"
  },
  {
    "number": 52,
    "title": "[FEATURE] add streaming for call",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-20T02:57:47Z",
    "closed_at": "2023-08-20T02:58:31Z",
    "merged_at": "2023-08-20T02:58:31Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/52"
  },
  {
    "number": 51,
    "title": "Create read1",
    "user": "nephp06",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-19T14:21:47Z",
    "closed_at": "2023-08-23T08:22:36Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/51"
  },
  {
    "number": 49,
    "title": "[FEATURE] add args for benchmark",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-15T23:00:45Z",
    "closed_at": "2023-08-15T23:01:40Z",
    "merged_at": "2023-08-15T23:01:40Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/49"
  },
  {
    "number": 46,
    "title": "[BUILD] update poetry",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T03:01:07Z",
    "closed_at": "2023-08-11T03:01:17Z",
    "merged_at": "2023-08-11T03:01:17Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/46"
  },
  {
    "number": 45,
    "title": "[FEATURE] Update env",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T02:57:57Z",
    "closed_at": "2023-08-11T02:58:18Z",
    "merged_at": "2023-08-11T02:58:18Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/45"
  },
  {
    "number": 44,
    "title": "[FEATURE] update default model path",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T02:52:54Z",
    "closed_at": "2023-08-11T02:53:28Z",
    "merged_at": "2023-08-11T02:53:28Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/44"
  },
  {
    "number": 43,
    "title": "[BUILD] update poetry",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T01:42:10Z",
    "closed_at": "2023-08-11T01:42:29Z",
    "merged_at": "2023-08-11T01:42:29Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/43"
  },
  {
    "number": 42,
    "title": "[FEATURE] Update requirements",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T01:34:50Z",
    "closed_at": "2023-08-11T01:35:12Z",
    "merged_at": "2023-08-11T01:35:12Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/42"
  },
  {
    "number": 41,
    "title": "[FEATURE] add download model for default",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T01:15:43Z",
    "closed_at": "2023-08-11T01:16:04Z",
    "merged_at": "2023-08-11T01:16:04Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/41"
  },
  {
    "number": 40,
    "title": "[DOCUMENT] update readme, news, performance",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-10T07:30:00Z",
    "closed_at": "2023-08-10T07:30:08Z",
    "merged_at": "2023-08-10T07:30:08Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/40"
  },
  {
    "number": 39,
    "title": "[DOCUMENT] update reademe, poetry for llama2-wrapper",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-10T05:36:00Z",
    "closed_at": "2023-08-10T05:36:41Z",
    "merged_at": "2023-08-10T05:36:41Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/39"
  },
  {
    "number": 38,
    "title": "[FEATURE] Llama2 wrapper unify arguments, change initial method",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-10T00:49:07Z",
    "closed_at": "2023-08-10T00:50:27Z",
    "merged_at": "2023-08-10T00:50:27Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/38"
  },
  {
    "number": 34,
    "title": "[FEATURE] Added iterations to most parts of the benchmark + Memory usage",
    "user": "jules552",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-03T02:55:58Z",
    "closed_at": "2023-08-03T22:40:31Z",
    "merged_at": "2023-08-03T22:40:31Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/34"
  },
  {
    "number": 32,
    "title": "[DOCUMENT] benchmark: AMD Ryzen 9 5900HS",
    "user": "jules552",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-02T22:34:14Z",
    "closed_at": "2023-08-02T22:48:52Z",
    "merged_at": "2023-08-02T22:48:52Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/32"
  },
  {
    "number": 30,
    "title": "[DOCUMENT] Add benchmarks of `i7-9700` and `GTX-1660 Super`",
    "user": "smithlai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-02T01:41:49Z",
    "closed_at": "2023-08-02T04:29:38Z",
    "merged_at": "2023-08-02T04:29:38Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/30"
  },
  {
    "number": 29,
    "title": "[DOCUMENT] benchmark: add vserver",
    "user": "step21",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-31T14:42:13Z",
    "closed_at": "2023-08-09T04:31:48Z",
    "merged_at": "2023-08-09T04:31:48Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/29"
  },
  {
    "number": 28,
    "title": "[DOCUMENT] update performance",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-31T05:41:38Z",
    "closed_at": "2023-07-31T05:41:55Z",
    "merged_at": "2023-07-31T05:41:55Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/28"
  },
  {
    "number": 22,
    "title": "[FEATURE] add benchmark tokens.sec",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-29T05:32:29Z",
    "closed_at": "2023-07-29T05:32:56Z",
    "merged_at": "2023-07-29T05:32:56Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/22"
  },
  {
    "number": 19,
    "title": "[FEATURE] Llama2 wrapper generate, __call__ func",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-28T09:28:10Z",
    "closed_at": "2023-07-28T09:31:07Z",
    "merged_at": "2023-07-28T09:31:07Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/19"
  },
  {
    "number": 18,
    "title": "[FEATURE] Llama2 wrapper",
    "user": "liltom-eth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-27T09:02:21Z",
    "closed_at": "2023-07-27T09:18:50Z",
    "merged_at": "2023-07-27T09:18:50Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/18"
  },
  {
    "number": 10,
    "title": "[DOCUMENT] add performance",
    "user": "minghaoBD",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-26T08:41:02Z",
    "closed_at": "2023-07-29T05:05:35Z",
    "merged_at": "2023-07-29T05:05:35Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/10"
  },
  {
    "number": 8,
    "title": "[DOCUMENT] update license, intro ",
    "user": "AndyW-llm",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-26T04:42:11Z",
    "closed_at": "2023-07-26T06:22:13Z",
    "merged_at": "2023-07-26T06:22:13Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/8"
  },
  {
    "number": 6,
    "title": "Update README.md",
    "user": "ysx1223",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-26T03:08:13Z",
    "closed_at": "2023-07-26T05:52:33Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/6"
  },
  {
    "number": 5,
    "title": "[DOCUMENT] update README.md for Windows dependencies",
    "user": "kemalariboga",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-26T02:03:59Z",
    "closed_at": "2023-07-26T06:32:42Z",
    "merged_at": "2023-07-26T06:32:42Z",
    "state": "closed",
    "html_url": "https://github.com/liltom-eth/llama2-webui/pull/5"
  }
]