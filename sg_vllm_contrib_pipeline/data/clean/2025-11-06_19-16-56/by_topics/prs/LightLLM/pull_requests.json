[
  {
    "number": 1099,
    "title": "add flashinfer-trtllm-ragged-prefill-attn",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-06T08:51:02Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1099"
  },
  {
    "number": 1098,
    "title": "feat: disk cache v1.0",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-05T07:15:44Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1098"
  },
  {
    "number": 1097,
    "title": "[model] Support Qwen3next",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-05T06:50:52Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1097"
  },
  {
    "number": 1096,
    "title": "fix-audio-rpyc",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-05T05:49:49Z",
    "closed_at": "2025-11-05T05:57:20Z",
    "merged_at": "2025-11-05T05:57:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1096"
  },
  {
    "number": 1095,
    "title": "Add qwen3 vl",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-04T11:06:43Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1095"
  },
  {
    "number": 1094,
    "title": "opti-qwen2-vl-pre-process",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-04T07:42:04Z",
    "closed_at": "2025-11-04T08:54:59Z",
    "merged_at": "2025-11-04T08:54:59Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1094"
  },
  {
    "number": 1093,
    "title": "[feature] Add prefix_kv_cache transfer between dp rankers.",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-04T06:07:47Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1093"
  },
  {
    "number": 1092,
    "title": "bugfix: Fix precision issue with Triton operator token_att_fwd",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-02T16:14:00Z",
    "closed_at": "2025-11-04T01:35:48Z",
    "merged_at": "2025-11-04T01:35:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1092"
  },
  {
    "number": 1091,
    "title": "add profile_demo.py and add synchronize in infer_loop",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-31T03:16:20Z",
    "closed_at": "2025-10-31T05:58:05Z",
    "merged_at": "2025-10-31T05:58:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1091"
  },
  {
    "number": 1090,
    "title": "implement radix_cache node merge function",
    "user": "Longxmas",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-29T06:06:26Z",
    "closed_at": "2025-10-30T06:11:30Z",
    "merged_at": "2025-10-30T06:11:30Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1090"
  },
  {
    "number": 1089,
    "title": "static test fix",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-29T05:42:28Z",
    "closed_at": "2025-10-29T05:59:12Z",
    "merged_at": "2025-10-29T05:59:12Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1089"
  },
  {
    "number": 1088,
    "title": "Add Lab4AI material in README",
    "user": "zhhangBian",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-28T07:12:44Z",
    "closed_at": "2025-10-28T08:41:07Z",
    "merged_at": "2025-10-28T08:41:07Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1088"
  },
  {
    "number": 1087,
    "title": "add time log for debug.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-28T06:33:26Z",
    "closed_at": "2025-10-28T06:48:50Z",
    "merged_at": "2025-10-28T06:48:50Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1087"
  },
  {
    "number": 1086,
    "title": "tpsp mode support db prefill balance.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-24T13:07:28Z",
    "closed_at": "2025-10-27T12:39:02Z",
    "merged_at": "2025-10-27T12:39:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1086"
  },
  {
    "number": 1085,
    "title": "fix api_cli & qwen25 parser",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-23T06:45:49Z",
    "closed_at": "2025-10-23T07:11:41Z",
    "merged_at": "2025-10-23T07:11:41Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1085"
  },
  {
    "number": 1084,
    "title": "Awq support",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-21T07:05:31Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1084"
  },
  {
    "number": 1083,
    "title": "fix: minor updates and fixs for unit_tests to match current code",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-16T20:28:24Z",
    "closed_at": "2025-10-29T02:10:16Z",
    "merged_at": "2025-10-29T02:10:16Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1083"
  },
  {
    "number": 1082,
    "title": "fix qwen2vl image process",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-15T10:18:40Z",
    "closed_at": "2025-10-15T10:36:24Z",
    "merged_at": "2025-10-15T10:36:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1082"
  },
  {
    "number": 1081,
    "title": "bugfix:qwen3 fa3 inferstruct init, add b_prefill_start_loc for init_req_to_token_indexes",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-15T09:41:15Z",
    "closed_at": "2025-10-15T10:35:49Z",
    "merged_at": "2025-10-15T10:35:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1081"
  },
  {
    "number": 1080,
    "title": "Fix Tool Call API & Minor Change",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-15T07:29:45Z",
    "closed_at": "2025-10-23T05:30:00Z",
    "merged_at": "2025-10-23T05:29:59Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1080"
  },
  {
    "number": 1079,
    "title": "fix: MTP in chunked prefill mode",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-14T06:02:24Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1079"
  },
  {
    "number": 1078,
    "title": "deepseek tpsp lora rank qkv all gather.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-13T04:29:45Z",
    "closed_at": "2025-10-13T07:29:49Z",
    "merged_at": "2025-10-13T07:29:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1078"
  },
  {
    "number": 1077,
    "title": "fix gpt_oss import",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-10T11:58:19Z",
    "closed_at": "2025-10-10T11:58:48Z",
    "merged_at": "2025-10-10T11:58:48Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1077"
  },
  {
    "number": 1076,
    "title": "Support qwen3 next",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-09T16:06:02Z",
    "closed_at": "2025-11-05T06:51:21Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1076"
  },
  {
    "number": 1075,
    "title": "fix unit test for silu_and_mul kernel.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-30T08:26:09Z",
    "closed_at": "2025-09-30T08:26:25Z",
    "merged_at": "2025-09-30T08:26:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1075"
  },
  {
    "number": 1073,
    "title": "deepseek-MTP eagle, topk=1",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-29T15:49:23Z",
    "closed_at": "2025-10-10T10:45:46Z",
    "merged_at": "2025-10-10T10:45:46Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1073"
  },
  {
    "number": 1071,
    "title": "[add]add whisper sdpa",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-26T07:45:52Z",
    "closed_at": "2025-09-28T03:13:36Z",
    "merged_at": "2025-09-28T03:13:36Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1071"
  },
  {
    "number": 1070,
    "title": "Fix qwen3moe overlap mode",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-26T02:00:49Z",
    "closed_at": "2025-09-28T06:03:54Z",
    "merged_at": "2025-09-28T06:03:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1070"
  },
  {
    "number": 1069,
    "title": "fix qwen3moe overlap",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-26T01:42:18Z",
    "closed_at": "2025-09-26T01:59:58Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1069"
  },
  {
    "number": 1067,
    "title": "Fix type hint in _create_paged_xfer_handles method",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-24T03:21:58Z",
    "closed_at": "2025-09-24T03:23:00Z",
    "merged_at": "2025-09-24T03:23:00Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1067"
  },
  {
    "number": 1066,
    "title": "reformat pre cache kv",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-24T02:58:59Z",
    "closed_at": "2025-09-24T10:51:15Z",
    "merged_at": "2025-09-24T10:51:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1066"
  },
  {
    "number": 1065,
    "title": "Ds MTP-eagle support, topk=1",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-23T06:32:59Z",
    "closed_at": "2025-09-29T15:48:35Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1065"
  },
  {
    "number": 1064,
    "title": "Fix the incorrect logic when loading Mixtral series model weights.",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-22T09:32:57Z",
    "closed_at": "2025-09-23T08:25:18Z",
    "merged_at": "2025-09-23T08:25:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1064"
  },
  {
    "number": 1063,
    "title": "[misc] Adding Generic Types for IDE",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-22T09:09:32Z",
    "closed_at": "2025-09-25T06:04:21Z",
    "merged_at": "2025-09-25T06:04:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1063"
  },
  {
    "number": 1061,
    "title": "[add] add skip image cache and disable_prompt_cache para",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-18T09:49:45Z",
    "closed_at": "2025-09-24T11:14:59Z",
    "merged_at": "2025-09-24T11:14:59Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1061"
  },
  {
    "number": 1060,
    "title": "support interns1",
    "user": "xhx1022",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-18T05:15:14Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1060"
  },
  {
    "number": 1059,
    "title": "add unit test for kv trans kernel",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-17T12:44:13Z",
    "closed_at": "2025-09-18T06:05:37Z",
    "merged_at": "2025-09-18T06:05:37Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1059"
  },
  {
    "number": 1058,
    "title": "fix deepgemm set_num_sms import",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-17T08:59:56Z",
    "closed_at": "2025-09-17T09:14:25Z",
    "merged_at": "2025-09-17T09:14:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1058"
  },
  {
    "number": 1057,
    "title": "Fix the pause issue under extremely aggressive scheduling.",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-17T08:18:27Z",
    "closed_at": "2025-09-17T08:31:47Z",
    "merged_at": "2025-09-17T08:31:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1057"
  },
  {
    "number": 1056,
    "title": "Remove prefill cpu sync op",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-17T07:22:35Z",
    "closed_at": "2025-10-10T09:20:31Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1056"
  },
  {
    "number": 1055,
    "title": "merge q_a_proj and kv_a_proj to reduce the kernel launch overhead",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-17T07:00:55Z",
    "closed_at": "2025-09-23T09:36:02Z",
    "merged_at": "2025-09-23T09:36:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1055"
  },
  {
    "number": 1054,
    "title": "add moe_align_fused",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-17T06:33:42Z",
    "closed_at": "2025-09-18T09:36:54Z",
    "merged_at": "2025-09-18T09:36:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1054"
  },
  {
    "number": 1053,
    "title": "enable fa3 and fused_shared_experts by default",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-15T13:27:57Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1053"
  },
  {
    "number": 1052,
    "title": "fix tl.where and set the default loader worker number",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-11T03:43:35Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1052"
  },
  {
    "number": 1051,
    "title": "Startup Optimization & Reliability: Shared Memory and Parallel Model Initialization.",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-10T09:38:48Z",
    "closed_at": "2025-09-24T07:55:55Z",
    "merged_at": "2025-09-24T07:55:55Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1051"
  },
  {
    "number": 1050,
    "title": "Fix the pause issue under extremely aggressive scheduling.",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-09T17:02:16Z",
    "closed_at": "2025-09-22T05:08:19Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1050"
  },
  {
    "number": 1049,
    "title": "Update Kernels",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-09T12:05:14Z",
    "closed_at": "2025-09-09T12:05:27Z",
    "merged_at": "2025-09-09T12:05:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1049"
  },
  {
    "number": 1048,
    "title": "feat: Implementing Past Future Scheduler",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-08T15:27:55Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1048"
  },
  {
    "number": 1047,
    "title": "vit fa3 api fix",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-08T11:33:27Z",
    "closed_at": "2025-09-08T11:50:29Z",
    "merged_at": "2025-09-08T11:50:29Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1047"
  },
  {
    "number": 1046,
    "title": "add stream_options for openai api",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-08T07:42:39Z",
    "closed_at": "2025-09-08T07:47:19Z",
    "merged_at": "2025-09-08T07:47:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1046"
  },
  {
    "number": 1045,
    "title": "[fix]fix fp8 bug when load moe model",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-08T07:41:38Z",
    "closed_at": "2025-09-08T07:52:27Z",
    "merged_at": "2025-09-08T07:52:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1045"
  },
  {
    "number": 1044,
    "title": "fix mtp mem alloc in overlap manner",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-08T07:12:05Z",
    "closed_at": "2025-09-08T07:36:43Z",
    "merged_at": "2025-09-08T07:36:43Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1044"
  },
  {
    "number": 1043,
    "title": "force to warmup triton autotune configs in start.",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-04T10:32:05Z",
    "closed_at": "2025-09-05T09:16:00Z",
    "merged_at": "2025-09-05T09:16:00Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1043"
  },
  {
    "number": 1042,
    "title": "pd with nixl backend",
    "user": "kingder",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-04T07:23:24Z",
    "closed_at": "2025-09-23T07:37:47Z",
    "merged_at": "2025-09-23T07:37:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1042"
  },
  {
    "number": 1041,
    "title": "fix tl.where warning",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-04T03:46:27Z",
    "closed_at": "2025-09-04T07:23:35Z",
    "merged_at": "2025-09-04T07:23:34Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1041"
  },
  {
    "number": 1040,
    "title": "v100 triton kernel fix",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-03T10:55:19Z",
    "closed_at": "2025-09-03T10:56:47Z",
    "merged_at": "2025-09-03T10:56:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1040"
  },
  {
    "number": 1039,
    "title": "LightLLM v1.1.0 release!",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-03T07:51:36Z",
    "closed_at": "2025-09-03T07:52:04Z",
    "merged_at": "2025-09-03T07:52:04Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1039"
  },
  {
    "number": 1038,
    "title": "add qwen235b autotune config",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-03T07:03:11Z",
    "closed_at": "2025-09-03T07:07:03Z",
    "merged_at": "2025-09-03T07:07:03Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1038"
  },
  {
    "number": 1037,
    "title": "fix autotune and benchmark",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-03T06:57:33Z",
    "closed_at": "2025-09-03T07:01:47Z",
    "merged_at": "2025-09-03T07:01:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1037"
  },
  {
    "number": 1036,
    "title": "add autotune configs and log",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-03T06:28:49Z",
    "closed_at": "2025-09-03T07:03:58Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1036"
  },
  {
    "number": 1035,
    "title": "group deepgemm update api",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-03T05:09:11Z",
    "closed_at": "2025-09-03T06:30:51Z",
    "merged_at": "2025-09-03T06:30:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1035"
  },
  {
    "number": 1034,
    "title": "Mineru adapt",
    "user": "zhhangBian",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-03T04:03:26Z",
    "closed_at": "2025-11-04T06:36:36Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1034"
  },
  {
    "number": 1033,
    "title": "fix benchmark",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-02T16:08:19Z",
    "closed_at": "2025-09-03T06:13:09Z",
    "merged_at": "2025-09-03T06:13:09Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1033"
  },
  {
    "number": 1032,
    "title": "tuning optimization",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-01T08:30:04Z",
    "closed_at": "2025-09-02T11:54:28Z",
    "merged_at": "2025-09-02T11:54:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1032"
  },
  {
    "number": 1031,
    "title": "add AutotuneLevel for more detailed autotune",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-01T02:56:02Z",
    "closed_at": "2025-09-01T09:53:59Z",
    "merged_at": "2025-09-01T09:53:58Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1031"
  },
  {
    "number": 1028,
    "title": "fix autotuning warmup length",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-29T09:55:39Z",
    "closed_at": "2025-08-29T09:56:25Z",
    "merged_at": "2025-08-29T09:56:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1028"
  },
  {
    "number": 1027,
    "title": "Use environment variable for RMSNORM_WARPS",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-29T09:02:04Z",
    "closed_at": "2025-09-10T06:27:03Z",
    "merged_at": "2025-09-10T06:27:03Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1027"
  },
  {
    "number": 1026,
    "title": "Add IS_OMNI5 to support dynamic rms_norm num_warps.",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-29T08:54:06Z",
    "closed_at": "2025-08-29T09:01:31Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1026"
  },
  {
    "number": 1025,
    "title": "fix autotuenr",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-29T07:39:26Z",
    "closed_at": "2025-08-29T08:30:27Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1025"
  },
  {
    "number": 1024,
    "title": "Add setproctitle",
    "user": "zhhangBian",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-29T07:03:46Z",
    "closed_at": "2025-09-02T06:46:38Z",
    "merged_at": "2025-09-02T06:46:38Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1024"
  },
  {
    "number": 1023,
    "title": "Add Support For GPT-OSS Model",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-27T07:18:02Z",
    "closed_at": "2025-09-29T01:24:03Z",
    "merged_at": "2025-09-29T01:24:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1023"
  },
  {
    "number": 1022,
    "title": "fix input_penalty token_id async update bug.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-25T10:29:51Z",
    "closed_at": "2025-08-25T10:30:58Z",
    "merged_at": "2025-08-25T10:30:57Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1022"
  },
  {
    "number": 1021,
    "title": "fix check_recommended_shm_size",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-22T08:41:57Z",
    "closed_at": "2025-08-22T08:43:02Z",
    "merged_at": "2025-08-22T08:43:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1021"
  },
  {
    "number": 1020,
    "title": "Autotuner",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-22T04:41:46Z",
    "closed_at": "2025-08-28T03:14:44Z",
    "merged_at": "2025-08-28T03:14:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1020"
  },
  {
    "number": 1019,
    "title": "add greedy_sample",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-21T07:36:46Z",
    "closed_at": "2025-08-22T06:08:03Z",
    "merged_at": "2025-08-22T06:08:03Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1019"
  },
  {
    "number": 1018,
    "title": "support more PD node select func. such as random or roundrobin.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-21T06:20:07Z",
    "closed_at": "2025-08-21T10:45:41Z",
    "merged_at": "2025-08-21T10:45:41Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1018"
  },
  {
    "number": 1017,
    "title": "Optimize multimodal resource allocation with concurrency and improved batch RPC",
    "user": "dyyoungg",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-21T04:35:09Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1017"
  },
  {
    "number": 1016,
    "title": "Add multimodal token usage",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-21T02:41:08Z",
    "closed_at": "2025-08-21T04:07:17Z",
    "merged_at": "2025-08-21T04:07:17Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1016"
  },
  {
    "number": 1015,
    "title": "Autotuner",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-20T09:24:26Z",
    "closed_at": "2025-08-20T11:35:20Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1015"
  },
  {
    "number": 1014,
    "title": "[support] vit and llm disaggregation",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-20T07:14:20Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1014"
  },
  {
    "number": 1013,
    "title": "Fix the overflow issue caused by the mem index type being int32 in the decode att operator.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-20T02:19:57Z",
    "closed_at": "2025-08-20T02:21:23Z",
    "merged_at": "2025-08-20T02:21:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1013"
  },
  {
    "number": 1011,
    "title": "Add multimodal token usage",
    "user": "zhhangBian",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-19T13:29:09Z",
    "closed_at": "2025-08-21T02:40:49Z",
    "merged_at": "2025-08-21T02:40:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1011"
  },
  {
    "number": 1010,
    "title": "Fix dynamic_prompt_cache for chunked prefill",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-19T09:43:03Z",
    "closed_at": "2025-08-20T03:27:13Z",
    "merged_at": "2025-08-20T03:27:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1010"
  },
  {
    "number": 1009,
    "title": "fix mtp static bench",
    "user": "STwangyingrui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-19T06:44:34Z",
    "closed_at": "2025-08-21T10:48:26Z",
    "merged_at": "2025-08-21T10:48:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1009"
  },
  {
    "number": 1008,
    "title": "[Misc] Add a progress bar when loading the model",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-18T12:37:14Z",
    "closed_at": "2025-08-20T01:20:24Z",
    "merged_at": "2025-08-20T01:20:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1008"
  },
  {
    "number": 1005,
    "title": "add fa3_mtp",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-11T04:52:19Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1005"
  },
  {
    "number": 1004,
    "title": "[opt]opti-qwen2-vl-vit",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-08T09:47:54Z",
    "closed_at": "2025-08-14T08:53:38Z",
    "merged_at": "2025-08-14T08:53:37Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1004"
  },
  {
    "number": 1003,
    "title": "Fix",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-08T04:42:56Z",
    "closed_at": "2025-08-14T08:07:50Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1003"
  },
  {
    "number": 1002,
    "title": "pd with nixl backend (rebase main)",
    "user": "kingder",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-07T08:47:30Z",
    "closed_at": "2025-09-04T07:25:08Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1002"
  },
  {
    "number": 1001,
    "title": "Torch.ops",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-05T12:25:34Z",
    "closed_at": "2025-08-06T16:45:52Z",
    "merged_at": "2025-08-06T16:45:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1001"
  },
  {
    "number": 1000,
    "title": "use torch ops",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-05T12:24:57Z",
    "closed_at": "2025-08-05T12:25:04Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1000"
  },
  {
    "number": 999,
    "title": "Support Qwen models' dp>1 in PD",
    "user": "zhhangBian",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-05T12:11:20Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/999"
  },
  {
    "number": 998,
    "title": "Fix  error illegal memory access when max_total_token_num is too large",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-04T09:47:55Z",
    "closed_at": "2025-08-12T08:50:26Z",
    "merged_at": "2025-08-12T08:50:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/998"
  },
  {
    "number": 997,
    "title": "Cpu KV Cache feature",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-04T09:22:35Z",
    "closed_at": "2025-10-23T04:10:45Z",
    "merged_at": "2025-10-23T04:10:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/997"
  },
  {
    "number": 996,
    "title": "add rmsnorm-add fusion kernel",
    "user": "theNiemand",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-04T08:16:34Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/996"
  },
  {
    "number": 995,
    "title": "fix: fix accuracy bug in flashinfer and fa3 kernel.",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-01T09:28:14Z",
    "closed_at": "2025-08-04T13:37:57Z",
    "merged_at": "2025-08-04T13:37:57Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/995"
  },
  {
    "number": 994,
    "title": "add grouped_moe_gemm_kernel configs",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-30T08:17:49Z",
    "closed_at": "2025-07-31T06:12:50Z",
    "merged_at": "2025-07-31T06:12:50Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/994"
  },
  {
    "number": 993,
    "title": "[fix]qwen2vl support fa3",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-30T04:04:25Z",
    "closed_at": "2025-07-31T13:00:41Z",
    "merged_at": "2025-07-31T13:00:41Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/993"
  },
  {
    "number": 992,
    "title": "fix abort",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-29T17:55:49Z",
    "closed_at": "2025-07-30T08:03:39Z",
    "merged_at": "2025-07-30T08:03:39Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/992"
  },
  {
    "number": 991,
    "title": "Dp balancer",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-29T06:01:15Z",
    "closed_at": "2025-08-25T10:05:07Z",
    "merged_at": "2025-08-25T10:05:07Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/991"
  },
  {
    "number": 990,
    "title": "update docs",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-25T07:05:18Z",
    "closed_at": "2025-07-25T07:07:50Z",
    "merged_at": "2025-07-25T07:07:50Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/990"
  },
  {
    "number": 989,
    "title": "improve the scheduler",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-25T07:02:32Z",
    "closed_at": "2025-07-25T08:44:51Z",
    "merged_at": "2025-07-25T08:44:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/989"
  },
  {
    "number": 988,
    "title": "fix gpu out token counter update error",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-25T04:10:00Z",
    "closed_at": "2025-07-25T06:45:51Z",
    "merged_at": "2025-07-25T06:45:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/988"
  },
  {
    "number": 987,
    "title": "add exception log for httpserver.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-24T10:57:02Z",
    "closed_at": "2025-07-24T10:58:35Z",
    "merged_at": "2025-07-24T10:58:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/987"
  },
  {
    "number": 986,
    "title": "fix multinode dp mode bug.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-24T08:30:07Z",
    "closed_at": "2025-07-24T08:30:45Z",
    "merged_at": "2025-07-24T08:30:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/986"
  },
  {
    "number": 985,
    "title": "update topk softmax",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-24T07:26:04Z",
    "closed_at": "2025-07-24T07:32:48Z",
    "merged_at": "2025-07-24T07:32:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/985"
  },
  {
    "number": 984,
    "title": "fix get_vocab_size for multimodal",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-24T06:31:25Z",
    "closed_at": "2025-07-24T06:33:27Z",
    "merged_at": "2025-07-24T06:33:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/984"
  },
  {
    "number": 983,
    "title": "fix dict.get no has  default key params.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-23T17:21:07Z",
    "closed_at": "2025-07-23T17:21:56Z",
    "merged_at": "2025-07-23T17:21:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/983"
  },
  {
    "number": 982,
    "title": "upgrade transformers version",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-23T16:52:51Z",
    "closed_at": "2025-07-23T16:54:33Z",
    "merged_at": "2025-07-23T16:54:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/982"
  },
  {
    "number": 981,
    "title": "update dockerfile",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-23T12:44:21Z",
    "closed_at": "2025-07-23T13:00:41Z",
    "merged_at": "2025-07-23T13:00:41Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/981"
  },
  {
    "number": 980,
    "title": "[fix] add visual_infer_batch_size check",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-23T09:14:48Z",
    "closed_at": "2025-07-23T09:26:56Z",
    "merged_at": "2025-07-23T09:26:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/980"
  },
  {
    "number": 979,
    "title": "[fix]rpyc pickle",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-23T07:58:33Z",
    "closed_at": "2025-07-23T08:03:22Z",
    "merged_at": "2025-07-23T08:03:22Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/979"
  },
  {
    "number": 978,
    "title": "Add shm size check",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-22T07:36:36Z",
    "closed_at": "2025-08-18T12:14:07Z",
    "merged_at": "2025-08-18T12:14:07Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/978"
  },
  {
    "number": 977,
    "title": "Asynchicache",
    "user": "jinbiaoyu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-21T05:44:58Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/977"
  },
  {
    "number": 975,
    "title": "Fp8 deepseek",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-17T08:18:27Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/975"
  },
  {
    "number": 974,
    "title": "support qwen3moe overlap mode",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-16T07:17:41Z",
    "closed_at": "2025-07-22T11:57:04Z",
    "merged_at": "2025-07-22T11:57:04Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/974"
  },
  {
    "number": 973,
    "title": "[perf] Batch rpyc calls in multimodal path -2",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-16T06:22:43Z",
    "closed_at": "2025-07-22T05:59:53Z",
    "merged_at": "2025-07-22T05:59:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/973"
  },
  {
    "number": 972,
    "title": "feat: extend the num head terms for fp8 calibration",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-15T07:44:28Z",
    "closed_at": "2025-07-22T09:11:19Z",
    "merged_at": "2025-07-22T09:11:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/972"
  },
  {
    "number": 971,
    "title": "[fix] verify image when preload",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-14T10:06:43Z",
    "closed_at": "2025-07-15T02:50:59Z",
    "merged_at": "2025-07-15T02:50:59Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/971"
  },
  {
    "number": 970,
    "title": "feat: support more PD node select func",
    "user": "zhhangBian",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-14T08:49:51Z",
    "closed_at": "2025-08-21T06:19:14Z",
    "merged_at": "2025-08-21T06:19:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/970"
  },
  {
    "number": 969,
    "title": "feat: add stop string matching",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-14T07:24:57Z",
    "closed_at": "2025-08-20T13:17:12Z",
    "merged_at": "2025-08-20T13:17:12Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/969"
  },
  {
    "number": 968,
    "title": "optimize radix cache.",
    "user": "kingder",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-11T02:52:58Z",
    "closed_at": "2025-07-11T03:11:22Z",
    "merged_at": "2025-07-11T03:11:22Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/968"
  },
  {
    "number": 967,
    "title": "[fix]pydantic to dict when build prompt",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-09T12:40:28Z",
    "closed_at": "2025-07-15T05:50:29Z",
    "merged_at": "2025-07-15T05:50:29Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/967"
  },
  {
    "number": 966,
    "title": "fix: fix a bug in flashinfer_struct",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-09T12:16:07Z",
    "closed_at": "2025-07-10T02:21:16Z",
    "merged_at": "2025-07-10T02:21:16Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/966"
  },
  {
    "number": 965,
    "title": "router and infer parrall.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-09T05:51:28Z",
    "closed_at": "2025-07-21T15:31:20Z",
    "merged_at": "2025-07-21T15:31:20Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/965"
  },
  {
    "number": 964,
    "title": "cuda graph pool with LRU",
    "user": "STwangyingrui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-08T14:10:52Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/964"
  },
  {
    "number": 963,
    "title": "fix: remove python310 feature",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-08T11:37:21Z",
    "closed_at": "2025-07-08T11:59:34Z",
    "merged_at": "2025-07-08T11:59:34Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/963"
  },
  {
    "number": 962,
    "title": "Add fake balance for EP mode",
    "user": "STwangyingrui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-08T07:26:32Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/962"
  },
  {
    "number": 961,
    "title": "Add EP fake balance",
    "user": "STwangyingrui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-08T04:30:11Z",
    "closed_at": "2025-07-08T07:25:55Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/961"
  },
  {
    "number": 960,
    "title": "[perf] Batch rpyc calls in multimodal path",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-07T13:28:17Z",
    "closed_at": "2025-07-22T06:11:58Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/960"
  },
  {
    "number": 959,
    "title": "Add EP fake balance",
    "user": "STwangyingrui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-07T12:38:06Z",
    "closed_at": "2025-07-08T04:18:33Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/959"
  },
  {
    "number": 958,
    "title": "feat: support openai v1/completions api",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-07T11:24:03Z",
    "closed_at": "2025-07-08T05:47:13Z",
    "merged_at": "2025-07-08T05:47:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/958"
  },
  {
    "number": 957,
    "title": "Update README.md",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-07T08:17:05Z",
    "closed_at": "2025-07-07T08:18:53Z",
    "merged_at": "2025-07-07T08:18:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/957"
  },
  {
    "number": 956,
    "title": "[fix]fix unit_tests func name",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-04T11:33:17Z",
    "closed_at": "2025-07-04T11:34:02Z",
    "merged_at": "2025-07-04T11:34:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/956"
  },
  {
    "number": 955,
    "title": "router recv reqs update",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-04T09:24:38Z",
    "closed_at": "2025-07-07T09:02:26Z",
    "merged_at": "2025-07-07T09:02:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/955"
  },
  {
    "number": 954,
    "title": "multimodal chuncked prefill select needed multimodal objs.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-03T07:47:14Z",
    "closed_at": "2025-07-04T07:10:18Z",
    "merged_at": "2025-07-04T07:10:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/954"
  },
  {
    "number": 953,
    "title": "[support] vit fa support cu_seqlens and max_seqlens",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-03T03:08:04Z",
    "closed_at": "2025-07-04T02:04:06Z",
    "merged_at": "2025-07-04T02:04:06Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/953"
  },
  {
    "number": 952,
    "title": "[quant] deepgemm-fp8w8a8-b128 quantize",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-02T03:19:47Z",
    "closed_at": "2025-07-02T06:51:06Z",
    "merged_at": "2025-07-02T06:51:06Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/952"
  },
  {
    "number": 951,
    "title": "Multimodal improve",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-01T14:09:24Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/951"
  },
  {
    "number": 950,
    "title": "fix bytes2tensor error in torch version == 2.6.0.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-01T06:51:51Z",
    "closed_at": "2025-07-01T06:52:02Z",
    "merged_at": "2025-07-01T06:52:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/950"
  },
  {
    "number": 949,
    "title": "fix lightllm vit triton",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-01T06:01:52Z",
    "closed_at": "2025-07-01T06:04:57Z",
    "merged_at": "2025-07-01T06:04:57Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/949"
  },
  {
    "number": 947,
    "title": "feat: internvl llm support qwen3moe",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-30T10:55:17Z",
    "closed_at": "2025-07-01T01:55:08Z",
    "merged_at": "2025-07-01T01:55:08Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/947"
  },
  {
    "number": 946,
    "title": "(fix) fix rms_norm op",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-30T09:23:02Z",
    "closed_at": "2025-06-30T09:50:23Z",
    "merged_at": "2025-06-30T09:50:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/946"
  },
  {
    "number": 945,
    "title": "fix rms_norm",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-26T09:09:30Z",
    "closed_at": "2025-06-30T09:22:34Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/945"
  },
  {
    "number": 944,
    "title": "feat: Support decode chunk PD serving mode",
    "user": "zhhangBian",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-25T01:45:26Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/944"
  },
  {
    "number": 943,
    "title": "fix:add fabsf() to general kernel when compare max values",
    "user": "theNiemand",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-24T12:26:20Z",
    "closed_at": "2025-06-24T12:29:55Z",
    "merged_at": "2025-06-24T12:29:55Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/943"
  },
  {
    "number": 942,
    "title": "vit + qwen3 moe",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-24T11:54:47Z",
    "closed_at": "2025-06-24T11:55:25Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/942"
  },
  {
    "number": 941,
    "title": "fix:add fabsf() to general kernel when compare max values",
    "user": "theNiemand",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-24T11:53:28Z",
    "closed_at": "2025-06-24T11:54:32Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/941"
  },
  {
    "number": 940,
    "title": "fix ci and update docs",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-24T10:45:43Z",
    "closed_at": "2025-06-24T10:46:17Z",
    "merged_at": "2025-06-24T10:46:17Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/940"
  },
  {
    "number": 939,
    "title": "add per_token_quant_bf16_int8 kernel",
    "user": "theNiemand",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-24T10:43:33Z",
    "closed_at": "2025-06-24T10:48:28Z",
    "merged_at": "2025-06-24T10:48:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/939"
  },
  {
    "number": 938,
    "title": "update docs and reorg /test",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-24T08:45:48Z",
    "closed_at": "2025-06-24T09:15:56Z",
    "merged_at": "2025-06-24T09:15:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/938"
  },
  {
    "number": 937,
    "title": "Feature dp chuncked prefill balance.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-24T08:06:46Z",
    "closed_at": "2025-06-26T09:55:00Z",
    "merged_at": "2025-06-26T09:55:00Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/937"
  },
  {
    "number": 936,
    "title": "Add Grammar Cache for XGrammar Backend",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-20T12:41:14Z",
    "closed_at": "2025-06-21T00:37:14Z",
    "merged_at": "2025-06-21T00:37:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/936"
  },
  {
    "number": 935,
    "title": "feat: kv fp8 quant calibration for fa3 and flashinfer",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-20T12:10:16Z",
    "closed_at": "2025-07-14T09:10:42Z",
    "merged_at": "2025-07-14T09:10:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/935"
  },
  {
    "number": 934,
    "title": "deepseek && qwen tp performance tuning",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-19T16:02:00Z",
    "closed_at": "2025-08-20T02:41:38Z",
    "merged_at": "2025-08-20T02:41:38Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/934"
  },
  {
    "number": 933,
    "title": "Add Cache For XGrammar Backend",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-19T10:04:13Z",
    "closed_at": "2025-06-20T12:39:57Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/933"
  },
  {
    "number": 932,
    "title": "add repetition_penalty for openai chat api",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-19T06:37:24Z",
    "closed_at": "2025-06-19T06:37:35Z",
    "merged_at": "2025-06-19T06:37:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/932"
  },
  {
    "number": 931,
    "title": "fix n-nodes inconsistencies when gpu G-MEM size differ",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-13T05:27:42Z",
    "closed_at": "2025-06-13T06:24:29Z",
    "merged_at": "2025-06-13T06:24:29Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/931"
  },
  {
    "number": 930,
    "title": "fix image cache overhead",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-12T12:17:24Z",
    "closed_at": "2025-06-20T02:38:45Z",
    "merged_at": "2025-06-20T02:38:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/930"
  },
  {
    "number": 928,
    "title": "add vit+qwen3",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-11T09:22:13Z",
    "closed_at": "2025-06-11T09:26:13Z",
    "merged_at": "2025-06-11T09:26:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/928"
  },
  {
    "number": 927,
    "title": "fix dependency",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-11T05:19:08Z",
    "closed_at": "2025-06-11T05:19:14Z",
    "merged_at": "2025-06-11T05:19:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/927"
  },
  {
    "number": 926,
    "title": "fix cuda init error for cpu-only (config_server mode) device",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-10T09:13:55Z",
    "closed_at": "2025-06-10T09:23:21Z",
    "merged_at": "2025-06-10T09:23:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/926"
  },
  {
    "number": 925,
    "title": "Add lightllm kernel",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-09T07:16:00Z",
    "closed_at": "2025-07-22T08:53:46Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/925"
  },
  {
    "number": 924,
    "title": "quick fix for w8a8 registry",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-09T05:21:47Z",
    "closed_at": "2025-06-09T05:22:38Z",
    "merged_at": "2025-06-09T05:22:38Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/924"
  },
  {
    "number": 923,
    "title": "Deepseek MTP for dp backend",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-09T02:19:24Z",
    "closed_at": "2025-06-09T02:26:42Z",
    "merged_at": "2025-06-09T02:26:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/923"
  },
  {
    "number": 922,
    "title": "mtp for dp backend",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-09T01:47:03Z",
    "closed_at": "2025-06-09T02:18:40Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/922"
  },
  {
    "number": 921,
    "title": "fix: fix bugs in flashinfer_struct",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-06T06:28:02Z",
    "closed_at": "2025-06-06T07:55:30Z",
    "merged_at": "2025-06-06T07:55:30Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/921"
  },
  {
    "number": 920,
    "title": "fix: reset tensor with zeros",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-06T05:52:03Z",
    "closed_at": "2025-06-06T05:55:03Z",
    "merged_at": "2025-06-06T05:55:03Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/920"
  },
  {
    "number": 919,
    "title": "Fix XGrammar Constrained Mode",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-03T05:19:16Z",
    "closed_at": "2025-06-03T06:01:07Z",
    "merged_at": "2025-06-03T06:01:07Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/919"
  },
  {
    "number": 918,
    "title": "feat(api): add response_format support for openai API",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-30T14:31:32Z",
    "closed_at": "2025-06-05T07:36:45Z",
    "merged_at": "2025-06-05T07:36:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/918"
  },
  {
    "number": 917,
    "title": "free ci disk space",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-30T05:55:19Z",
    "closed_at": "2025-05-30T05:55:32Z",
    "merged_at": "2025-05-30T05:55:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/917"
  },
  {
    "number": 916,
    "title": "add lightllm ops",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-28T08:49:28Z",
    "closed_at": "2025-05-29T09:26:22Z",
    "merged_at": "2025-05-29T09:26:22Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/916"
  },
  {
    "number": 915,
    "title": "[Draft] [Feature] Integrated the Pre^3 JSON Mode into LightLLM",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-28T07:27:53Z",
    "closed_at": "2025-05-28T07:36:06Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/915"
  },
  {
    "number": 914,
    "title": "auto save rank 0 redundancy_expert_config.json",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-27T09:56:28Z",
    "closed_at": "2025-05-27T10:14:15Z",
    "merged_at": "2025-05-27T10:14:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/914"
  },
  {
    "number": 913,
    "title": "DeepSeek MTP ",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-26T10:07:22Z",
    "closed_at": "2025-06-18T09:38:38Z",
    "merged_at": "2025-06-18T09:38:38Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/913"
  },
  {
    "number": 912,
    "title": "add triton_softmax_topk",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-26T06:24:47Z",
    "closed_at": "2025-05-27T05:11:21Z",
    "merged_at": "2025-05-27T05:11:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/912"
  },
  {
    "number": 911,
    "title": "feat: remove cutlass/include add cutlass submodule",
    "user": "theNiemand",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-23T10:05:48Z",
    "closed_at": "2025-05-26T02:37:10Z",
    "merged_at": "2025-05-26T02:37:10Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/911"
  },
  {
    "number": 910,
    "title": "featureadd redundancy expert",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-23T07:05:47Z",
    "closed_at": "2025-05-27T09:00:20Z",
    "merged_at": "2025-05-27T09:00:20Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/910"
  },
  {
    "number": 909,
    "title": "[Fix] Fix regex_guide cache in Outlines Backend",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-21T13:13:37Z",
    "closed_at": "2025-05-26T12:15:21Z",
    "merged_at": "2025-05-26T12:15:20Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/909"
  },
  {
    "number": 908,
    "title": "set disable custom gather by default",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-21T12:14:42Z",
    "closed_at": "2025-05-21T12:14:52Z",
    "merged_at": "2025-05-21T12:14:52Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/908"
  },
  {
    "number": 907,
    "title": "fix: fix an int32 overflow bug in destindex_copy_kv",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-21T06:56:33Z",
    "closed_at": "2025-05-21T07:39:44Z",
    "merged_at": "2025-05-21T07:39:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/907"
  },
  {
    "number": 906,
    "title": "[feature] use config_server to init nccl",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-21T04:44:22Z",
    "closed_at": "2025-05-21T07:27:26Z",
    "merged_at": "2025-05-21T07:27:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/906"
  },
  {
    "number": 905,
    "title": "[FIX]add shm lock",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-20T10:15:30Z",
    "closed_at": "2025-05-26T10:17:52Z",
    "merged_at": "2025-05-26T10:17:52Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/905"
  },
  {
    "number": 903,
    "title": "add Citation and Academia works based on LightLLM",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-16T18:57:58Z",
    "closed_at": "2025-05-26T08:15:51Z",
    "merged_at": "2025-05-26T08:15:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/903"
  },
  {
    "number": 902,
    "title": "[FIX]avoid image_max_patch_num=0",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-16T10:16:00Z",
    "closed_at": "2025-05-16T10:17:41Z",
    "merged_at": "2025-05-16T10:17:41Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/902"
  },
  {
    "number": 901,
    "title": "Fix deadlock when alloc resource",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-16T09:29:21Z",
    "closed_at": "2025-05-16T09:47:57Z",
    "merged_at": "2025-05-16T09:47:57Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/901"
  },
  {
    "number": 900,
    "title": "fix for cpu-only config server",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-16T07:05:23Z",
    "closed_at": "2025-05-16T07:33:03Z",
    "merged_at": "2025-05-16T07:33:03Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/900"
  },
  {
    "number": 899,
    "title": "opt: post processingwqa opt",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-15T12:50:00Z",
    "closed_at": "2025-06-04T08:40:29Z",
    "merged_at": "2025-06-04T08:40:29Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/899"
  },
  {
    "number": 898,
    "title": "fix create new group for current dp",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-15T09:49:39Z",
    "closed_at": "2025-05-15T10:20:33Z",
    "merged_at": "2025-05-15T10:20:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/898"
  },
  {
    "number": 897,
    "title": "fix tp moe and improve  dp router.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-15T08:19:14Z",
    "closed_at": "2025-05-15T08:22:24Z",
    "merged_at": "2025-05-15T08:22:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/897"
  },
  {
    "number": 896,
    "title": "fix qwen2 tp16",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-15T06:10:27Z",
    "closed_at": "2025-05-15T06:18:05Z",
    "merged_at": "2025-05-15T06:18:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/896"
  },
  {
    "number": 895,
    "title": "pd master health, tokens and server busy error",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-14T11:27:15Z",
    "closed_at": "2025-05-15T02:39:33Z",
    "merged_at": "2025-05-15T02:39:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/895"
  },
  {
    "number": 893,
    "title": "fix fa3 prompt cache for dsv3",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-14T08:42:05Z",
    "closed_at": "2025-05-14T08:43:15Z",
    "merged_at": "2025-05-14T08:43:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/893"
  },
  {
    "number": 892,
    "title": "qwen weight repeat for tp_size > kv_head_num",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-14T06:43:29Z",
    "closed_at": "2025-05-14T08:36:35Z",
    "merged_at": "2025-05-14T08:36:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/892"
  },
  {
    "number": 891,
    "title": "improve group_gemm kernel.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-13T12:24:07Z",
    "closed_at": "2025-05-14T07:12:48Z",
    "merged_at": "2025-05-14T07:12:48Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/891"
  },
  {
    "number": 890,
    "title": "sgl_kernel && vllm ops",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-13T08:08:45Z",
    "closed_at": "2025-05-13T15:27:29Z",
    "merged_at": "2025-05-13T15:27:29Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/890"
  },
  {
    "number": 889,
    "title": "[FIX] new whisper",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-12T09:02:59Z",
    "closed_at": "2025-05-12T09:59:01Z",
    "merged_at": "2025-05-12T09:59:01Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/889"
  },
  {
    "number": 888,
    "title": "perf(vit): add optimized rmsnorm and quant operator support",
    "user": "theNiemand",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-12T06:31:06Z",
    "closed_at": "2025-05-13T09:02:20Z",
    "merged_at": "2025-05-13T09:02:20Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/888"
  },
  {
    "number": 887,
    "title": "vit check max batch size infer",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-09T05:28:39Z",
    "closed_at": "2025-05-09T08:40:50Z",
    "merged_at": "2025-05-09T08:40:50Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/887"
  },
  {
    "number": 886,
    "title": "feat(vit_cuda_kernels):add norm quant and some fused ops",
    "user": "theNiemand",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-09T04:31:51Z",
    "closed_at": "2025-05-09T04:49:06Z",
    "merged_at": "2025-05-09T04:49:06Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/886"
  },
  {
    "number": 885,
    "title": "MTP",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-08T15:54:27Z",
    "closed_at": "2025-05-26T08:27:20Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/885"
  },
  {
    "number": 884,
    "title": "fix circle ref",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-07T11:26:25Z",
    "closed_at": "2025-05-07T11:26:38Z",
    "merged_at": "2025-05-07T11:26:38Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/884"
  },
  {
    "number": 883,
    "title": "fix: remove use_dynamic_prompt_cache code in flashinfer_struct.py",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-07T07:02:57Z",
    "closed_at": "2025-05-07T07:21:38Z",
    "merged_at": "2025-05-07T07:21:38Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/883"
  },
  {
    "number": 882,
    "title": "model factory",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-06T13:57:51Z",
    "closed_at": "2025-05-07T07:51:27Z",
    "merged_at": "2025-05-07T07:51:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/882"
  },
  {
    "number": 881,
    "title": "fix httpserver dict.values iteration error.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-06T08:16:51Z",
    "closed_at": "2025-07-23T16:44:52Z",
    "merged_at": "2025-07-23T16:44:52Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/881"
  },
  {
    "number": 880,
    "title": "add check for rope and tuning qwen3 on H200",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-30T16:02:48Z",
    "closed_at": "2025-04-30T16:32:56Z",
    "merged_at": "2025-04-30T16:32:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/880"
  },
  {
    "number": 879,
    "title": "fp8 scale repeat for qwen3",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-29T16:01:44Z",
    "closed_at": "2025-04-29T16:07:40Z",
    "merged_at": "2025-04-29T16:07:40Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/879"
  },
  {
    "number": 878,
    "title": "fix qwen3 infer bug.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-29T15:54:51Z",
    "closed_at": "2025-04-29T15:56:15Z",
    "merged_at": "2025-04-29T15:56:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/878"
  },
  {
    "number": 877,
    "title": "Qwen3MOE for tp8 (repeat kv) and qwen3 dense fix",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-29T13:30:54Z",
    "closed_at": "2025-04-29T13:39:51Z",
    "merged_at": "2025-04-29T13:39:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/877"
  },
  {
    "number": 875,
    "title": "add qwen3 and qwen3_moe",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-29T09:16:59Z",
    "closed_at": "2025-04-29T09:43:24Z",
    "merged_at": "2025-04-29T09:43:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/875"
  },
  {
    "number": 874,
    "title": "[FIX] support rms_norm input is non-contiguous",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-27T07:45:21Z",
    "closed_at": "2025-04-28T05:21:37Z",
    "merged_at": "2025-04-28T05:21:37Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/874"
  },
  {
    "number": 873,
    "title": "remove b_start_loc infer input param.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-27T03:03:10Z",
    "closed_at": "2025-04-27T09:17:10Z",
    "merged_at": "2025-04-27T09:17:10Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/873"
  },
  {
    "number": 872,
    "title": "fix pd split bug for multi node.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-25T16:11:48Z",
    "closed_at": "2025-04-25T16:12:58Z",
    "merged_at": "2025-04-25T16:12:58Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/872"
  },
  {
    "number": 871,
    "title": "update test",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-25T12:05:44Z",
    "closed_at": "2025-04-26T03:36:30Z",
    "merged_at": "2025-04-26T03:36:30Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/871"
  },
  {
    "number": 870,
    "title": "[fix]mistral and mixtral prompt_cache",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-25T12:03:52Z",
    "closed_at": "2025-04-25T12:06:47Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/870"
  },
  {
    "number": 869,
    "title": "recode inferstate_struct.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-25T10:21:14Z",
    "closed_at": "2025-04-26T03:31:53Z",
    "merged_at": "2025-04-26T03:31:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/869"
  },
  {
    "number": 868,
    "title": "[fix]input_ids=0",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-25T10:10:45Z",
    "closed_at": "2025-04-25T10:49:20Z",
    "merged_at": "2025-04-25T10:49:20Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/868"
  },
  {
    "number": 867,
    "title": "fix a bug in the flashinfer for deepseek2",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-25T02:33:43Z",
    "closed_at": "2025-04-25T02:41:51Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/867"
  },
  {
    "number": 866,
    "title": "fix pd decode req classed error.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T13:01:08Z",
    "closed_at": "2025-04-24T13:04:07Z",
    "merged_at": "2025-04-24T13:04:07Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/866"
  },
  {
    "number": 865,
    "title": "test",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T11:35:08Z",
    "closed_at": "2025-04-24T12:09:01Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/865"
  },
  {
    "number": 864,
    "title": "Update pre-commit.yml",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T11:29:07Z",
    "closed_at": "2025-04-24T11:33:42Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/864"
  },
  {
    "number": 863,
    "title": "[Fix] adjust pip install order to keep nccl version as 2.25.1",
    "user": "XHPlus",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T10:16:38Z",
    "closed_at": "2025-04-24T10:17:12Z",
    "merged_at": "2025-04-24T10:17:11Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/863"
  },
  {
    "number": 862,
    "title": "[Fix] use Flash-Attn-3 wheel in Dockerfile",
    "user": "XHPlus",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T10:09:12Z",
    "closed_at": "2025-04-24T10:09:49Z",
    "merged_at": "2025-04-24T10:09:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/862"
  },
  {
    "number": 861,
    "title": "fix prefix cache of ds with fa3",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T09:56:48Z",
    "closed_at": "2025-04-24T12:04:19Z",
    "merged_at": "2025-04-24T12:04:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/861"
  },
  {
    "number": 860,
    "title": "Code clean up",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T09:42:46Z",
    "closed_at": "2025-04-24T09:52:33Z",
    "merged_at": "2025-04-24T09:52:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/860"
  },
  {
    "number": 859,
    "title": "feat: add flashinfer for llama",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T09:29:14Z",
    "closed_at": "2025-04-24T13:32:32Z",
    "merged_at": "2025-04-24T13:32:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/859"
  },
  {
    "number": 858,
    "title": "add Fa3",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T05:46:05Z",
    "closed_at": "2025-04-24T08:25:31Z",
    "merged_at": "2025-04-24T08:25:31Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/858"
  },
  {
    "number": 857,
    "title": "improve post_process.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T04:14:57Z",
    "closed_at": "2025-04-24T06:00:23Z",
    "merged_at": "2025-04-24T06:00:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/857"
  },
  {
    "number": 856,
    "title": "pd with nixl backend",
    "user": "kingder",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T11:13:51Z",
    "closed_at": "2025-09-04T07:25:20Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/856"
  },
  {
    "number": 855,
    "title": "sampling_backend support sglang_kernel",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T08:43:08Z",
    "closed_at": "2025-04-23T09:50:29Z",
    "merged_at": "2025-04-23T09:50:29Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/855"
  },
  {
    "number": 854,
    "title": "add multimodal model's template",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T07:40:21Z",
    "closed_at": "2025-04-23T08:05:30Z",
    "merged_at": "2025-04-23T08:05:30Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/854"
  },
  {
    "number": 853,
    "title": "[Feature] Add OpenAI Compatible Function Call Interface",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T06:18:52Z",
    "closed_at": "2025-04-29T11:44:33Z",
    "merged_at": "2025-04-29T11:44:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/853"
  },
  {
    "number": 851,
    "title": "qwen2_vl support prompt cache.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T03:46:27Z",
    "closed_at": "2025-04-23T03:48:50Z",
    "merged_at": "2025-04-23T03:48:50Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/851"
  },
  {
    "number": 850,
    "title": "reduce the memory of flashinfer",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T02:57:30Z",
    "closed_at": "2025-04-23T05:03:23Z",
    "merged_at": "2025-04-23T05:03:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/850"
  },
  {
    "number": 849,
    "title": "fix mrope kernel error.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T02:56:56Z",
    "closed_at": "2025-04-23T03:02:19Z",
    "merged_at": "2025-04-23T03:02:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/849"
  },
  {
    "number": 847,
    "title": "config server add alloc multimodal token interface.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-22T14:10:32Z",
    "closed_at": "2025-04-23T01:52:02Z",
    "merged_at": "2025-04-23T01:52:01Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/847"
  },
  {
    "number": 846,
    "title": "token_healing mode and out constraint mode use chuncked prefill.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T09:57:06Z",
    "closed_at": "2025-04-21T12:31:23Z",
    "merged_at": "2025-04-21T12:31:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/846"
  },
  {
    "number": 845,
    "title": "fix input_len in benchmark_qps",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T09:00:14Z",
    "closed_at": "2025-04-21T09:13:05Z",
    "merged_at": "2025-04-21T09:13:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/845"
  },
  {
    "number": 844,
    "title": "[add] tri_mrope",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T08:44:06Z",
    "closed_at": "2025-04-22T10:21:29Z",
    "merged_at": "2025-04-22T10:21:29Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/844"
  },
  {
    "number": 843,
    "title": "Mrope triton",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T08:32:00Z",
    "closed_at": "2025-04-21T08:37:17Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/843"
  },
  {
    "number": 842,
    "title": "chunked for diversemode",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T08:24:59Z",
    "closed_at": "2025-04-22T10:09:31Z",
    "merged_at": "2025-04-22T10:09:31Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/842"
  },
  {
    "number": 841,
    "title": "Mrope",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T07:47:56Z",
    "closed_at": "2025-04-21T08:01:12Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/841"
  },
  {
    "number": 840,
    "title": "[add] mrope_triton",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T07:12:39Z",
    "closed_at": "2025-04-21T07:13:21Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/840"
  },
  {
    "number": 837,
    "title": "Support disk radix cache",
    "user": "jayfeather9",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-18T09:04:49Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/837"
  },
  {
    "number": 836,
    "title": "Vit fix",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-18T08:14:38Z",
    "closed_at": "2025-04-18T08:26:27Z",
    "merged_at": "2025-04-18T08:26:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/836"
  },
  {
    "number": 835,
    "title": "add keep alive params in gunicorn",
    "user": "black-eleven",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-18T06:57:27Z",
    "closed_at": "2025-04-18T07:08:51Z",
    "merged_at": "2025-04-18T07:08:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/835"
  },
  {
    "number": 834,
    "title": "feat: audio server and audio multimodal support",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-17T12:32:04Z",
    "closed_at": "2025-04-20T11:37:33Z",
    "merged_at": "2025-04-20T11:37:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/834"
  },
  {
    "number": 833,
    "title": "fix bug for pd mode, decode node need set finish status to time out reqs.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-17T07:26:26Z",
    "closed_at": "2025-04-17T07:27:04Z",
    "merged_at": "2025-04-17T07:27:04Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/833"
  },
  {
    "number": 832,
    "title": "feat: add benchmark_qps in test",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-17T07:21:55Z",
    "closed_at": "2025-04-18T03:46:25Z",
    "merged_at": "2025-04-18T03:46:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/832"
  },
  {
    "number": 831,
    "title": "Fix bug for pd mem manager.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-16T09:47:26Z",
    "closed_at": "2025-04-16T09:50:32Z",
    "merged_at": "2025-04-16T09:50:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/831"
  },
  {
    "number": 829,
    "title": "mutlimodal dp for pd and improve decode",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-16T06:16:42Z",
    "closed_at": "2025-04-16T11:42:10Z",
    "merged_at": "2025-04-16T11:42:10Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/829"
  },
  {
    "number": 828,
    "title": "pd master support multinode.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-16T03:30:45Z",
    "closed_at": "2025-04-16T04:48:37Z",
    "merged_at": "2025-04-16T04:48:37Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/828"
  },
  {
    "number": 827,
    "title": "Qwen2vl fix",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-15T11:31:41Z",
    "closed_at": "2025-04-15T12:43:22Z",
    "merged_at": "2025-04-15T12:43:22Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/827"
  },
  {
    "number": 826,
    "title": "add swap for flash-attention-3 build",
    "user": "XHPlus",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-15T06:23:26Z",
    "closed_at": "2025-04-15T06:23:35Z",
    "merged_at": "2025-04-15T06:23:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/826"
  },
  {
    "number": 825,
    "title": "[Model] Add support for gemma3 model",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-15T04:03:21Z",
    "closed_at": "2025-04-17T10:09:28Z",
    "merged_at": "2025-04-17T10:09:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/825"
  },
  {
    "number": 824,
    "title": "update healh check",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-15T03:21:58Z",
    "closed_at": "2025-04-15T12:18:09Z",
    "merged_at": "2025-04-15T12:18:09Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/824"
  },
  {
    "number": 823,
    "title": "health check update",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-15T03:17:13Z",
    "closed_at": "2025-04-15T03:21:16Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/823"
  },
  {
    "number": 822,
    "title": "add req pause for dp",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-14T06:33:01Z",
    "closed_at": "2025-04-15T04:13:02Z",
    "merged_at": "2025-04-15T04:13:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/822"
  },
  {
    "number": 821,
    "title": "support tarsier2",
    "user": "black-eleven",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-10T07:38:37Z",
    "closed_at": "2025-04-12T02:42:03Z",
    "merged_at": "2025-04-12T02:42:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/821"
  },
  {
    "number": 819,
    "title": "reduce inference memory of vit",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-09T13:13:11Z",
    "closed_at": "2025-04-09T13:46:57Z",
    "merged_at": "2025-04-09T13:46:57Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/819"
  },
  {
    "number": 817,
    "title": "add mps for multimodal",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-09T08:17:54Z",
    "closed_at": "2025-04-09T10:06:36Z",
    "merged_at": "2025-04-09T10:06:36Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/817"
  },
  {
    "number": 816,
    "title": "[FIX] specify NVCC_THREADS=1 to pass the docker build in GitHub CI",
    "user": "XHPlus",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-09T01:57:27Z",
    "closed_at": "2025-04-09T01:57:35Z",
    "merged_at": "2025-04-09T01:57:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/816"
  },
  {
    "number": 815,
    "title": "[FIX] specify MAX_JOB=1 to pass the docker build in GitHub CI",
    "user": "XHPlus",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T15:11:10Z",
    "closed_at": "2025-04-08T15:11:20Z",
    "merged_at": "2025-04-08T15:11:20Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/815"
  },
  {
    "number": 814,
    "title": "Fix ep",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T13:07:01Z",
    "closed_at": "2025-04-09T05:35:12Z",
    "merged_at": "2025-04-09T05:35:12Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/814"
  },
  {
    "number": 813,
    "title": "reduce kv transfer process to num of tp for pd.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T10:19:49Z",
    "closed_at": "2025-04-11T15:50:34Z",
    "merged_at": "2025-04-11T15:50:34Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/813"
  },
  {
    "number": 812,
    "title": "[FIX] specify MAX_JOB=4 to pass the docker build in GitHub CI",
    "user": "XHPlus",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T08:01:27Z",
    "closed_at": "2025-04-08T08:03:55Z",
    "merged_at": "2025-04-08T08:03:55Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/812"
  },
  {
    "number": 811,
    "title": "Fix image api",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T07:49:25Z",
    "closed_at": "2025-04-08T08:00:56Z",
    "merged_at": "2025-04-08T08:00:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/811"
  },
  {
    "number": 810,
    "title": "Fix image api",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T07:31:34Z",
    "closed_at": "2025-04-08T07:45:03Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/810"
  },
  {
    "number": 809,
    "title": "support pull image with proxy.",
    "user": "kingder",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T06:42:26Z",
    "closed_at": "2025-04-08T07:35:15Z",
    "merged_at": "2025-04-08T07:35:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/809"
  },
  {
    "number": 808,
    "title": "fix dpep",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T05:40:47Z",
    "closed_at": "2025-04-08T06:16:01Z",
    "merged_at": "2025-04-08T06:16:01Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/808"
  },
  {
    "number": 806,
    "title": "[fix]fix image api",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-07T12:27:36Z",
    "closed_at": "2025-04-07T12:30:19Z",
    "merged_at": "2025-04-07T12:30:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/806"
  },
  {
    "number": 805,
    "title": "Fix openai image",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-07T12:23:18Z",
    "closed_at": "2025-04-07T12:23:56Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/805"
  },
  {
    "number": 804,
    "title": "fix Dockerfile",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-07T11:13:47Z",
    "closed_at": "2025-04-07T11:13:59Z",
    "merged_at": "2025-04-07T11:13:59Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/804"
  },
  {
    "number": 803,
    "title": "fix image url read.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-07T09:01:53Z",
    "closed_at": "2025-04-07T10:56:21Z",
    "merged_at": "2025-04-07T10:56:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/803"
  },
  {
    "number": 802,
    "title": "fix gunivorn timeout error.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-07T04:23:32Z",
    "closed_at": "2025-04-07T04:24:54Z",
    "merged_at": "2025-04-07T04:24:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/802"
  },
  {
    "number": 801,
    "title": "[FIX] fix FlashAttention calling param to sync with hopper implementation in v2.7.4.post1",
    "user": "XHPlus",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-07T03:21:36Z",
    "closed_at": "2025-04-07T04:18:37Z",
    "merged_at": "2025-04-07T04:18:37Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/801"
  },
  {
    "number": 800,
    "title": "chuncked prefill must enable prompt cache.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-06T01:09:55Z",
    "closed_at": "2025-04-06T01:13:23Z",
    "merged_at": "2025-04-06T01:13:22Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/800"
  },
  {
    "number": 799,
    "title": "Fix stream ret",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-03T11:30:12Z",
    "closed_at": "2025-04-03T11:32:58Z",
    "merged_at": "2025-04-03T11:32:58Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/799"
  },
  {
    "number": 798,
    "title": "[add]add tokens_num api",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-03T10:59:46Z",
    "closed_at": "2025-04-07T07:49:34Z",
    "merged_at": "2025-04-07T07:49:34Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/798"
  },
  {
    "number": 797,
    "title": "fix mutlimodal_resources release.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-03T10:12:54Z",
    "closed_at": "2025-04-03T10:23:26Z",
    "merged_at": "2025-04-03T10:23:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/797"
  },
  {
    "number": 796,
    "title": "add yarn support for qwq",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-03T09:26:35Z",
    "closed_at": "2025-04-03T09:27:15Z",
    "merged_at": "2025-04-03T09:27:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/796"
  },
  {
    "number": 795,
    "title": "add deepseek demo start.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-03T04:18:10Z",
    "closed_at": "2025-04-03T04:19:05Z",
    "merged_at": "2025-04-03T04:19:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/795"
  },
  {
    "number": 794,
    "title": "fix httpserver mutlinode_tp mode code.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-03T03:06:04Z",
    "closed_at": "2025-04-03T03:08:12Z",
    "merged_at": "2025-04-03T03:08:12Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/794"
  },
  {
    "number": 793,
    "title": "[FIX] update flash_attention3 calling in ViT to sync with official repo",
    "user": "XHPlus",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-02T15:27:07Z",
    "closed_at": "2025-04-03T16:08:48Z",
    "merged_at": "2025-04-03T16:08:48Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/793"
  },
  {
    "number": 792,
    "title": "Update dependency",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-02T13:15:27Z",
    "closed_at": "2025-04-02T13:17:08Z",
    "merged_at": "2025-04-02T13:17:08Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/792"
  },
  {
    "number": 791,
    "title": "fix: sgl-kernel typo",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-02T12:54:20Z",
    "closed_at": "2025-04-02T12:54:30Z",
    "merged_at": "2025-04-02T12:54:30Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/791"
  },
  {
    "number": 790,
    "title": "python3.10",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-02T12:13:41Z",
    "closed_at": "2025-04-02T12:14:19Z",
    "merged_at": "2025-04-02T12:14:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/790"
  },
  {
    "number": 789,
    "title": "fix dependency",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-02T12:07:42Z",
    "closed_at": "2025-04-02T12:07:52Z",
    "merged_at": "2025-04-02T12:07:52Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/789"
  },
  {
    "number": 788,
    "title": "Prefill overlap",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-02T07:49:01Z",
    "closed_at": "2025-04-02T11:52:53Z",
    "merged_at": "2025-04-02T11:52:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/788"
  },
  {
    "number": 787,
    "title": "support qwen2_5_vl",
    "user": "black-eleven",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-31T09:58:20Z",
    "closed_at": "2025-04-02T14:23:43Z",
    "merged_at": "2025-04-02T14:23:43Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/787"
  },
  {
    "number": 786,
    "title": "add deepseek prefill microbatch overlap.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-31T05:39:29Z",
    "closed_at": "2025-03-31T06:24:29Z",
    "merged_at": "2025-03-31T06:24:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/786"
  },
  {
    "number": 785,
    "title": "Fix vision dp_size = 1",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-28T09:22:34Z",
    "closed_at": "2025-03-28T09:23:29Z",
    "merged_at": "2025-03-28T09:23:29Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/785"
  },
  {
    "number": 783,
    "title": "DeepseekV3 support deepep, deepgemm, PD, DP TP SP Mix mode.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-27T12:00:38Z",
    "closed_at": "2025-03-28T07:40:32Z",
    "merged_at": "2025-03-28T07:40:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/783"
  },
  {
    "number": 782,
    "title": "fix nvlink detect",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-26T08:18:24Z",
    "closed_at": "2025-03-28T08:07:47Z",
    "merged_at": "2025-03-28T08:07:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/782"
  },
  {
    "number": 781,
    "title": "Fix constrained decoding in deepep branch",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-25T06:29:55Z",
    "closed_at": "2025-03-25T06:53:40Z",
    "merged_at": "2025-03-25T06:53:40Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/781"
  },
  {
    "number": 780,
    "title": "Openai api support image",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-24T10:06:06Z",
    "closed_at": "2025-03-28T10:04:51Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/780"
  },
  {
    "number": 779,
    "title": "[add]openai_api_support_image",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-24T06:52:09Z",
    "closed_at": "2025-03-24T09:50:56Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/779"
  },
  {
    "number": 778,
    "title": "[add]openai_api_support_image",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-24T06:45:40Z",
    "closed_at": "2025-03-24T06:48:23Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/778"
  },
  {
    "number": 777,
    "title": "[Draft] [Feature] Add Flux Kernel Support for TP+SP Parallel",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-23T09:14:35Z",
    "closed_at": "2025-05-29T05:33:59Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/777"
  },
  {
    "number": 775,
    "title": "Health update",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-21T08:19:42Z",
    "closed_at": "2025-03-21T08:46:24Z",
    "merged_at": "2025-03-21T08:46:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/775"
  },
  {
    "number": 774,
    "title": "quick fix for dsv3 perchannel/pertensor (online quantization)",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-20T12:44:37Z",
    "closed_at": "2025-03-20T13:10:46Z",
    "merged_at": "2025-03-20T13:10:46Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/774"
  },
  {
    "number": 773,
    "title": "fix health timeout",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-18T06:56:19Z",
    "closed_at": "2025-03-18T07:04:07Z",
    "merged_at": "2025-03-18T07:04:07Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/773"
  },
  {
    "number": 772,
    "title": "[draft] use better gelu, rms_norm and fa3 ops",
    "user": "POI-WX",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-17T11:30:10Z",
    "closed_at": "2025-03-28T09:15:39Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/772"
  },
  {
    "number": 768,
    "title": "Micro batchs",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-14T10:00:03Z",
    "closed_at": "2025-03-28T08:08:41Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/768"
  },
  {
    "number": 766,
    "title": "speedup the inference of vit (gelu, rmsnorm and fa3 for H-series) and chunked prefill for multimodal",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-12T08:56:47Z",
    "closed_at": "2025-04-02T06:15:21Z",
    "merged_at": "2025-04-02T06:15:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/766"
  },
  {
    "number": 765,
    "title": "deepseek2 support pd multi dp kv trans.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-11T10:11:14Z",
    "closed_at": "2025-03-12T02:23:47Z",
    "merged_at": "2025-03-12T02:23:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/765"
  },
  {
    "number": 764,
    "title": "update test script",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-11T08:00:45Z",
    "closed_at": "2025-03-11T08:04:38Z",
    "merged_at": "2025-03-11T08:04:38Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/764"
  },
  {
    "number": 763,
    "title": "add kv trans v2 kernel for dp mode pd",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-10T10:33:14Z",
    "closed_at": "2025-03-11T02:38:29Z",
    "merged_at": "2025-03-11T02:38:29Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/763"
  },
  {
    "number": 762,
    "title": " modelinference refactor",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-10T08:51:11Z",
    "closed_at": "2025-03-11T07:28:23Z",
    "merged_at": "2025-03-11T07:28:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/762"
  },
  {
    "number": 761,
    "title": "add test_accuracy.py",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-10T06:33:15Z",
    "closed_at": "2025-03-10T06:40:47Z",
    "merged_at": "2025-03-10T06:40:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/761"
  },
  {
    "number": 760,
    "title": "Raccoon",
    "user": "Watebear",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-10T06:00:00Z",
    "closed_at": "2025-03-10T06:07:04Z",
    "merged_at": "2025-03-10T06:07:04Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/760"
  },
  {
    "number": 759,
    "title": "add prompt tokens, skip_spe for raccoon",
    "user": "Watebear",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-10T05:35:30Z",
    "closed_at": "2025-03-10T05:58:11Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/759"
  },
  {
    "number": 758,
    "title": "reduce kv transfer process to num of tp for pd.",
    "user": "kingder",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-07T12:09:11Z",
    "closed_at": "2025-04-14T02:28:15Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/758"
  },
  {
    "number": 757,
    "title": "fix internvl image token",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-06T13:28:17Z",
    "closed_at": "2025-03-07T02:13:54Z",
    "merged_at": "2025-03-07T02:13:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/757"
  },
  {
    "number": 756,
    "title": "Add PD disaggregating startup method in documentation",
    "user": "FDH21",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-05T14:42:12Z",
    "closed_at": "2025-03-06T02:29:53Z",
    "merged_at": "2025-03-06T02:29:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/756"
  },
  {
    "number": 755,
    "title": "update health_check, add HEALTH_FAILURE_THRESHOLD",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-04T06:05:16Z",
    "closed_at": "2025-03-04T06:14:27Z",
    "merged_at": "2025-03-04T06:14:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/755"
  },
  {
    "number": 753,
    "title": "fix /tokens docs && tag v1.0.1",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-03T09:32:02Z",
    "closed_at": "2025-03-03T09:33:29Z",
    "merged_at": "2025-03-03T09:33:29Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/753"
  },
  {
    "number": 752,
    "title": "Multinode",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-03T07:06:11Z",
    "closed_at": "2025-03-06T03:43:32Z",
    "merged_at": "2025-03-06T03:43:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/752"
  },
  {
    "number": 751,
    "title": "add support for  multinode tp",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-28T08:23:37Z",
    "closed_at": "2025-03-01T10:19:58Z",
    "merged_at": "2025-03-01T10:19:58Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/751"
  },
  {
    "number": 750,
    "title": "Fix Unit-test in PR: Add xgrammar",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-27T02:56:40Z",
    "closed_at": "2025-02-27T02:59:53Z",
    "merged_at": "2025-02-27T02:59:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/750"
  },
  {
    "number": 749,
    "title": "fix: add flashinfer-python in the requirements.txt",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-26T10:35:58Z",
    "closed_at": "2025-02-26T11:09:00Z",
    "merged_at": "2025-02-26T11:09:00Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/749"
  },
  {
    "number": 748,
    "title": "Fix tokens2",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-26T10:21:39Z",
    "closed_at": "2025-02-26T11:23:43Z",
    "merged_at": "2025-02-26T11:23:43Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/748"
  },
  {
    "number": 747,
    "title": "fix tokens",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-25T07:37:00Z",
    "closed_at": "2025-02-26T11:23:54Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/747"
  },
  {
    "number": 745,
    "title": "deepseekv3 bmm noquant and fix moe gemm bug.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-22T12:28:50Z",
    "closed_at": "2025-02-22T13:23:28Z",
    "merged_at": "2025-02-22T13:23:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/745"
  },
  {
    "number": 744,
    "title": "Improve the accuracy of deepseekv3",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-22T04:40:31Z",
    "closed_at": "2025-02-22T07:00:12Z",
    "merged_at": "2025-02-22T07:00:12Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/744"
  },
  {
    "number": 743,
    "title": "fix: fix a precision bug in the context_flashattention",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-21T03:42:15Z",
    "closed_at": "2025-02-21T03:50:42Z",
    "merged_at": "2025-02-21T03:50:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/743"
  },
  {
    "number": 742,
    "title": "add RETURN_LIST for tgi_api",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-20T06:54:54Z",
    "closed_at": "2025-02-20T06:55:35Z",
    "merged_at": "2025-02-20T06:55:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/742"
  },
  {
    "number": 741,
    "title": "fix pause reqs",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-20T05:24:55Z",
    "closed_at": "2025-02-20T05:28:50Z",
    "merged_at": "2025-02-20T05:28:50Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/741"
  },
  {
    "number": 740,
    "title": "Benchclient",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-19T14:02:12Z",
    "closed_at": "2025-02-19T14:15:14Z",
    "merged_at": "2025-02-19T14:15:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/740"
  },
  {
    "number": 737,
    "title": "fuse fp8 quant in kv copying and add flashinfer decode mla operator in the attention module",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-18T08:03:42Z",
    "closed_at": "2025-02-26T10:00:15Z",
    "merged_at": "2025-02-26T10:00:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/737"
  },
  {
    "number": 734,
    "title": "update dependcy",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-18T03:16:50Z",
    "closed_at": "2025-02-18T03:16:57Z",
    "merged_at": "2025-02-18T03:16:57Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/734"
  },
  {
    "number": 733,
    "title": "update doc and launch params",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-17T16:36:10Z",
    "closed_at": "2025-02-17T16:36:53Z",
    "merged_at": "2025-02-17T16:36:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/733"
  },
  {
    "number": 732,
    "title": "Enable CC_METHOD for dsv3 by default && fix test script && fix tgi stream api",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-17T14:27:14Z",
    "closed_at": "2025-02-17T14:27:53Z",
    "merged_at": "2025-02-17T14:27:52Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/732"
  },
  {
    "number": 731,
    "title": "fix promptcache for v3 && add H200 kernel configs",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-17T08:10:04Z",
    "closed_at": "2025-02-17T10:33:45Z",
    "merged_at": "2025-02-17T10:33:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/731"
  },
  {
    "number": 730,
    "title": "supporting multinode",
    "user": "jayfeather9",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-16T07:08:02Z",
    "closed_at": "2025-02-28T08:23:00Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/730"
  },
  {
    "number": 729,
    "title": "fix stream api for newer pydantic",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-15T09:27:57Z",
    "closed_at": "2025-02-15T09:59:06Z",
    "merged_at": "2025-02-15T09:59:06Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/729"
  },
  {
    "number": 728,
    "title": "vllm Fp8w8a8 block",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-15T08:18:10Z",
    "closed_at": "2025-02-15T09:22:13Z",
    "merged_at": "2025-02-15T09:22:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/728"
  },
  {
    "number": 727,
    "title": "fix tgi details interface",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-14T07:30:04Z",
    "closed_at": "2025-02-14T07:30:17Z",
    "merged_at": "2025-02-14T07:30:17Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/727"
  },
  {
    "number": 726,
    "title": "update tgi api for beam output",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-12T09:51:59Z",
    "closed_at": "2025-02-12T09:54:03Z",
    "merged_at": "2025-02-12T09:54:03Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/726"
  },
  {
    "number": 725,
    "title": "fix prefix noquant bug",
    "user": "helloyongyang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-12T05:22:38Z",
    "closed_at": "2025-02-12T05:59:31Z",
    "merged_at": "2025-02-12T05:59:31Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/725"
  },
  {
    "number": 724,
    "title": "fix grouped topk bf16 sigmoid mode.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-11T09:46:03Z",
    "closed_at": "2025-02-11T09:47:15Z",
    "merged_at": "2025-02-11T09:47:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/724"
  },
  {
    "number": 723,
    "title": "add grouped_topk_cuda",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-11T07:29:48Z",
    "closed_at": "2025-02-11T09:24:57Z",
    "merged_at": "2025-02-11T09:24:57Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/723"
  },
  {
    "number": 722,
    "title": "support prefix noquant",
    "user": "helloyongyang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-11T06:48:18Z",
    "closed_at": "2025-02-11T07:34:27Z",
    "merged_at": "2025-02-11T07:34:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/722"
  },
  {
    "number": 721,
    "title": "support prefix noquant",
    "user": "helloyongyang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-10T13:53:26Z",
    "closed_at": "2025-02-11T05:59:22Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/721"
  },
  {
    "number": 720,
    "title": "add triton grouped_topk",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-10T12:49:33Z",
    "closed_at": "2025-02-11T05:10:31Z",
    "merged_at": "2025-02-11T05:10:31Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/720"
  },
  {
    "number": 719,
    "title": "deepseekv3 cc mode fixed",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-10T08:12:39Z",
    "closed_at": "2025-02-10T08:40:35Z",
    "merged_at": "2025-02-10T08:40:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/719"
  },
  {
    "number": 718,
    "title": "fix moe_align1 kernel performance issue in prefill stage.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-10T03:01:27Z",
    "closed_at": "2025-02-10T03:20:28Z",
    "merged_at": "2025-02-10T03:20:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/718"
  },
  {
    "number": 717,
    "title": "Chunked prefill",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-08T13:31:15Z",
    "closed_at": "2025-02-14T07:25:49Z",
    "merged_at": "2025-02-14T07:25:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/717"
  },
  {
    "number": 716,
    "title": "RefactoredUse shared memory for request information management and significantly reducing CPU overhead.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-06T06:29:17Z",
    "closed_at": "2025-02-06T08:31:13Z",
    "merged_at": "2025-02-06T08:31:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/716"
  },
  {
    "number": 715,
    "title": "parse stop_sequences",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-24T11:11:14Z",
    "closed_at": "2025-01-24T11:11:25Z",
    "merged_at": "2025-01-24T11:11:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/715"
  },
  {
    "number": 714,
    "title": "docs: redesign the arch",
    "user": "PannenetsF",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-24T07:38:16Z",
    "closed_at": "2025-01-24T11:02:43Z",
    "merged_at": "2025-01-24T11:02:43Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/714"
  },
  {
    "number": 713,
    "title": "docs: add blog link",
    "user": "PannenetsF",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-24T02:57:10Z",
    "closed_at": "2025-01-24T04:22:35Z",
    "merged_at": "2025-01-24T04:22:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/713"
  },
  {
    "number": 712,
    "title": "feat: add deepseekv2_bf16kv and deepseekv2_fp8kv modes",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-23T12:37:50Z",
    "closed_at": "2025-02-13T05:28:06Z",
    "merged_at": "2025-02-13T05:28:06Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/712"
  },
  {
    "number": 711,
    "title": "Support preload prompt cache kv buffer",
    "user": "helloyongyang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-23T09:26:11Z",
    "closed_at": "2025-02-10T13:33:41Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/711"
  },
  {
    "number": 710,
    "title": "fix openai stream & update chat template",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-23T06:08:57Z",
    "closed_at": "2025-01-23T06:13:29Z",
    "merged_at": "2025-01-23T06:13:29Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/710"
  },
  {
    "number": 709,
    "title": "fix vit quantcfg init error.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-23T03:19:06Z",
    "closed_at": "2025-01-23T03:19:41Z",
    "merged_at": "2025-01-23T03:19:41Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/709"
  },
  {
    "number": 707,
    "title": "refine log",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-16T07:53:01Z",
    "closed_at": "2025-01-16T07:53:13Z",
    "merged_at": "2025-01-16T07:53:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/707"
  },
  {
    "number": 706,
    "title": "fix bug for waiting queue.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-16T04:40:47Z",
    "closed_at": "2025-01-16T04:42:19Z",
    "merged_at": "2025-01-16T04:42:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/706"
  },
  {
    "number": 705,
    "title": "Add a switch to custom_allgather import",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-16T01:46:30Z",
    "closed_at": "2025-01-16T01:47:26Z",
    "merged_at": "2025-01-16T01:47:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/705"
  },
  {
    "number": 704,
    "title": "fix: vit config",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-15T09:40:59Z",
    "closed_at": "2025-01-15T09:44:24Z",
    "merged_at": "2025-01-15T09:44:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/704"
  },
  {
    "number": 703,
    "title": "feat add bmm_scaled_fp8",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-15T06:23:42Z",
    "closed_at": "2025-01-22T02:24:55Z",
    "merged_at": "2025-01-22T02:24:55Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/703"
  },
  {
    "number": 702,
    "title": "refactor quantization for static quantized weight loading and add deepseek_v3",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-13T06:17:15Z",
    "closed_at": "2025-01-13T11:05:52Z",
    "merged_at": "2025-01-13T11:05:52Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/702"
  },
  {
    "number": 701,
    "title": "Add Xgrammar Support",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-07T11:17:02Z",
    "closed_at": "2025-02-26T09:33:53Z",
    "merged_at": "2025-02-26T09:33:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/701"
  },
  {
    "number": 700,
    "title": "Vsm llama pr",
    "user": "PannenetsF",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-07T03:19:26Z",
    "closed_at": "2025-01-26T02:29:43Z",
    "merged_at": "2025-01-26T02:29:43Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/700"
  },
  {
    "number": 699,
    "title": "[debug]: add some debug log",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-06T10:53:00Z",
    "closed_at": "2025-01-06T10:58:14Z",
    "merged_at": "2025-01-06T10:58:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/699"
  },
  {
    "number": 698,
    "title": "add sample_param logs and env: HEALTH_TIMEOUT",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-06T09:56:46Z",
    "closed_at": "2025-01-06T09:57:18Z",
    "merged_at": "2025-01-06T09:57:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/698"
  },
  {
    "number": 697,
    "title": "overlap post sample.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-06T03:41:53Z",
    "closed_at": "2025-01-06T03:42:32Z",
    "merged_at": "2025-01-06T03:42:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/697"
  },
  {
    "number": 696,
    "title": "udpate mla decode attention.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-04T09:29:55Z",
    "closed_at": "2025-01-04T09:34:04Z",
    "merged_at": "2025-01-04T09:34:04Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/696"
  },
  {
    "number": 695,
    "title": "update config and fix dp router error.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-03T11:03:08Z",
    "closed_at": "2025-01-03T11:18:56Z",
    "merged_at": "2025-01-03T11:18:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/695"
  },
  {
    "number": 694,
    "title": "better cuda graph mla decode kernel.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-02T11:12:23Z",
    "closed_at": "2025-01-03T02:58:44Z",
    "merged_at": "2025-01-03T02:58:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/694"
  },
  {
    "number": 693,
    "title": "feat: add _context_attention_kernel_with_CC in deepseek2",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-02T08:13:57Z",
    "closed_at": "2025-01-13T01:45:32Z",
    "merged_at": "2025-01-13T01:45:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/693"
  },
  {
    "number": 692,
    "title": "add custom allgather(into tensor)",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-02T06:23:03Z",
    "closed_at": "2025-01-02T10:56:25Z",
    "merged_at": "2025-01-02T10:56:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/692"
  },
  {
    "number": 691,
    "title": "pd mode use p2p triton kernel to manage kv trans && refactor deepseekv2 code",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-30T06:14:46Z",
    "closed_at": "2024-12-30T07:20:07Z",
    "merged_at": "2024-12-30T07:20:07Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/691"
  },
  {
    "number": 690,
    "title": "update health check",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-27T09:37:36Z",
    "closed_at": "2024-12-27T09:38:13Z",
    "merged_at": "2024-12-27T09:38:12Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/690"
  },
  {
    "number": 689,
    "title": "update configs.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-26T10:11:32Z",
    "closed_at": "2024-12-26T10:12:42Z",
    "merged_at": "2024-12-26T10:12:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/689"
  },
  {
    "number": 688,
    "title": "remove vllm fuse_moe kernel and add moe_sum_reduce, moe_silu_and_mul kernel.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-26T09:12:22Z",
    "closed_at": "2024-12-26T09:17:17Z",
    "merged_at": "2024-12-26T09:17:17Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/688"
  },
  {
    "number": 687,
    "title": "add H800 and A800 mla decode configs.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-26T01:52:59Z",
    "closed_at": "2024-12-26T03:01:17Z",
    "merged_at": "2024-12-26T03:01:17Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/687"
  },
  {
    "number": 686,
    "title": "add A800 grouped moe kernel json configs.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-25T10:52:17Z",
    "closed_at": "2024-12-25T10:52:50Z",
    "merged_at": "2024-12-25T10:52:50Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/686"
  },
  {
    "number": 685,
    "title": "fix config search type error.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-25T10:37:54Z",
    "closed_at": "2024-12-25T10:38:35Z",
    "merged_at": "2024-12-25T10:38:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/685"
  },
  {
    "number": 684,
    "title": "fix kernel config json load.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-25T10:22:14Z",
    "closed_at": "2024-12-25T10:24:34Z",
    "merged_at": "2024-12-25T10:24:34Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/684"
  },
  {
    "number": 683,
    "title": "fix tunning code.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-25T09:52:50Z",
    "closed_at": "2024-12-25T09:53:22Z",
    "merged_at": "2024-12-25T09:53:22Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/683"
  },
  {
    "number": 682,
    "title": "add H800 grouped moe kernel configs.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-25T09:33:18Z",
    "closed_at": "2024-12-25T09:33:56Z",
    "merged_at": "2024-12-25T09:33:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/682"
  },
  {
    "number": 681,
    "title": "add kernel config tuning way to get better performance.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-25T09:03:17Z",
    "closed_at": "2024-12-25T09:18:45Z",
    "merged_at": "2024-12-25T09:18:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/681"
  },
  {
    "number": 680,
    "title": "misc: update python requirements",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-24T13:32:00Z",
    "closed_at": "2024-12-25T01:36:10Z",
    "merged_at": "2024-12-25T01:36:10Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/680"
  },
  {
    "number": 678,
    "title": "[feature] add a grouped moe kernel. better performance in some case.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-24T09:08:52Z",
    "closed_at": "2024-12-25T09:19:44Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/678"
  },
  {
    "number": 677,
    "title": "fix bug for requrements.txt",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-24T05:37:26Z",
    "closed_at": "2024-12-24T05:48:01Z",
    "merged_at": "2024-12-24T05:48:01Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/677"
  },
  {
    "number": 675,
    "title": "add generation cfg parse",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-23T11:26:35Z",
    "closed_at": "2024-12-24T09:01:14Z",
    "merged_at": "2024-12-24T09:01:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/675"
  },
  {
    "number": 674,
    "title": "fix init",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-20T10:06:59Z",
    "closed_at": "2024-12-20T10:08:48Z",
    "merged_at": "2024-12-20T10:08:48Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/674"
  },
  {
    "number": 673,
    "title": "fix mistral13b tp",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-20T07:24:09Z",
    "closed_at": "2024-12-20T07:26:27Z",
    "merged_at": "2024-12-20T07:26:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/673"
  },
  {
    "number": 672,
    "title": "Deepseek rope fix",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-20T05:30:53Z",
    "closed_at": "2024-12-20T05:33:00Z",
    "merged_at": "2024-12-20T05:33:00Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/672"
  },
  {
    "number": 671,
    "title": "Fix deepseek  & update v1/completions",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-19T07:14:28Z",
    "closed_at": "2024-12-19T07:24:44Z",
    "merged_at": "2024-12-19T07:24:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/671"
  },
  {
    "number": 670,
    "title": "support for dp + tp end2end",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-18T08:13:50Z",
    "closed_at": "2024-12-21T07:31:47Z",
    "merged_at": "2024-12-21T07:31:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/670"
  },
  {
    "number": 669,
    "title": "edp with cc+acc is done",
    "user": "charlotteroes",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-16T11:37:28Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/669"
  },
  {
    "number": 668,
    "title": "gqa attention add Tuning code",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-16T05:30:39Z",
    "closed_at": "2024-12-16T05:58:26Z",
    "merged_at": "2024-12-16T05:58:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/668"
  },
  {
    "number": 667,
    "title": "pd mode. batch kv trans.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-15T14:28:01Z",
    "closed_at": "2024-12-15T14:31:16Z",
    "merged_at": "2024-12-15T14:31:16Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/667"
  },
  {
    "number": 666,
    "title": "Improve pd mode prell and decode node use parral to handle batch reqs.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-13T14:40:09Z",
    "closed_at": "2024-12-13T14:40:49Z",
    "merged_at": "2024-12-13T14:40:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/666"
  },
  {
    "number": 665,
    "title": "[feature]moe etp done, without group greed. (Charlotteroes main)",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-13T06:26:25Z",
    "closed_at": "2024-12-13T06:27:15Z",
    "merged_at": "2024-12-13T06:27:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/665"
  },
  {
    "number": 664,
    "title": "[Feature] improve p d mode performance.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-12T11:34:02Z",
    "closed_at": "2024-12-13T05:54:32Z",
    "merged_at": "2024-12-13T05:54:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/664"
  },
  {
    "number": 663,
    "title": "Vit triton (fp + quant / tp + dp), custom image pre_process",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-11T08:33:32Z",
    "closed_at": "2024-12-25T08:31:51Z",
    "merged_at": "2024-12-25T08:31:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/663"
  },
  {
    "number": 662,
    "title": "[feature] add deepseekv2 edp support, based on pr628",
    "user": "Vincent-syr",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-10T15:18:43Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/662"
  },
  {
    "number": 661,
    "title": "[BugFix] Fix silu kernel",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-10T10:07:06Z",
    "closed_at": "2024-12-11T14:33:05Z",
    "merged_at": "2024-12-11T14:33:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/661"
  },
  {
    "number": 660,
    "title": "fix api_start.py",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-10T09:48:47Z",
    "closed_at": "2024-12-10T09:49:23Z",
    "merged_at": "2024-12-10T09:49:22Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/660"
  },
  {
    "number": 659,
    "title": "Static quant for vllm-w8a8",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-09T10:04:20Z",
    "closed_at": "2024-12-10T07:10:20Z",
    "merged_at": "2024-12-10T07:10:20Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/659"
  },
  {
    "number": 658,
    "title": "Compatible with lower versions of torch",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-09T05:20:20Z",
    "closed_at": "2024-12-09T05:31:00Z",
    "merged_at": "2024-12-09T05:31:00Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/658"
  },
  {
    "number": 657,
    "title": "[kernel] Remove splitfuse kernel",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-06T11:00:14Z",
    "closed_at": "2024-12-09T01:37:26Z",
    "merged_at": "2024-12-09T01:37:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/657"
  },
  {
    "number": 656,
    "title": "update transformers",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-06T10:06:44Z",
    "closed_at": "2024-12-06T10:07:25Z",
    "merged_at": "2024-12-06T10:07:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/656"
  },
  {
    "number": 655,
    "title": "refactor reduce",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-06T06:59:33Z",
    "closed_at": "2024-12-06T07:54:51Z",
    "merged_at": "2024-12-06T07:54:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/655"
  },
  {
    "number": 654,
    "title": "fix reduce stuck on h100 with graph",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-06T05:52:28Z",
    "closed_at": "2024-12-06T05:52:51Z",
    "merged_at": "2024-12-06T05:52:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/654"
  },
  {
    "number": 653,
    "title": "rpyc and zmq use unix socket. ",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-06T05:18:51Z",
    "closed_at": "2024-12-06T05:22:56Z",
    "merged_at": "2024-12-06T05:22:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/653"
  },
  {
    "number": 652,
    "title": "[misc] Support deepseek splitfuse mode.",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-06T03:38:02Z",
    "closed_at": "2024-12-06T07:05:50Z",
    "merged_at": "2024-12-06T07:05:50Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/652"
  },
  {
    "number": 651,
    "title": "fix_openai_chat_bug",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-05T07:13:42Z",
    "closed_at": "2024-12-05T07:16:14Z",
    "merged_at": "2024-12-05T07:16:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/651"
  },
  {
    "number": 650,
    "title": "bug fix for max len prefill check error",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-05T06:08:05Z",
    "closed_at": "2024-12-05T06:13:53Z",
    "merged_at": "2024-12-05T06:13:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/650"
  },
  {
    "number": 649,
    "title": "fix format",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-05T01:15:09Z",
    "closed_at": "2024-12-05T01:15:44Z",
    "merged_at": "2024-12-05T01:15:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/649"
  },
  {
    "number": 648,
    "title": "add __init__.py",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-04T14:59:32Z",
    "closed_at": "2024-12-04T15:01:18Z",
    "merged_at": "2024-12-04T15:01:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/648"
  },
  {
    "number": 647,
    "title": "independent of vllm",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-04T13:16:41Z",
    "closed_at": "2024-12-09T06:20:01Z",
    "merged_at": "2024-12-09T06:20:01Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/647"
  },
  {
    "number": 646,
    "title": "fix rpyc tcp delay",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-04T11:04:17Z",
    "closed_at": "2024-12-04T11:04:50Z",
    "merged_at": "2024-12-04T11:04:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/646"
  },
  {
    "number": 645,
    "title": "fix rpyc tcp delay",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-04T10:06:09Z",
    "closed_at": "2024-12-04T10:07:02Z",
    "merged_at": "2024-12-04T10:07:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/645"
  },
  {
    "number": 643,
    "title": "opt: refactor some code for acc",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-04T06:09:36Z",
    "closed_at": "2024-12-09T02:45:20Z",
    "merged_at": "2024-12-09T02:45:20Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/643"
  },
  {
    "number": 642,
    "title": "fix log",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-04T05:44:30Z",
    "closed_at": "2024-12-04T05:45:50Z",
    "merged_at": "2024-12-04T05:45:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/642"
  },
  {
    "number": 641,
    "title": "better pickle mode",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-04T05:35:47Z",
    "closed_at": "2024-12-04T05:38:32Z",
    "merged_at": "2024-12-04T05:38:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/641"
  },
  {
    "number": 639,
    "title": "fix typo",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-04T04:12:17Z",
    "closed_at": "2024-12-04T04:12:25Z",
    "merged_at": "2024-12-04T04:12:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/639"
  },
  {
    "number": 638,
    "title": "Fix acc",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-03T13:46:24Z",
    "closed_at": "2024-12-04T02:59:51Z",
    "merged_at": "2024-12-04T02:59:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/638"
  },
  {
    "number": 637,
    "title": "Fix batch test",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-03T07:21:33Z",
    "closed_at": "2024-12-03T07:26:17Z",
    "merged_at": "2024-12-03T07:26:17Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/637"
  },
  {
    "number": 636,
    "title": "fix test",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-03T03:14:58Z",
    "closed_at": "2024-12-03T03:15:33Z",
    "merged_at": "2024-12-03T03:15:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/636"
  },
  {
    "number": 635,
    "title": "add qwen backend for internvl",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-02T12:26:21Z",
    "closed_at": "2024-12-02T12:27:12Z",
    "merged_at": "2024-12-02T12:27:12Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/635"
  },
  {
    "number": 634,
    "title": "complete test module",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-02T10:40:30Z",
    "closed_at": "2024-12-03T01:17:25Z",
    "merged_at": "2024-12-03T01:17:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/634"
  },
  {
    "number": 632,
    "title": "fix fp8 weight quant need contiguous tensor",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-02T08:44:42Z",
    "closed_at": "2024-12-02T08:45:19Z",
    "merged_at": "2024-12-02T08:45:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/632"
  },
  {
    "number": 631,
    "title": "fix set quantization",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-01T09:20:41Z",
    "closed_at": "2024-12-01T09:22:36Z",
    "merged_at": "2024-12-01T09:22:36Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/631"
  },
  {
    "number": 629,
    "title": "update pd master mode time out to 30s.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-29T11:51:08Z",
    "closed_at": "2024-11-29T11:51:17Z",
    "merged_at": "2024-11-29T11:51:17Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/629"
  },
  {
    "number": 628,
    "title": "[feature]moe etp done, without group greed",
    "user": "charlotteroes",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-29T08:59:01Z",
    "closed_at": "2024-12-13T06:28:30Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/628"
  },
  {
    "number": 627,
    "title": "fix mem alloc ",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-29T07:17:47Z",
    "closed_at": "2024-11-29T07:18:10Z",
    "merged_at": "2024-11-29T07:18:10Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/627"
  },
  {
    "number": 626,
    "title": "Refactor reduce",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-29T06:41:29Z",
    "closed_at": "2024-11-29T07:09:59Z",
    "merged_at": "2024-11-29T07:09:59Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/626"
  },
  {
    "number": 625,
    "title": "fix shm conflict error",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-28T09:07:02Z",
    "closed_at": "2024-11-28T09:07:35Z",
    "merged_at": "2024-11-28T09:07:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/625"
  },
  {
    "number": 624,
    "title": "Deepseek fix for  moe fp8",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-28T07:58:01Z",
    "closed_at": "2024-11-28T07:59:07Z",
    "merged_at": "2024-11-28T07:59:07Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/624"
  },
  {
    "number": 623,
    "title": "fix deepseekv2-lite tp>1",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-28T06:09:45Z",
    "closed_at": "2024-11-28T06:12:11Z",
    "merged_at": "2024-11-28T06:12:11Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/623"
  },
  {
    "number": 622,
    "title": "add DP framework support.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-28T03:03:15Z",
    "closed_at": "2024-11-28T04:32:56Z",
    "merged_at": "2024-11-28T04:32:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/622"
  },
  {
    "number": 621,
    "title": "[model] support Qwen2.5-RM",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-27T13:18:26Z",
    "closed_at": "2024-11-28T00:52:53Z",
    "merged_at": "2024-11-28T00:52:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/621"
  },
  {
    "number": 620,
    "title": "LIGHTLLM_PYNCCL_ENABLE default False",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-27T06:44:34Z",
    "closed_at": "2024-11-27T06:45:44Z",
    "merged_at": "2024-11-27T06:45:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/620"
  },
  {
    "number": 619,
    "title": "complete all_reduce and test",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-27T03:01:42Z",
    "closed_at": "2024-11-27T05:27:54Z",
    "merged_at": "2024-11-27T05:27:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/619"
  },
  {
    "number": 618,
    "title": "feat: add cc, acc method for deepseek2",
    "user": "blueswhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-27T02:18:59Z",
    "closed_at": "2024-12-02T05:13:28Z",
    "merged_at": "2024-12-02T05:13:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/618"
  },
  {
    "number": 617,
    "title": "upgrade deepseek kv copy & fix test/model_infer.py",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-26T11:48:46Z",
    "closed_at": "2024-11-26T11:51:17Z",
    "merged_at": "2024-11-26T11:51:16Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/617"
  },
  {
    "number": 616,
    "title": "optimze decode mla att",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-25T10:49:51Z",
    "closed_at": "2024-11-26T07:37:02Z",
    "merged_at": "2024-11-26T07:37:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/616"
  },
  {
    "number": 615,
    "title": "add vllm pynccl for cuda graph compatibility",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-25T10:08:31Z",
    "closed_at": "2024-11-26T07:01:40Z",
    "merged_at": "2024-11-26T07:01:40Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/615"
  },
  {
    "number": 614,
    "title": "Deepseek2 Support  PD mode",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-25T05:30:05Z",
    "closed_at": "2024-11-25T06:54:47Z",
    "merged_at": "2024-11-25T06:54:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/614"
  },
  {
    "number": 613,
    "title": "add vllm pynccl for cuda graph compatibility",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-22T09:11:08Z",
    "closed_at": "2024-11-25T10:08:49Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/613"
  },
  {
    "number": 612,
    "title": "refactor models",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-21T10:36:20Z",
    "closed_at": "2024-11-21T15:12:00Z",
    "merged_at": "2024-11-21T15:12:00Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/612"
  },
  {
    "number": 611,
    "title": "feat(misc): Profiler support",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-20T15:05:48Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/611"
  },
  {
    "number": 610,
    "title": "Fix a lot",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-20T09:07:30Z",
    "closed_at": "2024-11-20T11:51:04Z",
    "merged_at": "2024-11-20T11:51:04Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/610"
  },
  {
    "number": 609,
    "title": "Fix",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-20T09:06:40Z",
    "closed_at": "2024-11-20T09:06:55Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/609"
  },
  {
    "number": 608,
    "title": "[Refactor][model] Refactor models.",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-20T03:19:10Z",
    "closed_at": "2024-11-20T05:00:33Z",
    "merged_at": "2024-11-20T05:00:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/608"
  },
  {
    "number": 607,
    "title": "FeaturePD Mode Support",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-18T03:28:38Z",
    "closed_at": "2024-11-18T09:26:13Z",
    "merged_at": "2024-11-18T09:26:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/607"
  },
  {
    "number": 606,
    "title": "refactor models",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-15T08:14:35Z",
    "closed_at": "2024-11-15T10:40:43Z",
    "merged_at": "2024-11-15T10:40:43Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/606"
  },
  {
    "number": 605,
    "title": "[triton] autotune",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-11T12:24:10Z",
    "closed_at": "2024-11-20T07:50:42Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/605"
  },
  {
    "number": 603,
    "title": "update lightllm version to 3.0.0",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-01T09:55:25Z",
    "closed_at": "2024-11-01T09:55:35Z",
    "merged_at": "2024-11-01T09:55:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/603"
  },
  {
    "number": 602,
    "title": "[docs] Update docs.",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-01T03:12:07Z",
    "closed_at": "2024-11-01T09:47:45Z",
    "merged_at": "2024-11-01T09:47:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/602"
  },
  {
    "number": 600,
    "title": "[docs] Update docs.",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-30T07:29:44Z",
    "closed_at": "2024-11-01T02:43:17Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/600"
  },
  {
    "number": 599,
    "title": "add first_token_constraint_mode",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-30T03:41:02Z",
    "closed_at": "2024-10-31T10:41:57Z",
    "merged_at": "2024-10-31T10:41:57Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/599"
  },
  {
    "number": 598,
    "title": "Allowed token ids",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-30T02:21:27Z",
    "closed_at": "2024-10-30T02:24:32Z",
    "merged_at": "2024-10-30T02:24:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/598"
  },
  {
    "number": 597,
    "title": "\t [docs] Update docs.",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-29T13:23:37Z",
    "closed_at": "2024-10-30T02:21:18Z",
    "merged_at": "2024-10-30T02:21:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/597"
  },
  {
    "number": 596,
    "title": "refact quantization, support  torchao quant and vllm w8a8(int/fp), support mix quantization.",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-29T04:42:56Z",
    "closed_at": "2024-11-22T06:46:52Z",
    "merged_at": "2024-11-22T06:46:52Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/596"
  },
  {
    "number": 595,
    "title": "[BugFix] Fix reward model support",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T12:32:51Z",
    "closed_at": "2024-10-28T12:56:49Z",
    "merged_at": "2024-10-28T12:56:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/595"
  },
  {
    "number": 594,
    "title": "code clean.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T10:32:13Z",
    "closed_at": "2024-10-28T10:33:30Z",
    "merged_at": "2024-10-28T10:33:30Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/594"
  },
  {
    "number": 593,
    "title": "[BugFix] Fix reward model backend",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T10:16:13Z",
    "closed_at": "2024-10-28T10:30:09Z",
    "merged_at": "2024-10-28T10:30:09Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/593"
  },
  {
    "number": 592,
    "title": "Vit parallel",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T07:16:39Z",
    "closed_at": "2024-10-28T10:23:01Z",
    "merged_at": "2024-10-28T10:23:01Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/592"
  },
  {
    "number": 591,
    "title": "[misc] add import vllm",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T06:59:12Z",
    "closed_at": "2024-10-28T07:06:43Z",
    "merged_at": "2024-10-28T07:06:43Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/591"
  },
  {
    "number": 590,
    "title": "Vit parallel",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T06:05:18Z",
    "closed_at": "2024-10-28T07:15:35Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/590"
  },
  {
    "number": 589,
    "title": "default to get data_type startargs from config.json and fix deepseekv",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T05:55:42Z",
    "closed_at": "2024-10-28T05:56:40Z",
    "merged_at": "2024-10-28T05:56:40Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/589"
  },
  {
    "number": 588,
    "title": "alloc_tensor used for deepseek and qwen2, and update rmsnorm kernel",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T04:24:53Z",
    "closed_at": "2024-10-28T04:28:41Z",
    "merged_at": "2024-10-28T04:28:41Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/588"
  },
  {
    "number": 587,
    "title": "fix bug for deepseekv2 moe cache tensor manager",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-26T04:36:15Z",
    "closed_at": "2024-10-26T04:36:39Z",
    "merged_at": "2024-10-26T04:36:39Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/587"
  },
  {
    "number": 586,
    "title": "[model] Use cache memory manager",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T10:51:15Z",
    "closed_at": "2024-10-26T03:49:24Z",
    "merged_at": "2024-10-26T03:49:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/586"
  },
  {
    "number": 585,
    "title": "Vit parallel",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T09:49:24Z",
    "closed_at": "2024-10-28T06:05:09Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/585"
  },
  {
    "number": 584,
    "title": "Vit parallel",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T09:36:02Z",
    "closed_at": "2024-10-25T09:49:14Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/584"
  },
  {
    "number": 583,
    "title": "[misc] Use fastapi lifespan",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T09:16:08Z",
    "closed_at": "2024-10-25T10:04:31Z",
    "merged_at": "2024-10-25T10:04:31Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/583"
  },
  {
    "number": 582,
    "title": "[misc] Use fastapi lifespan",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T08:52:37Z",
    "closed_at": "2024-10-25T09:09:40Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/582"
  },
  {
    "number": 581,
    "title": "Vit parallel",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T08:35:01Z",
    "closed_at": "2024-10-25T09:35:52Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/581"
  },
  {
    "number": 580,
    "title": "add vllm moe configs",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T06:18:15Z",
    "closed_at": "2024-10-25T06:52:47Z",
    "merged_at": "2024-10-25T06:52:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/580"
  },
  {
    "number": 579,
    "title": "Vit parallel",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T14:22:05Z",
    "closed_at": "2024-10-25T08:34:41Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/579"
  },
  {
    "number": 578,
    "title": "add max len prefill infer check",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T12:29:36Z",
    "closed_at": "2024-10-25T05:01:35Z",
    "merged_at": "2024-10-25T05:01:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/578"
  },
  {
    "number": 577,
    "title": "Vit parallel",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T11:32:49Z",
    "closed_at": "2024-10-24T14:21:57Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/577"
  },
  {
    "number": 576,
    "title": "add lightllm_vllm_kernel",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-23T10:23:43Z",
    "closed_at": "2024-10-24T08:53:18Z",
    "merged_at": "2024-10-24T08:53:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/576"
  },
  {
    "number": 574,
    "title": "add profile max_total_token_nums",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-21T08:08:39Z",
    "closed_at": "2024-10-24T05:52:30Z",
    "merged_at": "2024-10-24T05:52:30Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/574"
  },
  {
    "number": 572,
    "title": "Vit parallel",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-18T12:00:03Z",
    "closed_at": "2024-10-24T11:32:39Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/572"
  },
  {
    "number": 571,
    "title": "Vit parallel",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-18T10:39:08Z",
    "closed_at": "2024-10-18T11:33:39Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/571"
  },
  {
    "number": 570,
    "title": "Vit parallel",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-18T10:29:58Z",
    "closed_at": "2024-10-18T10:38:54Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/570"
  },
  {
    "number": 569,
    "title": "support to read eos_id from config.json",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-18T05:43:14Z",
    "closed_at": "2024-10-18T05:58:21Z",
    "merged_at": "2024-10-18T05:58:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/569"
  },
  {
    "number": 568,
    "title": "release local tensors alloc during cudagraph warmup",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-17T06:42:47Z",
    "closed_at": "2024-10-17T10:48:09Z",
    "merged_at": "2024-10-17T10:48:09Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/568"
  },
  {
    "number": 567,
    "title": "[op] Modify embedding",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-15T09:23:30Z",
    "closed_at": "2024-10-16T02:20:49Z",
    "merged_at": "2024-10-16T02:20:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/567"
  },
  {
    "number": 566,
    "title": "attention decode use self.alloc_tensor interface.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-15T04:04:42Z",
    "closed_at": "2024-10-15T04:19:23Z",
    "merged_at": "2024-10-15T04:19:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/566"
  },
  {
    "number": 565,
    "title": "[misc] In-place add for embedding",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-15T02:07:28Z",
    "closed_at": "2024-10-15T02:43:40Z",
    "merged_at": "2024-10-15T02:43:40Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/565"
  },
  {
    "number": 564,
    "title": "[misc] modify flash decoding function",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-14T03:00:56Z",
    "closed_at": "2024-10-15T02:43:58Z",
    "merged_at": "2024-10-15T02:43:58Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/564"
  },
  {
    "number": 562,
    "title": "W4a16 fix",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-11T11:30:29Z",
    "closed_at": "2024-10-11T11:31:30Z",
    "merged_at": "2024-10-11T11:31:30Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/562"
  },
  {
    "number": 561,
    "title": "New embedding",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-10T11:56:01Z",
    "closed_at": "2024-10-11T06:48:52Z",
    "merged_at": "2024-10-11T06:48:52Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/561"
  },
  {
    "number": 560,
    "title": "New embedding",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-10T11:24:47Z",
    "closed_at": "2024-10-10T11:26:26Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/560"
  },
  {
    "number": 559,
    "title": "Update README.md",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-10T06:07:38Z",
    "closed_at": "2024-10-10T06:10:55Z",
    "merged_at": "2024-10-10T06:10:55Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/559"
  },
  {
    "number": 558,
    "title": "slim dockerfile",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-10T05:38:20Z",
    "closed_at": "2024-10-10T05:38:50Z",
    "merged_at": "2024-10-10T05:38:50Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/558"
  },
  {
    "number": 557,
    "title": "fix llama3 prelayer weight load.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-09T08:00:30Z",
    "closed_at": "2024-10-09T08:03:24Z",
    "merged_at": "2024-10-09T08:03:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/557"
  },
  {
    "number": 556,
    "title": "fix llama3 pre_layer_weight loading",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-09T07:35:08Z",
    "closed_at": "2024-10-09T07:43:19Z",
    "merged_at": "2024-10-09T07:43:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/556"
  },
  {
    "number": 555,
    "title": "add docker clean",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-09T06:03:19Z",
    "closed_at": "2024-10-09T06:03:53Z",
    "merged_at": "2024-10-09T06:03:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/555"
  },
  {
    "number": 554,
    "title": "fix cudagraph warmup for multimodal",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-08T11:59:36Z",
    "closed_at": "2024-10-08T12:01:28Z",
    "merged_at": "2024-10-08T12:01:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/554"
  },
  {
    "number": 553,
    "title": "bug fix alloc_tensor for torch.__version__ < 2.1.0",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-08T02:55:18Z",
    "closed_at": "2024-10-08T02:56:21Z",
    "merged_at": "2024-10-08T02:56:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/553"
  },
  {
    "number": 551,
    "title": "add cudagraph warmup",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-30T10:43:08Z",
    "closed_at": "2024-10-08T02:14:42Z",
    "merged_at": "2024-10-08T02:14:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/551"
  },
  {
    "number": 550,
    "title": "Visual rpc scm",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-30T09:18:00Z",
    "closed_at": "2024-10-24T12:39:23Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/550"
  },
  {
    "number": 549,
    "title": "upgrade cuda graph mem manager",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-29T11:21:57Z",
    "closed_at": "2024-09-30T07:49:03Z",
    "merged_at": "2024-09-30T07:49:03Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/549"
  },
  {
    "number": 548,
    "title": "fix cuda graph ",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-27T09:01:31Z",
    "closed_at": "2024-09-27T09:04:15Z",
    "merged_at": "2024-09-27T09:04:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/548"
  },
  {
    "number": 547,
    "title": "fix context_flashattention_nopad.py",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-27T04:14:50Z",
    "closed_at": "2024-09-27T04:15:02Z",
    "merged_at": "2024-09-27T04:15:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/547"
  },
  {
    "number": 546,
    "title": "fix bug for format out",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-26T10:59:45Z",
    "closed_at": "2024-09-26T11:01:09Z",
    "merged_at": "2024-09-26T11:01:09Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/546"
  },
  {
    "number": 544,
    "title": "add cudagraph for lightllm",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-26T07:35:13Z",
    "closed_at": "2024-09-27T08:44:59Z",
    "merged_at": "2024-09-27T08:44:59Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/544"
  },
  {
    "number": 543,
    "title": "New prefill op",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-26T07:28:22Z",
    "closed_at": "2024-09-27T04:01:07Z",
    "merged_at": "2024-09-27T04:01:07Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/543"
  },
  {
    "number": 542,
    "title": "New prefill op",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-25T14:18:54Z",
    "closed_at": "2024-09-26T06:31:32Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/542"
  },
  {
    "number": 541,
    "title": "fix health_monitor bug",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-19T08:44:54Z",
    "closed_at": "2024-09-19T08:46:40Z",
    "merged_at": "2024-09-19T08:46:40Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/541"
  },
  {
    "number": 540,
    "title": "Improve mixtral",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-14T06:19:57Z",
    "closed_at": "2024-09-19T06:51:40Z",
    "merged_at": "2024-09-19T06:51:40Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/540"
  },
  {
    "number": 539,
    "title": "Update Dockerfile",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-13T01:18:58Z",
    "closed_at": "2024-09-13T01:19:49Z",
    "merged_at": "2024-09-13T01:19:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/539"
  },
  {
    "number": 538,
    "title": "Update Dockerfile",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-12T06:03:25Z",
    "closed_at": "2024-09-12T06:04:05Z",
    "merged_at": "2024-09-12T06:04:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/538"
  },
  {
    "number": 537,
    "title": "add get_model_name interface to get model name in server",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-12T04:51:23Z",
    "closed_at": "2024-09-12T04:52:05Z",
    "merged_at": "2024-09-12T04:52:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/537"
  },
  {
    "number": 536,
    "title": "update torch version to 2.4.0 and update gqa flash decoding kernel",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-12T04:27:20Z",
    "closed_at": "2024-09-12T04:28:33Z",
    "merged_at": "2024-09-12T04:28:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/536"
  },
  {
    "number": 535,
    "title": "fix push interrupt",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-09T12:49:09Z",
    "closed_at": "2024-09-09T12:50:27Z",
    "merged_at": "2024-09-09T12:50:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/535"
  },
  {
    "number": 534,
    "title": "Add md qwen2 vl",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-09T06:55:29Z",
    "closed_at": "2024-09-09T07:06:04Z",
    "merged_at": "2024-09-09T07:06:03Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/534"
  },
  {
    "number": 533,
    "title": "add_readme_qwen2vl",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-09T06:11:06Z",
    "closed_at": "2024-09-09T06:52:21Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/533"
  },
  {
    "number": 532,
    "title": "Add qwen2 vl readme",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-09T05:54:32Z",
    "closed_at": "2024-09-09T06:00:34Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/532"
  },
  {
    "number": 531,
    "title": "Add qwen2 vl readme",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-09T05:50:54Z",
    "closed_at": "2024-09-09T05:51:44Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/531"
  },
  {
    "number": 530,
    "title": "Add qwen2 vl readme",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-09T05:36:32Z",
    "closed_at": "2024-09-09T05:37:16Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/530"
  },
  {
    "number": 529,
    "title": "Update requirements.txt",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-09T02:47:13Z",
    "closed_at": "2024-09-09T02:47:48Z",
    "merged_at": "2024-09-09T02:47:48Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/529"
  },
  {
    "number": 528,
    "title": "support_qwen2_vl",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-07T09:36:59Z",
    "closed_at": "2024-09-09T02:31:54Z",
    "merged_at": "2024-09-09T02:31:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/528"
  },
  {
    "number": 527,
    "title": "update log",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-05T14:33:27Z",
    "closed_at": "2024-09-05T14:34:35Z",
    "merged_at": "2024-09-05T14:34:34Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/527"
  },
  {
    "number": 526,
    "title": "fix",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T07:48:53Z",
    "closed_at": "2024-09-04T07:49:44Z",
    "merged_at": "2024-09-04T07:49:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/526"
  },
  {
    "number": 525,
    "title": "qabot demo.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T07:33:30Z",
    "closed_at": "2024-09-04T07:40:34Z",
    "merged_at": "2024-09-04T07:40:34Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/525"
  },
  {
    "number": 524,
    "title": "Revert \"Revert \"edit docs \"\"",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T05:53:12Z",
    "closed_at": "2024-09-04T07:35:21Z",
    "merged_at": "2024-09-04T07:35:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/524"
  },
  {
    "number": 523,
    "title": "add docs README.md",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T05:52:20Z",
    "closed_at": "2024-09-04T07:03:11Z",
    "merged_at": "2024-09-04T07:03:11Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/523"
  },
  {
    "number": 522,
    "title": "Revert \"ADD CN and EN docs\"",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T05:34:55Z",
    "closed_at": "2024-09-04T05:36:14Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/522"
  },
  {
    "number": 521,
    "title": "Update requirements.txt",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T03:18:38Z",
    "closed_at": "2024-09-04T03:18:48Z",
    "merged_at": "2024-09-04T03:18:48Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/521"
  },
  {
    "number": 520,
    "title": "Update requirements.txt",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T02:47:19Z",
    "closed_at": "2024-09-04T02:47:26Z",
    "merged_at": "2024-09-04T02:47:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/520"
  },
  {
    "number": 519,
    "title": "Update Dockerfile to fix package conficts",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T02:41:09Z",
    "closed_at": "2024-09-04T02:41:26Z",
    "merged_at": "2024-09-04T02:41:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/519"
  },
  {
    "number": 518,
    "title": "Revert \"edit docs \"",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-03T10:06:13Z",
    "closed_at": "2024-09-04T01:56:20Z",
    "merged_at": "2024-09-04T01:56:20Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/518"
  },
  {
    "number": 517,
    "title": "add push mertics log.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-02T08:43:40Z",
    "closed_at": "2024-09-02T08:46:45Z",
    "merged_at": "2024-09-02T08:46:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/517"
  },
  {
    "number": 516,
    "title": "[Feature] Token healing + regular format out.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-02T02:38:12Z",
    "closed_at": "2024-09-02T04:20:19Z",
    "merged_at": "2024-09-02T04:20:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/516"
  },
  {
    "number": 515,
    "title": "update to torch 2.1.0",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-28T03:17:16Z",
    "closed_at": "2024-08-28T03:19:13Z",
    "merged_at": "2024-08-28T03:19:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/515"
  },
  {
    "number": 514,
    "title": "Add dispatcher support",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-26T05:23:59Z",
    "closed_at": "2024-09-02T02:05:12Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/514"
  },
  {
    "number": 513,
    "title": "Assist",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-26T05:13:47Z",
    "closed_at": "2024-08-26T05:23:28Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/513"
  },
  {
    "number": 512,
    "title": "[Feature] add  gpu tensor cache feature.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-26T02:33:54Z",
    "closed_at": "2024-08-26T03:12:33Z",
    "merged_at": "2024-08-26T03:12:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/512"
  },
  {
    "number": 511,
    "title": "Data Parallelism for vision model",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-23T11:27:24Z",
    "closed_at": "2024-09-29T13:00:45Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/511"
  },
  {
    "number": 510,
    "title": "Add dispatch support",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-23T08:33:51Z",
    "closed_at": "2024-08-23T12:17:42Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/510"
  },
  {
    "number": 509,
    "title": "Add dispatch support",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-23T05:40:20Z",
    "closed_at": "2024-08-23T06:03:40Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/509"
  },
  {
    "number": 508,
    "title": "add req input log.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-21T07:54:57Z",
    "closed_at": "2024-08-21T07:56:42Z",
    "merged_at": "2024-08-21T07:56:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/508"
  },
  {
    "number": 507,
    "title": "fix qwen2 for 1.8B 128k",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-21T03:52:56Z",
    "closed_at": "2024-08-27T05:36:34Z",
    "merged_at": "2024-08-27T05:36:34Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/507"
  },
  {
    "number": 506,
    "title": "fix group pause",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-20T05:49:53Z",
    "closed_at": "2025-03-03T05:10:12Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/506"
  },
  {
    "number": 505,
    "title": "feat(model): static intermediate tensor allocation for llama and internlm model",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-19T16:21:18Z",
    "closed_at": "2024-08-26T03:12:25Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/505"
  },
  {
    "number": 504,
    "title": "fix(router): fix pause_reqs() in InferBatch",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-19T16:20:26Z",
    "closed_at": "2024-08-20T08:10:08Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/504"
  },
  {
    "number": 503,
    "title": "add benchmark of prompt cache",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-19T04:34:47Z",
    "closed_at": "2024-08-19T09:31:28Z",
    "merged_at": "2024-08-19T09:31:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/503"
  },
  {
    "number": 501,
    "title": "edit docs ",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-16T11:49:29Z",
    "closed_at": "2024-08-16T11:58:35Z",
    "merged_at": "2024-08-16T11:58:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/501"
  },
  {
    "number": 500,
    "title": "add readthedocs yaml",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-16T09:27:11Z",
    "closed_at": "2024-08-16T09:27:20Z",
    "merged_at": "2024-08-16T09:27:20Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/500"
  },
  {
    "number": 499,
    "title": "fix push_metrics  crash",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-16T05:16:55Z",
    "closed_at": "2024-08-16T07:56:15Z",
    "merged_at": "2024-08-16T07:56:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/499"
  },
  {
    "number": 498,
    "title": "fix Mistral for 13B",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-16T05:04:01Z",
    "closed_at": "2024-08-20T08:03:31Z",
    "merged_at": "2024-08-20T08:03:31Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/498"
  },
  {
    "number": 497,
    "title": "Add support for OpenGVLab/InternVL2-Llama3-76B",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-12T09:44:06Z",
    "closed_at": "2024-08-16T02:54:48Z",
    "merged_at": "2024-08-16T02:54:48Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/497"
  },
  {
    "number": 496,
    "title": "ADD CN and EN docs",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-12T06:25:28Z",
    "closed_at": "2024-08-16T02:27:44Z",
    "merged_at": "2024-08-16T02:27:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/496"
  },
  {
    "number": 495,
    "title": "update_readme_internvl",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-09T06:59:45Z",
    "closed_at": "2024-08-09T08:47:50Z",
    "merged_at": "2024-08-09T08:47:50Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/495"
  },
  {
    "number": 494,
    "title": "delete debug info",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-09T03:14:49Z",
    "closed_at": "2024-08-09T03:17:27Z",
    "merged_at": "2024-08-09T03:17:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/494"
  },
  {
    "number": 493,
    "title": "fix multithreading problem of deepseek-v2 and add __init__.py for new models",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-09T03:05:34Z",
    "closed_at": "2024-08-09T03:07:36Z",
    "merged_at": "2024-08-09T03:07:36Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/493"
  },
  {
    "number": 492,
    "title": "add __init__.py",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-07T09:30:34Z",
    "closed_at": "2024-08-08T09:23:51Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/492"
  },
  {
    "number": 491,
    "title": "Suport reward model with tp",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T09:57:04Z",
    "closed_at": "2024-08-07T04:51:59Z",
    "merged_at": "2024-08-07T04:51:59Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/491"
  },
  {
    "number": 489,
    "title": "Suport reward model",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T06:18:41Z",
    "closed_at": "2024-08-06T09:46:06Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/489"
  },
  {
    "number": 488,
    "title": "add internlm-reward model suport",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T03:35:22Z",
    "closed_at": "2024-08-06T06:18:19Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/488"
  },
  {
    "number": 487,
    "title": " add internlm-reward model suport",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T03:23:38Z",
    "closed_at": "2024-08-06T03:35:35Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/487"
  },
  {
    "number": 486,
    "title": "add internlm-reward model suport",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T03:16:08Z",
    "closed_at": "2024-08-06T03:23:13Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/486"
  },
  {
    "number": 485,
    "title": "suport internlm-reward model",
    "user": "sufubao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-05T12:39:35Z",
    "closed_at": "2024-08-06T03:14:55Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/485"
  },
  {
    "number": 484,
    "title": "support Internvl1.5 model",
    "user": "SangChengC",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-02T11:38:46Z",
    "closed_at": "2024-08-07T08:26:21Z",
    "merged_at": "2024-08-07T08:26:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/484"
  },
  {
    "number": 483,
    "title": "Fix splitfuse qwen",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-02T09:26:57Z",
    "closed_at": "2024-08-05T01:14:46Z",
    "merged_at": "2024-08-05T01:14:46Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/483"
  },
  {
    "number": 481,
    "title": "support llama3.1 rope rotary",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-31T11:20:36Z",
    "closed_at": "2024-07-31T11:22:24Z",
    "merged_at": "2024-07-31T11:22:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/481"
  },
  {
    "number": 480,
    "title": "[Bug] Move the validation of multimodal parameters forward to prevent readi",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-31T03:45:35Z",
    "closed_at": "2024-07-31T03:47:26Z",
    "merged_at": "2024-07-31T03:47:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/480"
  },
  {
    "number": 478,
    "title": "Fix bug for multi release multimodal_resources",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-29T02:10:56Z",
    "closed_at": "2024-07-29T02:25:28Z",
    "merged_at": "2024-07-29T02:25:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/478"
  },
  {
    "number": 477,
    "title": "fix prompt cache with input lenght =1",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-25T10:54:30Z",
    "closed_at": "2024-07-29T09:36:49Z",
    "merged_at": "2024-07-29T09:36:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/477"
  },
  {
    "number": 476,
    "title": "add grouping_key for monitor",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-25T07:02:11Z",
    "closed_at": "2024-07-25T07:10:18Z",
    "merged_at": "2024-07-25T07:10:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/476"
  },
  {
    "number": 474,
    "title": "Fix token attention kernel",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-23T09:30:15Z",
    "closed_at": "2024-07-25T05:16:16Z",
    "merged_at": "2024-07-25T05:16:16Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/474"
  },
  {
    "number": 473,
    "title": "maxsize to 4096",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-23T08:16:19Z",
    "closed_at": "2024-07-23T08:16:33Z",
    "merged_at": "2024-07-23T08:16:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/473"
  },
  {
    "number": 472,
    "title": "add deepseek2 support",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-22T07:08:08Z",
    "closed_at": "2024-07-25T04:59:41Z",
    "merged_at": "2024-07-25T04:59:41Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/472"
  },
  {
    "number": 471,
    "title": "fix openai api",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T07:38:38Z",
    "closed_at": "2024-07-19T08:28:12Z",
    "merged_at": "2024-07-19T08:28:12Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/471"
  },
  {
    "number": 470,
    "title": "fix openai api",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T07:35:27Z",
    "closed_at": "2024-07-19T07:35:51Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/470"
  },
  {
    "number": 469,
    "title": "remove sliding windows of qwen2",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-18T08:17:51Z",
    "closed_at": "2024-07-18T09:21:21Z",
    "merged_at": "2024-07-18T09:21:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/469"
  },
  {
    "number": 468,
    "title": "remove @mark_cost_time",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-17T06:01:44Z",
    "closed_at": "2024-07-17T06:25:16Z",
    "merged_at": "2024-07-17T06:25:16Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/468"
  },
  {
    "number": 465,
    "title": "refactor diverse mode to accelerate post process & fix dynamic_prompt_cache in diverse mode",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-15T11:12:03Z",
    "closed_at": "2024-07-18T08:02:54Z",
    "merged_at": "2024-07-18T08:02:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/465"
  },
  {
    "number": 464,
    "title": "make monitor client to sync in a thread",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-15T09:09:24Z",
    "closed_at": "2024-07-15T10:30:33Z",
    "merged_at": "2024-07-15T10:30:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/464"
  },
  {
    "number": 463,
    "title": "return prompt_tokens for generate/generate_stream of api_lightllm",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-11T10:16:20Z",
    "closed_at": "2024-07-11T10:30:23Z",
    "merged_at": "2024-07-11T10:30:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/463"
  },
  {
    "number": 460,
    "title": "fix odd vocab size for qwen2 tp>1",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T07:17:09Z",
    "closed_at": "2024-07-09T07:25:53Z",
    "merged_at": "2024-07-09T07:25:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/460"
  },
  {
    "number": 459,
    "title": "Set the default timeout of rpyc connect to 30s and add pushgateway  auth",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T05:53:10Z",
    "closed_at": "2024-07-09T06:01:58Z",
    "merged_at": "2024-07-09T06:01:58Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/459"
  },
  {
    "number": 458,
    "title": "fix: control the metric set frequency",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-08T11:44:24Z",
    "closed_at": "2024-07-08T11:49:49Z",
    "merged_at": "2024-07-08T11:49:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/458"
  },
  {
    "number": 455,
    "title": "fix a small bug in README.md",
    "user": "wzh1994",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-04T11:34:52Z",
    "closed_at": "2024-07-05T02:06:42Z",
    "merged_at": "2024-07-05T02:06:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/455"
  },
  {
    "number": 454,
    "title": "Refactor prometheus monitoring and add push gataway",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-04T07:46:35Z",
    "closed_at": "2024-07-08T11:20:49Z",
    "merged_at": "2024-07-08T11:20:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/454"
  },
  {
    "number": 453,
    "title": "Add `Projects using lightllm` in README.md and add `LazyLLM`",
    "user": "wzh1994",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-04T01:11:48Z",
    "closed_at": "2024-07-04T01:26:36Z",
    "merged_at": "2024-07-04T01:26:36Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/453"
  },
  {
    "number": 452,
    "title": "feat: Add weight-only quantization inference support for Qwen2 series",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-01T12:38:56Z",
    "closed_at": "2024-07-04T02:56:28Z",
    "merged_at": "2024-07-04T02:56:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/452"
  },
  {
    "number": 451,
    "title": "Llama wa quant support down_proj mix bits",
    "user": "helloyongyang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-26T19:00:35Z",
    "closed_at": "2024-07-01T04:34:45Z",
    "merged_at": "2024-07-01T04:34:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/451"
  },
  {
    "number": 450,
    "title": "refactor a little for --mode and start args logs.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-26T02:38:37Z",
    "closed_at": "2024-06-26T02:43:44Z",
    "merged_at": "2024-06-26T02:43:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/450"
  },
  {
    "number": 448,
    "title": "Create __init__.py",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-18T12:12:03Z",
    "closed_at": "2024-06-18T12:12:12Z",
    "merged_at": "2024-06-18T12:12:12Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/448"
  },
  {
    "number": 447,
    "title": "sync",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-17T08:30:40Z",
    "closed_at": "2024-06-17T08:31:52Z",
    "merged_at": "2024-06-17T08:31:52Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/447"
  },
  {
    "number": 446,
    "title": "remove return_logics params",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-17T06:53:22Z",
    "closed_at": "2024-06-17T06:57:44Z",
    "merged_at": "2024-06-17T06:57:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/446"
  },
  {
    "number": 443,
    "title": "remove return_logics params",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-17T06:38:40Z",
    "closed_at": "2024-06-17T06:42:36Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/443"
  },
  {
    "number": 442,
    "title": "fix bug of mulit eos_id",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-17T06:03:16Z",
    "closed_at": "2024-06-17T06:46:16Z",
    "merged_at": "2024-06-17T06:46:16Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/442"
  },
  {
    "number": 441,
    "title": "sync",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-17T03:40:30Z",
    "closed_at": "2024-06-17T03:40:46Z",
    "merged_at": "2024-06-17T03:40:46Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/441"
  },
  {
    "number": 440,
    "title": "fix mem manger get nccl_port way",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-17T03:35:25Z",
    "closed_at": "2024-06-17T03:39:58Z",
    "merged_at": "2024-06-17T03:39:58Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/440"
  },
  {
    "number": 439,
    "title": "fix log for mean_per_token_cost_time (#438)",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-14T05:09:58Z",
    "closed_at": "2024-06-14T05:10:05Z",
    "merged_at": "2024-06-14T05:10:04Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/439"
  },
  {
    "number": 438,
    "title": "fix log for mean_per_token_cost_time",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-14T03:22:57Z",
    "closed_at": "2024-06-14T03:24:21Z",
    "merged_at": "2024-06-14T03:24:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/438"
  },
  {
    "number": 437,
    "title": "ppl w8a8 support splitfuse mode.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T04:04:20Z",
    "closed_at": "2024-06-13T04:06:04Z",
    "merged_at": "2024-06-13T04:06:04Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/437"
  },
  {
    "number": 436,
    "title": "ppl w8a8 support splitfuse mode.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T03:53:28Z",
    "closed_at": "2024-06-13T04:02:48Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/436"
  },
  {
    "number": 435,
    "title": "add support for phi3-mini (#433)",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T03:52:11Z",
    "closed_at": "2024-06-13T03:52:21Z",
    "merged_at": "2024-06-13T03:52:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/435"
  },
  {
    "number": 433,
    "title": "add support for phi3-mini",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-12T12:23:59Z",
    "closed_at": "2024-06-13T03:09:14Z",
    "merged_at": "2024-06-13T03:09:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/433"
  },
  {
    "number": 432,
    "title": "add high performance layernorm triton kernels.",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-12T03:23:13Z",
    "closed_at": "2024-06-13T02:10:13Z",
    "merged_at": "2024-06-13T02:10:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/432"
  },
  {
    "number": 431,
    "title": "update tokenizer_mode help info.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-12T03:08:46Z",
    "closed_at": "2024-06-12T03:13:28Z",
    "merged_at": "2024-06-12T03:13:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/431"
  },
  {
    "number": 430,
    "title": "add high performance layernorm triton kernels.",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-11T11:29:16Z",
    "closed_at": "2024-06-12T11:45:26Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/430"
  },
  {
    "number": 429,
    "title": "feat: re-impl the cohere with template",
    "user": "PannenetsF",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-10T05:25:36Z",
    "closed_at": "2024-06-12T02:05:01Z",
    "merged_at": "2024-06-12T02:05:01Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/429"
  },
  {
    "number": 428,
    "title": "Update pre-commit.yml",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-08T12:47:18Z",
    "closed_at": "2024-06-08T12:47:24Z",
    "merged_at": "2024-06-08T12:47:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/428"
  },
  {
    "number": 427,
    "title": "Update pre-commit.yml",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-08T12:42:13Z",
    "closed_at": "2024-06-08T12:42:44Z",
    "merged_at": "2024-06-08T12:42:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/427"
  },
  {
    "number": 426,
    "title": "Update pre-commit.yml",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-08T12:37:00Z",
    "closed_at": "2024-06-08T12:37:06Z",
    "merged_at": "2024-06-08T12:37:06Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/426"
  },
  {
    "number": 425,
    "title": "Update pre-commit.yml",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-08T12:32:52Z",
    "closed_at": "2024-06-08T12:33:01Z",
    "merged_at": "2024-06-08T12:33:01Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/425"
  },
  {
    "number": 424,
    "title": "Create pre-commit.yml",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-08T12:16:48Z",
    "closed_at": "2024-06-08T12:17:07Z",
    "merged_at": "2024-06-08T12:17:07Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/424"
  },
  {
    "number": 423,
    "title": "update llama wa quant",
    "user": "helloyongyang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-07T13:26:51Z",
    "closed_at": "2024-06-08T11:50:36Z",
    "merged_at": "2024-06-08T11:50:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/423"
  },
  {
    "number": 421,
    "title": "adapt qwen2",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-07T07:24:51Z",
    "closed_at": "2024-06-07T07:30:30Z",
    "merged_at": "2024-06-07T07:30:30Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/421"
  },
  {
    "number": 420,
    "title": "use triton to init window info",
    "user": "ANDgate99",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-06T11:01:44Z",
    "closed_at": "2024-06-12T02:42:18Z",
    "merged_at": "2024-06-12T02:42:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/420"
  },
  {
    "number": 419,
    "title": "Support Llava hf model",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-04T05:10:42Z",
    "closed_at": "2024-06-04T08:33:50Z",
    "merged_at": "2024-06-04T08:33:50Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/419"
  },
  {
    "number": 418,
    "title": "add Visitor counter",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-03T06:57:01Z",
    "closed_at": "2024-06-03T06:57:13Z",
    "merged_at": "2024-06-03T06:57:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/418"
  },
  {
    "number": 417,
    "title": "Add triton w8a8",
    "user": "helloyongyang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-02T03:06:05Z",
    "closed_at": "2024-06-02T08:03:01Z",
    "merged_at": "2024-06-02T08:03:01Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/417"
  },
  {
    "number": 416,
    "title": "feat: add cohere model for v1 and plus",
    "user": "PannenetsF",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-28T08:26:10Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/416"
  },
  {
    "number": 414,
    "title": "Compat generate api",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T11:14:28Z",
    "closed_at": "2024-05-27T03:50:18Z",
    "merged_at": "2024-05-27T03:50:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/414"
  },
  {
    "number": 413,
    "title": "Dynamic img token",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T07:23:32Z",
    "closed_at": "2024-05-24T08:17:45Z",
    "merged_at": "2024-05-24T08:17:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/413"
  },
  {
    "number": 412,
    "title": "Add tokens http interface",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T09:41:41Z",
    "closed_at": "2024-05-20T09:43:07Z",
    "merged_at": "2024-05-20T09:43:07Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/412"
  },
  {
    "number": 411,
    "title": "fix bug for w8a8 mode",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T08:27:37Z",
    "closed_at": "2024-05-20T08:29:18Z",
    "merged_at": "2024-05-20T08:29:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/411"
  },
  {
    "number": 410,
    "title": "Add cohere model type",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-15T11:07:55Z",
    "closed_at": "2024-06-12T11:44:58Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/410"
  },
  {
    "number": 409,
    "title": "Feature Refactor the code and add support for multi-output features like beam search.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-15T07:14:53Z",
    "closed_at": "2024-05-15T08:20:14Z",
    "merged_at": "2024-05-15T08:20:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/409"
  },
  {
    "number": 397,
    "title": "bf16 compatibility for omitted kernel (#396)",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-15T03:05:26Z",
    "closed_at": "2024-04-15T03:05:31Z",
    "merged_at": "2024-04-15T03:05:30Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/397"
  },
  {
    "number": 396,
    "title": "bf16 compatibility for omitted kernel",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-12T11:23:38Z",
    "closed_at": "2024-04-15T03:05:03Z",
    "merged_at": "2024-04-15T03:05:03Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/396"
  },
  {
    "number": 395,
    "title": "remove the support for triton==2.0.0",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-12T09:28:00Z",
    "closed_at": "2024-04-12T10:19:46Z",
    "merged_at": "2024-04-12T10:19:46Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/395"
  },
  {
    "number": 394,
    "title": "merge",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-12T07:43:29Z",
    "closed_at": "2024-04-12T07:49:35Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/394"
  },
  {
    "number": 392,
    "title": "Fix CI",
    "user": "llehtahw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-11T09:29:58Z",
    "closed_at": "2024-04-11T09:30:15Z",
    "merged_at": "2024-04-11T09:30:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/392"
  },
  {
    "number": 391,
    "title": "Unbind rpyc for model_rpc",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-11T07:22:22Z",
    "closed_at": "2024-06-04T05:11:50Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/391"
  },
  {
    "number": 390,
    "title": "fix input_embdings.dtype=None.dtype",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-11T07:15:15Z",
    "closed_at": "2024-04-11T07:15:31Z",
    "merged_at": "2024-04-11T07:15:31Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/390"
  },
  {
    "number": 388,
    "title": "Add bf16 inference for llm model (#387)",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T14:29:00Z",
    "closed_at": "2024-04-10T14:29:16Z",
    "merged_at": "2024-04-10T14:29:16Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/388"
  },
  {
    "number": 387,
    "title": "Add bf16 inference for llm model",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T08:37:54Z",
    "closed_at": "2024-04-10T14:28:27Z",
    "merged_at": "2024-04-10T14:28:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/387"
  },
  {
    "number": 386,
    "title": "support llama-quik, a w4a4 quantization method",
    "user": "huakaigo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T08:20:03Z",
    "closed_at": "2024-04-08T03:03:37Z",
    "merged_at": "2024-04-08T03:03:36Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/386"
  },
  {
    "number": 385,
    "title": "Align generate and generate_stream api with tgi & fix internlm2 weights split size",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T03:11:49Z",
    "closed_at": "2024-04-09T13:13:31Z",
    "merged_at": "2024-04-09T13:13:30Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/385"
  },
  {
    "number": 384,
    "title": "add min_new_tokens sampling parameter",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-01T03:34:27Z",
    "closed_at": "2024-04-01T03:37:04Z",
    "merged_at": "2024-04-01T03:37:04Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/384"
  },
  {
    "number": 382,
    "title": "w6a16 mode",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-29T01:26:04Z",
    "closed_at": "2024-03-29T01:31:09Z",
    "merged_at": "2024-03-29T01:31:09Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/382"
  },
  {
    "number": 378,
    "title": "fix eos_id default value to [2]",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-26T09:43:02Z",
    "closed_at": "2024-03-26T09:43:56Z",
    "merged_at": "2024-03-26T09:43:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/378"
  },
  {
    "number": 377,
    "title": "Add tools/function call interface",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-26T09:04:09Z",
    "closed_at": "2024-05-15T11:12:55Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/377"
  },
  {
    "number": 376,
    "title": "Update model.py To Fix ntk length bug. (#375)",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-26T07:11:35Z",
    "closed_at": "2024-03-26T07:11:42Z",
    "merged_at": "2024-03-26T07:11:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/376"
  },
  {
    "number": 375,
    "title": "Update model.py To Fix ntk length bug.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-26T07:06:32Z",
    "closed_at": "2024-03-26T07:06:56Z",
    "merged_at": "2024-03-26T07:06:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/375"
  },
  {
    "number": 374,
    "title": "reset the ntk length range",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-25T11:55:40Z",
    "closed_at": "2024-03-25T12:00:22Z",
    "merged_at": "2024-03-25T12:00:22Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/374"
  },
  {
    "number": 373,
    "title": "add sampling params: skip_special_tokens spaces_between_special_tokens",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-25T06:46:38Z",
    "closed_at": "2024-03-26T09:37:41Z",
    "merged_at": "2024-03-26T09:37:41Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/373"
  },
  {
    "number": 371,
    "title": "fix: intxweigtht -> wxa16, b_ready_cache_len -> infer_state.b_ready_c",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T08:52:56Z",
    "closed_at": "2024-03-21T08:53:25Z",
    "merged_at": "2024-03-21T08:53:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/371"
  },
  {
    "number": 370,
    "title": "Bug Fix #368",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T07:47:15Z",
    "closed_at": "2024-03-21T07:51:46Z",
    "merged_at": "2024-03-21T07:51:46Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/370"
  },
  {
    "number": 369,
    "title": "add cuda int4kv copy kernel",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T05:57:02Z",
    "closed_at": "2024-03-21T05:57:25Z",
    "merged_at": "2024-03-21T05:57:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/369"
  },
  {
    "number": 367,
    "title": "add mode ppl_int4kv_flashdecoding",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-20T08:56:27Z",
    "closed_at": "2024-03-20T08:58:44Z",
    "merged_at": "2024-03-20T08:58:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/367"
  },
  {
    "number": 366,
    "title": "fix: b_ready_cache_len default value",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-20T06:11:07Z",
    "closed_at": "2024-03-20T09:21:22Z",
    "merged_at": "2024-03-20T09:21:22Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/366"
  },
  {
    "number": 365,
    "title": "fix issue #357",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-19T08:22:41Z",
    "closed_at": "2024-03-19T09:26:13Z",
    "merged_at": "2024-03-19T09:26:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/365"
  },
  {
    "number": 364,
    "title": "Update context_flashattention_nopad.py To fix triton 2.0.0 import error.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-19T06:50:54Z",
    "closed_at": "2024-03-19T06:51:16Z",
    "merged_at": "2024-03-19T06:51:16Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/364"
  },
  {
    "number": 363,
    "title": "add ppl int8kv flashdecoding mode",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-19T05:39:08Z",
    "closed_at": "2024-03-19T05:41:21Z",
    "merged_at": "2024-03-19T05:41:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/363"
  },
  {
    "number": 361,
    "title": "To improve the code's compatibility with different PyTorch versions.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-18T11:01:02Z",
    "closed_at": "2024-03-18T11:01:15Z",
    "merged_at": "2024-03-18T11:01:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/361"
  },
  {
    "number": 360,
    "title": "fix requirements.txt",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-18T10:48:25Z",
    "closed_at": "2024-03-18T10:48:34Z",
    "merged_at": "2024-03-18T10:48:34Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/360"
  },
  {
    "number": 359,
    "title": "Fix bug for rope_scaling in config.josn is None",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-18T03:12:01Z",
    "closed_at": "2024-03-18T10:40:40Z",
    "merged_at": "2024-03-18T10:40:40Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/359"
  },
  {
    "number": 358,
    "title": "support length penalty",
    "user": "ANDgate99",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-15T11:12:51Z",
    "closed_at": "2024-03-18T10:38:08Z",
    "merged_at": "2024-03-18T10:38:08Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/358"
  },
  {
    "number": 356,
    "title": "[Feature] Dynamic prompt cache",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-14T02:56:49Z",
    "closed_at": "2024-03-18T07:35:45Z",
    "merged_at": "2024-03-18T07:35:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/356"
  },
  {
    "number": 355,
    "title": "merge",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-14T02:44:13Z",
    "closed_at": "2024-03-14T02:44:49Z",
    "merged_at": "2024-03-14T02:44:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/355"
  },
  {
    "number": 354,
    "title": "Update silu_and_mul.py to fix the int32 overflow issue",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-14T02:43:14Z",
    "closed_at": "2024-03-14T02:43:26Z",
    "merged_at": "2024-03-14T02:43:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/354"
  },
  {
    "number": 353,
    "title": "bugfix: fix uncorrect quantize when using lmdeploy_w4a16 mode with bf",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-12T04:06:40Z",
    "closed_at": "2024-03-12T04:11:24Z",
    "merged_at": "2024-03-12T04:11:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/353"
  },
  {
    "number": 352,
    "title": "bugfix: fix uncorrect quantize when using lmdeploy_w4a16 mode with bfloat16 model",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-11T12:58:21Z",
    "closed_at": "2024-03-12T04:06:18Z",
    "merged_at": "2024-03-12T04:06:17Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/352"
  },
  {
    "number": 351,
    "title": "merge code",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-11T03:10:41Z",
    "closed_at": "2024-03-11T03:54:07Z",
    "merged_at": "2024-03-11T03:54:07Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/351"
  },
  {
    "number": 349,
    "title": "Feat llava",
    "user": "black-eleven",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-08T08:08:56Z",
    "closed_at": "2024-03-08T08:09:19Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/349"
  },
  {
    "number": 348,
    "title": "feat: Implement future-past scheduler",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-07T10:29:48Z",
    "closed_at": "2024-03-08T02:28:54Z",
    "merged_at": "2024-03-08T02:28:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/348"
  },
  {
    "number": 347,
    "title": "add support for starcoder2",
    "user": "WuSiYu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-05T14:04:25Z",
    "closed_at": "2024-03-07T09:17:11Z",
    "merged_at": "2024-03-07T09:17:11Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/347"
  },
  {
    "number": 346,
    "title": "[gemma_2b] support",
    "user": "ANDgate99",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-05T11:54:12Z",
    "closed_at": "2024-03-07T08:34:49Z",
    "merged_at": "2024-03-07T08:34:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/346"
  },
  {
    "number": 345,
    "title": "Support internlm2 wquant.",
    "user": "helloyongyang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T13:54:12Z",
    "closed_at": "2024-03-06T02:35:14Z",
    "merged_at": "2024-03-06T02:35:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/345"
  },
  {
    "number": 344,
    "title": "Fix bug for rope_scaling in config.josn is None",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T10:13:55Z",
    "closed_at": "2024-03-04T10:14:05Z",
    "merged_at": "2024-03-04T10:14:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/344"
  },
  {
    "number": 342,
    "title": "Fix weight only quant bug.",
    "user": "helloyongyang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T07:01:32Z",
    "closed_at": "2024-03-04T08:59:24Z",
    "merged_at": "2024-03-04T08:59:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/342"
  },
  {
    "number": 341,
    "title": "add dynamic parse for internlm2",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T05:41:24Z",
    "closed_at": "2024-03-04T05:41:33Z",
    "merged_at": "2024-03-04T05:41:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/341"
  },
  {
    "number": 340,
    "title": "Add Qwen2 Model",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-01T11:04:24Z",
    "closed_at": "2024-03-07T06:47:02Z",
    "merged_at": "2024-03-07T06:47:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/340"
  },
  {
    "number": 339,
    "title": "add support for MiniCPM (#338)",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-27T02:53:01Z",
    "closed_at": "2024-02-27T02:54:03Z",
    "merged_at": "2024-02-27T02:54:03Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/339"
  },
  {
    "number": 338,
    "title": "add support for MiniCPM",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-26T11:59:29Z",
    "closed_at": "2024-02-27T02:50:05Z",
    "merged_at": "2024-02-27T02:50:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/338"
  },
  {
    "number": 337,
    "title": "rebase merge",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-26T07:58:22Z",
    "closed_at": "2024-02-26T08:19:34Z",
    "merged_at": "2024-02-26T08:19:34Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/337"
  },
  {
    "number": 336,
    "title": "add support for stablelm & add adaption for partial rotrary pos emb",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-26T05:59:01Z",
    "closed_at": "2024-02-26T07:56:18Z",
    "merged_at": "2024-02-26T07:56:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/336"
  },
  {
    "number": 335,
    "title": "merge",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-22T02:48:18Z",
    "closed_at": "2024-02-22T02:49:54Z",
    "merged_at": "2024-02-22T02:49:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/335"
  },
  {
    "number": 334,
    "title": "add support for internlmxcomposer",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-21T07:27:52Z",
    "closed_at": "2024-02-26T07:35:54Z",
    "merged_at": "2024-02-26T07:35:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/334"
  },
  {
    "number": 332,
    "title": "read the img size from the config",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-20T05:51:28Z",
    "closed_at": "2024-02-20T05:56:25Z",
    "merged_at": "2024-02-20T05:56:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/332"
  },
  {
    "number": 331,
    "title": "Update test_settings.py",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-19T05:35:01Z",
    "closed_at": "2024-02-19T05:35:16Z",
    "merged_at": "2024-02-19T05:35:16Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/331"
  },
  {
    "number": 330,
    "title": "add details info for streaming generation",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-18T05:40:32Z",
    "closed_at": "2024-02-18T09:50:26Z",
    "merged_at": "2024-02-18T09:50:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/330"
  },
  {
    "number": 328,
    "title": "fix support for model_type internlm2",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-05T09:11:50Z",
    "closed_at": "2024-02-05T09:12:23Z",
    "merged_at": "2024-02-05T09:12:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/328"
  },
  {
    "number": 322,
    "title": "128 k",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-26T08:01:20Z",
    "closed_at": "2024-01-26T08:01:28Z",
    "merged_at": "2024-01-26T08:01:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/322"
  },
  {
    "number": 321,
    "title": "Revert \"[Update] KV Merge And FFn up gate merge.\"",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-25T10:55:15Z",
    "closed_at": "2024-01-25T10:55:31Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/321"
  },
  {
    "number": 320,
    "title": "[Update] KV Merge And FFn up gate merge.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-25T10:48:27Z",
    "closed_at": "2024-01-25T10:52:23Z",
    "merged_at": "2024-01-25T10:52:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/320"
  },
  {
    "number": 318,
    "title": "feat: add load_from_weight_dict interface",
    "user": "bingo787",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-25T07:53:40Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/318"
  },
  {
    "number": 317,
    "title": "outputinput_ptr",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-25T06:43:21Z",
    "closed_at": "2024-01-25T06:52:33Z",
    "merged_at": "2024-01-25T06:52:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/317"
  },
  {
    "number": 316,
    "title": "fix triton_int8kv with gqa",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-24T10:55:48Z",
    "closed_at": "2024-01-25T02:08:06Z",
    "merged_at": "2024-01-25T02:08:06Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/316"
  },
  {
    "number": 315,
    "title": "Kv merge and ffn",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-23T14:49:40Z",
    "closed_at": "2024-01-24T02:10:42Z",
    "merged_at": "2024-01-24T02:10:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/315"
  },
  {
    "number": 314,
    "title": "Kv merge and ffn",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-23T08:03:57Z",
    "closed_at": "2024-01-23T11:03:57Z",
    "merged_at": "2024-01-23T11:03:57Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/314"
  },
  {
    "number": 313,
    "title": "Fix tp id for triton kernel",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-23T06:42:39Z",
    "closed_at": "2024-01-23T06:42:51Z",
    "merged_at": "2024-01-23T06:42:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/313"
  },
  {
    "number": 312,
    "title": "output_ptrres",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-22T05:43:35Z",
    "closed_at": "2024-01-22T07:13:56Z",
    "merged_at": "2024-01-22T07:13:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/312"
  },
  {
    "number": 311,
    "title": "fix rotary_kernel",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-22T05:35:12Z",
    "closed_at": "2024-01-22T07:12:21Z",
    "merged_at": "2024-01-22T07:12:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/311"
  },
  {
    "number": 307,
    "title": "Fuse ffn up gate",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-18T11:42:15Z",
    "closed_at": "2024-01-19T02:02:54Z",
    "merged_at": "2024-01-19T02:02:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/307"
  },
  {
    "number": 306,
    "title": "combine kv_cache & kv_weight",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-18T10:48:24Z",
    "closed_at": "2024-01-18T10:51:13Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/306"
  },
  {
    "number": 305,
    "title": "Kvcache",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-18T08:35:27Z",
    "closed_at": "2024-01-18T10:57:27Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/305"
  },
  {
    "number": 304,
    "title": "Kvcache",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-17T10:19:32Z",
    "closed_at": "2024-01-17T10:23:14Z",
    "merged_at": "2024-01-17T10:23:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/304"
  },
  {
    "number": 303,
    "title": "fix bug for qwen without dynamic ntk",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-17T08:24:38Z",
    "closed_at": "2024-01-17T08:24:45Z",
    "merged_at": "2024-01-17T08:24:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/303"
  },
  {
    "number": 301,
    "title": "all",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T10:32:55Z",
    "closed_at": "2024-01-16T10:33:27Z",
    "merged_at": "2024-01-16T10:33:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/301"
  },
  {
    "number": 300,
    "title": "fix bug when vob_size % world_size != 0",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T09:21:07Z",
    "closed_at": "2024-01-16T09:24:41Z",
    "merged_at": "2024-01-16T09:24:41Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/300"
  },
  {
    "number": 299,
    "title": "fix PetrelHelper",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T09:06:30Z",
    "closed_at": "2024-01-16T10:03:24Z",
    "merged_at": "2024-01-16T10:03:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/299"
  },
  {
    "number": 297,
    "title": "Fix when request << capacity, alloc too frequency, caused low throughput",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-12T08:02:32Z",
    "closed_at": "2024-01-12T08:07:02Z",
    "merged_at": "2024-01-12T08:07:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/297"
  },
  {
    "number": 296,
    "title": "Fuse up&gate matmul in Llama Model",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-11T11:39:30Z",
    "closed_at": "2024-03-01T11:02:18Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/296"
  },
  {
    "number": 295,
    "title": "add test script",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-11T07:26:45Z",
    "closed_at": "2024-01-11T08:15:10Z",
    "merged_at": "2024-01-11T08:15:10Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/295"
  },
  {
    "number": 294,
    "title": "merge kvcache",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-11T06:41:07Z",
    "closed_at": "2024-01-18T10:59:19Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/294"
  },
  {
    "number": 293,
    "title": "add support for internlm2",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-11T05:02:26Z",
    "closed_at": "2024-01-11T05:26:19Z",
    "merged_at": "2024-01-11T05:26:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/293"
  },
  {
    "number": 292,
    "title": "add ppl_fp16_flashdecoding kernel support",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-10T03:00:30Z",
    "closed_at": "2024-01-10T03:02:40Z",
    "merged_at": "2024-01-10T03:02:40Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/292"
  },
  {
    "number": 290,
    "title": "add ceph-based model loading",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-09T03:12:45Z",
    "closed_at": "2024-01-09T07:27:01Z",
    "merged_at": "2024-01-09T07:27:01Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/290"
  },
  {
    "number": 289,
    "title": "Revert \"add ceph-based model loading\"",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-09T02:12:05Z",
    "closed_at": "2024-01-09T02:12:19Z",
    "merged_at": "2024-01-09T02:12:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/289"
  },
  {
    "number": 288,
    "title": "add ceph-based model loading",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-08T09:01:43Z",
    "closed_at": "2024-01-08T12:13:56Z",
    "merged_at": "2024-01-08T12:13:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/288"
  },
  {
    "number": 285,
    "title": "Return meaningful finish reason instead of a boolean",
    "user": "zeyugao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-07T03:18:49Z",
    "closed_at": "2024-01-08T04:50:51Z",
    "merged_at": "2024-01-08T04:50:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/285"
  },
  {
    "number": 284,
    "title": "Revert \"[refactor] merge rotary_emb_fwd and destindex_copy_kv for streamlined execution\"",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-05T10:28:08Z",
    "closed_at": "2024-01-05T10:28:15Z",
    "merged_at": "2024-01-05T10:28:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/284"
  },
  {
    "number": 283,
    "title": "fix for torch 1.13",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-05T07:54:33Z",
    "closed_at": "2024-01-05T07:55:18Z",
    "merged_at": "2024-01-05T07:55:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/283"
  },
  {
    "number": 282,
    "title": "Code Style Improvement",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-04T11:24:50Z",
    "closed_at": "2024-01-12T08:01:42Z",
    "merged_at": "2024-01-12T08:01:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/282"
  },
  {
    "number": 281,
    "title": "Multi embed",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-04T10:28:42Z",
    "closed_at": "2024-01-05T07:17:56Z",
    "merged_at": "2024-01-05T07:17:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/281"
  },
  {
    "number": 280,
    "title": "[refactor] merge rotary_emb_fwd and destindex_copy_kv for streamlined execution",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-04T08:45:15Z",
    "closed_at": "2024-01-05T07:05:46Z",
    "merged_at": "2024-01-05T07:05:46Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/280"
  },
  {
    "number": 278,
    "title": "add mulitmodal_emb kernel",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-04T04:12:08Z",
    "closed_at": "2024-01-04T04:12:27Z",
    "merged_at": "2024-01-04T04:12:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/278"
  },
  {
    "number": 276,
    "title": "fix batch merge for dynamic ntk",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-03T12:45:32Z",
    "closed_at": "2024-01-04T02:24:41Z",
    "merged_at": "2024-01-04T02:24:41Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/276"
  },
  {
    "number": 275,
    "title": "feat(): add some feature and fixed T4, V100 triton error",
    "user": "bingo787",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-03T06:41:11Z",
    "closed_at": "2024-01-03T08:37:14Z",
    "merged_at": "2024-01-03T08:37:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/275"
  },
  {
    "number": 274,
    "title": "[refactor] combine rotary_emb_fwd of q and k into single op",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-02T09:34:23Z",
    "closed_at": "2024-01-04T06:45:34Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/274"
  },
  {
    "number": 273,
    "title": "[mistral] fix sliding_window = null",
    "user": "ANDgate99",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-02T08:37:49Z",
    "closed_at": "2024-01-02T08:42:45Z",
    "merged_at": "2024-01-02T08:42:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/273"
  },
  {
    "number": 272,
    "title": "fix precision of dynamic ntk",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-02T05:47:11Z",
    "closed_at": "2024-01-02T05:47:55Z",
    "merged_at": "2024-01-02T05:47:55Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/272"
  },
  {
    "number": 270,
    "title": "Fix",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-28T11:42:19Z",
    "closed_at": "2023-12-28T11:42:56Z",
    "merged_at": "2023-12-28T11:42:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/270"
  },
  {
    "number": 269,
    "title": "Support mistralai/Mixtral-8x7B-v0.1 for lightllm",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-27T13:09:25Z",
    "closed_at": "2023-12-28T02:53:22Z",
    "merged_at": "2023-12-28T02:53:22Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/269"
  },
  {
    "number": 267,
    "title": "update ppl int4 matmul op",
    "user": "fuheaven",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-27T07:23:25Z",
    "closed_at": "2023-12-27T07:38:16Z",
    "merged_at": "2023-12-27T07:38:16Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/267"
  },
  {
    "number": 266,
    "title": "Support Multimodal",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-26T02:54:11Z",
    "closed_at": "2023-12-28T11:00:04Z",
    "merged_at": "2023-12-28T11:00:04Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/266"
  },
  {
    "number": 265,
    "title": "[feature] long_truncation_mode supported",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-25T10:09:31Z",
    "closed_at": "2023-12-25T10:13:49Z",
    "merged_at": "2023-12-25T10:13:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/265"
  },
  {
    "number": 264,
    "title": "mutlimodal support",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-25T09:23:12Z",
    "closed_at": "2023-12-26T02:16:28Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/264"
  },
  {
    "number": 263,
    "title": "[feature]Context flashattention with blocks",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-25T08:32:49Z",
    "closed_at": "2024-01-02T09:25:52Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/263"
  },
  {
    "number": 262,
    "title": "Add __init__.py for mistral",
    "user": "JingofXin",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-25T03:12:00Z",
    "closed_at": "2023-12-25T03:14:09Z",
    "merged_at": "2023-12-25T03:14:09Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/262"
  },
  {
    "number": 261,
    "title": "fix",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-22T05:29:43Z",
    "closed_at": "2023-12-22T05:31:22Z",
    "merged_at": "2023-12-22T05:31:22Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/261"
  },
  {
    "number": 260,
    "title": "[feature]Splitfuse int8kv kernel",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-21T09:19:37Z",
    "closed_at": "2023-12-21T10:29:23Z",
    "merged_at": "2023-12-21T10:29:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/260"
  },
  {
    "number": 259,
    "title": "add ppl int8 quant mode",
    "user": "fuheaven",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-21T06:20:12Z",
    "closed_at": "2023-12-21T10:23:49Z",
    "merged_at": "2023-12-21T10:23:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/259"
  },
  {
    "number": 258,
    "title": "fix skip speical tokens",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-20T06:35:01Z",
    "closed_at": "2023-12-20T06:35:27Z",
    "merged_at": "2023-12-20T06:35:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/258"
  },
  {
    "number": 257,
    "title": "fix log",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-20T06:27:20Z",
    "closed_at": "2023-12-20T06:27:31Z",
    "merged_at": "2023-12-20T06:27:31Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/257"
  },
  {
    "number": 256,
    "title": "fix log.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-20T06:20:53Z",
    "closed_at": "2023-12-20T06:21:11Z",
    "merged_at": "2023-12-20T06:21:11Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/256"
  },
  {
    "number": 255,
    "title": "Add unified log utility for lightllm",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-19T05:15:45Z",
    "closed_at": "2023-12-20T06:11:08Z",
    "merged_at": "2023-12-20T06:11:08Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/255"
  },
  {
    "number": 254,
    "title": "Update to make splitfuse_mode can run rightly when using triton-nightly.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-19T04:59:56Z",
    "closed_at": "2023-12-19T05:00:42Z",
    "merged_at": "2023-12-19T05:00:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/254"
  },
  {
    "number": 253,
    "title": "[Feature] support to output all prompt logprobs.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-19T03:32:47Z",
    "closed_at": "2023-12-19T03:42:23Z",
    "merged_at": "2023-12-19T03:42:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/253"
  },
  {
    "number": 252,
    "title": "Add logging module for lightllm",
    "user": "flyinglandlord",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-18T11:17:48Z",
    "closed_at": "2023-12-19T04:38:35Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/252"
  },
  {
    "number": 250,
    "title": "fix precision for ppl int4 quant",
    "user": "fuheaven",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-18T05:01:27Z",
    "closed_at": "2023-12-18T06:32:17Z",
    "merged_at": "2023-12-18T06:32:17Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/250"
  },
  {
    "number": 249,
    "title": "Fix special token id filter",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-15T11:06:28Z",
    "closed_at": "2023-12-15T11:09:12Z",
    "merged_at": "2023-12-15T11:09:12Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/249"
  },
  {
    "number": 248,
    "title": "[mistral] swa",
    "user": "ANDgate99",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-14T13:05:04Z",
    "closed_at": "2023-12-15T09:37:19Z",
    "merged_at": "2023-12-15T09:37:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/248"
  },
  {
    "number": 247,
    "title": "Upgrade gqa attention kernel.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-14T08:01:48Z",
    "closed_at": "2023-12-14T08:04:14Z",
    "merged_at": "2023-12-14T08:04:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/247"
  },
  {
    "number": 243,
    "title": "Adaptation of InternLM to GQA",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-07T12:09:19Z",
    "closed_at": "2023-12-07T12:09:37Z",
    "merged_at": "2023-12-07T12:09:37Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/243"
  },
  {
    "number": 242,
    "title": "upgrade gqa kernel to mode setting.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-04T07:42:08Z",
    "closed_at": "2023-12-04T07:48:03Z",
    "merged_at": "2023-12-04T07:48:03Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/242"
  },
  {
    "number": 238,
    "title": "add lmdeploy int4 weight quant mode",
    "user": "fuheaven",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-01T10:39:37Z",
    "closed_at": "2023-12-05T07:47:12Z",
    "merged_at": "2023-12-05T07:47:12Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/238"
  },
  {
    "number": 237,
    "title": "fix the bug of weight multiprocess loading",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-01T08:23:25Z",
    "closed_at": "2023-12-01T08:23:58Z",
    "merged_at": "2023-12-01T08:23:58Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/237"
  },
  {
    "number": 235,
    "title": "support ppl fp16 attention",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-01T07:13:08Z",
    "closed_at": "2023-12-01T07:13:59Z",
    "merged_at": "2023-12-01T07:13:59Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/235"
  },
  {
    "number": 232,
    "title": "upgrade router len calcu way. ",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-30T10:55:35Z",
    "closed_at": "2023-11-30T10:55:54Z",
    "merged_at": "2023-11-30T10:55:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/232"
  },
  {
    "number": 231,
    "title": "[feature] GQA triton flashdecoding kernel",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-29T08:47:35Z",
    "closed_at": "2023-11-29T08:49:12Z",
    "merged_at": "2023-11-29T08:49:12Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/231"
  },
  {
    "number": 229,
    "title": "fix",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-28T12:36:35Z",
    "closed_at": "2023-11-28T12:38:44Z",
    "merged_at": "2023-11-28T12:38:44Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/229"
  },
  {
    "number": 228,
    "title": "[feature] fast GQA decode attention kernel.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-28T11:17:58Z",
    "closed_at": "2023-11-28T11:18:45Z",
    "merged_at": "2023-11-28T11:18:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/228"
  },
  {
    "number": 227,
    "title": "fix splitfuse kernel bug",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-28T07:06:38Z",
    "closed_at": "2023-11-28T07:07:11Z",
    "merged_at": "2023-11-28T07:07:11Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/227"
  },
  {
    "number": 226,
    "title": "[Feature] Prompt cache and Splitfuse.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-27T07:53:58Z",
    "closed_at": "2023-11-27T10:32:06Z",
    "merged_at": "2023-11-27T10:32:06Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/226"
  },
  {
    "number": 225,
    "title": "Update version to 2.0.0",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-27T03:01:52Z",
    "closed_at": "2023-11-27T03:02:11Z",
    "merged_at": "2023-11-27T03:02:11Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/225"
  },
  {
    "number": 221,
    "title": "add args no_skipping_special_tokens and no_spaces_between_special_tokens",
    "user": "ChieloNewctle",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-21T02:29:28Z",
    "closed_at": "2023-11-21T07:39:05Z",
    "merged_at": "2023-11-21T07:39:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/221"
  },
  {
    "number": 220,
    "title": "add gpu name for test all settings.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-20T03:47:35Z",
    "closed_at": "2023-11-20T03:48:02Z",
    "merged_at": "2023-11-20T03:48:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/220"
  },
  {
    "number": 219,
    "title": "Update README.md",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-17T08:32:46Z",
    "closed_at": "2023-11-17T08:33:05Z",
    "merged_at": "2023-11-17T08:33:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/219"
  },
  {
    "number": 218,
    "title": "support Baichuan2-13b model",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-17T08:28:34Z",
    "closed_at": "2023-11-17T08:30:16Z",
    "merged_at": "2023-11-17T08:30:16Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/218"
  },
  {
    "number": 217,
    "title": "Baichuan2 13b",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-17T05:59:45Z",
    "closed_at": "2023-11-17T08:25:31Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/217"
  },
  {
    "number": 216,
    "title": "fix bug for lose token",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-16T09:25:43Z",
    "closed_at": "2023-11-16T09:26:28Z",
    "merged_at": "2023-11-16T09:26:28Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/216"
  },
  {
    "number": 215,
    "title": "fix Ppl int4 python impl bug",
    "user": "fuheaven",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-16T03:50:59Z",
    "closed_at": "2023-11-16T05:43:20Z",
    "merged_at": "2023-11-16T05:43:20Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/215"
  },
  {
    "number": 213,
    "title": "add support for repetition_penalty",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-14T02:31:55Z",
    "closed_at": "2023-11-14T02:32:06Z",
    "merged_at": "2023-11-14T02:32:06Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/213"
  },
  {
    "number": 212,
    "title": "add test setting tools code",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-13T12:13:02Z",
    "closed_at": "2023-11-13T12:15:37Z",
    "merged_at": "2023-11-13T12:15:37Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/212"
  },
  {
    "number": 211,
    "title": "add ppl int4 kernel",
    "user": "fuheaven",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-13T04:53:32Z",
    "closed_at": "2023-11-15T02:26:25Z",
    "merged_at": "2023-11-15T02:26:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/211"
  },
  {
    "number": 210,
    "title": "fix bug for #208",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-13T03:37:29Z",
    "closed_at": "2023-11-13T03:38:24Z",
    "merged_at": "2023-11-13T03:38:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/210"
  },
  {
    "number": 207,
    "title": "[feature] add chatglm3-6b-32k support",
    "user": "ChieloNewctle",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-10T09:45:05Z",
    "closed_at": "2023-11-13T02:29:38Z",
    "merged_at": "2023-11-13T02:29:38Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/207"
  },
  {
    "number": 206,
    "title": "add qwen_wquant support",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-10T09:19:49Z",
    "closed_at": "2023-11-10T09:23:40Z",
    "merged_at": "2023-11-10T09:23:40Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/206"
  },
  {
    "number": 205,
    "title": "Support multimodal llm model llava:  liuhaotian / llava-v1.5-7b and  liuhaotian / llava-v1.5-13b",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-10T07:05:18Z",
    "closed_at": "2024-01-02T06:41:12Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/205"
  },
  {
    "number": 204,
    "title": "fix bug for multi threads load weights.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-10T06:05:04Z",
    "closed_at": "2023-11-10T06:06:17Z",
    "merged_at": "2023-11-10T06:06:17Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/204"
  },
  {
    "number": 201,
    "title": "[feature] add lmdeploy int4weight kernel.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-09T11:46:06Z",
    "closed_at": "2023-11-09T11:46:40Z",
    "merged_at": "2023-11-09T11:46:40Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/201"
  },
  {
    "number": 200,
    "title": "fix",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-09T08:56:37Z",
    "closed_at": "2023-11-09T08:57:00Z",
    "merged_at": "2023-11-09T08:56:59Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/200"
  },
  {
    "number": 199,
    "title": "add support for Yi",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-09T08:19:39Z",
    "closed_at": "2023-11-09T08:20:05Z",
    "merged_at": "2023-11-09T08:20:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/199"
  },
  {
    "number": 198,
    "title": "fix",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-09T07:07:39Z",
    "closed_at": "2023-11-09T07:08:12Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/198"
  },
  {
    "number": 197,
    "title": "fix",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-09T06:58:34Z",
    "closed_at": "2023-11-09T07:02:13Z",
    "merged_at": "2023-11-09T07:02:13Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/197"
  },
  {
    "number": 196,
    "title": "fix",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-09T06:55:51Z",
    "closed_at": "2023-11-09T06:56:26Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/196"
  },
  {
    "number": 195,
    "title": "[feature] recode model framework and add new router ",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-09T04:29:12Z",
    "closed_at": "2023-11-09T04:31:39Z",
    "merged_at": "2023-11-09T04:31:39Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/195"
  },
  {
    "number": 194,
    "title": "recode model framework and add new router ",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-08T11:20:45Z",
    "closed_at": "2023-11-09T04:27:52Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/194"
  },
  {
    "number": 193,
    "title": "[feature] recode model framework and add new router",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-08T10:46:52Z",
    "closed_at": "2023-11-08T11:19:53Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/193"
  },
  {
    "number": 190,
    "title": "support Baichuan2-13b model",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-02T08:07:52Z",
    "closed_at": "2023-11-16T12:45:29Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/190"
  },
  {
    "number": 189,
    "title": "support Baichuan2-13b model",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-02T05:28:42Z",
    "closed_at": "2023-11-02T08:05:11Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/189"
  },
  {
    "number": 188,
    "title": "Dev/router new",
    "user": "jinbiaoyu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-01T09:14:18Z",
    "closed_at": "2023-11-10T02:12:56Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/188"
  },
  {
    "number": 186,
    "title": "Update README.md for Baichuan2-7b",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-31T06:07:18Z",
    "closed_at": "2023-10-31T06:08:19Z",
    "merged_at": "2023-10-31T06:08:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/186"
  },
  {
    "number": 185,
    "title": "[feature] llama llama2 qwen support flashdecoding kernel for long context",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-31T06:00:31Z",
    "closed_at": "2023-10-31T06:03:03Z",
    "merged_at": "2023-10-31T06:03:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/185"
  },
  {
    "number": 184,
    "title": "[Feature] Support to load quant weight.",
    "user": "helloyongyang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-29T17:32:36Z",
    "closed_at": "2024-03-04T06:52:03Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/184"
  },
  {
    "number": 183,
    "title": "support Baichuan2-7b model",
    "user": "wxd000000",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-27T09:11:49Z",
    "closed_at": "2023-10-30T02:37:14Z",
    "merged_at": "2023-10-30T02:37:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/183"
  },
  {
    "number": 182,
    "title": "Minor docs improvements",
    "user": "tmsagarofficial",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-27T07:00:07Z",
    "closed_at": "2023-10-27T07:01:48Z",
    "merged_at": "2023-10-27T07:01:48Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/182"
  },
  {
    "number": 181,
    "title": "fix bug for qwen tp 2 setting",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-26T09:22:16Z",
    "closed_at": "2023-10-26T09:23:23Z",
    "merged_at": "2023-10-26T09:23:23Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/181"
  },
  {
    "number": 179,
    "title": "[Feature] Add int8 and int4 quantize for starcoder.",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-25T09:09:18Z",
    "closed_at": "2023-10-27T05:32:21Z",
    "merged_at": "2023-10-27T05:32:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/179"
  },
  {
    "number": 175,
    "title": "fix bug for /v1/chat/completions",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-23T02:27:04Z",
    "closed_at": "2023-10-23T02:27:25Z",
    "merged_at": "2023-10-23T02:27:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/175"
  },
  {
    "number": 173,
    "title": "Token healing",
    "user": "ChieloNewctle",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-20T08:56:36Z",
    "closed_at": "2023-10-24T04:05:07Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/173"
  },
  {
    "number": 172,
    "title": "Expose interfaces to interpolate prefilling",
    "user": "ChieloNewctle",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-20T08:56:16Z",
    "closed_at": "2023-10-24T00:58:56Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/172"
  },
  {
    "number": 167,
    "title": "fix the invalid fig",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-17T10:32:18Z",
    "closed_at": "2023-10-17T10:32:25Z",
    "merged_at": "2023-10-17T10:32:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/167"
  },
  {
    "number": 166,
    "title": "GitHub main",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-16T12:32:14Z",
    "closed_at": "2023-10-16T12:32:27Z",
    "merged_at": "2023-10-16T12:32:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/166"
  },
  {
    "number": 165,
    "title": "Revert \"Merge internal (#164)\"",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-16T11:53:20Z",
    "closed_at": "2023-10-16T11:53:32Z",
    "merged_at": "2023-10-16T11:53:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/165"
  },
  {
    "number": 164,
    "title": "Merge internal",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-16T11:45:24Z",
    "closed_at": "2023-10-16T11:46:02Z",
    "merged_at": "2023-10-16T11:46:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/164"
  },
  {
    "number": 162,
    "title": "Dev/router upgrade",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-16T02:57:29Z",
    "closed_at": "2023-10-30T02:19:39Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/162"
  },
  {
    "number": 159,
    "title": "update the docker start command",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-12T03:18:57Z",
    "closed_at": "2023-10-12T03:19:33Z",
    "merged_at": "2023-10-12T03:19:33Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/159"
  },
  {
    "number": 151,
    "title": "Update README.md",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-25T08:12:33Z",
    "closed_at": "2023-09-25T08:13:05Z",
    "merged_at": "2023-09-25T08:13:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/151"
  },
  {
    "number": 150,
    "title": "Update Readme.md",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-25T07:58:52Z",
    "closed_at": "2023-09-25T07:59:18Z",
    "merged_at": "2023-09-25T07:59:18Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/150"
  },
  {
    "number": 149,
    "title": "modify setup.py triton version",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-25T07:39:27Z",
    "closed_at": "2023-09-25T07:40:06Z",
    "merged_at": "2023-09-25T07:40:06Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/149"
  },
  {
    "number": 148,
    "title": "Dev/router",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-25T05:59:43Z",
    "closed_at": "2023-10-16T02:58:13Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/148"
  },
  {
    "number": 144,
    "title": "[Quant] INT4 weight using different kernel when prefill & decode.",
    "user": "Tracin",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-22T05:19:28Z",
    "closed_at": "2023-09-22T06:27:42Z",
    "merged_at": "2023-09-22T06:27:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/144"
  },
  {
    "number": 143,
    "title": "Fix internlm bias",
    "user": "ChieloNewctle",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-22T04:30:45Z",
    "closed_at": "2023-09-22T07:45:02Z",
    "merged_at": "2023-09-22T07:45:02Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/143"
  },
  {
    "number": 141,
    "title": "starcoder support ppl int8kv",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-21T10:11:07Z",
    "closed_at": "2023-09-21T10:12:14Z",
    "merged_at": "2023-09-21T10:12:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/141"
  },
  {
    "number": 140,
    "title": "fix bug for qwen7b 8k length",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-20T10:54:33Z",
    "closed_at": "2023-09-20T10:55:56Z",
    "merged_at": "2023-09-20T10:55:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/140"
  },
  {
    "number": 139,
    "title": "qwen7b to support 8k length",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-20T10:33:26Z",
    "closed_at": "2023-09-20T10:35:37Z",
    "merged_at": "2023-09-20T10:35:37Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/139"
  },
  {
    "number": 137,
    "title": "add stop_sequences way to stop generate tokens",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-19T08:32:41Z",
    "closed_at": "2023-09-19T08:50:00Z",
    "merged_at": "2023-09-19T08:50:00Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/137"
  },
  {
    "number": 136,
    "title": "add llama2_ppl model, that use ppl int8kv kernel",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-18T07:21:33Z",
    "closed_at": "2023-09-18T07:22:58Z",
    "merged_at": "2023-09-18T07:22:58Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/136"
  },
  {
    "number": 133,
    "title": "Support Llama Multimodal",
    "user": "huochaitiantang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-15T07:00:02Z",
    "closed_at": "2023-09-18T02:17:35Z",
    "merged_at": "2023-09-18T02:17:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/133"
  },
  {
    "number": 132,
    "title": "add a llama_ppl model that use ppl fast decode attention kernel.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-14T06:27:13Z",
    "closed_at": "2023-09-14T06:29:01Z",
    "merged_at": "2023-09-14T06:29:01Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/132"
  },
  {
    "number": 127,
    "title": "add support dynamic ntk for llama",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-12T03:38:41Z",
    "closed_at": "2023-09-12T03:40:35Z",
    "merged_at": "2023-09-12T03:40:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/127"
  },
  {
    "number": 125,
    "title": "Some API changes",
    "user": "yunfeng-scale",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-11T22:28:40Z",
    "closed_at": "2023-09-18T06:55:42Z",
    "merged_at": "2023-09-18T06:55:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/125"
  },
  {
    "number": 123,
    "title": "Support OpenAI-Compatible APIs",
    "user": "WANDY666",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-08T09:01:38Z",
    "closed_at": "2023-09-11T01:39:03Z",
    "merged_at": "2023-09-11T01:39:03Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/123"
  },
  {
    "number": 118,
    "title": "[Support to CodeLlama] Add `rope_theta` to llama models",
    "user": "ChieloNewctle",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-06T02:57:01Z",
    "closed_at": "2023-09-08T05:27:27Z",
    "merged_at": "2023-09-08T05:27:26Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/118"
  },
  {
    "number": 113,
    "title": "[Bug Fix] Fix bug for triton 2.1.0 llama decode kernel and add llama2 decode attention kernel.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-31T11:02:32Z",
    "closed_at": "2023-08-31T11:04:51Z",
    "merged_at": "2023-08-31T11:04:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/113"
  },
  {
    "number": 112,
    "title": "[Feature] Add int8 quantize for llama.",
    "user": "Tracin",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-31T08:19:45Z",
    "closed_at": "2023-09-12T05:56:15Z",
    "merged_at": "2023-09-12T05:56:15Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/112"
  },
  {
    "number": 108,
    "title": "Uniform code style for utils for better readability",
    "user": "UranusSeven",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-29T04:13:29Z",
    "closed_at": "2023-09-05T06:53:25Z",
    "merged_at": "2023-09-05T06:53:25Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/108"
  },
  {
    "number": 105,
    "title": "update llama attention decode kernel support for triton2.1.0, better performance",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-28T07:17:13Z",
    "closed_at": "2023-08-28T07:17:47Z",
    "merged_at": "2023-08-28T07:17:47Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/105"
  },
  {
    "number": 103,
    "title": "fix the rotary for the chatglm2",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-24T11:09:27Z",
    "closed_at": "2023-08-24T11:09:51Z",
    "merged_at": "2023-08-24T11:09:51Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/103"
  },
  {
    "number": 99,
    "title": "Add `id` and `logprob` to `generate_stream`",
    "user": "ChieloNewctle",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-24T04:47:23Z",
    "closed_at": "2023-08-24T06:58:40Z",
    "merged_at": "2023-08-24T06:58:40Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/99"
  },
  {
    "number": 98,
    "title": "Add a cn doc about how to add a new model",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-23T06:02:10Z",
    "closed_at": "2023-08-23T06:09:01Z",
    "merged_at": "2023-08-23T06:09:01Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/98"
  },
  {
    "number": 97,
    "title": "support sending input_emds as input for TpPartBaseModel.forward",
    "user": "Lighten001",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-22T16:42:52Z",
    "closed_at": "2023-08-25T09:34:21Z",
    "merged_at": "2023-08-25T09:34:21Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/97"
  },
  {
    "number": 96,
    "title": "Internlm",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-22T15:39:55Z",
    "closed_at": "2023-08-22T15:40:05Z",
    "merged_at": "2023-08-22T15:40:05Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/96"
  },
  {
    "number": 94,
    "title": "Fix installer not copying all files",
    "user": "singularity-s0",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-21T09:25:16Z",
    "closed_at": "2023-08-21T09:28:31Z",
    "merged_at": "2023-08-21T09:28:31Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/94"
  },
  {
    "number": 93,
    "title": "Support for NTK-aware Scaled RoPE from Environment Variables",
    "user": "singularity-s0",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-21T09:14:47Z",
    "closed_at": "2023-08-22T07:42:34Z",
    "merged_at": "2023-08-22T07:42:34Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/93"
  },
  {
    "number": 91,
    "title": "fix bug for aborted req",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-21T04:27:52Z",
    "closed_at": "2023-08-21T04:28:32Z",
    "merged_at": "2023-08-21T04:28:32Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/91"
  },
  {
    "number": 87,
    "title": "Update README.md to Add support For Baichuan13B",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-18T10:23:00Z",
    "closed_at": "2023-08-18T10:23:14Z",
    "merged_at": "2023-08-18T10:23:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/87"
  },
  {
    "number": 86,
    "title": "Refactor the code to make adding models easier.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-18T10:13:24Z",
    "closed_at": "2023-08-18T10:17:41Z",
    "merged_at": "2023-08-18T10:17:41Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/86"
  },
  {
    "number": 85,
    "title": "Starcoder chatglm2",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-18T07:32:34Z",
    "closed_at": "2023-08-18T07:36:36Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/85"
  },
  {
    "number": 82,
    "title": "Support for NTK-aware Scaled RoPE",
    "user": "singularity-s0",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-17T07:52:13Z",
    "closed_at": "2023-08-21T07:57:42Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/82"
  },
  {
    "number": 81,
    "title": "Support automatically calculate max_total_token_num",
    "user": "singularity-s0",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-17T05:46:26Z",
    "closed_at": "2025-04-14T02:28:32Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/81"
  },
  {
    "number": 77,
    "title": "Update shield",
    "user": "llehtahw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-16T08:51:29Z",
    "closed_at": "2023-08-16T08:51:48Z",
    "merged_at": "2023-08-16T08:51:48Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/77"
  },
  {
    "number": 76,
    "title": "Update about discord",
    "user": "llehtahw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-16T04:32:55Z",
    "closed_at": "2023-08-16T04:34:29Z",
    "merged_at": "2023-08-16T04:34:29Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/76"
  },
  {
    "number": 74,
    "title": "fix readme.md",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-15T08:39:19Z",
    "closed_at": "2023-08-15T08:39:38Z",
    "merged_at": "2023-08-15T08:39:38Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/74"
  },
  {
    "number": 72,
    "title": "Update issue templates",
    "user": "llehtahw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-15T01:37:40Z",
    "closed_at": "2023-08-15T02:02:52Z",
    "merged_at": "2023-08-15T02:02:52Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/72"
  },
  {
    "number": 70,
    "title": "fix readme",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-14T08:03:40Z",
    "closed_at": "2023-08-14T08:04:08Z",
    "merged_at": "2023-08-14T08:04:08Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/70"
  },
  {
    "number": 69,
    "title": "fix readme",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-14T08:00:35Z",
    "closed_at": "2023-08-14T08:00:59Z",
    "merged_at": "2023-08-14T08:00:59Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/69"
  },
  {
    "number": 68,
    "title": "fix readme",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-14T07:58:31Z",
    "closed_at": "2023-08-14T07:59:14Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/68"
  },
  {
    "number": 67,
    "title": "Support Baichuan-7B",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-14T07:29:53Z",
    "closed_at": "2023-08-14T07:31:54Z",
    "merged_at": "2023-08-14T07:31:54Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/67"
  },
  {
    "number": 63,
    "title": "Modify readme about container multiple GPUs usage",
    "user": "llehtahw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-12T16:00:51Z",
    "closed_at": "2023-08-12T16:24:48Z",
    "merged_at": "2023-08-12T16:24:48Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/63"
  },
  {
    "number": 60,
    "title": "fix Qwen-7b --tp 2 load weights bug",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T17:23:13Z",
    "closed_at": "2023-08-11T17:23:56Z",
    "merged_at": "2023-08-11T17:23:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/60"
  },
  {
    "number": 59,
    "title": "Update dockerfile and related readme",
    "user": "llehtahw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T16:34:42Z",
    "closed_at": "2023-08-11T16:35:45Z",
    "merged_at": "2023-08-11T16:35:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/59"
  },
  {
    "number": 58,
    "title": "Refactoring the implementation of throughput analysis logs",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T10:16:04Z",
    "closed_at": "2023-08-11T10:17:49Z",
    "merged_at": "2023-08-11T10:17:49Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/58"
  },
  {
    "number": 55,
    "title": "fix Qwen-7b start error",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T09:20:55Z",
    "closed_at": "2023-08-11T09:21:24Z",
    "merged_at": "2023-08-11T09:21:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/55"
  },
  {
    "number": 53,
    "title": "update context_flashattention triton kernel to support V100",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T08:03:47Z",
    "closed_at": "2023-08-11T08:04:55Z",
    "merged_at": "2023-08-11T08:04:55Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/53"
  },
  {
    "number": 51,
    "title": "Add docker build action",
    "user": "llehtahw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T04:33:54Z",
    "closed_at": "2023-08-11T10:04:43Z",
    "merged_at": "2023-08-11T10:04:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/51"
  },
  {
    "number": 50,
    "title": "fix bug for start up llama2",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T01:41:54Z",
    "closed_at": "2023-08-11T01:43:24Z",
    "merged_at": "2023-08-11T01:43:24Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/50"
  },
  {
    "number": 49,
    "title": "Report traceback from router init process",
    "user": "llehtahw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T01:04:05Z",
    "closed_at": "2023-08-11T01:07:27Z",
    "merged_at": "2023-08-11T01:07:27Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/49"
  },
  {
    "number": 47,
    "title": "add support for chatglm and trust_remote_code",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-10T16:53:22Z",
    "closed_at": "2023-08-10T16:53:46Z",
    "merged_at": "2023-08-10T16:53:46Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/47"
  },
  {
    "number": 46,
    "title": "Support Qwen-7b",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-10T12:24:32Z",
    "closed_at": "2023-08-10T12:26:45Z",
    "merged_at": "2023-08-10T12:26:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/46"
  },
  {
    "number": 42,
    "title": "Fix garbled Chinese output",
    "user": "llehtahw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-10T03:20:43Z",
    "closed_at": "2023-08-10T03:26:45Z",
    "merged_at": "2023-08-10T03:26:45Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/42"
  },
  {
    "number": 38,
    "title": "Add log to print average tokens throughput.",
    "user": "shanshanpt",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-09T08:35:34Z",
    "closed_at": "2023-08-11T09:08:30Z",
    "merged_at": "2023-08-11T09:08:30Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/38"
  },
  {
    "number": 36,
    "title": "Fix the encoding problem of Chinese",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-09T06:59:20Z",
    "closed_at": "2023-08-09T06:59:34Z",
    "merged_at": "2023-08-09T06:59:34Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/36"
  },
  {
    "number": 33,
    "title": "add support for starcoder",
    "user": "shihaobai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-08T14:58:22Z",
    "closed_at": "2023-08-08T14:58:58Z",
    "merged_at": "2023-08-08T14:58:58Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/33"
  },
  {
    "number": 32,
    "title": "support int8kv cache in llama model",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-08T12:28:05Z",
    "closed_at": "2023-08-08T12:28:53Z",
    "merged_at": "2023-08-08T12:28:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/32"
  },
  {
    "number": 30,
    "title": "Refactoring code for readability",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-08T09:11:31Z",
    "closed_at": "2023-08-08T09:11:42Z",
    "merged_at": "2023-08-08T09:11:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/30"
  },
  {
    "number": 29,
    "title": "Add error reports from sub process",
    "user": "llehtahw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-08T07:30:59Z",
    "closed_at": "2023-08-08T08:29:53Z",
    "merged_at": "2023-08-08T08:29:53Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/29"
  },
  {
    "number": 27,
    "title": "add nccl_port to startup args",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-08T07:09:45Z",
    "closed_at": "2023-08-08T07:10:31Z",
    "merged_at": "2023-08-08T07:10:31Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/27"
  },
  {
    "number": 24,
    "title": "Implementation of Positional Interpolation (PI) Feature",
    "user": "andy-yang-1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-07T21:22:59Z",
    "closed_at": "2023-08-08T06:17:19Z",
    "merged_at": "2023-08-08T06:17:19Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/24"
  },
  {
    "number": 22,
    "title": "api server args batch_max_tokens auto set value, To avoid the problem of a program getting stuck",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-07T11:05:09Z",
    "closed_at": "2023-08-07T11:10:14Z",
    "merged_at": "2023-08-07T11:10:14Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/22"
  },
  {
    "number": 18,
    "title": "Install lightllm in dockerfile",
    "user": "hamelsmu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-05T22:13:53Z",
    "closed_at": "2023-08-07T03:43:04Z",
    "merged_at": "2023-08-07T03:43:04Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/18"
  },
  {
    "number": 14,
    "title": "Usage instructions for the server parameter",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-03T09:18:54Z",
    "closed_at": "2023-08-03T09:19:17Z",
    "merged_at": "2023-08-03T09:19:17Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/14"
  },
  {
    "number": 11,
    "title": "Optimize test code to reduce duplicate code.",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-03T03:03:41Z",
    "closed_at": "2023-08-03T03:04:35Z",
    "merged_at": "2023-08-03T03:04:35Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/11"
  },
  {
    "number": 6,
    "title": "Fix filter batch",
    "user": "llehtahw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-01T16:38:06Z",
    "closed_at": "2023-08-02T10:37:11Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/6"
  },
  {
    "number": 5,
    "title": "Reduce some gpu ops",
    "user": "llehtahw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-31T12:54:52Z",
    "closed_at": "2023-08-16T04:34:38Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/5"
  },
  {
    "number": 3,
    "title": "add dep package \"safetensors\" in setup.py and requirements.txt for feature \"support llama model load from safetensor format\"",
    "user": "hiworldwzj",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-27T10:54:15Z",
    "closed_at": "2023-07-27T10:56:42Z",
    "merged_at": "2023-07-27T10:56:42Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/3"
  },
  {
    "number": 1,
    "title": "[feat]: support safetensors for llama && llama2",
    "user": "XFPlus",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-26T08:10:25Z",
    "closed_at": "2023-07-27T09:25:56Z",
    "merged_at": "2023-07-27T09:25:56Z",
    "state": "closed",
    "html_url": "https://github.com/ModelTC/LightLLM/pull/1"
  }
]