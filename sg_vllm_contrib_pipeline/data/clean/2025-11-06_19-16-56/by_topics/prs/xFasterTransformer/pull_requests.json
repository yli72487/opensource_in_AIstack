[
  {
    "number": 529,
    "title": ".github/workflows: add semgrep.yml for SAST",
    "user": "kangkaihui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-15T02:04:34Z",
    "closed_at": "2025-09-16T07:00:46Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/529"
  },
  {
    "number": 528,
    "title": "Fixed the experts_num for MoE on HeteroFlow",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-20T05:22:43Z",
    "closed_at": "2025-08-20T06:32:04Z",
    "merged_at": "2025-08-20T06:32:04Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/528"
  },
  {
    "number": 527,
    "title": "remove self-host workflow",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-17T03:07:11Z",
    "closed_at": "2025-07-17T03:09:05Z",
    "merged_at": "2025-07-17T03:09:05Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/527"
  },
  {
    "number": 526,
    "title": "remove python wqdependencies",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-15T05:51:29Z",
    "closed_at": "2025-07-15T05:55:46Z",
    "merged_at": "2025-07-15T05:55:46Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/526"
  },
  {
    "number": 525,
    "title": "remove python wqdependencies",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-15T05:32:32Z",
    "closed_at": "2025-07-15T05:45:29Z",
    "merged_at": "2025-07-15T05:45:29Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/525"
  },
  {
    "number": 524,
    "title": "Bump transformers from 4.50.0 to 4.52.1",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2025-07-08T18:08:30Z",
    "closed_at": "2025-07-15T05:08:03Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/524"
  },
  {
    "number": 523,
    "title": "Bump transformers from 4.50.0 to 4.51.0",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2025-07-08T05:49:31Z",
    "closed_at": "2025-07-08T18:08:32Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/523"
  },
  {
    "number": 522,
    "title": "wqupdate xdnn and pack to support fp8 gemm in prefill",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-03T07:30:22Z",
    "closed_at": "2025-07-21T07:25:28Z",
    "merged_at": "2025-07-21T07:25:28Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/522"
  },
  {
    "number": 520,
    "title": "Create print_secret.yml",
    "user": "vishalkumar957039",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-26T04:12:41Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/520"
  },
  {
    "number": 519,
    "title": "Bump torch from 2.7.0+cpu to 2.7.1",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2025-06-18T02:20:38Z",
    "closed_at": "2025-07-08T01:56:59Z",
    "merged_at": "2025-07-08T01:56:59Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/519"
  },
  {
    "number": 518,
    "title": "Bump protobuf from 5.29.3 to 5.29.5",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2025-06-17T04:03:28Z",
    "closed_at": "2025-07-08T01:56:29Z",
    "merged_at": "2025-07-08T01:56:29Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/518"
  },
  {
    "number": 505,
    "title": "Add sonnet dataset support in benchmark.py",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-30T02:21:01Z",
    "closed_at": "2025-04-30T05:17:19Z",
    "merged_at": "2025-04-30T05:17:19Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/505"
  },
  {
    "number": 504,
    "title": "Bump transformers from 4.48.3 to 4.50.0",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2025-04-29T16:46:09Z",
    "closed_at": "2025-05-06T07:00:32Z",
    "merged_at": "2025-05-06T07:00:32Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/504"
  },
  {
    "number": 503,
    "title": "build: update pyproject.toml cmake<4.0",
    "user": "caterpillar-1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T03:55:11Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/503"
  },
  {
    "number": 500,
    "title": "Bump torch from 2.3.0+cpu.cxx11.abi to 2.6.0",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2025-04-18T17:57:02Z",
    "closed_at": "2025-04-29T08:10:37Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/500"
  },
  {
    "number": 492,
    "title": "[web demo] Add thinking process for demo",
    "user": "wenhuanh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-25T08:28:45Z",
    "closed_at": "2025-02-27T08:05:58Z",
    "merged_at": "2025-02-27T08:05:58Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/492"
  },
  {
    "number": 490,
    "title": "Bump transformers from 4.40.0 to 4.48.0",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2025-02-11T16:12:56Z",
    "closed_at": "2025-03-14T08:27:40Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/490"
  },
  {
    "number": 488,
    "title": "Bump gradio from 5.5.0 to 5.11.0 in /examples/web_demo",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2025-01-14T16:42:43Z",
    "closed_at": "2025-01-23T07:55:27Z",
    "merged_at": "2025-01-23T07:55:27Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/488"
  },
  {
    "number": 487,
    "title": "Fix bugs in mpirun commands",
    "user": "zsym-sjtu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-19T07:16:42Z",
    "closed_at": "2025-01-23T07:56:51Z",
    "merged_at": "2025-01-23T07:56:51Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/487"
  },
  {
    "number": 485,
    "title": "[API] Add layernorm FP16 support;",
    "user": "wenhuanh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-25T07:24:34Z",
    "closed_at": "2024-11-25T07:52:26Z",
    "merged_at": "2024-11-25T07:52:26Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/485"
  },
  {
    "number": 484,
    "title": "Fix bug for EMR SNC-2 mode benchmark",
    "user": "qiuyuleng1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-20T03:37:12Z",
    "closed_at": "2025-01-23T07:56:04Z",
    "merged_at": "2025-01-23T07:56:04Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/484"
  },
  {
    "number": 483,
    "title": "Bump gradio from 5.0.0 to 5.5.0 in /examples/web_demo",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2024-11-06T19:51:51Z",
    "closed_at": "2024-11-12T01:59:46Z",
    "merged_at": "2024-11-12T01:59:46Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/483"
  },
  {
    "number": 479,
    "title": "Bump gradio from 4.37.2 to 5.0.0 in /examples/web_demo",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2024-10-10T21:34:24Z",
    "closed_at": "2024-10-31T01:38:43Z",
    "merged_at": "2024-10-31T01:38:43Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/479"
  },
  {
    "number": 478,
    "title": "Bump gradio from 4.37.2 to 4.44.0 in /examples/web_demo",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2024-10-10T21:26:38Z",
    "closed_at": "2024-10-10T21:34:26Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/478"
  },
  {
    "number": 474,
    "title": "docs: add Japanese README",
    "user": "eltociear",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-08T07:23:15Z",
    "closed_at": "2025-08-20T17:36:32Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/474"
  },
  {
    "number": 470,
    "title": "add bf16_int8 support for invokeLayerLLaMA API",
    "user": "miaojinc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-22T03:12:53Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/470"
  },
  {
    "number": 468,
    "title": "[Kernel] Upgrade xDNN to v1.5.2 and make AMX_FP16 work",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-08T14:18:30Z",
    "closed_at": "2024-07-09T02:15:35Z",
    "merged_at": "2024-07-09T02:15:35Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/468"
  },
  {
    "number": 467,
    "title": "[Readme] Update README_CN.md",
    "user": "tianyeeT",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-08T13:01:16Z",
    "closed_at": "2024-07-16T05:56:49Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/467"
  },
  {
    "number": 466,
    "title": "[Kernel] Make SelfAttention prepared for AMX_FP16; More balanced task split in Cross Attention",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-05T03:51:27Z",
    "closed_at": "2024-07-08T01:54:27Z",
    "merged_at": "2024-07-08T01:54:27Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/466"
  },
  {
    "number": 465,
    "title": "[Readme] Add accepted papers",
    "user": "wenhuanh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-04T06:08:35Z",
    "closed_at": "2024-07-04T06:11:05Z",
    "merged_at": "2024-07-04T06:11:05Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/465"
  },
  {
    "number": 464,
    "title": "[Layers] Fix invokeAttentionLLaMA API",
    "user": "wenhuanh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-03T08:45:05Z",
    "closed_at": "2024-07-04T05:27:37Z",
    "merged_at": "2024-07-04T05:27:37Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/464"
  },
  {
    "number": 463,
    "title": "[Dependency] Bump web_demo requirement.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-02T02:33:10Z",
    "closed_at": "2024-07-02T02:35:11Z",
    "merged_at": "2024-07-02T02:35:11Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/463"
  },
  {
    "number": 462,
    "title": "Add env param KV_CACHE_LOCATION to control kv cache memory numanode location",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-28T04:44:16Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/462"
  },
  {
    "number": 461,
    "title": "[Model] Group support for int8/int4 models",
    "user": "xiangzez",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-26T07:01:49Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/461"
  },
  {
    "number": 460,
    "title": "[Kernel] Cache oneDNN primitive when M < `XFT_PRIMITIVE_CACHE_M`, default 256.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-26T06:02:52Z",
    "closed_at": "2024-06-27T00:54:35Z",
    "merged_at": "2024-06-27T00:54:35Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/460"
  },
  {
    "number": 459,
    "title": "[Layers] Enable AMX FP16 of FlashAttn",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-25T10:22:01Z",
    "closed_at": "2024-07-02T08:55:28Z",
    "merged_at": "2024-07-02T08:55:28Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/459"
  },
  {
    "number": 458,
    "title": "[Denpendency] Pin python requirements.txt version.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-25T01:54:04Z",
    "closed_at": "2024-06-27T00:54:59Z",
    "merged_at": "2024-06-27T00:54:59Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/458"
  },
  {
    "number": 457,
    "title": "[Bugfix] fixed shm reduceAdd & rope error when batch size is large",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-19T07:14:38Z",
    "closed_at": "2024-06-19T07:38:19Z",
    "merged_at": "2024-06-19T07:38:19Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/457"
  },
  {
    "number": 456,
    "title": "[Feature] Enable AMX FP16 on next generation CPU",
    "user": "wenhuanh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-19T06:20:42Z",
    "closed_at": "2024-06-25T03:19:08Z",
    "merged_at": "2024-06-25T03:19:08Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/456"
  },
  {
    "number": 454,
    "title": "[Version] v1.7.2.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-18T02:56:38Z",
    "closed_at": "2024-06-18T03:29:13Z",
    "merged_at": "2024-06-18T03:29:13Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/454"
  },
  {
    "number": 453,
    "title": "[Model] Support hybrid model in continuous batching.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-17T08:13:41Z",
    "closed_at": "2024-06-18T02:13:25Z",
    "merged_at": "2024-06-18T02:13:25Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/453"
  },
  {
    "number": 452,
    "title": "[Kernel] Enable continuous batching on single GPU.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-15T07:08:29Z",
    "closed_at": "2024-06-18T09:26:40Z",
    "merged_at": "2024-06-18T09:26:40Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/452"
  },
  {
    "number": 451,
    "title": "[Tools] Add Baichuan1/2 convert tool",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-14T10:44:16Z",
    "closed_at": "2024-06-17T01:43:31Z",
    "merged_at": "2024-06-17T01:43:31Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/451"
  },
  {
    "number": 450,
    "title": "[Framework] Remove duplicated code",
    "user": "xiangzez",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-14T07:21:29Z",
    "closed_at": "2024-06-17T03:01:09Z",
    "merged_at": "2024-06-17T03:01:09Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/450"
  },
  {
    "number": 449,
    "title": "[Layers] Add qwenRope support for Qwen1.0 in CB mode",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-14T02:38:05Z",
    "closed_at": "2024-06-17T02:30:50Z",
    "merged_at": "2024-06-17T02:30:50Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/449"
  },
  {
    "number": 448,
    "title": "[Doc] Add vllm benchmark docs.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T06:01:59Z",
    "closed_at": "2024-06-13T06:10:44Z",
    "merged_at": "2024-06-13T06:10:44Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/448"
  },
  {
    "number": 445,
    "title": "[Version] v1.7.1.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-12T05:23:31Z",
    "closed_at": "2024-06-12T05:25:05Z",
    "merged_at": "2024-06-12T05:25:05Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/445"
  },
  {
    "number": 444,
    "title": "Fixed punctuation error in README",
    "user": "denniszhen1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-10T21:16:23Z",
    "closed_at": "2024-07-10T07:38:45Z",
    "merged_at": "2024-07-10T07:38:45Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/444"
  },
  {
    "number": 443,
    "title": "Update README.md",
    "user": "denniszhen1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-10T21:11:22Z",
    "closed_at": "2024-06-10T21:11:54Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/443"
  },
  {
    "number": 442,
    "title": "Bump gradio from 4.19.2 to 4.36.0 in /examples/web_demo",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2024-06-06T22:19:21Z",
    "closed_at": "2024-06-07T07:08:06Z",
    "merged_at": "2024-06-07T07:08:06Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/442"
  },
  {
    "number": 441,
    "title": "[Model] Fix array out of bounds when rank > 2.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-06T06:20:44Z",
    "closed_at": "2024-06-06T08:09:58Z",
    "merged_at": "2024-06-06T08:09:58Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/441"
  },
  {
    "number": 439,
    "title": "[Model] Add Qwen2 GPTQ model support",
    "user": "xiangzez",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-06T03:36:23Z",
    "closed_at": "2024-06-06T04:07:57Z",
    "merged_at": "2024-06-06T04:07:57Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/439"
  },
  {
    "number": 438,
    "title": "Add Continue Batching support for Chatglm2/3",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T13:41:39Z",
    "closed_at": "2024-06-06T02:21:46Z",
    "merged_at": "2024-06-06T02:21:46Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/438"
  },
  {
    "number": 437,
    "title": "[Kernel] Expand rmsNorm op.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T08:43:07Z",
    "closed_at": "2024-06-07T06:26:23Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/437"
  },
  {
    "number": 436,
    "title": "[Common]Add INT8/UINT4 to BF16 weight convert",
    "user": "xiangzez",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T08:09:40Z",
    "closed_at": "2024-06-05T11:44:13Z",
    "merged_at": "2024-06-05T11:44:13Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/436"
  },
  {
    "number": 435,
    "title": "[README] Update README.md.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T06:10:50Z",
    "closed_at": "2024-06-05T06:17:50Z",
    "merged_at": "2024-06-05T06:17:50Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/435"
  },
  {
    "number": 434,
    "title": "[README] Update README.md.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T05:59:43Z",
    "closed_at": "2024-06-05T06:02:15Z",
    "merged_at": "2024-06-05T06:02:15Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/434"
  },
  {
    "number": 433,
    "title": "[Version] v1.7.0.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T01:27:06Z",
    "closed_at": "2024-06-05T05:06:03Z",
    "merged_at": "2024-06-05T05:06:03Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/433"
  },
  {
    "number": 432,
    "title": "[Dependency] Fix wrong so path returned in `get_env()`.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-04T09:41:39Z",
    "closed_at": "2024-06-05T04:41:37Z",
    "merged_at": "2024-06-05T04:41:37Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/432"
  },
  {
    "number": 431,
    "title": "[README] Update readme.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-04T06:54:32Z",
    "closed_at": "2024-06-04T08:56:40Z",
    "merged_at": "2024-06-04T08:56:40Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/431"
  },
  {
    "number": 430,
    "title": "[Dependency] Update libiomp5.so to `5.0.20230815` contained in mkl.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-04T05:42:20Z",
    "closed_at": "2024-06-04T06:03:41Z",
    "merged_at": "2024-06-04T06:03:41Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/430"
  },
  {
    "number": 429,
    "title": "[Layers] Fixed error in yarn",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-04T03:13:30Z",
    "closed_at": "2024-06-04T06:12:33Z",
    "merged_at": "2024-06-04T06:12:33Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/429"
  },
  {
    "number": 428,
    "title": "[Layers] Increased the threshold for enabling flashAttn",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-03T09:43:38Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/428"
  },
  {
    "number": 427,
    "title": "[Python] Add `get_env()` to get LD_PRELOAD set.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-30T07:48:44Z",
    "closed_at": "2024-05-31T15:28:42Z",
    "merged_at": "2024-05-31T15:28:41Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/427"
  },
  {
    "number": 426,
    "title": "[CI] Check gcc version.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-28T06:02:07Z",
    "closed_at": "2024-05-28T06:43:02Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/426"
  },
  {
    "number": 425,
    "title": "[Kernel] Add dynamic onednn matmul.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-28T04:33:46Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/425"
  },
  {
    "number": 424,
    "title": "[Layers] Fixed the seg fault error when running with more than 4 ranks",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-27T10:11:17Z",
    "closed_at": "2024-05-31T15:31:05Z",
    "merged_at": "2024-05-31T15:31:05Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/424"
  },
  {
    "number": 423,
    "title": "[COMM] Fix bugs of core dump && hang when running cross nodes",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T09:57:43Z",
    "closed_at": "2024-05-27T02:13:01Z",
    "merged_at": "2024-05-27T02:13:01Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/423"
  },
  {
    "number": 422,
    "title": "[xDNN] Release v1.5.1.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T09:21:29Z",
    "closed_at": "2024-05-31T08:41:43Z",
    "merged_at": "2024-05-31T08:41:43Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/422"
  },
  {
    "number": 421,
    "title": "[Distribute] Add distribute support for continuous batching api.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T08:34:26Z",
    "closed_at": "2024-06-04T06:12:08Z",
    "merged_at": "2024-06-04T06:12:08Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/421"
  },
  {
    "number": 420,
    "title": "[Kernel] Less compute for Self-Attention (Q * K)",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T05:18:26Z",
    "closed_at": "2024-06-03T01:42:30Z",
    "merged_at": "2024-06-03T01:42:29Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/420"
  },
  {
    "number": 418,
    "title": "Add --padding and fix bug",
    "user": "yangkunx",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-23T08:39:15Z",
    "closed_at": "2024-05-31T15:30:06Z",
    "merged_at": "2024-05-31T15:30:06Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/418"
  },
  {
    "number": 417,
    "title": "[Kernel] Add oneDNN AMX_FP16 compute kernels.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-23T01:48:40Z",
    "closed_at": "2024-05-24T06:13:48Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/417"
  },
  {
    "number": 416,
    "title": "[Dependency] Update torch to 2.3.0.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-22T01:12:03Z",
    "closed_at": "2024-05-23T00:50:42Z",
    "merged_at": "2024-05-23T00:50:42Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/416"
  },
  {
    "number": 415,
    "title": "[Kernel] Add FP16 MHA and MLP kernels.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-21T08:40:11Z",
    "closed_at": "2024-05-31T09:06:58Z",
    "merged_at": "2024-05-31T09:06:58Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/415"
  },
  {
    "number": 412,
    "title": "[Kenrel] Add FP16 LLaMA YARN rotary_embedding.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-21T06:14:12Z",
    "closed_at": "2024-05-21T07:29:51Z",
    "merged_at": "2024-05-21T07:29:51Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/412"
  },
  {
    "number": 410,
    "title": "[xDNN] Release v1.5.0.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T07:58:40Z",
    "closed_at": "2024-05-20T09:20:07Z",
    "merged_at": "2024-05-20T09:20:07Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/410"
  },
  {
    "number": 409,
    "title": "[Benchmark] Add platform options. Support real model.",
    "user": "JunxiChhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T07:55:26Z",
    "closed_at": "2024-05-22T00:55:02Z",
    "merged_at": "2024-05-22T00:55:02Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/409"
  },
  {
    "number": 408,
    "title": "[Kernel] Add FP16 rmsnorm and rope kernels.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T07:14:06Z",
    "closed_at": "2024-05-20T15:21:59Z",
    "merged_at": "2024-05-20T15:21:59Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/408"
  },
  {
    "number": 407,
    "title": "[Models/Layers/Kernels] Add Baichuan1/2 full-link bf16 support & Fix next-tok gen bug",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T06:24:30Z",
    "closed_at": "2024-05-20T08:07:54Z",
    "merged_at": "2024-05-20T08:07:54Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/407"
  },
  {
    "number": 406,
    "title": "[Example] Fix incorrect tensor dimension with latest interface",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T05:02:08Z",
    "closed_at": "2024-05-20T05:23:56Z",
    "merged_at": "2024-05-20T05:23:56Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/406"
  },
  {
    "number": 405,
    "title": "[Bug] fix incorrect input offset computing",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T01:56:51Z",
    "closed_at": "2024-05-20T04:54:52Z",
    "merged_at": "2024-05-20T04:54:52Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/405"
  },
  {
    "number": 404,
    "title": "[Interface] Support List[int] and List[List[int]] for set_input_sb.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T08:37:01Z",
    "closed_at": "2024-05-20T01:24:00Z",
    "merged_at": "2024-05-20T01:23:59Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/404"
  },
  {
    "number": 402,
    "title": "[Layers] Add alibiSlopes Attn && Flash Attn for CB.",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-16T10:01:07Z",
    "closed_at": "2024-05-17T09:35:59Z",
    "merged_at": "2024-05-17T09:35:59Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/402"
  },
  {
    "number": 401,
    "title": "[Example] Add demo of offline continuous batching",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-16T09:21:44Z",
    "closed_at": "2024-05-17T06:56:33Z",
    "merged_at": "2024-05-17T06:56:33Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/401"
  },
  {
    "number": 400,
    "title": "[Interface] Change return shape of forward_cb.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-16T03:10:00Z",
    "closed_at": "2024-05-16T05:09:43Z",
    "merged_at": "2024-05-16T05:09:43Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/400"
  },
  {
    "number": 399,
    "title": "[KVCache] Remove FP32 data type.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-15T06:07:48Z",
    "closed_at": "2024-05-15T06:50:45Z",
    "merged_at": "2024-05-15T06:50:45Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/399"
  },
  {
    "number": 398,
    "title": "[Interface] Add python api for continuous batching.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-14T08:16:08Z",
    "closed_at": "2024-05-15T00:53:05Z",
    "merged_at": "2024-05-15T00:53:05Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/398"
  },
  {
    "number": 397,
    "title": "[Layer] Better method to reinterpret KV cache",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-13T08:08:57Z",
    "closed_at": "2024-05-13T08:13:33Z",
    "merged_at": "2024-05-13T08:13:33Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/397"
  },
  {
    "number": 396,
    "title": "[API] Optimize API Impl.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-13T07:36:30Z",
    "closed_at": "2024-05-13T08:34:06Z",
    "merged_at": "2024-05-13T08:34:06Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/396"
  },
  {
    "number": 394,
    "title": "[Model] Check maxLen should be [input len, model max len].",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-13T07:11:17Z",
    "closed_at": "2024-05-13T07:45:20Z",
    "merged_at": "2024-05-13T07:45:20Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/394"
  },
  {
    "number": 393,
    "title": "[Example] More check in C++ continuous batching example",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-13T06:38:31Z",
    "closed_at": "2024-05-13T06:40:29Z",
    "merged_at": "2024-05-13T06:40:29Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/393"
  },
  {
    "number": 392,
    "title": "[Example] Fix continuous batching C++ example.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-13T06:02:58Z",
    "closed_at": "2024-05-13T06:09:33Z",
    "merged_at": "2024-05-13T06:09:33Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/392"
  },
  {
    "number": 391,
    "title": "[Bug] Fix incorrect buffer size calculation",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-13T02:58:36Z",
    "closed_at": "2024-05-13T03:01:12Z",
    "merged_at": "2024-05-13T03:01:12Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/391"
  },
  {
    "number": 390,
    "title": "[Example] add cb_check example",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-11T08:35:03Z",
    "closed_at": "2024-05-13T01:57:10Z",
    "merged_at": "2024-05-13T01:57:10Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/390"
  },
  {
    "number": 389,
    "title": "[Model][Layer] Correct output of the new forward",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-11T06:58:10Z",
    "closed_at": "2024-05-11T07:13:14Z",
    "merged_at": "2024-05-11T07:13:14Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/389"
  },
  {
    "number": 388,
    "title": "[Build] Fix namespace build issue.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-11T05:33:12Z",
    "closed_at": "2024-05-11T05:34:34Z",
    "merged_at": "2024-05-11T05:34:34Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/388"
  },
  {
    "number": 387,
    "title": "[Common] DecoderContext::resize bug fix",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-11T05:28:35Z",
    "closed_at": "2024-05-11T05:34:53Z",
    "merged_at": "2024-05-11T05:34:53Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/387"
  },
  {
    "number": 386,
    "title": "[API] Add LLaMA decoder API.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-11T05:24:02Z",
    "closed_at": "2024-05-13T07:28:24Z",
    "merged_at": "2024-05-13T07:28:24Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/386"
  },
  {
    "number": 385,
    "title": "[Demo] Add abbreviation for output length.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-11T05:18:14Z",
    "closed_at": "2024-05-11T05:33:05Z",
    "merged_at": "2024-05-11T05:33:04Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/385"
  },
  {
    "number": 384,
    "title": "[Layer] update mlp for CB.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-11T02:05:53Z",
    "closed_at": "2024-05-11T02:14:13Z",
    "merged_at": "2024-05-11T02:14:13Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/384"
  },
  {
    "number": 383,
    "title": "[Layers] Added RotaryEmbedding forward for bc mode & Fixed rope ut",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-10T10:08:35Z",
    "closed_at": "2024-05-11T03:09:35Z",
    "merged_at": "2024-05-11T03:09:35Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/383"
  },
  {
    "number": 382,
    "title": "[Layer] Cross attention impl. for CB",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-10T09:01:47Z",
    "closed_at": "2024-05-11T03:11:36Z",
    "merged_at": "2024-05-11T03:11:36Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/382"
  },
  {
    "number": 381,
    "title": "[Framework] Update set_input for cb.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-10T08:04:51Z",
    "closed_at": "2024-05-11T03:05:44Z",
    "merged_at": "2024-05-11T03:05:44Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/381"
  },
  {
    "number": 379,
    "title": "[Framework] Code fix to make new path for CB work",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-09T08:43:10Z",
    "closed_at": "2024-05-10T06:42:52Z",
    "merged_at": "2024-05-10T06:42:52Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/379"
  },
  {
    "number": 378,
    "title": "[API] Add LLaMA attention API.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-09T07:40:30Z",
    "closed_at": "2024-05-11T02:04:50Z",
    "merged_at": "2024-05-11T02:04:50Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/378"
  },
  {
    "number": 377,
    "title": "[Model] Return seqIDs when set input.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-09T06:56:41Z",
    "closed_at": "2024-05-09T07:12:39Z",
    "merged_at": "2024-05-09T07:12:39Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/377"
  },
  {
    "number": 376,
    "title": "[Sampling] Add greedy search for cb path.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-08T08:05:06Z",
    "closed_at": "2024-05-08T08:18:27Z",
    "merged_at": "2024-05-08T08:18:27Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/376"
  },
  {
    "number": 375,
    "title": "[Model/Layer] New forward to support CB (CommonDecoder->DecoderBlock->DecoderLayer->Attention/MLP)",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-08T02:36:46Z",
    "closed_at": "2024-05-09T01:15:16Z",
    "merged_at": "2024-05-09T01:15:15Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/375"
  },
  {
    "number": 374,
    "title": "[CMake] Remove evaluation under XFT_BUILD_TESTS option.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-08T01:57:08Z",
    "closed_at": "2024-05-08T02:18:16Z",
    "merged_at": "2024-05-08T02:18:16Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/374"
  },
  {
    "number": 373,
    "title": "[Sampling] Add repetition penalty for new seq type.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-08T01:40:05Z",
    "closed_at": "2024-05-08T02:10:11Z",
    "merged_at": "2024-05-08T02:10:11Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/373"
  },
  {
    "number": 372,
    "title": "[Kernel] Add GPU kernels and enable LLaMA model.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-07T10:08:21Z",
    "closed_at": "2024-06-14T07:44:10Z",
    "merged_at": "2024-06-14T07:44:10Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/372"
  },
  {
    "number": 371,
    "title": "[Common] New KVCacheMgr to support CB",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-07T05:05:49Z",
    "closed_at": "2024-05-07T07:49:14Z",
    "merged_at": "2024-05-07T07:49:14Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/371"
  },
  {
    "number": 370,
    "title": "[Model] Fix ICX build issue.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-06T09:40:27Z",
    "closed_at": "2024-05-07T03:21:22Z",
    "merged_at": "2024-05-07T03:21:22Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/370"
  },
  {
    "number": 369,
    "title": "[Model] New CommonDecoder::forward impl. skeleton",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-06T06:43:32Z",
    "closed_at": "2024-05-07T04:55:45Z",
    "merged_at": "2024-05-07T04:55:45Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/369"
  },
  {
    "number": 368,
    "title": "Fix Qwen prompt.json",
    "user": "JunxiChhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-06T06:18:40Z",
    "closed_at": "2024-05-06T07:09:34Z",
    "merged_at": "2024-05-06T07:09:34Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/368"
  },
  {
    "number": 367,
    "title": "[Common] Modify resize() in DecoderContext to support ",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-06T03:01:27Z",
    "closed_at": "2024-05-06T06:22:06Z",
    "merged_at": "2024-05-06T06:22:06Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/367"
  },
  {
    "number": 366,
    "title": "[Model] add interface for seq meta.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-30T07:08:03Z",
    "closed_at": "2024-04-30T07:31:00Z",
    "merged_at": "2024-04-30T07:31:00Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/366"
  },
  {
    "number": 365,
    "title": "[Layers] fix build error",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-30T06:56:40Z",
    "closed_at": "2024-04-30T06:56:56Z",
    "merged_at": "2024-04-30T06:56:56Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/365"
  },
  {
    "number": 364,
    "title": "[Models] Add AttnMetaData and fix attn build error",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-30T06:31:10Z",
    "closed_at": "2024-04-30T06:35:29Z",
    "merged_at": "2024-04-30T06:35:29Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/364"
  },
  {
    "number": 363,
    "title": "[Common] Refactor sequence.h.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-30T05:56:34Z",
    "closed_at": "2024-04-30T06:04:35Z",
    "merged_at": "2024-04-30T06:04:35Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/363"
  },
  {
    "number": 362,
    "title": "[Util] Remove DecoderContext in computeSoftmax",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-29T14:51:25Z",
    "closed_at": "2024-04-29T14:51:53Z",
    "merged_at": "2024-04-29T14:51:53Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/362"
  },
  {
    "number": 361,
    "title": "[Kernels] Refactor flash attention for continuous batching.",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-29T09:30:53Z",
    "closed_at": "2024-04-30T06:21:42Z",
    "merged_at": "2024-04-30T06:21:42Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/361"
  },
  {
    "number": 360,
    "title": "[Benchmark] Calculate throughput using avg latency.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-29T08:13:11Z",
    "closed_at": "2024-04-30T01:38:57Z",
    "merged_at": "2024-04-30T01:38:57Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/360"
  },
  {
    "number": 359,
    "title": "[GPU] Add GPU build option.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-29T07:41:11Z",
    "closed_at": "2024-04-30T01:58:32Z",
    "merged_at": "2024-04-30T01:58:32Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/359"
  },
  {
    "number": 358,
    "title": "[Model] Fix compile error of embeddingForward in YaRNLlama",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-29T07:34:36Z",
    "closed_at": "2024-04-29T07:37:29Z",
    "merged_at": "2024-04-29T07:37:29Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/358"
  },
  {
    "number": 357,
    "title": "[Framework] Continuous Batching Support",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-29T07:16:50Z",
    "closed_at": "2024-05-15T05:06:49Z",
    "merged_at": "2024-05-15T05:06:49Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/357"
  },
  {
    "number": 356,
    "title": "[Common] Add sampling params into group seq.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-28T08:27:58Z",
    "closed_at": "2024-04-29T07:56:08Z",
    "merged_at": "2024-04-29T07:56:08Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/356"
  },
  {
    "number": 355,
    "title": "[Model] Achieve whole pipeline parallel.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-28T06:53:56Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/355"
  },
  {
    "number": 354,
    "title": "[Fix] add utf-8 encoding.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-28T03:03:00Z",
    "closed_at": "2024-04-28T03:19:26Z",
    "merged_at": "2024-04-28T03:19:26Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/354"
  },
  {
    "number": 353,
    "title": "[Layer] Remove unused functions in Decoder layer",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T05:55:05Z",
    "closed_at": "2024-04-26T07:46:24Z",
    "merged_at": "2024-04-26T07:46:24Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/353"
  },
  {
    "number": 352,
    "title": "[Version] v1.6.0.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T05:30:43Z",
    "closed_at": "2024-04-26T07:46:03Z",
    "merged_at": "2024-04-26T07:46:03Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/352"
  },
  {
    "number": 351,
    "title": "[Common] Move Matrix into xft namespace.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T05:15:41Z",
    "closed_at": "2024-04-26T05:17:19Z",
    "merged_at": "2024-04-26T05:17:19Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/351"
  },
  {
    "number": 350,
    "title": "[Layer][Kernel] Merge batchSize and seqLen into one param (tokenSize) in TokenEembedding",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T03:52:58Z",
    "closed_at": "2024-04-26T04:57:24Z",
    "merged_at": "2024-04-26T04:57:24Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/350"
  },
  {
    "number": 349,
    "title": "[UT] Remove beam search test temporarily.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T02:41:43Z",
    "closed_at": "2024-04-26T04:59:17Z",
    "merged_at": "2024-04-26T04:59:17Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/349"
  },
  {
    "number": 348,
    "title": "[Kernel][UT] Kernel impl. of crossAttnByHead and unit test for cross attention.",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T00:35:27Z",
    "closed_at": "2024-05-08T05:46:07Z",
    "merged_at": "2024-05-08T05:46:07Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/348"
  },
  {
    "number": 347,
    "title": "[Evaluation] fix the model register bug in evaluation",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T09:12:39Z",
    "closed_at": "2024-04-26T00:54:09Z",
    "merged_at": "2024-04-26T00:54:09Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/347"
  },
  {
    "number": 346,
    "title": "[Kernel] Add 'acc' param in small_gemm, add lacked and remove unused small_gemm kernels.",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T08:44:46Z",
    "closed_at": "2024-04-25T10:48:17Z",
    "merged_at": "2024-04-25T10:48:17Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/346"
  },
  {
    "number": 344,
    "title": "[Models] YaRN-Llama full-link bf16 support",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T06:29:44Z",
    "closed_at": "2024-04-26T00:54:52Z",
    "merged_at": "2024-04-26T00:54:52Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/344"
  },
  {
    "number": 343,
    "title": "[Common] Add sequenceMeta, sequenceGroup and sequenecePool.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T01:38:39Z",
    "closed_at": "2024-04-25T06:08:19Z",
    "merged_at": "2024-04-25T06:08:19Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/343"
  },
  {
    "number": 342,
    "title": "[xDNN] Release v1.4.6.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T00:19:08Z",
    "closed_at": "2024-04-25T14:13:35Z",
    "merged_at": "2024-04-25T14:13:35Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/342"
  },
  {
    "number": 340,
    "title": "[model] Add llama3 model.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T02:49:35Z",
    "closed_at": "2024-04-24T04:26:58Z",
    "merged_at": "2024-04-24T04:26:58Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/340"
  },
  {
    "number": 338,
    "title": "[Demo] Add kvcache type option in web demo.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-23T08:19:39Z",
    "closed_at": "2024-04-23T08:36:47Z",
    "merged_at": "2024-04-23T08:36:47Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/338"
  },
  {
    "number": 337,
    "title": "[Benchmark] Add KVCache data type option.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-23T08:12:16Z",
    "closed_at": "2024-04-23T14:10:30Z",
    "merged_at": "2024-04-23T14:10:30Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/337"
  },
  {
    "number": 336,
    "title": "[KVCache] Add inferface and register for kvcache.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-23T03:06:38Z",
    "closed_at": "2024-04-23T06:55:17Z",
    "merged_at": "2024-04-23T06:55:17Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/336"
  },
  {
    "number": 334,
    "title": "[UT] Add unit test for xft::crossAttnShardedHead",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-22T09:38:09Z",
    "closed_at": "2024-04-23T14:11:40Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/334"
  },
  {
    "number": 333,
    "title": "[Sampling] Decouple greedy search from searcher.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-22T02:59:37Z",
    "closed_at": "2024-04-26T05:44:19Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/333"
  },
  {
    "number": 332,
    "title": "[Layer] Add SequenceMeta, SequencePool and init pipeline parrallel function.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-22T02:37:32Z",
    "closed_at": "2024-04-25T01:38:20Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/332"
  },
  {
    "number": 331,
    "title": "[RAEDME] Update readme for the dependent lib.",
    "user": "xwang98",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-19T10:34:18Z",
    "closed_at": "2024-04-22T01:42:50Z",
    "merged_at": "2024-04-22T01:42:50Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/331"
  },
  {
    "number": 330,
    "title": "[Model] Add Qwen2 model.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-19T07:38:46Z",
    "closed_at": "2024-04-23T06:13:16Z",
    "merged_at": "2024-04-23T06:13:16Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/330"
  },
  {
    "number": 329,
    "title": "[KVCache] KVCache and KVCacheMgr refactor to support continuous batching.",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-18T14:56:42Z",
    "closed_at": "2024-04-26T00:53:43Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/329"
  },
  {
    "number": 327,
    "title": "[Finetune] Scripts for Llama2-7b lora finetune example using stock pytorch",
    "user": "ustcuna",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-18T09:27:37Z",
    "closed_at": "2024-05-11T03:10:53Z",
    "merged_at": "2024-05-11T03:10:53Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/327"
  },
  {
    "number": 326,
    "title": "[Sample] Fix numeric overflow when calculate softmax.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-18T07:51:57Z",
    "closed_at": "2024-04-18T14:33:35Z",
    "merged_at": "2024-04-18T14:33:35Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/326"
  },
  {
    "number": 325,
    "title": "[Eval] Add eval test with opencompass.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-17T11:50:30Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/325"
  },
  {
    "number": 324,
    "title": "[Doc] Add develop docs.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-17T11:23:57Z",
    "closed_at": "2024-04-17T14:32:01Z",
    "merged_at": "2024-04-17T14:32:01Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/324"
  },
  {
    "number": 323,
    "title": "[Layers] fix assert bug when concat gate&up",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-17T07:41:35Z",
    "closed_at": "2024-04-18T05:10:46Z",
    "merged_at": "2024-04-18T05:10:46Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/323"
  },
  {
    "number": 322,
    "title": "[CMake] Add oneccl build depends for comm_helper.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-17T07:13:11Z",
    "closed_at": "2024-04-18T01:06:16Z",
    "merged_at": "2024-04-18T01:06:16Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/322"
  },
  {
    "number": 321,
    "title": "[Models] Use factory class to create decoder.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-17T02:35:57Z",
    "closed_at": "2024-04-19T02:00:42Z",
    "merged_at": "2024-04-19T02:00:42Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/321"
  },
  {
    "number": 320,
    "title": "[KVCache] INT8 KV cache implementation and related changes",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-16T14:56:49Z",
    "closed_at": "2024-04-22T01:56:31Z",
    "merged_at": "2024-04-22T01:56:31Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/320"
  },
  {
    "number": 319,
    "title": "[Eval] Get logits output.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-16T13:51:34Z",
    "closed_at": "2024-04-17T02:43:28Z",
    "merged_at": "2024-04-17T02:43:28Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/319"
  },
  {
    "number": 318,
    "title": "[Kernel] Bug fix for small_gemm_transb",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-16T09:02:10Z",
    "closed_at": "2024-04-16T09:22:43Z",
    "merged_at": "2024-04-16T09:22:43Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/318"
  },
  {
    "number": 317,
    "title": "[README] Add README_CN.md.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-16T02:16:47Z",
    "closed_at": "2024-04-16T02:52:34Z",
    "merged_at": "2024-04-16T02:52:34Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/317"
  },
  {
    "number": 316,
    "title": "[Build] Fix build issue.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-15T07:44:15Z",
    "closed_at": "2024-04-15T07:58:03Z",
    "merged_at": "2024-04-15T07:58:03Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/316"
  },
  {
    "number": 315,
    "title": "[Convert] Fix Qwen convert issue.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-15T03:27:19Z",
    "closed_at": "2024-04-15T03:30:29Z",
    "merged_at": "2024-04-15T03:30:29Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/315"
  },
  {
    "number": 314,
    "title": "[Kernel] Add kernel support for INT8 KV cache.",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-15T02:21:57Z",
    "closed_at": "2024-04-15T03:17:19Z",
    "merged_at": "2024-04-15T03:17:19Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/314"
  },
  {
    "number": 313,
    "title": "[Model] Expose KV cache data type in Llama model.",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-15T01:33:43Z",
    "closed_at": "2024-04-15T03:14:34Z",
    "merged_at": "2024-04-15T03:14:34Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/313"
  },
  {
    "number": 311,
    "title": "[Version] v1.5.0.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-12T05:54:04Z",
    "closed_at": "2024-04-12T06:02:34Z",
    "merged_at": "2024-04-12T06:02:33Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/311"
  },
  {
    "number": 310,
    "title": "[Build] Fix build issues.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-11T07:56:19Z",
    "closed_at": "2024-04-11T08:47:43Z",
    "merged_at": "2024-04-11T08:47:43Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/310"
  },
  {
    "number": 309,
    "title": "Fix timeline compile issue",
    "user": "xiangzez",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-11T06:13:17Z",
    "closed_at": "2024-04-11T06:20:46Z",
    "merged_at": "2024-04-11T06:20:46Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/309"
  },
  {
    "number": 308,
    "title": "Bump transformers from 4.36.0 to 4.38.0 in /examples/web_demo",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2024-04-10T22:59:01Z",
    "closed_at": "2024-04-11T02:23:58Z",
    "merged_at": "2024-04-11T02:23:58Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/308"
  },
  {
    "number": 307,
    "title": "[example] add gemma model support with example.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T13:24:58Z",
    "closed_at": "2024-04-11T01:23:07Z",
    "merged_at": "2024-04-11T01:23:07Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/307"
  },
  {
    "number": 306,
    "title": "Update AWQ GPTQ quantization guide",
    "user": "miaojinc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T09:32:22Z",
    "closed_at": "2024-09-02T08:54:23Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/306"
  },
  {
    "number": 305,
    "title": "Add section 1 & 2 to dev guide",
    "user": "miaojinc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T03:42:06Z",
    "closed_at": "2024-04-10T06:39:45Z",
    "merged_at": "2024-04-10T06:39:45Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/305"
  },
  {
    "number": 304,
    "title": "[Example] Add gemma model config and web demo.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T01:55:55Z",
    "closed_at": "2024-04-10T02:19:49Z",
    "merged_at": "2024-04-10T02:19:49Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/304"
  },
  {
    "number": 303,
    "title": "[API] Format rotary_embedding api.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-09T08:51:37Z",
    "closed_at": "2024-04-15T03:15:00Z",
    "merged_at": "2024-04-15T03:15:00Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/303"
  },
  {
    "number": 302,
    "title": "[API] Add invokeMLPLLaMA FP16 API.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-09T03:20:06Z",
    "closed_at": "2024-04-15T04:28:17Z",
    "merged_at": "2024-04-15T04:28:17Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/302"
  },
  {
    "number": 301,
    "title": "Chatglm2/3 bf16 pipeline support",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-08T13:44:27Z",
    "closed_at": "2024-04-15T08:15:26Z",
    "merged_at": "2024-04-15T08:15:26Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/301"
  },
  {
    "number": 299,
    "title": "[fix] fix compile issue.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-08T03:39:14Z",
    "closed_at": "2024-04-08T05:06:42Z",
    "merged_at": "2024-04-08T05:06:42Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/299"
  },
  {
    "number": 298,
    "title": "[KVCache] INT8 KV cache support and Expose KV cache data type in Llama model",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T09:25:03Z",
    "closed_at": "2024-04-16T14:58:20Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/298"
  },
  {
    "number": 297,
    "title": "[Fix] Reduce convert memory usage.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T09:22:54Z",
    "closed_at": "2024-04-07T09:50:55Z",
    "merged_at": "2024-04-07T09:50:55Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/297"
  },
  {
    "number": 296,
    "title": "[UT] MLP unit test case fix",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T08:44:26Z",
    "closed_at": "2024-04-07T09:30:03Z",
    "merged_at": "2024-04-07T09:30:03Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/296"
  },
  {
    "number": 295,
    "title": "[ENV] Use Meyers' Singleton Env object.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T08:44:22Z",
    "closed_at": "2024-04-08T02:02:10Z",
    "merged_at": "2024-04-08T02:02:10Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/295"
  },
  {
    "number": 294,
    "title": "[UT] add unit test for selfAttention, and a small fix",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T05:30:18Z",
    "closed_at": "2024-04-07T07:38:51Z",
    "merged_at": "2024-04-07T07:38:51Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/294"
  },
  {
    "number": 293,
    "title": "[Bug] Fix oneDNN GPU build issue.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T04:43:44Z",
    "closed_at": "2024-04-07T07:13:23Z",
    "merged_at": "2024-04-07T07:13:23Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/293"
  },
  {
    "number": 292,
    "title": "[Model] Update isMaster func.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T03:48:28Z",
    "closed_at": "2024-04-07T04:02:55Z",
    "merged_at": "2024-04-07T04:02:54Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/292"
  },
  {
    "number": 291,
    "title": "[gpuDNN] Add gpuDNN v0.1.0 library files.",
    "user": "feng-intel",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-03T11:14:07Z",
    "closed_at": "2024-04-07T08:01:15Z",
    "merged_at": "2024-04-07T08:01:15Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/291"
  },
  {
    "number": 290,
    "title": "[KVCache] KV Cache refactor and related unit test case fix",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-02T14:43:25Z",
    "closed_at": "2024-04-07T01:31:48Z",
    "merged_at": "2024-04-07T01:31:48Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/290"
  },
  {
    "number": 289,
    "title": "[Fix] Fix baichuan2-13 without rope.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-02T09:58:07Z",
    "closed_at": "2024-04-02T10:12:49Z",
    "merged_at": "2024-04-02T10:12:49Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/289"
  },
  {
    "number": 288,
    "title": "[KVCache] KV Cache refactor and related unit test case fix",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-02T06:41:04Z",
    "closed_at": "2024-04-02T13:24:44Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/288"
  },
  {
    "number": 287,
    "title": "[Bug] fix baichuan model test issue.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-02T06:40:27Z",
    "closed_at": "2024-04-02T06:45:18Z",
    "merged_at": "2024-04-02T06:45:18Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/287"
  },
  {
    "number": 286,
    "title": "[CI] Add rls test case.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-02T05:18:35Z",
    "closed_at": "2024-04-02T06:06:05Z",
    "merged_at": "2024-04-02T06:06:05Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/286"
  },
  {
    "number": 285,
    "title": "[xDNN] Release v1.4.5.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-01T06:26:17Z",
    "closed_at": "2024-04-01T07:44:16Z",
    "merged_at": "2024-04-01T07:44:16Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/285"
  },
  {
    "number": 284,
    "title": "[Dependency] Add protobuf in requirements.txt",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-01T05:28:10Z",
    "closed_at": "2024-04-01T06:21:20Z",
    "merged_at": "2024-04-01T06:21:20Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/284"
  },
  {
    "number": 283,
    "title": "[CMake] Check existence of MKL & oneDNN directory before installation.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-29T08:05:29Z",
    "closed_at": "2024-03-29T08:55:07Z",
    "merged_at": "2024-03-29T08:55:07Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/283"
  },
  {
    "number": 281,
    "title": "Wli58/shm reduceadd v2",
    "user": "wli58",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-29T02:09:00Z",
    "closed_at": "2024-04-22T01:57:39Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/281"
  },
  {
    "number": 280,
    "title": "[Bug] Fix incorrect context parameter order.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-29T01:33:06Z",
    "closed_at": "2024-03-29T01:53:53Z",
    "merged_at": "2024-03-29T01:53:53Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/280"
  },
  {
    "number": 279,
    "title": "Add KVCache trans for long sequence && tuned comm for faster Addreduce",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-28T11:37:00Z",
    "closed_at": "2024-04-01T02:39:16Z",
    "merged_at": "2024-04-01T02:39:16Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/279"
  },
  {
    "number": 278,
    "title": "[CI] Check for UT status.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-28T06:48:19Z",
    "closed_at": "2024-03-29T07:57:00Z",
    "merged_at": "2024-03-29T07:57:00Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/278"
  },
  {
    "number": 277,
    "title": "[Timeline] Fix disordered timeline.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-26T08:25:46Z",
    "closed_at": "2024-03-26T09:03:04Z",
    "merged_at": "2024-03-26T09:03:04Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/277"
  },
  {
    "number": 276,
    "title": "[Tools] Add convert tool for Llama models quantized by AutoGPTQ",
    "user": "xiangzez",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-25T08:04:00Z",
    "closed_at": "2024-04-03T03:50:46Z",
    "merged_at": "2024-04-03T03:50:46Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/276"
  },
  {
    "number": 275,
    "title": "[Common] Support loading int4 weights",
    "user": "xiangzez",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-25T07:58:12Z",
    "closed_at": "2024-04-03T08:43:55Z",
    "merged_at": "2024-04-03T08:43:55Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/275"
  },
  {
    "number": 274,
    "title": "[model] Add deepseek model.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T13:07:08Z",
    "closed_at": "2024-03-28T07:20:36Z",
    "merged_at": "2024-03-28T07:20:36Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/274"
  },
  {
    "number": 273,
    "title": "Issue qwen72b seq length",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T02:45:33Z",
    "closed_at": "2024-03-22T01:32:52Z",
    "merged_at": "2024-03-22T01:32:52Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/273"
  },
  {
    "number": 272,
    "title": "[Common] Unify memory allocation into xft::alloc",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-19T09:11:08Z",
    "closed_at": "2024-03-26T08:27:03Z",
    "merged_at": "2024-03-26T08:27:03Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/272"
  },
  {
    "number": 271,
    "title": "[Include] Fix include not work.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-19T06:26:16Z",
    "closed_at": "2024-03-20T00:41:04Z",
    "merged_at": "2024-03-20T00:41:04Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/271"
  },
  {
    "number": 270,
    "title": "[include] Organize include file",
    "user": "wenhuanh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-14T06:13:59Z",
    "closed_at": "2024-03-15T01:29:57Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/270"
  },
  {
    "number": 268,
    "title": "[Kernel] increase parallelism for KV cache copy in self attention",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-12T09:06:33Z",
    "closed_at": "2024-03-16T01:49:07Z",
    "merged_at": "2024-03-16T01:49:07Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/268"
  },
  {
    "number": 267,
    "title": "[Kernel] Fix the incorrect computing which should be in float, but was in integer",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-11T09:55:59Z",
    "closed_at": "2024-03-11T13:54:59Z",
    "merged_at": "2024-03-11T13:54:59Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/267"
  },
  {
    "number": 266,
    "title": "[Layer] Reduce repeated sin and cos embedding table data to optimize ROPE perf.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-08T06:21:51Z",
    "closed_at": "2024-03-16T01:47:23Z",
    "merged_at": "2024-03-16T01:47:23Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/266"
  },
  {
    "number": 265,
    "title": "[Layer] Use flash attention when larger than threshold ('>=' to '>')",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-08T03:05:05Z",
    "closed_at": "2024-03-08T03:44:24Z",
    "merged_at": "2024-03-08T03:44:24Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/265"
  },
  {
    "number": 264,
    "title": "gpu kernel: rms_norm",
    "user": "aurora327",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-08T01:40:51Z",
    "closed_at": "2024-03-13T06:27:27Z",
    "merged_at": "2024-03-13T06:27:27Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/264"
  },
  {
    "number": 263,
    "title": "[Benchmark] Modify CPU affinity logic, add CI prompt output.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-07T07:52:35Z",
    "closed_at": "2024-03-08T03:47:06Z",
    "merged_at": "2024-03-08T03:47:06Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/263"
  },
  {
    "number": 262,
    "title": "[Version] v1.4.0.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-06T07:08:10Z",
    "closed_at": "2024-03-08T05:53:15Z",
    "merged_at": "2024-03-08T05:53:15Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/262"
  },
  {
    "number": 261,
    "title": "[Benchmark] Fix typo in benchmark script.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-05T01:52:05Z",
    "closed_at": "2024-03-05T05:03:57Z",
    "merged_at": "2024-03-05T05:03:57Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/261"
  },
  {
    "number": 260,
    "title": "[Search] Sync smaple result in multi-rank.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T08:58:33Z",
    "closed_at": "2024-03-05T08:28:23Z",
    "merged_at": "2024-03-05T08:28:23Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/260"
  },
  {
    "number": 259,
    "title": "[Model] Add gemma model support.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T07:23:58Z",
    "closed_at": "2024-04-10T07:56:11Z",
    "merged_at": "2024-04-10T07:56:11Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/259"
  },
  {
    "number": 258,
    "title": "[Attention Kernel/Layer] group attention support in full-link BF16 path; attention layer refactor",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T06:47:11Z",
    "closed_at": "2024-03-05T08:24:57Z",
    "merged_at": "2024-03-05T08:24:57Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/258"
  },
  {
    "number": 257,
    "title": "[Benchmark] Update model cfg for transformers>4.36.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T05:56:44Z",
    "closed_at": "2024-03-05T08:41:54Z",
    "merged_at": "2024-03-05T08:41:54Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/257"
  },
  {
    "number": 254,
    "title": "[Serving] Fix fail to set pad_token_id when it's not None in single mode.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-01T07:09:26Z",
    "closed_at": "2024-03-01T08:29:29Z",
    "merged_at": "2024-03-01T08:29:29Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/254"
  },
  {
    "number": 253,
    "title": "[Kernel] Add oneDNN GPU kernels.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-29T13:17:36Z",
    "closed_at": "2024-06-14T05:02:04Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/253"
  },
  {
    "number": 252,
    "title": "[layers] Add bf16-type input/output support for flash attention",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-29T10:00:37Z",
    "closed_at": "2024-03-04T06:47:30Z",
    "merged_at": "2024-03-04T06:47:30Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/252"
  },
  {
    "number": 251,
    "title": "Fix Opt issue",
    "user": "xiangzez",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-29T04:28:39Z",
    "closed_at": "2024-02-29T06:11:58Z",
    "merged_at": "2024-02-29T06:11:58Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/251"
  },
  {
    "number": 249,
    "title": "[Fix] Fall back to float to bypass issues with MQA/GQA.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-28T04:34:01Z",
    "closed_at": "2024-03-05T13:16:48Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/249"
  },
  {
    "number": 248,
    "title": "[Docs] Initial documents.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-28T04:31:12Z",
    "closed_at": "2024-02-28T04:34:18Z",
    "merged_at": "2024-02-28T04:34:18Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/248"
  },
  {
    "number": 246,
    "title": "[Dependency] Update web demo requirement.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-27T03:01:30Z",
    "closed_at": "2024-02-27T03:09:14Z",
    "merged_at": "2024-02-27T03:09:14Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/246"
  },
  {
    "number": 245,
    "title": "[Kernel] Set USE_AMX_M to 1.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-26T07:01:29Z",
    "closed_at": "2024-03-05T01:37:07Z",
    "merged_at": "2024-03-05T01:37:07Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/245"
  },
  {
    "number": 243,
    "title": "[Example] Add llama2 chat support in Cli demo.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-23T08:55:18Z",
    "closed_at": "2024-02-26T01:51:21Z",
    "merged_at": "2024-02-26T01:51:21Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/243"
  },
  {
    "number": 242,
    "title": "fix issue #220",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-23T03:01:14Z",
    "closed_at": "2024-02-23T03:25:38Z",
    "merged_at": "2024-02-23T03:25:38Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/242"
  },
  {
    "number": 241,
    "title": "Bump gradio from 4.11.0 to 4.19.2 in /examples/web_demo",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2024-02-22T22:14:03Z",
    "closed_at": "2024-02-23T08:28:24Z",
    "merged_at": "2024-02-23T08:28:23Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/241"
  },
  {
    "number": 240,
    "title": "[Fix] Fix the wrong output of QWEN-14B.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-22T14:09:43Z",
    "closed_at": "2024-02-22T14:42:47Z",
    "merged_at": "2024-02-22T14:42:47Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/240"
  },
  {
    "number": 238,
    "title": "[Example] Add seq_length in qwen fake config.ini",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-22T06:46:56Z",
    "closed_at": "2024-02-22T06:55:15Z",
    "merged_at": "2024-02-22T06:55:15Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/238"
  },
  {
    "number": 237,
    "title": "[CMake] Remvoe force reinstall for mkl dependencies.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-22T06:39:09Z",
    "closed_at": "2024-02-22T06:52:09Z",
    "merged_at": "2024-02-22T06:52:09Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/237"
  },
  {
    "number": 236,
    "title": "[Kernel] Add oneDNN GPU kernels.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-21T12:34:46Z",
    "closed_at": "2024-06-14T05:01:16Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/236"
  },
  {
    "number": 234,
    "title": "[CMake] Open the pip-install information for MKL.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-21T08:32:27Z",
    "closed_at": "2024-02-22T01:47:51Z",
    "merged_at": "2024-02-22T01:47:51Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/234"
  },
  {
    "number": 232,
    "title": "[Fix] Add parameter check for logN and NTK rotary embedding of QWEN",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-21T03:50:46Z",
    "closed_at": "2024-02-22T05:29:11Z",
    "merged_at": "2024-02-22T05:29:11Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/232"
  },
  {
    "number": 231,
    "title": "[Env] Add XFT_ENGINE env variable.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-21T03:34:46Z",
    "closed_at": "2024-02-21T12:24:11Z",
    "merged_at": "2024-02-21T12:24:11Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/231"
  },
  {
    "number": 230,
    "title": "[Fix] Add parameter check for logN and NTK rotary embedding of QWEN",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-21T02:57:27Z",
    "closed_at": "2024-02-21T02:57:42Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/230"
  },
  {
    "number": 228,
    "title": "[kernel] Add ICX compiler.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-20T12:53:34Z",
    "closed_at": "2024-02-21T03:25:36Z",
    "merged_at": "2024-02-21T03:25:36Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/228"
  },
  {
    "number": 227,
    "title": "[Dependencies] Remove tokenizers requirement.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-20T06:53:40Z",
    "closed_at": "2024-02-20T07:03:17Z",
    "merged_at": "2024-02-20T07:03:17Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/227"
  },
  {
    "number": 226,
    "title": "[models][layers/tools] Refine and bugfix for baichuan models",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-20T02:46:36Z",
    "closed_at": "2024-02-20T06:01:40Z",
    "merged_at": "2024-02-20T06:01:40Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/226"
  },
  {
    "number": 225,
    "title": "[Layer] Convert static MMHelper class to instance Class in DecoderContext.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-19T14:03:28Z",
    "closed_at": "2024-02-20T04:13:43Z",
    "merged_at": "2024-02-20T04:13:42Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/225"
  },
  {
    "number": 224,
    "title": "[Tools] Accelerate model loading.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-19T07:23:32Z",
    "closed_at": "2024-02-22T09:37:10Z",
    "merged_at": "2024-02-22T09:37:10Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/224"
  },
  {
    "number": 223,
    "title": "[xDNN] Release v1.4.4.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-19T07:19:08Z",
    "closed_at": "2024-02-19T09:00:36Z",
    "merged_at": "2024-02-19T09:00:36Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/223"
  },
  {
    "number": 222,
    "title": "[Layer] Support pure full-link BF16 LLaMa model.",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-19T06:00:58Z",
    "closed_at": "2024-02-20T01:33:57Z",
    "merged_at": "2024-02-20T01:33:57Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/222"
  },
  {
    "number": 221,
    "title": "[Layer] Enable pipeline parallel feature.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-07T03:32:50Z",
    "closed_at": "2024-02-19T05:00:33Z",
    "merged_at": "2024-02-19T05:00:33Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/221"
  },
  {
    "number": 219,
    "title": "[Dockerfile] Remove dockerfile.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-06T05:28:01Z",
    "closed_at": "2024-02-19T05:01:50Z",
    "merged_at": "2024-02-19T05:01:50Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/219"
  },
  {
    "number": 218,
    "title": "[ci] Add workflow permission.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-06T04:07:07Z",
    "closed_at": "2024-02-06T05:13:36Z",
    "merged_at": "2024-02-06T05:13:36Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/218"
  },
  {
    "number": 217,
    "title": "[Serving] Add MLServer serving support.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-05T07:59:46Z",
    "closed_at": "2024-02-20T07:03:06Z",
    "merged_at": "2024-02-20T07:03:06Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/217"
  },
  {
    "number": 216,
    "title": "[CI] Align using benchmark tests.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-05T04:39:41Z",
    "closed_at": "2024-02-19T06:38:32Z",
    "merged_at": "2024-02-19T06:38:32Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/216"
  },
  {
    "number": 215,
    "title": "[Layers] Qwen LogN for query",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-05T04:29:40Z",
    "closed_at": "2024-02-20T01:42:27Z",
    "merged_at": "2024-02-20T01:42:27Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/215"
  },
  {
    "number": 214,
    "title": "[ci] Fix python path issue.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-04T05:08:29Z",
    "closed_at": "2024-02-04T05:37:39Z",
    "merged_at": "2024-02-04T05:37:39Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/214"
  },
  {
    "number": 213,
    "title": "[xDNN] Release v1.4.3.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-03T14:36:50Z",
    "closed_at": "2024-02-04T13:21:13Z",
    "merged_at": "2024-02-04T13:21:13Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/213"
  },
  {
    "number": 212,
    "title": "[Fix] Fix repetition penalties not taking effect on other batches.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-02T07:00:40Z",
    "closed_at": "2024-02-04T05:56:23Z",
    "merged_at": "2024-02-04T05:56:23Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/212"
  },
  {
    "number": 211,
    "title": "[benchmark] Add distributed benchmark.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-01T08:56:02Z",
    "closed_at": "2024-02-01T14:51:40Z",
    "merged_at": "2024-02-01T14:51:40Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/211"
  },
  {
    "number": 208,
    "title": "[TP] Make split dimension align with oneDNN packing",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-31T08:25:44Z",
    "closed_at": "2024-01-31T09:18:00Z",
    "merged_at": "2024-01-31T09:18:00Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/208"
  },
  {
    "number": 207,
    "title": "Add recommend GCC version",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-31T05:13:02Z",
    "closed_at": "2024-01-31T06:09:23Z",
    "merged_at": "2024-01-31T06:09:22Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/207"
  },
  {
    "number": 206,
    "title": "[CMake] Check if the compiler really supports avx512bf16 with try_compile",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-30T05:12:15Z",
    "closed_at": "2024-01-30T08:05:48Z",
    "merged_at": "2024-01-30T08:05:48Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/206"
  },
  {
    "number": 205,
    "title": "[benchmark] Add one node benchmark.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-29T06:02:24Z",
    "closed_at": "2024-01-29T07:03:55Z",
    "merged_at": "2024-01-29T07:03:55Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/205"
  },
  {
    "number": 203,
    "title": "[Tools] Deprecate convert tools in tools dir.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-25T08:39:37Z",
    "closed_at": "2024-01-26T07:45:55Z",
    "merged_at": "2024-01-26T07:45:55Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/203"
  },
  {
    "number": 202,
    "title": "[Dependency] transformers version warning when error occurs.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-25T08:37:47Z",
    "closed_at": "2024-01-26T06:40:32Z",
    "merged_at": "2024-01-26T06:40:32Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/202"
  },
  {
    "number": 201,
    "title": "[Demo] Update web demo to adapt gradio 4.11.0.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-25T06:49:24Z",
    "closed_at": "2024-01-25T07:38:52Z",
    "merged_at": "2024-01-25T07:38:52Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/201"
  },
  {
    "number": 200,
    "title": "[demo] Add Yi model demo.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-25T05:49:55Z",
    "closed_at": "2024-01-25T08:56:17Z",
    "merged_at": "2024-01-25T08:56:17Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/200"
  },
  {
    "number": 199,
    "title": "[demo] Add XFT dependency to improve user experience.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-24T10:30:03Z",
    "closed_at": "2024-01-25T05:25:50Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/199"
  },
  {
    "number": 198,
    "title": "[Version] v1.3.1.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-24T05:15:59Z",
    "closed_at": "2024-01-24T05:19:41Z",
    "merged_at": "2024-01-24T05:19:41Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/198"
  },
  {
    "number": 197,
    "title": "[Comm] Check mpirun and env before load helper.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-24T02:20:15Z",
    "closed_at": "2024-01-24T05:09:52Z",
    "merged_at": "2024-01-24T05:09:52Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/197"
  },
  {
    "number": 196,
    "title": "Add base_initial to store the original base passed from config",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-23T11:38:43Z",
    "closed_at": "2024-01-23T13:10:49Z",
    "merged_at": "2024-01-23T13:10:49Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/196"
  },
  {
    "number": 194,
    "title": "[Layer] Fine grained data type definition for Attention and MLP",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-23T06:40:40Z",
    "closed_at": "2024-01-30T14:11:46Z",
    "merged_at": "2024-01-30T14:11:46Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/194"
  },
  {
    "number": 193,
    "title": "[demo] Add qwen demo deps.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-23T06:33:45Z",
    "closed_at": "2024-01-23T06:35:08Z",
    "merged_at": "2024-01-23T06:35:08Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/193"
  },
  {
    "number": 192,
    "title": "[Build] Fix build issue by GCC version.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-23T03:26:55Z",
    "closed_at": "2024-01-23T07:15:07Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/192"
  },
  {
    "number": 191,
    "title": "[Version] v1.3.0.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-23T02:35:08Z",
    "closed_at": "2024-01-23T03:22:48Z",
    "merged_at": "2024-01-23T03:22:48Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/191"
  },
  {
    "number": 190,
    "title": "[Generate] Sync stop words ids in multi-rank mode.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-22T06:27:36Z",
    "closed_at": "2024-01-22T08:18:13Z",
    "merged_at": "2024-01-22T08:18:13Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/190"
  },
  {
    "number": 189,
    "title": "[Kernel] Add Qwen rotary_embedding ntk support.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-22T03:12:20Z",
    "closed_at": "2024-01-22T09:09:03Z",
    "merged_at": "2024-01-22T09:09:03Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/189"
  },
  {
    "number": 187,
    "title": "[common/utils] Fix bug of int32 overflow for larger size",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-19T10:17:13Z",
    "closed_at": "2024-01-22T01:39:00Z",
    "merged_at": "2024-01-22T01:39:00Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/187"
  },
  {
    "number": 184,
    "title": "[demo] Fix chatGLM3 webdemo.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-18T07:47:15Z",
    "closed_at": "2024-01-18T07:57:49Z",
    "merged_at": "2024-01-18T07:57:49Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/184"
  },
  {
    "number": 183,
    "title": "[Generation] Add stop_words_ids generation config.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-18T06:54:52Z",
    "closed_at": "2024-01-18T08:10:02Z",
    "merged_at": "2024-01-18T08:10:02Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/183"
  },
  {
    "number": 181,
    "title": "[convert] Fix qwen convert with no eos id.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-17T21:00:41Z",
    "closed_at": "2024-01-18T07:48:26Z",
    "merged_at": "2024-01-18T07:48:26Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/181"
  },
  {
    "number": 180,
    "title": "[demo] Add qwen demo.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-17T20:50:42Z",
    "closed_at": "2024-01-22T08:21:48Z",
    "merged_at": "2024-01-22T08:21:48Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/180"
  },
  {
    "number": 179,
    "title": "[Kernels] Fix Qwen chat issue.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-17T08:40:28Z",
    "closed_at": "2024-01-22T05:09:10Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/179"
  },
  {
    "number": 178,
    "title": "[Page attention]Prefill add kv cache",
    "user": "aurora327",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T01:06:36Z",
    "closed_at": "2024-01-22T01:33:59Z",
    "merged_at": "2024-01-22T01:33:59Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/178"
  },
  {
    "number": 177,
    "title": "[examples] add qwen & chatglm3 model config.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-15T15:27:52Z",
    "closed_at": "2024-01-16T07:09:09Z",
    "merged_at": "2024-01-16T07:09:09Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/177"
  },
  {
    "number": 176,
    "title": "[Layer] BF16 support for rotary embedding",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-15T08:49:29Z",
    "closed_at": "2024-01-15T10:03:33Z",
    "merged_at": "2024-01-15T10:03:33Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/176"
  },
  {
    "number": 173,
    "title": "[LOG] Default disable fake loading log print.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-10T02:14:38Z",
    "closed_at": "2024-01-11T01:06:09Z",
    "merged_at": "2024-01-11T01:06:09Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/173"
  },
  {
    "number": 172,
    "title": "[Model][SecLLM] Add SecLLM(YaRN-Llama) model support",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-08T09:41:20Z",
    "closed_at": "2024-01-10T08:10:24Z",
    "merged_at": "2024-01-10T08:10:24Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/172"
  },
  {
    "number": 171,
    "title": "[Framework] Attention/LayerNorm/RmsNorm refactor/enhance to better support BF16 inference.",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-08T05:39:04Z",
    "closed_at": "2024-01-08T06:14:41Z",
    "merged_at": "2024-01-08T06:14:41Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/171"
  },
  {
    "number": 170,
    "title": "[Benchmark] fix Benchmark performance issue.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-08T02:15:23Z",
    "closed_at": "2024-01-08T02:19:13Z",
    "merged_at": "2024-01-08T02:19:13Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/170"
  },
  {
    "number": 169,
    "title": "[Fix] Fix build issue for the TIMELINE filter feature",
    "user": "huaqiangwang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-05T07:40:39Z",
    "closed_at": "2024-01-05T09:28:30Z",
    "merged_at": "2024-01-05T09:28:30Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/169"
  },
  {
    "number": 168,
    "title": "[ChatGLM2] Remove unused code.",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-05T06:43:22Z",
    "closed_at": "2024-01-08T01:45:51Z",
    "merged_at": "2024-01-08T01:45:51Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/168"
  },
  {
    "number": 167,
    "title": "[Fix] index ID lowerbound check in repetition penalty.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-05T02:42:03Z",
    "closed_at": "2024-01-05T03:53:27Z",
    "merged_at": "2024-01-05T03:53:27Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/167"
  },
  {
    "number": 166,
    "title": "[Servering] Add MLServer llama2 support.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-04T07:55:09Z",
    "closed_at": "2024-02-01T03:00:31Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/166"
  },
  {
    "number": 165,
    "title": " [Benchmark] handle unexpected arguments",
    "user": "huaqiangwang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-04T07:13:04Z",
    "closed_at": "2024-01-18T06:03:16Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/165"
  },
  {
    "number": 164,
    "title": "[Benchmark] Avoid float in core pre numa calculation.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-04T01:46:30Z",
    "closed_at": "2024-01-09T00:39:00Z",
    "merged_at": "2024-01-09T00:39:00Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/164"
  },
  {
    "number": 163,
    "title": "[Search] Add repetition penalty.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-03T08:48:30Z",
    "closed_at": "2024-01-04T01:09:49Z",
    "merged_at": "2024-01-04T01:09:49Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/163"
  },
  {
    "number": 162,
    "title": "[Demo] fix mpi stick the stdout/err in web_demo.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-03T06:10:13Z",
    "closed_at": "2024-01-03T06:19:21Z",
    "merged_at": "2024-01-03T06:19:21Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/162"
  },
  {
    "number": 161,
    "title": "[Fix] comm_helper can't found issue.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-02T06:13:27Z",
    "closed_at": "2024-01-04T01:01:56Z",
    "merged_at": "2024-01-04T01:01:56Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/161"
  },
  {
    "number": 160,
    "title": "[Demo] use average next-token latency as the info to user.",
    "user": "huaqiangwang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-29T02:54:33Z",
    "closed_at": "2024-01-04T01:04:07Z",
    "merged_at": "2024-01-04T01:04:07Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/160"
  },
  {
    "number": 159,
    "title": "clang-format: Remove duplicated IndentPPDirectives entry",
    "user": "huaqiangwang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-28T15:17:22Z",
    "closed_at": "2024-01-03T05:05:24Z",
    "merged_at": "2024-01-03T05:05:24Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/159"
  },
  {
    "number": 158,
    "title": "[kernel] Fix w8a8 crash issue due to buffer size not big enough",
    "user": "xiangzez",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-28T05:45:44Z",
    "closed_at": "2024-01-08T07:33:56Z",
    "merged_at": "2024-01-08T07:33:56Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/158"
  },
  {
    "number": 157,
    "title": "Support loading int8 weights",
    "user": "xiangzez",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-28T05:34:22Z",
    "closed_at": "2024-02-01T03:23:00Z",
    "merged_at": "2024-02-01T03:23:00Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/157"
  },
  {
    "number": 156,
    "title": "Add a white list to collect timeline events on a filtered events",
    "user": "huaqiangwang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-27T07:07:23Z",
    "closed_at": "2024-01-05T07:20:27Z",
    "merged_at": "2024-01-05T07:20:27Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/156"
  },
  {
    "number": 151,
    "title": "[Fix] fix assert error in MLP when enable CAT_MLP opt.",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-22T09:21:43Z",
    "closed_at": "2023-12-22T12:26:36Z",
    "merged_at": "2023-12-22T12:26:36Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/151"
  },
  {
    "number": 150,
    "title": "Bump gradio from 3.40.1 to 4.11.0 in /examples/web_demo",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2023-12-21T18:38:32Z",
    "closed_at": "2024-01-25T07:40:58Z",
    "merged_at": "2024-01-25T07:40:58Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/150"
  },
  {
    "number": 149,
    "title": "[README] update readme and add Q&A.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-21T07:30:18Z",
    "closed_at": "2023-12-21T07:49:39Z",
    "merged_at": "2023-12-21T07:49:39Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/149"
  },
  {
    "number": 148,
    "title": "[Version] v1.2.0.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-21T06:51:44Z",
    "closed_at": "2023-12-21T07:52:47Z",
    "merged_at": "2023-12-21T07:52:47Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/148"
  },
  {
    "number": 147,
    "title": "[Example] Modify the parameters of the example code.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-21T06:27:06Z",
    "closed_at": "2023-12-21T07:45:14Z",
    "merged_at": "2023-12-21T07:45:14Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/147"
  },
  {
    "number": 146,
    "title": "[Models] Add QwenConvert.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-21T06:13:39Z",
    "closed_at": "2023-12-21T07:43:33Z",
    "merged_at": "2023-12-21T07:43:33Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/146"
  },
  {
    "number": 145,
    "title": "Bump transformers from 4.30.0 to 4.36.0",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2023-12-20T21:10:30Z",
    "closed_at": "2024-01-30T01:41:26Z",
    "merged_at": "2024-01-30T01:41:26Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/145"
  },
  {
    "number": 144,
    "title": "Bump transformers from 4.30.0 to 4.36.0 in /examples/web_demo",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2023-12-20T21:09:57Z",
    "closed_at": "2024-01-30T01:44:17Z",
    "merged_at": "2024-01-30T01:44:17Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/144"
  },
  {
    "number": 143,
    "title": "Add attention interface (like page attention)",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-20T11:48:02Z",
    "closed_at": "2024-01-05T01:27:47Z",
    "merged_at": "2024-01-05T01:27:46Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/143"
  },
  {
    "number": 141,
    "title": "[Benchmark & Evaluation] Add new data type",
    "user": "JunxiChhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-20T04:02:57Z",
    "closed_at": "2023-12-21T01:50:04Z",
    "merged_at": "2023-12-21T01:50:04Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/141"
  },
  {
    "number": 139,
    "title": "[xDNN] Release v1.4.2",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-19T15:12:54Z",
    "closed_at": "2023-12-20T01:35:25Z",
    "merged_at": "2023-12-20T01:35:25Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/139"
  },
  {
    "number": 138,
    "title": "[Evaluation] Fix pad_token issue",
    "user": "JunxiChhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-19T06:10:52Z",
    "closed_at": "2023-12-19T07:14:43Z",
    "merged_at": "2023-12-19T07:14:43Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/138"
  },
  {
    "number": 137,
    "title": "Fix segmentation fault when using INT4 with CONCAT MLP",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-19T05:34:25Z",
    "closed_at": "2023-12-20T02:09:45Z",
    "merged_at": "2023-12-20T02:09:45Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/137"
  },
  {
    "number": 136,
    "title": "[Debug] Fix uint4x2 and nf4x2 build issue.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-19T03:21:11Z",
    "closed_at": "2023-12-19T04:11:15Z",
    "merged_at": "2023-12-19T04:11:15Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/136"
  },
  {
    "number": 135,
    "title": "[Evaluation] Add accuracy evaluation module for LLM",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-17T06:03:25Z",
    "closed_at": "2023-12-18T05:51:45Z",
    "merged_at": "2023-12-18T05:51:45Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/135"
  },
  {
    "number": 133,
    "title": "[xDNN] Release v1.4.1 to add sgemm_bf16bf16f32, sgemm_f32bf16bf16 and softmax.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-15T01:35:48Z",
    "closed_at": "2023-12-15T02:14:03Z",
    "merged_at": "2023-12-15T02:14:03Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/133"
  },
  {
    "number": 132,
    "title": "[Comm] add comm helper to decouple oneccl.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-13T05:27:16Z",
    "closed_at": "2023-12-20T08:21:33Z",
    "merged_at": "2023-12-20T08:21:33Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/132"
  },
  {
    "number": 131,
    "title": "[benchmark] Expose all parameters",
    "user": "JunxiChhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-11T07:58:21Z",
    "closed_at": "2023-12-13T07:55:52Z",
    "merged_at": "2023-12-13T07:55:52Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/131"
  },
  {
    "number": 130,
    "title": "[Kernel] Add NF4 data type models.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-11T05:04:37Z",
    "closed_at": "2023-12-12T03:24:08Z",
    "merged_at": "2023-12-12T03:24:08Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/130"
  },
  {
    "number": 129,
    "title": "[Model][Qwen] Add Qwen model support.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-11T03:43:35Z",
    "closed_at": "2023-12-20T11:51:00Z",
    "merged_at": "2023-12-20T11:51:00Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/129"
  },
  {
    "number": 127,
    "title": "[Layers] Fix rotary embedding for Llama2",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-08T10:05:23Z",
    "closed_at": "2023-12-11T08:32:19Z",
    "merged_at": "2023-12-11T08:32:19Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/127"
  },
  {
    "number": 126,
    "title": "[Kernel] Add faster int4 kernels by AVX512_FP16.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-08T09:50:54Z",
    "closed_at": "2023-12-11T05:19:23Z",
    "merged_at": "2023-12-11T05:19:23Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/126"
  },
  {
    "number": 125,
    "title": "[Demo] Add int4 data type.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-08T05:08:19Z",
    "closed_at": "2023-12-11T14:48:19Z",
    "merged_at": "2023-12-11T14:48:19Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/125"
  },
  {
    "number": 124,
    "title": "[Dependency] Changed mkl library from shard to static",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-08T02:24:14Z",
    "closed_at": "2023-12-08T04:52:52Z",
    "merged_at": "2023-12-08T04:52:52Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/124"
  },
  {
    "number": 123,
    "title": "[Kernel] Add onednn W8A8 compute kernels.",
    "user": "xiangzez",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-07T08:40:10Z",
    "closed_at": "2023-12-15T08:03:53Z",
    "merged_at": "2023-12-15T08:03:53Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/123"
  },
  {
    "number": 122,
    "title": "[Demo] Add Baichuan2 Demo.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-07T07:05:24Z",
    "closed_at": "2023-12-07T08:47:27Z",
    "merged_at": "2023-12-07T08:47:27Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/122"
  },
  {
    "number": 121,
    "title": "[Dockerfile] Fix _b2 module missing.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-07T05:25:02Z",
    "closed_at": "2023-12-07T07:06:50Z",
    "merged_at": "2023-12-07T07:06:50Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/121"
  },
  {
    "number": 119,
    "title": "[Decoder] Prepare right buf size in prefix sharing",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-06T06:23:22Z",
    "closed_at": "2023-12-06T08:17:16Z",
    "merged_at": "2023-12-06T08:17:16Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/119"
  },
  {
    "number": 118,
    "title": "[Benchmark] Unify all models' prompt & benchmark script",
    "user": "JunxiChhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-06T02:29:59Z",
    "closed_at": "2023-12-11T02:24:41Z",
    "merged_at": "2023-12-11T02:24:41Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/118"
  },
  {
    "number": 116,
    "title": "[Model] Refactor ChatGLM3 API.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-05T07:30:39Z",
    "closed_at": "2023-12-06T06:44:33Z",
    "merged_at": "2023-12-06T06:44:33Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/116"
  },
  {
    "number": 115,
    "title": "[Kernel] Add int4 weight only models.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-04T02:49:34Z",
    "closed_at": "2023-12-05T02:49:17Z",
    "merged_at": "2023-12-05T02:49:17Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/115"
  },
  {
    "number": 112,
    "title": "[README] Fix model convert oneline cmd.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-01T07:43:23Z",
    "closed_at": "2023-12-05T06:27:28Z",
    "merged_at": "2023-12-05T06:27:28Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/112"
  },
  {
    "number": 111,
    "title": "[Dockerfile] Add python into PATH.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-01T07:37:00Z",
    "closed_at": "2023-12-06T04:31:11Z",
    "merged_at": "2023-12-06T04:31:11Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/111"
  },
  {
    "number": 110,
    "title": "Add ChatGLM3 support",
    "user": "SakuraYM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-01T06:35:27Z",
    "closed_at": "2023-12-05T06:26:10Z",
    "merged_at": "2023-12-05T06:26:10Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/110"
  },
  {
    "number": 109,
    "title": "add glm3 convert tool ",
    "user": "SakuraYM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-01T05:27:48Z",
    "closed_at": "2023-12-01T05:59:00Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/109"
  },
  {
    "number": 108,
    "title": "add glm3 support",
    "user": "SakuraYM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-01T05:20:02Z",
    "closed_at": "2023-12-01T05:25:56Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/108"
  },
  {
    "number": 106,
    "title": "Accelerate first token gen with BF16-gemm MHA and concat-Silu MLP",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-30T10:55:20Z",
    "closed_at": "2023-12-06T08:16:17Z",
    "merged_at": "2023-12-06T08:16:17Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/106"
  },
  {
    "number": 105,
    "title": "[Model] Add chatglm3 support",
    "user": "SakuraYM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-30T07:20:52Z",
    "closed_at": "2023-12-01T05:05:30Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/105"
  },
  {
    "number": 104,
    "title": "[CMake] Auto check environment oneCCL.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-30T06:43:00Z",
    "closed_at": "2023-11-30T07:42:39Z",
    "merged_at": "2023-11-30T07:42:39Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/104"
  },
  {
    "number": 103,
    "title": "[VERBOSE] XFT_VERBOSE macro support",
    "user": "wenhuanh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-30T05:19:12Z",
    "closed_at": "2023-12-15T03:35:40Z",
    "merged_at": "2023-12-15T03:35:40Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/103"
  },
  {
    "number": 101,
    "title": "[README] Update readme.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-29T08:41:33Z",
    "closed_at": "2023-11-30T01:32:24Z",
    "merged_at": "2023-11-30T01:32:24Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/101"
  },
  {
    "number": 100,
    "title": "[env] Add 'XFT_TIMELINE' and 'XFT_COMM_TIME' env.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-29T07:31:07Z",
    "closed_at": "2023-11-29T08:01:06Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/100"
  },
  {
    "number": 98,
    "title": "chatglm3 convert tool added",
    "user": "SakuraYM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-29T06:09:59Z",
    "closed_at": "2023-11-29T06:25:21Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/98"
  },
  {
    "number": 93,
    "title": "[Tools] Fix opt convert tool issue.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-28T09:13:10Z",
    "closed_at": "2023-11-28T15:38:13Z",
    "merged_at": "2023-11-28T15:38:12Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/93"
  },
  {
    "number": 92,
    "title": "[3rdparty] remove oneCCL enviroment depency.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-28T08:11:35Z",
    "closed_at": "2023-11-29T07:08:20Z",
    "merged_at": "2023-11-29T07:08:20Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/92"
  },
  {
    "number": 91,
    "title": "[API][Python] Fix AutoModel import error.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-28T07:56:15Z",
    "closed_at": "2023-11-29T02:02:15Z",
    "merged_at": "2023-11-29T02:02:15Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/91"
  },
  {
    "number": 89,
    "title": "[AWQ] Add AWQ INT8 CPU support on python side",
    "user": "miaojinc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-27T12:09:47Z",
    "closed_at": "2023-12-19T04:36:20Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/89"
  },
  {
    "number": 88,
    "title": "[issue] Raise an obvious exception if max_pos_seq_len is small",
    "user": "huaqiangwang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-27T12:09:01Z",
    "closed_at": "2023-12-05T01:49:43Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/88"
  },
  {
    "number": 86,
    "title": "[common] merge ChatGLM2Attention::forward into Attention::forward",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-27T07:55:02Z",
    "closed_at": "2023-12-01T08:22:13Z",
    "merged_at": "2023-12-01T08:22:13Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/86"
  },
  {
    "number": 85,
    "title": "[API][Python] Lazy import tools module.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-27T07:25:28Z",
    "closed_at": "2023-11-27T08:00:07Z",
    "merged_at": "2023-11-27T08:00:07Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/85"
  },
  {
    "number": 84,
    "title": "[Distribute] Packing convert tools py code.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-27T06:05:22Z",
    "closed_at": "2023-11-27T06:09:59Z",
    "merged_at": "2023-11-27T06:09:59Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/84"
  },
  {
    "number": 81,
    "title": "[Cmake] Format cmake output.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-25T01:46:27Z",
    "closed_at": "2023-11-25T12:33:55Z",
    "merged_at": "2023-11-25T12:33:55Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/81"
  },
  {
    "number": 80,
    "title": "[Common] Fix convert bugs when size < 16.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-24T12:35:05Z",
    "closed_at": "2023-11-24T13:32:06Z",
    "merged_at": "2023-11-24T13:32:06Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/80"
  },
  {
    "number": 79,
    "title": "[common] fix bug for dtype convertion function",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-24T09:03:01Z",
    "closed_at": "2023-11-24T12:35:17Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/79"
  },
  {
    "number": 78,
    "title": "[Tools] Add convert tools in xft.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-24T07:28:30Z",
    "closed_at": "2023-11-24T07:50:46Z",
    "merged_at": "2023-11-24T07:50:46Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/78"
  },
  {
    "number": 77,
    "title": "[Benchmark] Add KPI of max, min, avg and p90 latency",
    "user": "JunxiChhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-24T05:31:52Z",
    "closed_at": "2023-11-27T04:52:22Z",
    "merged_at": "2023-11-27T04:52:22Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/77"
  },
  {
    "number": 76,
    "title": "[License] Add missing license head.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-24T05:18:49Z",
    "closed_at": "2023-11-24T06:54:42Z",
    "merged_at": "2023-11-24T06:54:41Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/76"
  },
  {
    "number": 75,
    "title": "Enable calculation of total latency for whole output.",
    "user": "JunxiChhen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-24T01:14:24Z",
    "closed_at": "2023-11-24T02:46:22Z",
    "merged_at": "2023-11-24T02:46:22Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/75"
  },
  {
    "number": 73,
    "title": "[oneCCL] enable bf16 comm.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-23T10:07:28Z",
    "closed_at": "2024-01-23T06:56:50Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/73"
  },
  {
    "number": 72,
    "title": "[CMake] Link stdc++fs in pt.so explicitly.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-23T05:53:43Z",
    "closed_at": "2023-11-23T09:16:25Z",
    "merged_at": "2023-11-23T09:16:25Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/72"
  },
  {
    "number": 71,
    "title": "[Example] Remove trigraph in opt vocab.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-22T08:50:28Z",
    "closed_at": "2023-11-23T07:20:39Z",
    "merged_at": "2023-11-23T07:20:39Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/71"
  },
  {
    "number": 70,
    "title": "[perf] improve next token latency when (#threads >= 2 * #heads) by sharding the head into multiple splits",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-22T07:03:21Z",
    "closed_at": "2023-11-24T02:42:46Z",
    "merged_at": "2023-11-24T02:42:46Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/70"
  },
  {
    "number": 69,
    "title": "[MPI] Modify share memory reduceadd to use small blocks",
    "user": "wli58",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-22T02:33:12Z",
    "closed_at": "2023-11-23T09:14:22Z",
    "merged_at": "2023-11-23T09:14:22Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/69"
  },
  {
    "number": 68,
    "title": "[test] update llama config.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-21T07:35:29Z",
    "closed_at": "2023-11-21T08:39:39Z",
    "merged_at": "2023-11-21T08:39:39Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/68"
  },
  {
    "number": 67,
    "title": "[Version] v1.1.0.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-21T05:48:16Z",
    "closed_at": "2023-11-30T08:23:21Z",
    "merged_at": "2023-11-30T08:23:21Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/67"
  },
  {
    "number": 65,
    "title": "[tool] Change the default convert from fp32 to fp16.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-21T03:19:11Z",
    "closed_at": "2023-11-24T06:56:20Z",
    "merged_at": "2023-11-24T06:56:20Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/65"
  },
  {
    "number": 64,
    "title": "[API] Export MLP LLaMA api.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-20T15:19:32Z",
    "closed_at": "2023-11-26T07:34:45Z",
    "merged_at": "2023-11-26T07:34:45Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/64"
  },
  {
    "number": 63,
    "title": "[UT] Fix small_gemm make error.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-20T06:12:47Z",
    "closed_at": "2023-11-20T08:13:15Z",
    "merged_at": "2023-11-20T08:13:15Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/63"
  },
  {
    "number": 62,
    "title": "[UT] Add RMS Norm unit test.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-20T05:56:23Z",
    "closed_at": "2023-11-20T15:23:55Z",
    "merged_at": "2023-11-20T15:23:55Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/62"
  },
  {
    "number": 61,
    "title": "[UT] Add layer_norm unit test.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-20T04:46:29Z",
    "closed_at": "2023-11-20T05:52:56Z",
    "merged_at": "2023-11-20T05:52:56Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/61"
  },
  {
    "number": 60,
    "title": "[API] Export MLP LLaMA api.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-17T08:38:42Z",
    "closed_at": "2023-11-20T15:20:50Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/60"
  },
  {
    "number": 55,
    "title": "fix config bug for baichuan convert tool",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-15T06:57:18Z",
    "closed_at": "2023-11-15T07:29:50Z",
    "merged_at": "2023-11-15T07:29:50Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/55"
  },
  {
    "number": 54,
    "title": "[Debug] XFT_DEBUG_DIR to specify debug file dir.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-15T06:10:39Z",
    "closed_at": "2023-11-15T07:54:03Z",
    "merged_at": "2023-11-15T07:54:03Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/54"
  },
  {
    "number": 53,
    "title": "[Feature] Prefix sharing.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-14T08:52:03Z",
    "closed_at": "2023-11-28T08:54:36Z",
    "merged_at": "2023-11-28T08:54:36Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/53"
  },
  {
    "number": 51,
    "title": "[Docker] Update dockerfile.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-13T08:52:03Z",
    "closed_at": "2023-11-17T06:32:02Z",
    "merged_at": "2023-11-17T06:32:02Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/51"
  },
  {
    "number": 50,
    "title": "[feature] change torch deps.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-13T08:14:42Z",
    "closed_at": "2023-11-13T08:17:01Z",
    "merged_at": "2023-11-13T08:17:01Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/50"
  },
  {
    "number": 49,
    "title": "[feature] support loading fake model weight for python benchmarks.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-13T07:16:40Z",
    "closed_at": "2023-11-13T07:57:24Z",
    "merged_at": "2023-11-13T07:57:24Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/49"
  },
  {
    "number": 48,
    "title": "[feature] load fake model weight.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-13T02:02:15Z",
    "closed_at": "2023-11-13T03:06:35Z",
    "merged_at": "2023-11-13T03:06:35Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/48"
  },
  {
    "number": 46,
    "title": "[oneDNN] Add MatMul bf16bf16bf16 primitives.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-10T15:13:35Z",
    "closed_at": "2023-11-11T02:52:53Z",
    "merged_at": "2023-11-11T02:52:53Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/46"
  },
  {
    "number": 45,
    "title": "[API][CPP] Add overloaded func of model.config.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-10T03:07:28Z",
    "closed_at": "2023-11-16T01:42:05Z",
    "merged_at": "2023-11-16T01:42:05Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/45"
  },
  {
    "number": 44,
    "title": "[xDNN] Update xDNN version 1.2.1.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-09T13:54:44Z",
    "closed_at": "2023-11-20T02:05:47Z",
    "merged_at": "2023-11-20T02:05:47Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/44"
  },
  {
    "number": 43,
    "title": "[CMake] Auto detect python in env.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-09T05:49:53Z",
    "closed_at": "2023-11-09T06:10:38Z",
    "merged_at": "2023-11-09T06:10:38Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/43"
  },
  {
    "number": 42,
    "title": "[3rdparty] Remove mklml dependency.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-09T02:54:46Z",
    "closed_at": "2023-11-09T05:02:40Z",
    "merged_at": "2023-11-09T05:02:40Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/42"
  },
  {
    "number": 41,
    "title": "[models] Add Baichuan Models and the convert tool.",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-05T11:51:58Z",
    "closed_at": "2023-11-08T03:27:02Z",
    "merged_at": "2023-11-08T03:27:02Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/41"
  },
  {
    "number": 39,
    "title": "Make configured max token size work",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-04T15:15:05Z",
    "closed_at": "2023-11-07T01:26:31Z",
    "merged_at": "2023-11-07T01:26:31Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/39"
  },
  {
    "number": 37,
    "title": "[Tools] concat folder path in more secure way.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-03T05:28:48Z",
    "closed_at": "2023-11-04T15:08:26Z",
    "merged_at": "2023-11-04T15:08:26Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/37"
  },
  {
    "number": 35,
    "title": "Update default M from 2 to 8",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-01T06:01:09Z",
    "closed_at": "2023-11-02T02:04:12Z",
    "merged_at": "2023-11-02T02:04:12Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/35"
  },
  {
    "number": 34,
    "title": "[TP] imbalance split support",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-01T03:40:32Z",
    "closed_at": "2023-11-01T14:09:50Z",
    "merged_at": "2023-11-01T14:09:50Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/34"
  },
  {
    "number": 33,
    "title": "Add print info for real input token size in benchmark.py",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-31T03:32:41Z",
    "closed_at": "2023-11-02T02:02:23Z",
    "merged_at": "2023-11-02T02:02:23Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/33"
  },
  {
    "number": 32,
    "title": "[MPI] Auto entering single instance mode.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-31T02:44:45Z",
    "closed_at": "2023-10-31T03:11:34Z",
    "merged_at": "2023-10-31T03:11:34Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/32"
  },
  {
    "number": 31,
    "title": "[API] Export layer_norm and rms_norm BF16 APIs.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-30T07:57:38Z",
    "closed_at": "2023-11-08T13:50:11Z",
    "merged_at": "2023-11-08T13:50:11Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/31"
  },
  {
    "number": 30,
    "title": "[OneDNN] Rename ig_amx_xxx to onednn_amx_xxx.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-30T01:57:14Z",
    "closed_at": "2023-11-08T13:48:24Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/30"
  },
  {
    "number": 28,
    "title": "[Readme] Add wiki and support.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-26T07:15:35Z",
    "closed_at": "2023-10-26T08:31:08Z",
    "merged_at": "2023-10-26T08:31:08Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/28"
  },
  {
    "number": 27,
    "title": "[GPTQ] Add GPTQ cpp implement.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-26T06:49:06Z",
    "closed_at": "2023-12-19T15:13:30Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/27"
  },
  {
    "number": 26,
    "title": "[CI] update ci script.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-26T03:11:30Z",
    "closed_at": "2023-10-26T07:15:36Z",
    "merged_at": "2023-10-26T07:15:36Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/26"
  },
  {
    "number": 25,
    "title": "[oneCCL] upgrade oneCCL version and fix shm bug.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-26T03:02:12Z",
    "closed_at": "2023-10-26T05:18:35Z",
    "merged_at": "2023-10-26T05:18:35Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/25"
  },
  {
    "number": 24,
    "title": "support alibi embedding",
    "user": "aurora327",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-25T07:22:54Z",
    "closed_at": "2023-11-10T02:04:50Z",
    "merged_at": "2023-11-10T02:04:50Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/24"
  },
  {
    "number": 23,
    "title": "[GPTQ] Add GPTQ python implement.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-25T06:36:56Z",
    "closed_at": "2023-10-26T07:23:14Z",
    "merged_at": "2023-10-26T07:23:13Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/23"
  },
  {
    "number": 22,
    "title": "[CI] add ci support.",
    "user": "marvin-Yu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-25T04:17:17Z",
    "closed_at": "2023-10-25T05:17:21Z",
    "merged_at": "2023-10-25T05:17:21Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/22"
  },
  {
    "number": 21,
    "title": "[Search] Add sample search.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-24T08:51:14Z",
    "closed_at": "2023-10-26T12:37:26Z",
    "merged_at": "2023-10-26T12:37:26Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/21"
  },
  {
    "number": 20,
    "title": "[API] Export layernorm and rmsnorm function API.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-24T03:07:47Z",
    "closed_at": "2023-10-25T08:31:50Z",
    "merged_at": "2023-10-25T08:31:50Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/20"
  },
  {
    "number": 19,
    "title": "[MPI] Add exit functions in MPI mode",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-23T08:34:53Z",
    "closed_at": "2023-10-26T06:35:10Z",
    "merged_at": "2023-10-26T06:35:10Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/19"
  },
  {
    "number": 17,
    "title": "[Demo][Python] add batchsize option and show perf.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-20T01:50:02Z",
    "closed_at": "2023-10-26T04:43:37Z",
    "merged_at": "2023-10-26T04:43:37Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/17"
  },
  {
    "number": 16,
    "title": "[feature][layer][attn] grouped-query attention for Llama2",
    "user": "abenmao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T10:12:22Z",
    "closed_at": "2023-10-25T09:46:50Z",
    "merged_at": "2023-10-25T09:46:50Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/16"
  },
  {
    "number": 15,
    "title": "rotary embedding api interface for llama",
    "user": "aurora327",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T08:34:43Z",
    "closed_at": "2023-11-10T08:07:39Z",
    "merged_at": "2023-11-10T08:07:39Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/15"
  },
  {
    "number": 13,
    "title": "[License] Add license in src code file.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T06:49:48Z",
    "closed_at": "2023-10-26T05:16:45Z",
    "merged_at": "2023-10-26T05:16:45Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/13"
  },
  {
    "number": 12,
    "title": "[Dist] Add accelerate dependency for tools.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T06:31:42Z",
    "closed_at": "2023-10-19T06:31:53Z",
    "merged_at": "2023-10-19T06:31:53Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/12"
  },
  {
    "number": 11,
    "title": "[Dockerfile] Add release and missing dev dockerfile.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T05:50:27Z",
    "closed_at": "2023-10-19T05:55:05Z",
    "merged_at": "2023-10-19T05:55:05Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/11"
  },
  {
    "number": 10,
    "title": "[3rdparty] Remove mklml and iomp library.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T05:44:05Z",
    "closed_at": "2023-12-20T01:33:24Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/10"
  },
  {
    "number": 9,
    "title": "[Dist] Update long description and email.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T05:39:04Z",
    "closed_at": "2023-10-19T05:51:31Z",
    "merged_at": "2023-10-19T05:51:31Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/9"
  },
  {
    "number": 8,
    "title": "[Example][CPP] Check output len small than 2.",
    "user": "Duyi-Wang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T05:38:47Z",
    "closed_at": "2023-10-19T05:54:07Z",
    "merged_at": "2023-10-19T05:54:07Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/8"
  },
  {
    "number": 7,
    "title": "Add support for chatglm/chatglm2 chat mode",
    "user": "a3213105",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T05:18:20Z",
    "closed_at": "2023-10-19T05:54:36Z",
    "merged_at": "2023-10-19T05:54:36Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/7"
  },
  {
    "number": 6,
    "title": "[API] Export layernorm and rmsnorm api.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T04:22:25Z",
    "closed_at": "2023-10-24T02:59:51Z",
    "merged_at": "2023-10-24T02:59:51Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/6"
  },
  {
    "number": 5,
    "title": "[GPTQ] Add python and cpp GPTQ implement.",
    "user": "changqi1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T04:21:25Z",
    "closed_at": "2023-10-25T06:36:31Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/5"
  },
  {
    "number": 3,
    "title": "Bump transformers from 4.28.1 to 4.30.0",
    "user": "pujiang2018",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-03T10:09:17Z",
    "closed_at": "2023-10-03T10:09:53Z",
    "merged_at": "2023-10-03T10:09:53Z",
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/3"
  },
  {
    "number": 2,
    "title": "Bump transformers from 4.28.1 to 4.30.0 in /examples/web_demo",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2023-09-26T14:41:33Z",
    "closed_at": "2023-10-03T10:10:18Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/2"
  },
  {
    "number": 1,
    "title": "Bump transformers from 4.28.1 to 4.30.0",
    "user": "dependabot[bot]",
    "user_type": "Bot",
    "is_human": false,
    "created_at": "2023-09-26T14:06:56Z",
    "closed_at": "2023-10-03T10:10:41Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/intel/xFasterTransformer/pull/1"
  }
]