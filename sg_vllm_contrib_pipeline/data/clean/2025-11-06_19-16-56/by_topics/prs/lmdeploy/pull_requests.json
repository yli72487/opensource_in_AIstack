[
  {
    "number": 4107,
    "title": "[Fix] all RayEngineWorker actors created at node 0 in RL training",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-06T12:11:13Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4107"
  },
  {
    "number": 4106,
    "title": "fix: fix lora weight loading for internvl",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-06T08:11:57Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4106"
  },
  {
    "number": 4104,
    "title": "Enhance request checker",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-06T06:24:28Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4104"
  },
  {
    "number": 4103,
    "title": "workaround for issue \"TypeError argument 'tokens': 'NoneType' object cannot be converted to 'PyString\"",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-05T10:52:18Z",
    "closed_at": "2025-11-06T06:31:53Z",
    "merged_at": "2025-11-06T06:31:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4103"
  },
  {
    "number": 4101,
    "title": "Fix update_params for pytorch backend when loading vl model",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-05T06:20:18Z",
    "closed_at": "2025-11-06T03:12:51Z",
    "merged_at": "2025-11-06T03:12:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4101"
  },
  {
    "number": 4100,
    "title": "fix bug: schedule ratio support prefix-caching",
    "user": "Tsundoku958",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-05T04:02:01Z",
    "closed_at": "2025-11-06T12:48:49Z",
    "merged_at": "2025-11-06T12:48:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4100"
  },
  {
    "number": 4099,
    "title": "add missing update_model_meta",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-04T08:25:04Z",
    "closed_at": "2025-11-04T10:39:04Z",
    "merged_at": "2025-11-04T10:39:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4099"
  },
  {
    "number": 4097,
    "title": "add ascend_a3 Dockerfile",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-03T10:49:59Z",
    "closed_at": "2025-11-06T06:29:30Z",
    "merged_at": "2025-11-06T06:29:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4097"
  },
  {
    "number": 4095,
    "title": "Update installation.md",
    "user": "krescent",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-03T06:58:14Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4095"
  },
  {
    "number": 4094,
    "title": "Update model evalution guide",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-11-02T13:53:02Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4094"
  },
  {
    "number": 4093,
    "title": "Support Qwen3-VL",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-31T12:03:52Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4093"
  },
  {
    "number": 4092,
    "title": "add endpoint /abort_request",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-31T10:40:29Z",
    "closed_at": "2025-11-05T09:51:02Z",
    "merged_at": "2025-11-05T09:51:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4092"
  },
  {
    "number": 4091,
    "title": "add dockerfile to build dev image",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-31T07:21:21Z",
    "closed_at": "2025-10-31T09:10:12Z",
    "merged_at": "2025-10-31T09:10:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4091"
  },
  {
    "number": 4090,
    "title": "[Feature]: return routed experts to reuse",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-31T03:25:04Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4090"
  },
  {
    "number": 4089,
    "title": "revert masking vocab_size",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-30T15:14:01Z",
    "closed_at": "2025-10-31T12:34:40Z",
    "merged_at": "2025-10-31T12:34:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4089"
  },
  {
    "number": 4088,
    "title": "remove num_tokens from EngineOutput",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-30T14:58:03Z",
    "closed_at": "2025-10-31T07:23:03Z",
    "merged_at": "2025-10-31T07:23:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4088"
  },
  {
    "number": 4087,
    "title": "[ci] refactor longtext benchmark",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-30T10:12:20Z",
    "closed_at": "2025-11-06T06:51:22Z",
    "merged_at": "2025-11-06T06:51:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4087"
  },
  {
    "number": 4086,
    "title": "support image_data input to /generate endpoint",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-30T06:45:02Z",
    "closed_at": "2025-11-04T11:47:42Z",
    "merged_at": "2025-11-04T11:47:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4086"
  },
  {
    "number": 4084,
    "title": "Fix ep deployment issues",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-30T03:10:08Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4084"
  },
  {
    "number": 4083,
    "title": "Fix inputs split",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-30T02:50:00Z",
    "closed_at": "2025-10-30T13:31:32Z",
    "merged_at": "2025-10-30T13:31:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4083"
  },
  {
    "number": 4080,
    "title": "feat: add json_object support in response_format",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-29T07:52:20Z",
    "closed_at": "2025-11-01T14:56:07Z",
    "merged_at": "2025-11-01T14:56:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4080"
  },
  {
    "number": 4078,
    "title": "fix type hint",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-29T02:52:49Z",
    "closed_at": "2025-10-29T12:54:38Z",
    "merged_at": "2025-10-29T12:54:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4078"
  },
  {
    "number": 4077,
    "title": "fix duplicated stop_token_string when ignore_special_tokens is False",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-27T12:54:23Z",
    "closed_at": "2025-10-28T03:46:09Z",
    "merged_at": "2025-10-28T03:46:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4077"
  },
  {
    "number": 4076,
    "title": "Enlarge gc threshold",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-27T12:42:46Z",
    "closed_at": "2025-10-30T08:35:50Z",
    "merged_at": "2025-10-30T08:35:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4076"
  },
  {
    "number": 4074,
    "title": "Optimize sleep level=1 for turbomind backend",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-24T11:01:36Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4074"
  },
  {
    "number": 4070,
    "title": "[ci] repair fail daily testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-24T02:16:28Z",
    "closed_at": "2025-10-24T08:07:08Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4070"
  },
  {
    "number": 4069,
    "title": "fix builder for kimi-k2",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-23T12:06:29Z",
    "closed_at": "2025-10-23T12:07:56Z",
    "merged_at": "2025-10-23T12:07:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4069"
  },
  {
    "number": 4068,
    "title": "Skip unnecessary sampling and fix the random offset",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-23T07:59:31Z",
    "closed_at": "2025-10-24T07:05:59Z",
    "merged_at": "2025-10-24T07:05:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4068"
  },
  {
    "number": 4066,
    "title": "update ascend requirements",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-23T07:50:48Z",
    "closed_at": "2025-10-23T07:58:54Z",
    "merged_at": "2025-10-23T07:58:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4066"
  },
  {
    "number": 4063,
    "title": "[ascend] support aclgraph",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-22T08:10:33Z",
    "closed_at": "2025-10-23T05:35:09Z",
    "merged_at": "2025-10-23T05:35:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4063"
  },
  {
    "number": 4062,
    "title": "bump version to v0.10.2",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-22T08:00:34Z",
    "closed_at": "2025-10-28T11:31:18Z",
    "merged_at": "2025-10-28T11:31:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4062"
  },
  {
    "number": 4061,
    "title": "Update API testing with HLE and LCB datasets",
    "user": "littlegy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-22T07:50:32Z",
    "closed_at": "2025-10-23T07:35:34Z",
    "merged_at": "2025-10-23T07:35:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4061"
  },
  {
    "number": 4060,
    "title": "Check color logger",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-22T06:37:05Z",
    "closed_at": "2025-10-22T08:54:40Z",
    "merged_at": "2025-10-22T08:54:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4060"
  },
  {
    "number": 4057,
    "title": "Add step_map to track token decoding order in DLLM",
    "user": "Auraithm",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-21T12:11:38Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4057"
  },
  {
    "number": 4056,
    "title": "Optimize multinomial sampling",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-21T10:19:57Z",
    "closed_at": "2025-10-23T08:22:52Z",
    "merged_at": "2025-10-23T08:22:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4056"
  },
  {
    "number": 4054,
    "title": "Leverage incremental output between the inference and async engines to improve performance",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-20T13:32:54Z",
    "closed_at": "2025-10-23T07:26:46Z",
    "merged_at": "2025-10-23T07:26:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4054"
  },
  {
    "number": 4048,
    "title": "incrementally send / recv EngineOutput in ray mp engine",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-17T12:15:13Z",
    "closed_at": "2025-10-22T03:28:35Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4048"
  },
  {
    "number": 4047,
    "title": "[POC] Encoder Disaggregation",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-17T07:50:34Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4047"
  },
  {
    "number": 4046,
    "title": "[ci] refactor api evaluate test into llm judger evaluation",
    "user": "littlegy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-17T02:15:09Z",
    "closed_at": "2025-10-20T03:03:32Z",
    "merged_at": "2025-10-20T03:03:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4046"
  },
  {
    "number": 4044,
    "title": "fix: fix tokenizer parsing bug for guided decoding",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-16T10:49:31Z",
    "closed_at": "2025-10-17T04:25:10Z",
    "merged_at": "2025-10-17T04:25:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4044"
  },
  {
    "number": 4043,
    "title": "fope",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-16T09:52:35Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4043"
  },
  {
    "number": 4041,
    "title": "move releasing resource from async_engine to inference engine",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-15T13:58:58Z",
    "closed_at": "2025-10-16T10:42:53Z",
    "merged_at": "2025-10-16T10:42:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4041"
  },
  {
    "number": 4039,
    "title": "Qwen3 next",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-14T10:48:43Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4039"
  },
  {
    "number": 4029,
    "title": "Fix message content field handling for tool calls and multimodal input",
    "user": "QwertyJack",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-09T08:57:11Z",
    "closed_at": "2025-10-20T04:17:09Z",
    "merged_at": "2025-10-20T04:17:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4029"
  },
  {
    "number": 4028,
    "title": "Reimplement guided decoding with xgrammar for PyTorch Engine",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-09T07:38:34Z",
    "closed_at": "2025-10-15T14:05:33Z",
    "merged_at": "2025-10-15T14:05:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4028"
  },
  {
    "number": 4027,
    "title": "remove profile_generation.py and its testcases",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-09T05:32:09Z",
    "closed_at": "2025-10-10T04:47:16Z",
    "merged_at": "2025-10-10T04:47:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4027"
  },
  {
    "number": 4026,
    "title": "Support Deepseek v32",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-08T07:11:04Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4026"
  },
  {
    "number": 4023,
    "title": "Fix GPT-OSS streaming tool call parsing",
    "user": "QwertyJack",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-10-03T09:43:37Z",
    "closed_at": "2025-10-11T11:16:40Z",
    "merged_at": "2025-10-11T11:16:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4023"
  },
  {
    "number": 4019,
    "title": "add /generate api",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-30T02:59:21Z",
    "closed_at": "2025-10-09T08:25:49Z",
    "merged_at": "2025-10-09T08:25:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4019"
  },
  {
    "number": 4018,
    "title": "quant blocked fp8",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-29T12:57:17Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4018"
  },
  {
    "number": 4017,
    "title": "zmqrpc localhost only",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-29T06:58:28Z",
    "closed_at": "2025-09-29T13:02:43Z",
    "merged_at": "2025-09-29T13:02:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4017"
  },
  {
    "number": 4016,
    "title": "fix(security): use json serialization instead of pickle for security",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-29T04:00:54Z",
    "closed_at": "2025-09-29T05:38:20Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4016"
  },
  {
    "number": 4013,
    "title": "Drop CUDA 11.8 build support, upgrade CI/CD to CUDA 12.6/12.8",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-28T11:32:08Z",
    "closed_at": "2025-10-07T05:56:34Z",
    "merged_at": "2025-10-07T05:56:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4013"
  },
  {
    "number": 4012,
    "title": "fix dllm long-context",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-28T02:54:11Z",
    "closed_at": "2025-10-10T04:48:10Z",
    "merged_at": "2025-10-10T04:48:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4012"
  },
  {
    "number": 4011,
    "title": "fix qwenvl on ascend device",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-26T08:42:35Z",
    "closed_at": "2025-09-28T09:01:38Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4011"
  },
  {
    "number": 4008,
    "title": "[ci] refactor eval into api eval and add h800 eval workflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-26T01:10:23Z",
    "closed_at": "2025-10-10T06:35:33Z",
    "merged_at": "2025-10-10T06:35:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4008"
  },
  {
    "number": 4006,
    "title": "add openai_harmony to requirements",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-25T02:21:59Z",
    "closed_at": "2025-09-25T03:11:28Z",
    "merged_at": "2025-09-25T03:11:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4006"
  },
  {
    "number": 4005,
    "title": "fix cudagraph without warmup",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-24T09:15:24Z",
    "closed_at": "2025-09-24T12:47:04Z",
    "merged_at": "2025-09-24T12:47:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4005"
  },
  {
    "number": 4004,
    "title": "Refactor dp tp",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-24T04:39:38Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4004"
  },
  {
    "number": 4003,
    "title": "fix internvl flash long context acc",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-23T13:19:50Z",
    "closed_at": "2025-09-24T13:01:14Z",
    "merged_at": "2025-09-24T13:01:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4003"
  },
  {
    "number": 4001,
    "title": "fix not-returned iterator in SequenceManager::Erase",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-23T06:52:56Z",
    "closed_at": "2025-09-23T08:05:13Z",
    "merged_at": "2025-09-23T08:05:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4001"
  },
  {
    "number": 4000,
    "title": "return the last token's logprobs, logits and last_hidden_states if include_stop_str_in_output is requested",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-22T09:28:56Z",
    "closed_at": "2025-09-22T12:23:34Z",
    "merged_at": "2025-09-22T12:23:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4000"
  },
  {
    "number": 3999,
    "title": "[Fix] device args in chat cli when using pytorch engine",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-22T04:59:26Z",
    "closed_at": "2025-09-22T13:20:30Z",
    "merged_at": "2025-09-22T13:20:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3999"
  },
  {
    "number": 3998,
    "title": "Add reasoning parser for GPT-OSS style channels.",
    "user": "GY19A",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-21T11:30:52Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3998"
  },
  {
    "number": 3997,
    "title": "fix internvl",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-19T12:18:33Z",
    "closed_at": "2025-09-23T06:14:26Z",
    "merged_at": "2025-09-23T06:14:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3997"
  },
  {
    "number": 3994,
    "title": "remove NCCL_LAUNCH_MODE",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-19T06:27:32Z",
    "closed_at": "2025-09-19T09:06:56Z",
    "merged_at": "2025-09-19T09:06:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3994"
  },
  {
    "number": 3991,
    "title": "fix bug: dp+tp warmup",
    "user": "Tsundoku958",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-18T12:18:11Z",
    "closed_at": "2025-09-29T13:17:13Z",
    "merged_at": "2025-09-29T13:17:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3991"
  },
  {
    "number": 3990,
    "title": "Disable prefix caching when serving a VLM model",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-18T12:10:18Z",
    "closed_at": "2025-09-19T06:05:56Z",
    "merged_at": "2025-09-19T06:05:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3990"
  },
  {
    "number": 3989,
    "title": "bump version to v0.10.1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-18T10:39:27Z",
    "closed_at": "2025-09-26T02:19:56Z",
    "merged_at": "2025-09-26T02:19:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3989"
  },
  {
    "number": 3987,
    "title": "[CI] add API evaluation test",
    "user": "littlegy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-18T09:07:16Z",
    "closed_at": "2025-09-26T01:02:18Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3987"
  },
  {
    "number": 3986,
    "title": "update serve requirement",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-18T06:15:33Z",
    "closed_at": "2025-09-18T07:28:46Z",
    "merged_at": "2025-09-18T07:28:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3986"
  },
  {
    "number": 3985,
    "title": "[ci] add h800 function test workflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-18T02:18:55Z",
    "closed_at": "2025-09-19T02:57:46Z",
    "merged_at": "2025-09-19T02:57:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3985"
  },
  {
    "number": 3984,
    "title": "support returning stop_str in output",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-17T07:40:36Z",
    "closed_at": "2025-09-18T11:35:56Z",
    "merged_at": "2025-09-18T11:35:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3984"
  },
  {
    "number": 3983,
    "title": "add LlavaQwenForCausalLM vision arch",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-17T07:00:59Z",
    "closed_at": "2025-09-21T07:05:16Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3983"
  },
  {
    "number": 3982,
    "title": "Optimize AsyncEngine generation method",
    "user": "shell-nlp",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-16T15:32:51Z",
    "closed_at": "2025-09-17T05:40:34Z",
    "merged_at": "2025-09-17T05:40:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3982"
  },
  {
    "number": 3978,
    "title": "[Refactor]: Remove tokenizer when building engine",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-16T06:47:46Z",
    "closed_at": "2025-09-17T03:26:16Z",
    "merged_at": "2025-09-17T03:26:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3978"
  },
  {
    "number": 3976,
    "title": "cherry pick PR-3708 to return token_id",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-16T03:53:01Z",
    "closed_at": "2025-09-16T07:03:17Z",
    "merged_at": "2025-09-16T07:03:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3976"
  },
  {
    "number": 3974,
    "title": "Use blocking sync when TP engine is idling",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-15T14:37:49Z",
    "closed_at": "2025-09-17T06:37:26Z",
    "merged_at": "2025-09-17T06:37:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3974"
  },
  {
    "number": 3969,
    "title": "remove cudnn",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-15T03:27:43Z",
    "closed_at": "2025-09-15T07:59:20Z",
    "merged_at": "2025-09-15T07:59:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3969"
  },
  {
    "number": 3968,
    "title": "fix longrope",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-15T03:24:00Z",
    "closed_at": "2025-09-15T06:22:24Z",
    "merged_at": "2025-09-15T06:22:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3968"
  },
  {
    "number": 3965,
    "title": "Guided decoding with xgrammar for TurboMind",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-12T09:16:51Z",
    "closed_at": "2025-10-13T11:33:28Z",
    "merged_at": "2025-10-13T11:33:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3965"
  },
  {
    "number": 3962,
    "title": "support gpt-oss function/reasoning in /v1/chat/completions",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-12T03:21:41Z",
    "closed_at": "2025-09-18T10:35:47Z",
    "merged_at": "2025-09-18T10:35:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3962"
  },
  {
    "number": 3960,
    "title": "Add FP8*(B)F16 GEMM",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-11T13:01:14Z",
    "closed_at": "2025-09-15T13:20:37Z",
    "merged_at": "2025-09-15T13:20:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3960"
  },
  {
    "number": 3959,
    "title": "[CI] add ascend test",
    "user": "littlegy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-11T09:56:44Z",
    "closed_at": "2025-09-18T04:53:03Z",
    "merged_at": "2025-09-18T04:53:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3959"
  },
  {
    "number": 3958,
    "title": "[maca] change kv layout from pagedattn to flashattn",
    "user": "yuchiwang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-11T08:58:29Z",
    "closed_at": "2025-09-15T07:01:22Z",
    "merged_at": "2025-09-15T07:01:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3958"
  },
  {
    "number": 3956,
    "title": "support gpt-oss basic output",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-10T13:32:34Z",
    "closed_at": "2025-09-11T09:51:18Z",
    "merged_at": "2025-09-11T09:51:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3956"
  },
  {
    "number": 3952,
    "title": "Support InternVL3.5-Flash",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-09T13:09:42Z",
    "closed_at": "2025-09-17T14:44:50Z",
    "merged_at": "2025-09-17T14:44:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3952"
  },
  {
    "number": 3951,
    "title": "support context parallel",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-09T11:46:20Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3951"
  },
  {
    "number": 3948,
    "title": "build(pypi): add cuda 12.8 support for wheels",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-09T09:28:35Z",
    "closed_at": "2025-09-15T10:31:44Z",
    "merged_at": "2025-09-15T10:31:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3948"
  },
  {
    "number": 3947,
    "title": "specify installation on GeForce RTX 50 series",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-09T08:47:39Z",
    "closed_at": "2025-09-10T06:07:39Z",
    "merged_at": "2025-09-10T06:07:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3947"
  },
  {
    "number": 3946,
    "title": "fix bugs with triton3.4.0",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-09T08:09:10Z",
    "closed_at": "2025-09-11T14:01:05Z",
    "merged_at": "2025-09-11T14:01:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3946"
  },
  {
    "number": 3945,
    "title": "[Feature]: Support speculative decoding",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-09T06:26:14Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3945"
  },
  {
    "number": 3944,
    "title": "[ci] update daily testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-09T06:13:20Z",
    "closed_at": "2025-09-12T03:36:26Z",
    "merged_at": "2025-09-12T03:36:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3944"
  },
  {
    "number": 3941,
    "title": "put eot_token to stop_words",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-06T10:41:45Z",
    "closed_at": "2025-09-08T04:04:43Z",
    "merged_at": "2025-09-08T04:04:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3941"
  },
  {
    "number": 3940,
    "title": "build(docker): use Azure APT source to speed-up",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-05T06:26:08Z",
    "closed_at": "2025-09-05T09:35:48Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3940"
  },
  {
    "number": 3939,
    "title": "build(docker): fix ascend tag name",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-05T04:28:16Z",
    "closed_at": "2025-09-05T05:53:20Z",
    "merged_at": "2025-09-05T05:53:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3939"
  },
  {
    "number": 3938,
    "title": "Dlinfer readme",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-04T16:57:47Z",
    "closed_at": "2025-09-08T04:01:17Z",
    "merged_at": "2025-09-08T04:01:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3938"
  },
  {
    "number": 3937,
    "title": "Dispatch MXFP4 weight conversion for sm70 & sm75",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-04T14:24:22Z",
    "closed_at": "2025-09-05T07:51:04Z",
    "merged_at": "2025-09-05T07:51:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3937"
  },
  {
    "number": 3936,
    "title": "use FA 2.8.3 which is compatible with torch 2.8.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-04T14:16:44Z",
    "closed_at": "2025-09-05T09:31:57Z",
    "merged_at": "2025-09-05T09:31:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3936"
  },
  {
    "number": 3933,
    "title": "bump version to v0.10.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-04T06:50:54Z",
    "closed_at": "2025-09-09T04:51:01Z",
    "merged_at": "2025-09-09T04:51:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3933"
  },
  {
    "number": 3932,
    "title": "fix internvl3 hf",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-04T06:40:36Z",
    "closed_at": "2025-09-04T06:47:42Z",
    "merged_at": "2025-09-04T06:47:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3932"
  },
  {
    "number": 3930,
    "title": "upgrade torch to 2.8.0 and triton 3.4.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-04T04:49:09Z",
    "closed_at": "2025-09-04T13:10:11Z",
    "merged_at": "2025-09-04T13:10:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3930"
  },
  {
    "number": 3927,
    "title": "MXFP4 support for turbomind GEMM library",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-02T13:14:27Z",
    "closed_at": "2025-09-04T09:05:29Z",
    "merged_at": "2025-09-04T09:05:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3927"
  },
  {
    "number": 3926,
    "title": "refactor ascend Dockerfile",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-02T11:27:08Z",
    "closed_at": "2025-09-08T04:02:26Z",
    "merged_at": "2025-09-08T04:02:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3926"
  },
  {
    "number": 3925,
    "title": "Add ROCm support: installation guide and FlashAttention compatibility for AMD GPUs",
    "user": "Vivicai1005",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-02T09:50:42Z",
    "closed_at": "2025-09-09T08:08:12Z",
    "merged_at": "2025-09-09T08:08:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3925"
  },
  {
    "number": 3922,
    "title": "Support SDAR",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-02T02:59:52Z",
    "closed_at": "2025-09-19T04:05:26Z",
    "merged_at": "2025-09-19T04:05:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3922"
  },
  {
    "number": 3921,
    "title": "adjust default values",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-01T11:12:13Z",
    "closed_at": "2025-09-04T09:31:18Z",
    "merged_at": "2025-09-04T09:31:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3921"
  },
  {
    "number": 3919,
    "title": "style(types): fix return type annotation for get_all_requests",
    "user": "xiaoajie738",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-09-01T08:45:17Z",
    "closed_at": "2025-09-03T10:28:37Z",
    "merged_at": "2025-09-03T10:28:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3919"
  },
  {
    "number": 3915,
    "title": "[dlinfer] fix nn layout typo and scale t",
    "user": "yuchiwang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-29T09:44:11Z",
    "closed_at": "2025-08-29T10:57:46Z",
    "merged_at": "2025-08-29T10:57:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3915"
  },
  {
    "number": 3914,
    "title": "disable check_env in multiprocess on dlinfer devices",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-29T07:12:35Z",
    "closed_at": "2025-08-29T07:46:21Z",
    "merged_at": "2025-08-29T07:46:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3914"
  },
  {
    "number": 3913,
    "title": "support cache_max_entry_count >= 1 for Turbomind backend",
    "user": "lh9171338",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-29T06:42:18Z",
    "closed_at": "2025-08-29T10:59:04Z",
    "merged_at": "2025-08-29T10:59:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3913"
  },
  {
    "number": 3912,
    "title": "Fix tm rl usage in xtuner",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-29T06:01:44Z",
    "closed_at": "2025-09-16T03:05:52Z",
    "merged_at": "2025-09-16T03:05:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3912"
  },
  {
    "number": 3911,
    "title": "fix chat and warmup of lora adapter",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-29T03:29:08Z",
    "closed_at": "2025-08-29T13:03:33Z",
    "merged_at": "2025-08-29T13:03:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3911"
  },
  {
    "number": 3908,
    "title": "[ci] remove flash attn installation in ete test workflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-28T11:45:11Z",
    "closed_at": "2025-08-28T12:54:42Z",
    "merged_at": "2025-08-28T12:54:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3908"
  },
  {
    "number": 3906,
    "title": "build(acsend): try to fix acsend CI docker build",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-28T08:02:05Z",
    "closed_at": "2025-09-01T11:14:07Z",
    "merged_at": "2025-09-01T11:14:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3906"
  },
  {
    "number": 3904,
    "title": "remove ppu backend",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-28T07:13:27Z",
    "closed_at": "2025-08-28T10:45:39Z",
    "merged_at": "2025-08-28T10:45:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3904"
  },
  {
    "number": 3903,
    "title": "dlinfer backend support ray",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-28T06:36:36Z",
    "closed_at": "2025-08-29T03:49:50Z",
    "merged_at": "2025-08-29T03:49:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3903"
  },
  {
    "number": 3898,
    "title": "build(ascend): upgrade ascend base image to fix CI",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-27T13:45:10Z",
    "closed_at": "2025-08-27T14:57:00Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3898"
  },
  {
    "number": 3897,
    "title": "Resolve a crash in the `sleep` endpoint by casting the `level` parameter from string to int",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-27T12:39:58Z",
    "closed_at": "2025-08-27T12:56:58Z",
    "merged_at": "2025-08-27T12:56:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3897"
  },
  {
    "number": 3896,
    "title": "Fix nccl for docker cu11",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-27T12:23:51Z",
    "closed_at": "2025-08-27T13:55:22Z",
    "merged_at": "2025-08-27T13:55:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3896"
  },
  {
    "number": 3895,
    "title": "fix cli serve --help",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-27T06:38:19Z",
    "closed_at": "2025-08-27T11:32:14Z",
    "merged_at": "2025-08-27T11:32:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3895"
  },
  {
    "number": 3894,
    "title": "[ascend] add env to set rt visable by ray and disable warmup",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-27T03:47:37Z",
    "closed_at": "2025-08-27T11:45:04Z",
    "merged_at": "2025-08-27T11:45:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3894"
  },
  {
    "number": 3893,
    "title": "1. [PD Disaggregation] Some Bug Fix (adapte p2p_initialize, metrics, uniexecutor with pd disagg)",
    "user": "JimyMa",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-27T03:47:35Z",
    "closed_at": "2025-08-27T11:48:00Z",
    "merged_at": "2025-08-27T11:48:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3893"
  },
  {
    "number": 3891,
    "title": "block sparse attn [BD Part1]",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-27T02:55:53Z",
    "closed_at": "2025-10-10T06:00:43Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3891"
  },
  {
    "number": 3890,
    "title": "fix flashmla docker build",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-26T12:26:43Z",
    "closed_at": "2025-08-27T03:11:53Z",
    "merged_at": "2025-08-27T03:11:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3890"
  },
  {
    "number": 3889,
    "title": "update news and citation",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-26T11:55:01Z",
    "closed_at": "2025-08-27T03:55:38Z",
    "merged_at": "2025-08-27T03:55:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3889"
  },
  {
    "number": 3888,
    "title": "fix side effect brought by #3821",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-26T10:51:47Z",
    "closed_at": "2025-08-26T11:59:37Z",
    "merged_at": "2025-08-26T11:59:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3888"
  },
  {
    "number": 3887,
    "title": "fix batched prefill",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-26T10:13:50Z",
    "closed_at": "2025-08-26T10:35:14Z",
    "merged_at": "2025-08-26T10:35:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3887"
  },
  {
    "number": 3886,
    "title": "support internvl3.5",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-26T09:11:38Z",
    "closed_at": "2025-08-27T03:55:15Z",
    "merged_at": "2025-08-27T03:55:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3886"
  },
  {
    "number": 3885,
    "title": "fix docs",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-26T07:29:35Z",
    "closed_at": "2025-08-26T08:09:57Z",
    "merged_at": "2025-08-26T08:09:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3885"
  },
  {
    "number": 3884,
    "title": "refactor SchedulerSequence [BD Part0]",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-26T06:36:02Z",
    "closed_at": "2025-09-08T07:22:09Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3884"
  },
  {
    "number": 3883,
    "title": "Fix stream assert error when wakeup 30+ times",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-26T06:09:45Z",
    "closed_at": "2025-08-26T08:08:59Z",
    "merged_at": "2025-08-26T08:08:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3883"
  },
  {
    "number": 3882,
    "title": "fix pytorch metrics in mp engine",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-26T04:35:59Z",
    "closed_at": "2025-08-26T06:44:27Z",
    "merged_at": "2025-08-26T06:44:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3882"
  },
  {
    "number": 3880,
    "title": "Fix side effect brought by gpt-oss support",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-25T13:14:42Z",
    "closed_at": "2025-08-25T13:45:50Z",
    "merged_at": "2025-08-25T13:45:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3880"
  },
  {
    "number": 3879,
    "title": "check_env in multiprocess",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-25T12:08:02Z",
    "closed_at": "2025-08-27T10:14:39Z",
    "merged_at": "2025-08-27T10:14:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3879"
  },
  {
    "number": 3878,
    "title": "[Fix] remove set_device on ascend single node",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-25T09:17:56Z",
    "closed_at": "2025-09-04T07:08:13Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3878"
  },
  {
    "number": 3877,
    "title": "[Fix] ray mp engine on ascend platform",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-25T06:43:00Z",
    "closed_at": "2025-08-25T08:14:22Z",
    "merged_at": "2025-08-25T08:14:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3877"
  },
  {
    "number": 3876,
    "title": "Support OpenAI compatible parameter max_completion_tokens",
    "user": "Huarong",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-25T06:39:44Z",
    "closed_at": "2025-08-26T06:49:21Z",
    "merged_at": "2025-08-26T06:49:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3876"
  },
  {
    "number": 3874,
    "title": "Fix uninitialized members in cuBLAS wrapper",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-22T12:37:24Z",
    "closed_at": "2025-08-22T15:02:34Z",
    "merged_at": "2025-08-22T15:02:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3874"
  },
  {
    "number": 3873,
    "title": "fix flash-attn bc",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-22T11:57:25Z",
    "closed_at": "2025-08-25T03:22:26Z",
    "merged_at": "2025-08-25T03:22:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3873"
  },
  {
    "number": 3872,
    "title": "fix flashmla build for cuda12.4",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-22T10:41:55Z",
    "closed_at": "2025-08-25T08:12:56Z",
    "merged_at": "2025-08-25T08:12:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3872"
  },
  {
    "number": 3871,
    "title": "add missing docs",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-22T09:05:47Z",
    "closed_at": "2025-08-22T12:37:44Z",
    "merged_at": "2025-08-22T12:37:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3871"
  },
  {
    "number": 3869,
    "title": "optimize prefill preprocess",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-22T07:21:49Z",
    "closed_at": "2025-08-24T07:08:53Z",
    "merged_at": "2025-08-24T07:08:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3869"
  },
  {
    "number": 3868,
    "title": "fix bug: leaves empty",
    "user": "Tsundoku958",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-22T06:56:35Z",
    "closed_at": "2025-08-25T08:15:34Z",
    "merged_at": "2025-08-25T08:15:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3868"
  },
  {
    "number": 3866,
    "title": "[ci] change restful api into openai and add more testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-22T02:26:23Z",
    "closed_at": "2025-08-25T13:59:57Z",
    "merged_at": "2025-08-25T13:59:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3866"
  },
  {
    "number": 3865,
    "title": "fix inference on windows platform",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-22T02:13:37Z",
    "closed_at": "2025-08-22T04:42:55Z",
    "merged_at": "2025-08-22T04:42:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3865"
  },
  {
    "number": 3863,
    "title": "Support GLM-4.5",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-21T06:05:42Z",
    "closed_at": "2025-09-16T08:22:35Z",
    "merged_at": "2025-09-16T08:22:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3863"
  },
  {
    "number": 3862,
    "title": "fix chatting with VLM model via CLI",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-21T04:47:26Z",
    "closed_at": "2025-08-21T10:49:14Z",
    "merged_at": "2025-08-21T10:49:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3862"
  },
  {
    "number": 3861,
    "title": "fix partial rotary factor",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-21T03:24:16Z",
    "closed_at": "2025-08-21T05:43:44Z",
    "merged_at": "2025-08-21T05:43:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3861"
  },
  {
    "number": 3859,
    "title": "fix: duplicated token usage in /chat/completions stream mode",
    "user": "Huarong",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-19T09:59:40Z",
    "closed_at": "2025-08-21T06:40:21Z",
    "merged_at": "2025-08-21T06:40:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3859"
  },
  {
    "number": 3858,
    "title": "Remove unused code in PT Engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-19T06:30:08Z",
    "closed_at": "2025-08-21T05:52:10Z",
    "merged_at": "2025-08-21T05:52:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3858"
  },
  {
    "number": 3857,
    "title": "fix prebuild on cuda12.8",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-19T03:24:15Z",
    "closed_at": "2025-08-22T07:32:26Z",
    "merged_at": "2025-08-22T07:32:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3857"
  },
  {
    "number": 3854,
    "title": "[PD Disaggregation] remote recomputation preemption",
    "user": "JimyMa",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-18T03:41:37Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3854"
  },
  {
    "number": 3852,
    "title": "support logprobs",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-17T11:08:21Z",
    "closed_at": "2025-08-22T04:44:26Z",
    "merged_at": "2025-08-22T04:44:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3852"
  },
  {
    "number": 3851,
    "title": "Graph warmup",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-16T07:07:18Z",
    "closed_at": "2025-08-25T13:20:37Z",
    "merged_at": "2025-08-25T13:20:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3851"
  },
  {
    "number": 3850,
    "title": "[Feat] support using external ray pg with bundles",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-16T05:44:19Z",
    "closed_at": "2025-08-18T12:40:32Z",
    "merged_at": "2025-08-18T12:40:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3850"
  },
  {
    "number": 3849,
    "title": "bump version to v0.9.2.post1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-15T10:50:27Z",
    "closed_at": "2025-08-19T09:43:29Z",
    "merged_at": "2025-08-19T09:43:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3849"
  },
  {
    "number": 3848,
    "title": "Fix interns1 LLM mapping for turbomind engine",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-15T09:52:27Z",
    "closed_at": "2025-08-15T10:48:36Z",
    "merged_at": "2025-08-15T10:48:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3848"
  },
  {
    "number": 3847,
    "title": "[dlinfer] fix get_backend err",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-15T08:02:57Z",
    "closed_at": "2025-08-15T10:50:51Z",
    "merged_at": "2025-08-15T10:50:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3847"
  },
  {
    "number": 3846,
    "title": "Support GLM-4-0414 and GLM-4.1V",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-15T07:16:13Z",
    "closed_at": "2025-08-22T04:44:57Z",
    "merged_at": "2025-08-22T04:44:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3846"
  },
  {
    "number": 3845,
    "title": "[refactor][chat_template][1/N] adopt tokenizer's apply_chat_template",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-15T06:51:03Z",
    "closed_at": "2025-09-04T12:07:10Z",
    "merged_at": "2025-09-04T12:07:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3845"
  },
  {
    "number": 3841,
    "title": "add ppu quick start doc",
    "user": "guozixu2001",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-14T02:52:44Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3841"
  },
  {
    "number": 3839,
    "title": "Initial gpt-oss support for turbomind",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-13T14:25:05Z",
    "closed_at": "2025-08-19T03:25:11Z",
    "merged_at": "2025-08-19T03:25:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3839"
  },
  {
    "number": 3838,
    "title": "[ci] refactor restful api testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-13T12:18:09Z",
    "closed_at": "2025-08-19T05:03:42Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3838"
  },
  {
    "number": 3837,
    "title": "Update internvl.py to fix InternLM/lmdeploy#3528",
    "user": "zodiacg",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-13T12:00:25Z",
    "closed_at": "2025-08-18T03:48:00Z",
    "merged_at": "2025-08-18T03:48:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3837"
  },
  {
    "number": 3836,
    "title": "Make a common chat.py to replace each engine's",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-13T11:20:27Z",
    "closed_at": "2025-08-15T06:27:56Z",
    "merged_at": "2025-08-15T06:27:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3836"
  },
  {
    "number": 3835,
    "title": "Improve turbomind's prefix cache",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-13T09:12:01Z",
    "closed_at": "2025-08-25T14:23:21Z",
    "merged_at": "2025-08-25T14:23:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3835"
  },
  {
    "number": 3834,
    "title": "Add Docker image for NVIDIA Jetson",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-13T08:49:52Z",
    "closed_at": "2025-10-13T11:44:40Z",
    "merged_at": "2025-10-13T11:44:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3834"
  },
  {
    "number": 3831,
    "title": "[ascend] run intern-s1 on A3",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-12T07:35:05Z",
    "closed_at": "2025-08-14T23:42:42Z",
    "merged_at": "2025-08-14T23:42:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3831"
  },
  {
    "number": 3830,
    "title": "Deprecate interactive mode from api_server",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-11T13:14:52Z",
    "closed_at": "2025-08-13T03:06:23Z",
    "merged_at": "2025-08-13T03:06:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3830"
  },
  {
    "number": 3829,
    "title": "remove serving with gradio",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-11T12:52:45Z",
    "closed_at": "2025-08-12T05:59:17Z",
    "merged_at": "2025-08-12T05:59:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3829"
  },
  {
    "number": 3828,
    "title": "Fix v1 comp protocol",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-11T12:23:50Z",
    "closed_at": "2025-08-12T03:32:28Z",
    "merged_at": "2025-08-12T03:32:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3828"
  },
  {
    "number": 3827,
    "title": "support deepgemm new api",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-11T08:02:12Z",
    "closed_at": "2025-08-12T05:58:39Z",
    "merged_at": "2025-08-12T05:58:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3827"
  },
  {
    "number": 3826,
    "title": "assert PytorchEngineConfig block size",
    "user": "Tsundoku958",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-11T04:35:59Z",
    "closed_at": "2025-08-11T13:57:59Z",
    "merged_at": "2025-08-11T13:57:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3826"
  },
  {
    "number": 3824,
    "title": "fix: set text_config.tie_word_embedding = False in qwen2vl",
    "user": "zenosai",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-08T11:30:00Z",
    "closed_at": "2025-08-10T02:53:11Z",
    "merged_at": "2025-08-10T02:53:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3824"
  },
  {
    "number": 3821,
    "title": "Align response behavior across both engines",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-07T08:38:53Z",
    "closed_at": "2025-08-08T06:34:08Z",
    "merged_at": "2025-08-08T06:34:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3821"
  },
  {
    "number": 3820,
    "title": "PytorchEngine support gpt-oss bf16",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-07T07:01:18Z",
    "closed_at": "2025-08-13T10:25:25Z",
    "merged_at": "2025-08-13T10:25:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3820"
  },
  {
    "number": 3818,
    "title": "Simplify GEMM interface",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-06T02:57:40Z",
    "closed_at": "2025-08-06T10:54:25Z",
    "merged_at": "2025-08-06T10:54:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3818"
  },
  {
    "number": 3814,
    "title": "Optimize rmsnorm with head_dim=128",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-05T08:32:43Z",
    "closed_at": "2025-08-06T06:13:12Z",
    "merged_at": "2025-08-06T06:13:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3814"
  },
  {
    "number": 3813,
    "title": "remove 'lmdeploy convert' from CLI",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-05T06:41:37Z",
    "closed_at": "2025-08-06T05:03:10Z",
    "merged_at": "2025-08-06T05:03:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3813"
  },
  {
    "number": 3811,
    "title": "Add turbomind metrics",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-04T12:11:14Z",
    "closed_at": "2025-08-13T03:06:05Z",
    "merged_at": "2025-08-13T03:06:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3811"
  },
  {
    "number": 3809,
    "title": "fix(turbomind): try to import turbomind in a robust way",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-04T06:10:34Z",
    "closed_at": "2025-08-04T11:26:44Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3809"
  },
  {
    "number": 3808,
    "title": "Fix EP with large batch size",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-04T04:49:26Z",
    "closed_at": "2025-08-06T06:05:43Z",
    "merged_at": "2025-08-06T06:05:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3808"
  },
  {
    "number": 3807,
    "title": "Add PPU backend support ",
    "user": "guozixu2001",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-08-01T06:32:37Z",
    "closed_at": "2025-08-12T13:48:48Z",
    "merged_at": "2025-08-12T13:48:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3807"
  },
  {
    "number": 3803,
    "title": "fix: add dummy_prefill guard for PD connection operations",
    "user": "FirwoodLin",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-31T01:54:37Z",
    "closed_at": "2025-08-01T03:08:01Z",
    "merged_at": "2025-08-01T03:08:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3803"
  },
  {
    "number": 3800,
    "title": "fix internvl disable_vision_encoder",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-30T06:38:15Z",
    "closed_at": "2025-08-06T06:31:42Z",
    "merged_at": "2025-08-06T06:31:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3800"
  },
  {
    "number": 3798,
    "title": "support offloading weights & kv_cache for turbomind",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-29T10:40:17Z",
    "closed_at": "2025-08-06T06:30:06Z",
    "merged_at": "2025-08-06T06:30:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3798"
  },
  {
    "number": 3796,
    "title": "update proxy docs",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-29T08:57:07Z",
    "closed_at": "2025-07-29T10:53:46Z",
    "merged_at": "2025-07-29T10:53:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3796"
  },
  {
    "number": 3795,
    "title": "Refactor FP8 MoE GEMM",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-29T08:24:35Z",
    "closed_at": "2025-08-01T03:10:31Z",
    "merged_at": "2025-08-01T03:10:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3795"
  },
  {
    "number": 3793,
    "title": "fix head_dim=None",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-29T03:26:21Z",
    "closed_at": "2025-08-01T02:31:41Z",
    "merged_at": "2025-08-01T02:31:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3793"
  },
  {
    "number": 3792,
    "title": "add prometheus client",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-28T08:47:55Z",
    "closed_at": "2025-07-28T09:52:44Z",
    "merged_at": "2025-07-28T09:52:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3792"
  },
  {
    "number": 3790,
    "title": "Ray mp engine backend",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-28T08:16:42Z",
    "closed_at": "2025-08-18T03:48:25Z",
    "merged_at": "2025-08-18T03:48:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3790"
  },
  {
    "number": 3785,
    "title": "fix user-specified max_session_len",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-28T03:55:53Z",
    "closed_at": "2025-08-05T03:18:59Z",
    "merged_at": "2025-08-05T03:18:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3785"
  },
  {
    "number": 3784,
    "title": "fix: turbomind backend config in cli serve",
    "user": "PeymanRM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-27T14:09:52Z",
    "closed_at": "2025-07-28T02:40:01Z",
    "merged_at": "2025-07-28T02:40:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3784"
  },
  {
    "number": 3779,
    "title": "build(docker): Try to optimize docker",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-26T15:41:56Z",
    "closed_at": "2025-08-13T12:35:54Z",
    "merged_at": "2025-08-13T12:35:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3779"
  },
  {
    "number": 3776,
    "title": "fix vl nothink mode",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-26T00:04:37Z",
    "closed_at": "2025-07-26T04:43:50Z",
    "merged_at": "2025-07-26T04:43:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3776"
  },
  {
    "number": 3774,
    "title": "fix: make RelWithDebInfo default cmake build type",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-25T13:10:50Z",
    "closed_at": "2025-07-26T07:30:27Z",
    "merged_at": "2025-07-26T07:30:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3774"
  },
  {
    "number": 3773,
    "title": "fix chat template with tool call",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-25T10:08:08Z",
    "closed_at": "2025-07-25T12:14:18Z",
    "merged_at": "2025-07-25T12:14:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3773"
  },
  {
    "number": 3772,
    "title": "fix gemma3",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-25T03:58:58Z",
    "closed_at": "2025-07-30T02:53:23Z",
    "merged_at": "2025-07-30T02:53:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3772"
  },
  {
    "number": 3771,
    "title": "adapt transformers>=v4.52.0 to loading qwen2.5-vl with turbomind",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-25T02:58:26Z",
    "closed_at": "2025-07-25T06:42:14Z",
    "merged_at": "2025-07-25T06:42:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3771"
  },
  {
    "number": 3770,
    "title": "bump version to v0.9.2",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-25T02:12:46Z",
    "closed_at": "2025-07-26T09:59:48Z",
    "merged_at": "2025-07-26T09:59:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3770"
  },
  {
    "number": 3769,
    "title": "Improve internvl for turbomind engine",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-25T02:10:19Z",
    "closed_at": "2025-07-25T06:41:44Z",
    "merged_at": "2025-07-25T06:41:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3769"
  },
  {
    "number": 3768,
    "title": "support pp in turbomind",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-24T14:30:35Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3768"
  },
  {
    "number": 3766,
    "title": "Optimize create_model_inputs and schedule_decoding",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-24T13:05:30Z",
    "closed_at": "2025-08-08T12:22:56Z",
    "merged_at": "2025-08-08T12:22:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3766"
  },
  {
    "number": 3765,
    "title": "Internvl pt",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-24T12:11:12Z",
    "closed_at": "2025-07-25T02:00:24Z",
    "merged_at": "2025-07-25T02:00:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3765"
  },
  {
    "number": 3764,
    "title": "fix(build): fix version parse regex to support post-release versions",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-24T06:09:15Z",
    "closed_at": "2025-07-25T02:01:01Z",
    "merged_at": "2025-07-25T02:01:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3764"
  },
  {
    "number": 3762,
    "title": "[PD Disaggregation] fix double unshelf",
    "user": "JimyMa",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-23T16:45:57Z",
    "closed_at": "2025-07-24T06:26:05Z",
    "merged_at": "2025-07-24T06:26:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3762"
  },
  {
    "number": 3761,
    "title": "Fix double unshelf",
    "user": "JimyMa",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-23T16:36:58Z",
    "closed_at": "2025-07-23T16:41:37Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3761"
  },
  {
    "number": 3760,
    "title": "Fix build rope params",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-23T07:41:18Z",
    "closed_at": "2025-08-06T04:47:18Z",
    "merged_at": "2025-08-06T04:47:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3760"
  },
  {
    "number": 3759,
    "title": "remove deprecated codes",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-22T13:48:23Z",
    "closed_at": "2025-07-28T08:14:58Z",
    "merged_at": "2025-07-28T08:14:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3759"
  },
  {
    "number": 3758,
    "title": "minor fix about the log level and logs",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-22T13:06:22Z",
    "closed_at": "2025-08-05T07:01:19Z",
    "merged_at": "2025-08-05T07:01:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3758"
  },
  {
    "number": 3757,
    "title": "support qwen3 moe yarn and vlm hf_overrides",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-22T10:11:05Z",
    "closed_at": "2025-07-23T12:28:10Z",
    "merged_at": "2025-07-23T12:28:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3757"
  },
  {
    "number": 3756,
    "title": "fix internvl norm",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-22T04:44:45Z",
    "closed_at": "2025-07-23T03:03:19Z",
    "merged_at": "2025-07-23T03:03:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3756"
  },
  {
    "number": 3754,
    "title": "estimate runtime memory usage",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-21T08:31:44Z",
    "closed_at": "2025-08-11T03:06:45Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3754"
  },
  {
    "number": 3751,
    "title": "limit max_session_len",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-20T05:40:20Z",
    "closed_at": "2025-07-21T09:57:43Z",
    "merged_at": "2025-07-21T09:57:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3751"
  },
  {
    "number": 3750,
    "title": "feat: add pytorch_engine_qwen2_5vl_sm120",
    "user": "kolmogorov-quyet",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-19T03:21:31Z",
    "closed_at": "2025-07-24T05:42:21Z",
    "merged_at": "2025-07-24T05:42:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3750"
  },
  {
    "number": 3748,
    "title": "fix: qwen3 nonstream parse with no or uncompleted think content",
    "user": "ywx217",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-18T09:35:32Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3748"
  },
  {
    "number": 3746,
    "title": "[Fix]: kernel meta retrieval for SM7X does not work",
    "user": "xiaoajie738",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-18T02:13:45Z",
    "closed_at": "2025-07-18T05:33:30Z",
    "merged_at": "2025-07-18T05:33:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3746"
  },
  {
    "number": 3745,
    "title": "Make loading llm without vlm as an option",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-17T12:27:14Z",
    "closed_at": "2025-07-22T14:30:53Z",
    "merged_at": "2025-07-22T14:30:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3745"
  },
  {
    "number": 3744,
    "title": "support qwen2/2.5-vl in turbomind",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-17T08:58:57Z",
    "closed_at": "2025-07-23T12:25:48Z",
    "merged_at": "2025-07-23T12:25:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3744"
  },
  {
    "number": 3741,
    "title": "doc: fix dead links to MindX DL to recover CI.",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-17T04:22:28Z",
    "closed_at": "2025-07-17T04:38:43Z",
    "merged_at": "2025-07-17T04:38:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3741"
  },
  {
    "number": 3740,
    "title": "Generate the benchmark output filename with given arguments",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-17T04:05:37Z",
    "closed_at": "2025-07-22T04:45:35Z",
    "merged_at": "2025-07-22T04:45:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3740"
  },
  {
    "number": 3739,
    "title": "fix py313 env creation failed when building lmdeploy-builder image",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-17T02:48:09Z",
    "closed_at": "2025-07-17T06:21:49Z",
    "merged_at": "2025-07-17T06:21:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3739"
  },
  {
    "number": 3738,
    "title": "fix: make project PEP 517 compliant.",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-17T02:30:13Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3738"
  },
  {
    "number": 3737,
    "title": "add remote logs;optimize forward lock",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-16T13:05:44Z",
    "closed_at": "2025-08-10T02:54:09Z",
    "merged_at": "2025-08-10T02:54:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3737"
  },
  {
    "number": 3736,
    "title": "Update turbomind communication library",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-16T12:39:00Z",
    "closed_at": "2025-08-28T10:42:17Z",
    "merged_at": "2025-08-28T10:42:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3736"
  },
  {
    "number": 3733,
    "title": "[Fix]: Avoid quantize qk norm for qwen3 dense models",
    "user": "taishan1994",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-14T09:01:51Z",
    "closed_at": "2025-07-17T03:20:46Z",
    "merged_at": "2025-07-17T03:20:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3733"
  },
  {
    "number": 3731,
    "title": "Add VRAM bandwidth utilization stat to attention test",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-11T10:34:41Z",
    "closed_at": "2025-07-14T10:46:39Z",
    "merged_at": "2025-07-14T10:46:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3731"
  },
  {
    "number": 3730,
    "title": "[Fix]: Replace mutable default with default_factory for scheduler_stats",
    "user": "ConvolutedDog",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-11T02:56:21Z",
    "closed_at": "2025-07-11T10:45:31Z",
    "merged_at": "2025-07-11T10:45:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3730"
  },
  {
    "number": 3729,
    "title": "[ci] add fp8 evaluation workflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-10T10:09:55Z",
    "closed_at": "2025-07-11T07:08:47Z",
    "merged_at": "2025-07-11T07:08:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3729"
  },
  {
    "number": 3728,
    "title": "fix accessing undefined attribute `seq_aux` of deepseek-r1-0528",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-10T09:23:29Z",
    "closed_at": "2025-07-11T07:09:20Z",
    "merged_at": "2025-07-11T07:09:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3728"
  },
  {
    "number": 3727,
    "title": "Fix the logic of calculating max_new_tokens and determining finish_reason",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-10T08:57:49Z",
    "closed_at": "2025-07-15T06:05:25Z",
    "merged_at": "2025-07-15T06:05:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3727"
  },
  {
    "number": 3726,
    "title": "feat(build): Integrate and build turbomind backend directly in setup.py",
    "user": "windreamer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-10T07:26:35Z",
    "closed_at": "2025-07-16T12:04:44Z",
    "merged_at": "2025-07-16T12:04:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3726"
  },
  {
    "number": 3722,
    "title": "Override HF config.json via CLI",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-09T04:10:43Z",
    "closed_at": "2025-07-15T11:19:44Z",
    "merged_at": "2025-07-15T11:19:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3722"
  },
  {
    "number": 3721,
    "title": "update reward model docs",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-09T02:59:30Z",
    "closed_at": "2025-07-09T11:41:16Z",
    "merged_at": "2025-07-09T11:41:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3721"
  },
  {
    "number": 3720,
    "title": "Add dp rank into proxy node status",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-08T13:12:43Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3720"
  },
  {
    "number": 3718,
    "title": "[CI]: Upgrade to py310 for ut",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-07T10:23:48Z",
    "closed_at": "2025-07-07T13:05:29Z",
    "merged_at": "2025-07-07T13:05:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3718"
  },
  {
    "number": 3717,
    "title": "[CI]: Upgrade to py310 for ut",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-07T10:22:15Z",
    "closed_at": "2025-07-07T10:22:51Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3717"
  },
  {
    "number": 3716,
    "title": "[ci] update dailytest environment and scripts",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-07T08:39:23Z",
    "closed_at": "2025-07-07T14:14:38Z",
    "merged_at": "2025-07-07T14:14:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3716"
  },
  {
    "number": 3715,
    "title": "[ascend] support lora",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-07T07:23:59Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3715"
  },
  {
    "number": 3713,
    "title": "add ray to ascend requirements",
    "user": "sigma-plus",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-04T08:46:08Z",
    "closed_at": "2025-07-08T08:08:30Z",
    "merged_at": "2025-07-08T08:08:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3713"
  },
  {
    "number": 3711,
    "title": "update dlblas version in dockerfile",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-04T06:37:14Z",
    "closed_at": "2025-07-04T07:43:01Z",
    "merged_at": "2025-07-04T07:43:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3711"
  },
  {
    "number": 3709,
    "title": "expert distributions",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-04T04:01:07Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3709"
  },
  {
    "number": 3708,
    "title": "Output generated token ids for  api server",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-03T08:25:18Z",
    "closed_at": "2025-07-03T14:30:03Z",
    "merged_at": "2025-07-03T14:30:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3708"
  },
  {
    "number": 3707,
    "title": "fix profile_generation.py",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-03T05:58:56Z",
    "closed_at": "2025-07-04T04:52:13Z",
    "merged_at": "2025-07-04T04:52:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3707"
  },
  {
    "number": 3706,
    "title": "add reward model documents",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-03T04:12:06Z",
    "closed_at": "2025-07-03T08:54:34Z",
    "merged_at": "2025-07-03T08:54:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3706"
  },
  {
    "number": 3703,
    "title": "fix reward model api",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-02T13:37:23Z",
    "closed_at": "2025-07-02T13:49:04Z",
    "merged_at": "2025-07-02T13:49:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3703"
  },
  {
    "number": 3701,
    "title": "Preliminary Blackwell (sm_120a, RTX 50 series) support",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-02T10:32:35Z",
    "closed_at": "2025-07-09T11:42:03Z",
    "merged_at": "2025-07-09T11:42:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3701"
  },
  {
    "number": 3699,
    "title": "refactor vl inputs split",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-02T03:51:07Z",
    "closed_at": "2025-07-09T11:40:56Z",
    "merged_at": "2025-07-09T11:40:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3699"
  },
  {
    "number": 3698,
    "title": "consume the weight tensors that locates on the local_rank when updating model weight",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-01T12:24:38Z",
    "closed_at": "2025-07-11T10:47:27Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3698"
  },
  {
    "number": 3697,
    "title": "Relax FP8 TP requirement",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-01T10:45:41Z",
    "closed_at": "2025-07-15T08:59:19Z",
    "merged_at": "2025-07-15T08:59:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3697"
  },
  {
    "number": 3696,
    "title": "[ascend]suppot deepseek eager_mode",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-01T10:27:59Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3696"
  },
  {
    "number": 3695,
    "title": "Defer build cache engine",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-01T10:08:04Z",
    "closed_at": "2025-07-01T10:08:24Z",
    "merged_at": "2025-07-01T10:08:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3695"
  },
  {
    "number": 3694,
    "title": "support partial quant",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-01T10:02:17Z",
    "closed_at": "2025-07-01T10:08:58Z",
    "merged_at": "2025-07-01T10:08:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3694"
  },
  {
    "number": 3693,
    "title": "Defer build cache engine",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-01T10:01:52Z",
    "closed_at": "2025-07-01T10:02:08Z",
    "merged_at": "2025-07-01T10:02:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3693"
  },
  {
    "number": 3692,
    "title": "fix profile_throughput.py",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-01T07:32:11Z",
    "closed_at": "2025-07-01T10:16:45Z",
    "merged_at": "2025-07-01T10:16:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3692"
  },
  {
    "number": 3691,
    "title": "disable torch.compile in cuda graph runner",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-07-01T05:41:14Z",
    "closed_at": "2025-07-01T11:54:39Z",
    "merged_at": "2025-07-01T11:54:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3691"
  },
  {
    "number": 3688,
    "title": "[ci] change flash atten installation in pr test",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-30T11:13:33Z",
    "closed_at": "2025-07-01T07:44:55Z",
    "merged_at": "2025-07-01T07:44:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3688"
  },
  {
    "number": 3687,
    "title": "support sleep/wakeup for pt engine",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-30T10:32:27Z",
    "closed_at": "2025-08-14T12:04:28Z",
    "merged_at": "2025-08-14T12:04:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3687"
  },
  {
    "number": 3686,
    "title": "Fix convert bf16 to numpy",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-30T08:40:52Z",
    "closed_at": "2025-07-01T07:47:21Z",
    "merged_at": "2025-07-01T07:47:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3686"
  },
  {
    "number": 3685,
    "title": "bump version to v0.9.1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-30T05:35:26Z",
    "closed_at": "2025-07-04T10:04:21Z",
    "merged_at": "2025-07-04T10:04:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3685"
  },
  {
    "number": 3683,
    "title": "defer building cache engine until weight migration is done",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-28T13:58:11Z",
    "closed_at": "2025-06-30T10:31:42Z",
    "merged_at": "2025-06-30T10:31:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3683"
  },
  {
    "number": 3682,
    "title": "support partial quant",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-27T11:14:08Z",
    "closed_at": "2025-07-01T06:14:49Z",
    "merged_at": "2025-07-01T06:14:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3682"
  },
  {
    "number": 3681,
    "title": "fix pt engine stop & cancel",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-27T09:15:47Z",
    "closed_at": "2025-06-30T10:24:19Z",
    "merged_at": "2025-06-30T10:24:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3681"
  },
  {
    "number": 3677,
    "title": "upgrade torch and triton",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-26T07:26:47Z",
    "closed_at": "2025-06-27T02:49:25Z",
    "merged_at": "2025-06-27T02:49:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3677"
  },
  {
    "number": 3676,
    "title": "ray close wait for forward finish",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-26T07:09:20Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3676"
  },
  {
    "number": 3672,
    "title": "Support load fused moe weights",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-26T03:56:17Z",
    "closed_at": "2025-06-26T13:09:55Z",
    "merged_at": "2025-06-26T13:09:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3672"
  },
  {
    "number": 3671,
    "title": "[ascend]use custon transdata in python kernel",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-25T09:14:39Z",
    "closed_at": "2025-06-26T04:41:28Z",
    "merged_at": "2025-06-26T04:41:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3671"
  },
  {
    "number": 3670,
    "title": "fix free cache in MPEngine branch",
    "user": "JimyMa",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-25T06:02:33Z",
    "closed_at": "2025-07-23T12:31:55Z",
    "merged_at": "2025-07-23T12:31:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3670"
  },
  {
    "number": 3666,
    "title": "Reduce sampling memory usage",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-24T12:40:49Z",
    "closed_at": "2025-06-26T13:13:14Z",
    "merged_at": "2025-06-26T13:13:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3666"
  },
  {
    "number": 3665,
    "title": "add reward model api",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-24T12:34:33Z",
    "closed_at": "2025-06-30T09:32:37Z",
    "merged_at": "2025-06-30T09:32:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3665"
  },
  {
    "number": 3662,
    "title": "[ascend]import patch at initiazing time",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-24T02:46:27Z",
    "closed_at": "2025-06-25T15:29:36Z",
    "merged_at": "2025-06-25T15:29:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3662"
  },
  {
    "number": 3661,
    "title": "Fix top-p only sampling with padded vocab size",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-23T14:26:23Z",
    "closed_at": "2025-06-24T14:11:01Z",
    "merged_at": "2025-06-24T14:11:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3661"
  },
  {
    "number": 3660,
    "title": "move import transformers in patch",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-23T09:08:35Z",
    "closed_at": "2025-06-26T05:25:08Z",
    "merged_at": "2025-06-26T05:25:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3660"
  },
  {
    "number": 3659,
    "title": "custom triton cache manager",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-20T08:06:04Z",
    "closed_at": "2025-08-19T06:26:35Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3659"
  },
  {
    "number": 3657,
    "title": "fix dockerfile",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-19T11:46:07Z",
    "closed_at": "2025-06-20T04:10:40Z",
    "merged_at": "2025-06-20T04:10:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3657"
  },
  {
    "number": 3653,
    "title": "Refactor linear",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-19T02:35:57Z",
    "closed_at": "2025-07-07T08:08:02Z",
    "merged_at": "2025-07-07T08:08:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3653"
  },
  {
    "number": 3652,
    "title": "Fix zero scale in fp8 quantization",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-18T10:18:08Z",
    "closed_at": "2025-06-18T10:39:58Z",
    "merged_at": "2025-06-18T10:39:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3652"
  },
  {
    "number": 3651,
    "title": "update twomicrobatch",
    "user": "SHshenhao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-18T08:42:20Z",
    "closed_at": "2025-07-07T08:30:51Z",
    "merged_at": "2025-07-07T08:30:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3651"
  },
  {
    "number": 3650,
    "title": "fix blocked fp8 overflow",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-18T08:15:39Z",
    "closed_at": "2025-06-18T09:44:59Z",
    "merged_at": "2025-06-18T09:44:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3650"
  },
  {
    "number": 3649,
    "title": "Synchronize weight processing",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-18T07:34:15Z",
    "closed_at": "2025-06-18T08:07:27Z",
    "merged_at": "2025-06-18T08:07:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3649"
  },
  {
    "number": 3647,
    "title": "Fix 'Namespace' object has no attribute 'num_tokens_per_iter' when serving by gradio",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-17T04:54:06Z",
    "closed_at": "2025-06-17T06:48:21Z",
    "merged_at": "2025-06-17T06:48:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3647"
  },
  {
    "number": 3645,
    "title": "support do_preprocess=False for chat.completions",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-16T10:44:34Z",
    "closed_at": "2025-06-27T02:50:32Z",
    "merged_at": "2025-06-27T02:50:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3645"
  },
  {
    "number": 3644,
    "title": "fix vlm runtime quant",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-16T04:20:02Z",
    "closed_at": "2025-06-17T03:47:12Z",
    "merged_at": "2025-06-17T03:47:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3644"
  },
  {
    "number": 3643,
    "title": "set ray envs",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-16T02:37:46Z",
    "closed_at": "2025-06-26T06:48:32Z",
    "merged_at": "2025-06-26T06:48:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3643"
  },
  {
    "number": 3641,
    "title": "fix qwen3 chat template",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-13T03:29:22Z",
    "closed_at": "2025-06-13T12:14:32Z",
    "merged_at": "2025-06-13T12:14:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3641"
  },
  {
    "number": 3640,
    "title": "fix for default quant",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-12T09:28:23Z",
    "closed_at": "2025-06-12T10:32:01Z",
    "merged_at": "2025-06-12T10:32:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3640"
  },
  {
    "number": 3638,
    "title": "remove python3.8 support and add python3.13 support",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-12T08:48:34Z",
    "closed_at": "2025-07-07T13:04:02Z",
    "merged_at": "2025-07-07T13:04:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3638"
  },
  {
    "number": 3636,
    "title": "raise ImportError when enable ep and not install dlblas",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-11T12:22:32Z",
    "closed_at": "2025-06-26T13:10:24Z",
    "merged_at": "2025-06-26T13:10:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3636"
  },
  {
    "number": 3634,
    "title": "update Dockerfile",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-11T10:13:33Z",
    "closed_at": "2025-06-11T13:13:28Z",
    "merged_at": "2025-06-11T13:13:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3634"
  },
  {
    "number": 3633,
    "title": "[Feat]: Support internvl3-8b-hf",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-11T07:16:02Z",
    "closed_at": "2025-06-13T12:43:09Z",
    "merged_at": "2025-06-13T12:43:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3633"
  },
  {
    "number": 3631,
    "title": "Quantize Qwen3 MoE bf16 model to fp8 model at runtime",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-11T03:58:20Z",
    "closed_at": "2025-06-12T07:34:58Z",
    "merged_at": "2025-06-12T07:34:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3631"
  },
  {
    "number": 3630,
    "title": "check in lmdeploy-builder on cuda 12.4 and 12.8 platform",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-10T13:47:11Z",
    "closed_at": "2025-06-12T09:13:40Z",
    "merged_at": "2025-06-12T09:13:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3630"
  },
  {
    "number": 3627,
    "title": "Seperate api_server and pytorch engine into different processors",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-09T12:21:45Z",
    "closed_at": "2025-06-26T13:11:45Z",
    "merged_at": "2025-06-26T13:11:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3627"
  },
  {
    "number": 3625,
    "title": "improve loading model performance by shuffling the weight files",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-09T09:35:25Z",
    "closed_at": "2025-06-11T06:22:32Z",
    "merged_at": "2025-06-11T06:22:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3625"
  },
  {
    "number": 3624,
    "title": "Fix log file env in ray worker",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-09T07:07:48Z",
    "closed_at": "2025-06-13T10:24:08Z",
    "merged_at": "2025-06-13T10:24:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3624"
  },
  {
    "number": 3623,
    "title": "FA3",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-09T02:09:01Z",
    "closed_at": "2025-07-15T09:05:51Z",
    "merged_at": "2025-07-15T09:05:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3623"
  },
  {
    "number": 3622,
    "title": "add benchmark scripts about pipeline api and inference engines according to the config file",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-08T12:00:10Z",
    "closed_at": "2025-06-12T07:12:59Z",
    "merged_at": "2025-06-12T07:12:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3622"
  },
  {
    "number": 3621,
    "title": "update some logs of proxy_server and pt engine",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-08T06:13:15Z",
    "closed_at": "2025-06-09T04:20:19Z",
    "merged_at": "2025-06-09T04:20:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3621"
  },
  {
    "number": 3620,
    "title": "Support Mooncake migration backend for PD disaggregation",
    "user": "Risc-lt",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-07T15:34:47Z",
    "closed_at": "2025-06-20T04:00:31Z",
    "merged_at": "2025-06-20T04:00:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3620"
  },
  {
    "number": 3618,
    "title": "fix awq kernel",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-07T06:26:21Z",
    "closed_at": "2025-06-09T12:43:22Z",
    "merged_at": "2025-06-09T12:43:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3618"
  },
  {
    "number": 3617,
    "title": "fix flash mla interface",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-06T10:50:29Z",
    "closed_at": "2025-06-10T13:05:40Z",
    "merged_at": "2025-06-10T13:05:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3617"
  },
  {
    "number": 3615,
    "title": "feature: enable tool_call and reasoning_content parsing for qwen3",
    "user": "ywx217",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-05T08:58:57Z",
    "closed_at": "2025-06-19T13:28:19Z",
    "merged_at": "2025-06-19T13:28:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3615"
  },
  {
    "number": 3614,
    "title": "fix bug in qwen2",
    "user": "LKJacky",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-05T08:21:28Z",
    "closed_at": "2025-06-05T12:06:28Z",
    "merged_at": "2025-06-05T12:06:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3614"
  },
  {
    "number": 3610,
    "title": "[PDDisaggreagtion] Async migration",
    "user": "JimyMa",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-04T11:44:18Z",
    "closed_at": "2025-06-06T13:30:56Z",
    "merged_at": "2025-06-06T13:30:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3610"
  },
  {
    "number": 3609,
    "title": "Bump version to v0.9.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-04T09:15:04Z",
    "closed_at": "2025-06-19T02:27:01Z",
    "merged_at": "2025-06-19T02:27:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3609"
  },
  {
    "number": 3608,
    "title": "fix side-effect caused by PR 3590",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-04T08:10:46Z",
    "closed_at": "2025-06-05T07:37:15Z",
    "merged_at": "2025-06-05T07:37:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3608"
  },
  {
    "number": 3607,
    "title": "add sampling_vocab_size",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-04T07:55:29Z",
    "closed_at": "2025-06-11T14:32:52Z",
    "merged_at": "2025-06-11T14:32:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3607"
  },
  {
    "number": 3606,
    "title": "update deepgemm version",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-04T06:51:47Z",
    "closed_at": "2025-06-04T09:18:17Z",
    "merged_at": "2025-06-04T09:18:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3606"
  },
  {
    "number": 3604,
    "title": "sampling on the tokenizer's vocab",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-03T12:11:08Z",
    "closed_at": "2025-06-03T13:33:49Z",
    "merged_at": "2025-06-03T13:33:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3604"
  },
  {
    "number": 3603,
    "title": "[Ascend] set default distrbuted backend as ray for ascend device",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-06-03T09:51:55Z",
    "closed_at": "2025-06-04T13:44:21Z",
    "merged_at": "2025-06-04T13:44:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3603"
  },
  {
    "number": 3602,
    "title": "async update weights",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-31T13:13:40Z",
    "closed_at": "2025-06-05T12:45:55Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3602"
  },
  {
    "number": 3601,
    "title": "Add FP8 MoE for turbomind",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-30T17:19:30Z",
    "closed_at": "2025-06-13T12:49:44Z",
    "merged_at": "2025-06-13T12:49:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3601"
  },
  {
    "number": 3600,
    "title": "read distributed envs",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-30T09:42:13Z",
    "closed_at": "2025-06-02T03:57:37Z",
    "merged_at": "2025-06-02T03:57:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3600"
  },
  {
    "number": 3599,
    "title": "1. add migration flow control",
    "user": "JimyMa",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-30T09:27:15Z",
    "closed_at": "2025-06-03T13:30:35Z",
    "merged_at": "2025-06-03T13:30:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3599"
  },
  {
    "number": 3598,
    "title": "move dp loop to model agent",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-30T04:22:57Z",
    "closed_at": "2025-06-06T13:48:10Z",
    "merged_at": "2025-06-06T13:48:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3598"
  },
  {
    "number": 3597,
    "title": "Fix symbol error when dlBLAS is not imported",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-29T12:23:19Z",
    "closed_at": "2025-05-30T03:58:56Z",
    "merged_at": "2025-05-30T03:58:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3597"
  },
  {
    "number": 3596,
    "title": "Add log_file and set loglevel in launch_servers",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-29T07:05:13Z",
    "closed_at": "2025-05-29T09:09:35Z",
    "merged_at": "2025-05-29T09:09:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3596"
  },
  {
    "number": 3593,
    "title": "[ci] add qwen3 models into testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-28T03:23:21Z",
    "closed_at": "2025-06-03T05:10:18Z",
    "merged_at": "2025-06-03T05:10:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3593"
  },
  {
    "number": 3592,
    "title": "Fix batch infer for gemma3vl",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-28T02:57:31Z",
    "closed_at": "2025-05-29T03:15:13Z",
    "merged_at": "2025-05-29T03:15:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3592"
  },
  {
    "number": 3591,
    "title": "support both eplb and microbatch simultaneously",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-27T11:16:06Z",
    "closed_at": "2025-05-28T13:37:40Z",
    "merged_at": "2025-05-28T13:37:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3591"
  },
  {
    "number": 3590,
    "title": "[Misc] minor api_server and tm loader, and upgrade docformatter to resolve lint error",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-27T04:44:36Z",
    "closed_at": "2025-06-02T08:19:04Z",
    "merged_at": "2025-06-02T08:19:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3590"
  },
  {
    "number": 3589,
    "title": "[Fix]: reset step after eviction",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-26T13:40:12Z",
    "closed_at": "2025-05-27T02:38:25Z",
    "merged_at": "2025-05-27T02:38:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3589"
  },
  {
    "number": 3587,
    "title": "It can solve the problem of accessing the swagger interface without Internet access",
    "user": "bltcn",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-24T08:18:00Z",
    "closed_at": "2025-05-24T12:41:46Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3587"
  },
  {
    "number": 3584,
    "title": "[ci] fix transformers version in prtest",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-23T07:55:53Z",
    "closed_at": "2025-05-28T11:15:15Z",
    "merged_at": "2025-05-28T11:15:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3584"
  },
  {
    "number": 3582,
    "title": "support eplb for Qwen3-MoE",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-23T05:52:48Z",
    "closed_at": "2025-06-04T09:29:15Z",
    "merged_at": "2025-06-04T09:29:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3582"
  },
  {
    "number": 3580,
    "title": "fix mixtral on new transformers",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-22T04:24:09Z",
    "closed_at": "2025-05-26T05:32:04Z",
    "merged_at": "2025-05-26T05:32:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3580"
  },
  {
    "number": 3578,
    "title": "Update benchmark",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-20T08:55:57Z",
    "closed_at": "2025-05-26T10:32:32Z",
    "merged_at": "2025-05-26T10:32:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3578"
  },
  {
    "number": 3577,
    "title": "add rate limiter middleware",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-20T03:51:34Z",
    "closed_at": "2025-06-05T04:08:55Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3577"
  },
  {
    "number": 3575,
    "title": "fix parsing dynamic rope param failed",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-19T14:34:49Z",
    "closed_at": "2025-05-28T05:59:43Z",
    "merged_at": "2025-05-28T05:59:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3575"
  },
  {
    "number": 3573,
    "title": "block output when prefetch next forward inputs.",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-18T13:16:44Z",
    "closed_at": "2025-05-28T09:32:19Z",
    "merged_at": "2025-05-28T09:32:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3573"
  },
  {
    "number": 3572,
    "title": "Eplb",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-17T15:09:51Z",
    "closed_at": "2025-05-21T10:27:27Z",
    "merged_at": "2025-05-21T10:27:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3572"
  },
  {
    "number": 3570,
    "title": "perform torch.cuda.empty_cache() after conversion",
    "user": "bltcn",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-17T06:17:38Z",
    "closed_at": "2025-05-19T10:38:17Z",
    "merged_at": "2025-05-19T10:38:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3570"
  },
  {
    "number": 3566,
    "title": "support update params for turbomind backend",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-16T08:35:02Z",
    "closed_at": "2025-06-04T13:43:54Z",
    "merged_at": "2025-06-04T13:43:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3566"
  },
  {
    "number": 3564,
    "title": "support qwen3 /think & /no_think & enable_thinking parameter",
    "user": "BUJIDAOVS",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-15T14:49:24Z",
    "closed_at": "2025-05-20T13:46:51Z",
    "merged_at": "2025-05-20T13:46:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3564"
  },
  {
    "number": 3562,
    "title": "support update params with dp=1 for pytorch engine",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-15T08:24:55Z",
    "closed_at": "2025-05-15T11:50:17Z",
    "merged_at": "2025-05-15T11:50:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3562"
  },
  {
    "number": 3561,
    "title": "[ci] add test workflow for 3090 machine",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-15T07:14:17Z",
    "closed_at": "2025-05-26T04:05:42Z",
    "merged_at": "2025-05-26T04:05:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3561"
  },
  {
    "number": 3560,
    "title": "Add 3090",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-15T06:32:31Z",
    "closed_at": "2025-05-15T06:32:51Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3560"
  },
  {
    "number": 3559,
    "title": "support awq for Qwen2.5-VL ",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-15T04:43:36Z",
    "closed_at": "2025-05-19T14:36:24Z",
    "merged_at": "2025-05-19T14:36:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3559"
  },
  {
    "number": 3555,
    "title": "fix dp>1 tp=1 ep=1",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-14T13:26:39Z",
    "closed_at": "2025-05-15T06:38:05Z",
    "merged_at": "2025-05-15T06:38:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3555"
  },
  {
    "number": 3552,
    "title": "Skip dp dummy input forward",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-14T08:33:33Z",
    "closed_at": "2025-05-16T08:08:03Z",
    "merged_at": "2025-05-16T08:08:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3552"
  },
  {
    "number": 3550,
    "title": "Unclock mutual exclusivity of argument:  `tool-call-parser` and `reasoning-parser`",
    "user": "jingyibo123",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-14T07:48:35Z",
    "closed_at": "2025-05-19T10:34:23Z",
    "merged_at": "2025-05-19T10:34:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3550"
  },
  {
    "number": 3548,
    "title": "pipeline warmup",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-14T06:07:57Z",
    "closed_at": "2025-05-19T13:48:30Z",
    "merged_at": "2025-05-19T13:48:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3548"
  },
  {
    "number": 3547,
    "title": "[bug fix] fix PD Disaggregation in DSV3",
    "user": "JimyMa",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-13T23:25:21Z",
    "closed_at": "2025-05-15T06:25:13Z",
    "merged_at": "2025-05-15T06:25:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3547"
  },
  {
    "number": 3545,
    "title": "ray safe exit",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-13T09:21:31Z",
    "closed_at": "2025-05-15T06:26:47Z",
    "merged_at": "2025-05-15T06:26:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3545"
  },
  {
    "number": 3543,
    "title": "fix proxy server heart beat",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-13T07:50:17Z",
    "closed_at": "2025-05-15T06:35:16Z",
    "merged_at": "2025-05-15T06:35:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3543"
  },
  {
    "number": 3541,
    "title": "Refactor engine 2505",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-12T12:32:41Z",
    "closed_at": "2025-05-21T07:21:02Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3541"
  },
  {
    "number": 3540,
    "title": "update two microbatch",
    "user": "SHshenhao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-12T08:38:25Z",
    "closed_at": "2025-05-12T11:47:12Z",
    "merged_at": "2025-05-12T11:47:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3540"
  },
  {
    "number": 3538,
    "title": "Fix role attr error for tubomind config",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-12T03:14:57Z",
    "closed_at": "2025-05-12T07:25:02Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3538"
  },
  {
    "number": 3535,
    "title": "support update params for pytorch backend from api server",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-09T13:24:43Z",
    "closed_at": "2025-05-13T04:21:46Z",
    "merged_at": "2025-05-13T04:21:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3535"
  },
  {
    "number": 3534,
    "title": "[Feature] metrics support",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-09T13:07:32Z",
    "closed_at": "2025-07-09T11:38:44Z",
    "merged_at": "2025-07-09T11:38:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3534"
  },
  {
    "number": 3533,
    "title": "allow api server terminated through requests from clients",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-09T11:52:27Z",
    "closed_at": "2025-05-12T07:13:36Z",
    "merged_at": "2025-05-12T07:13:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3533"
  },
  {
    "number": 3532,
    "title": "update blockedfp8 scale name",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-09T09:36:56Z",
    "closed_at": "2025-05-12T09:58:30Z",
    "merged_at": "2025-05-12T09:58:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3532"
  },
  {
    "number": 3531,
    "title": "[ascend]set transdata dynamic shape true",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-09T09:31:28Z",
    "closed_at": "2025-05-13T04:35:51Z",
    "merged_at": "2025-05-13T04:35:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3531"
  },
  {
    "number": 3530,
    "title": "random pad input ids",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-09T03:09:24Z",
    "closed_at": "2025-05-12T03:36:47Z",
    "merged_at": "2025-05-12T03:36:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3530"
  },
  {
    "number": 3527,
    "title": "internlm3 dense fp8",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-08T03:11:41Z",
    "closed_at": "2025-05-08T10:43:35Z",
    "merged_at": "2025-05-08T10:43:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3527"
  },
  {
    "number": 3526,
    "title": "update doc for  ascend 300I Duo docker image",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-07T15:02:48Z",
    "closed_at": "2025-05-08T05:17:13Z",
    "merged_at": "2025-05-08T05:17:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3526"
  },
  {
    "number": 3523,
    "title": "start engine loop on server startup event",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-07T09:52:53Z",
    "closed_at": "2025-05-12T10:03:57Z",
    "merged_at": "2025-05-12T10:03:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3523"
  },
  {
    "number": 3522,
    "title": "[dlinfer][ascend]set blcoksize default to 128 for 310P device",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-07T09:28:49Z",
    "closed_at": "2025-06-09T03:26:13Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3522"
  },
  {
    "number": 3519,
    "title": "fix attention sm86",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-05-06T08:15:56Z",
    "closed_at": "2025-05-07T02:47:32Z",
    "merged_at": "2025-05-07T02:47:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3519"
  },
  {
    "number": 3513,
    "title": "[ascend] fix recompile on different rank",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-30T16:23:45Z",
    "closed_at": "2025-05-06T03:09:32Z",
    "merged_at": "2025-05-06T03:09:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3513"
  },
  {
    "number": 3510,
    "title": "optimize longcontext decoding",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-30T04:26:01Z",
    "closed_at": "2025-04-30T11:43:31Z",
    "merged_at": "2025-04-30T11:43:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3510"
  },
  {
    "number": 3508,
    "title": "fix sampling if data overflow after temperature penalty",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-30T02:26:42Z",
    "closed_at": "2025-05-01T09:03:43Z",
    "merged_at": "2025-05-01T09:03:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3508"
  },
  {
    "number": 3506,
    "title": "Support min_p in openai completions_v1",
    "user": "josephrocca",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-29T09:13:00Z",
    "closed_at": "2025-04-30T12:29:36Z",
    "merged_at": "2025-04-30T12:29:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3506"
  },
  {
    "number": 3505,
    "title": "support qwen3 fp8",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-29T09:06:44Z",
    "closed_at": "2025-04-30T03:40:32Z",
    "merged_at": "2025-04-30T03:40:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3505"
  },
  {
    "number": 3504,
    "title": "Pass num_tokens_per_iter and max_prefill_iters params through in `lmdeploy serve api_server`",
    "user": "josephrocca",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-29T09:04:27Z",
    "closed_at": "2025-04-29T13:27:25Z",
    "merged_at": "2025-04-29T13:27:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3504"
  },
  {
    "number": 3503,
    "title": "support qwen3-dense models awq quantization",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-29T08:20:18Z",
    "closed_at": "2025-04-29T10:34:18Z",
    "merged_at": "2025-04-29T10:34:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3503"
  },
  {
    "number": 3500,
    "title": "Optimize MoE gate for Qwen3",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-29T06:26:07Z",
    "closed_at": "2025-04-29T12:58:42Z",
    "merged_at": "2025-04-29T12:58:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3500"
  },
  {
    "number": 3499,
    "title": "fix replicate kv for qwen3-moe",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-29T03:40:28Z",
    "closed_at": "2025-04-29T06:12:41Z",
    "merged_at": "2025-04-29T06:12:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3499"
  },
  {
    "number": 3494,
    "title": "fix stopwords kv cache",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-28T10:06:12Z",
    "closed_at": "2025-05-12T11:47:29Z",
    "merged_at": "2025-05-12T11:47:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3494"
  },
  {
    "number": 3493,
    "title": "move partial_json_parser from serve.txt to runtime.txt",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-28T08:51:20Z",
    "closed_at": "2025-04-28T09:29:47Z",
    "merged_at": "2025-04-28T09:29:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3493"
  },
  {
    "number": 3492,
    "title": "fix stop/bad words",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-28T08:26:58Z",
    "closed_at": "2025-04-28T09:05:36Z",
    "merged_at": "2025-04-28T09:05:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3492"
  },
  {
    "number": 3491,
    "title": "Fix Qwen2MoE shared expert gate",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-28T07:04:31Z",
    "closed_at": "2025-04-28T08:11:44Z",
    "merged_at": "2025-04-28T08:11:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3491"
  },
  {
    "number": 3490,
    "title": "simulate EPLB for benchmark only",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-27T14:02:43Z",
    "closed_at": "2025-05-15T11:05:56Z",
    "merged_at": "2025-05-15T11:05:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3490"
  },
  {
    "number": 3489,
    "title": "use dlblas",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-27T11:37:46Z",
    "closed_at": "2025-05-06T07:06:04Z",
    "merged_at": "2025-05-06T07:06:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3489"
  },
  {
    "number": 3488,
    "title": "fix output logprobs",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-27T11:16:44Z",
    "closed_at": "2025-04-27T13:07:57Z",
    "merged_at": "2025-04-27T13:07:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3488"
  },
  {
    "number": 3487,
    "title": "reduce ray memory usage",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-27T07:50:44Z",
    "closed_at": "2025-05-06T04:01:45Z",
    "merged_at": "2025-05-06T04:01:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3487"
  },
  {
    "number": 3486,
    "title": "[Dlinfer][Ascend] Optimize performance of 310P device",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-27T05:42:06Z",
    "closed_at": "2025-04-30T04:40:44Z",
    "merged_at": "2025-04-30T04:40:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3486"
  },
  {
    "number": 3484,
    "title": "[Dlinfer][Ascend] support 310P",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-25T10:00:04Z",
    "closed_at": "2025-04-27T11:13:32Z",
    "merged_at": "2025-04-27T11:13:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3484"
  },
  {
    "number": 3482,
    "title": "update dockerfile",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-25T03:26:03Z",
    "closed_at": "2025-04-25T05:43:20Z",
    "merged_at": "2025-04-25T05:43:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3482"
  },
  {
    "number": 3481,
    "title": "Fix disorder of ray execution",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T13:10:56Z",
    "closed_at": "2025-04-25T03:20:07Z",
    "merged_at": "2025-04-25T03:20:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3481"
  },
  {
    "number": 3479,
    "title": "fix turbomind lib missing to link nccl by exporting nccl path",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T09:38:27Z",
    "closed_at": "2025-04-24T09:40:33Z",
    "merged_at": "2025-04-24T09:40:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3479"
  },
  {
    "number": 3478,
    "title": "fix flash attention crash on triton3.1.0",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T07:12:53Z",
    "closed_at": "2025-04-24T13:28:08Z",
    "merged_at": "2025-04-24T13:28:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3478"
  },
  {
    "number": 3477,
    "title": "fix dsvl2 no attr config error",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-24T07:10:02Z",
    "closed_at": "2025-04-24T10:09:41Z",
    "merged_at": "2025-04-24T10:09:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3477"
  },
  {
    "number": 3475,
    "title": "fix qwen2.5-vl chat template",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T10:31:42Z",
    "closed_at": "2025-04-24T03:43:11Z",
    "merged_at": "2025-04-24T03:43:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3475"
  },
  {
    "number": 3474,
    "title": "Align forward arguments of deepgemm blockedf8",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T09:27:11Z",
    "closed_at": "2025-04-24T04:11:14Z",
    "merged_at": "2025-04-24T04:11:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3474"
  },
  {
    "number": 3471,
    "title": "failed to end session properly",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T02:48:00Z",
    "closed_at": "2025-04-23T13:55:36Z",
    "merged_at": "2025-04-23T13:55:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3471"
  },
  {
    "number": 3470,
    "title": "Blocked fp8 tma",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T02:45:59Z",
    "closed_at": "2025-06-06T09:57:04Z",
    "merged_at": "2025-06-06T09:57:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3470"
  },
  {
    "number": 3469,
    "title": "use dlblas",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-23T02:45:52Z",
    "closed_at": "2025-04-27T13:08:19Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3469"
  },
  {
    "number": 3468,
    "title": "Update batched dynamic ntk",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-22T13:29:08Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3468"
  },
  {
    "number": 3467,
    "title": "Support phi4 mini",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-22T12:30:10Z",
    "closed_at": "2025-04-23T09:21:08Z",
    "merged_at": "2025-04-23T09:21:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3467"
  },
  {
    "number": 3465,
    "title": "optimize sm80 long context",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-22T04:33:07Z",
    "closed_at": "2025-04-23T07:24:50Z",
    "merged_at": "2025-04-23T07:24:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3465"
  },
  {
    "number": 3463,
    "title": "[ci] testcase bugfix and add more models into testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T06:02:51Z",
    "closed_at": "2025-04-30T12:24:45Z",
    "merged_at": "2025-04-30T12:24:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3463"
  },
  {
    "number": 3462,
    "title": "remove barely used code to improve maintenance",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T04:27:49Z",
    "closed_at": "2025-04-23T05:43:51Z",
    "merged_at": "2025-04-23T05:43:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3462"
  },
  {
    "number": 3461,
    "title": "Opt moe block by dlblas, when ep > 1",
    "user": "hellozmz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T03:27:03Z",
    "closed_at": "2025-07-07T08:30:31Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3461"
  },
  {
    "number": 3460,
    "title": "Remove empty prompts in benchmark scripts",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T02:55:04Z",
    "closed_at": "2025-04-23T07:25:53Z",
    "merged_at": "2025-04-23T07:25:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3460"
  },
  {
    "number": 3458,
    "title": "fix mllm testcase fail",
    "user": "caikun-pjlab",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-21T02:27:13Z",
    "closed_at": "2025-04-21T10:23:08Z",
    "merged_at": "2025-04-21T10:23:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3458"
  },
  {
    "number": 3452,
    "title": "remove paged attention autotune",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-17T11:26:37Z",
    "closed_at": "2025-04-23T07:25:21Z",
    "merged_at": "2025-04-23T07:25:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3452"
  },
  {
    "number": 3450,
    "title": "map internvl3 chat template to builtin chat template internvl2_5",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-17T08:15:01Z",
    "closed_at": "2025-04-17T10:42:16Z",
    "merged_at": "2025-04-17T10:42:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3450"
  },
  {
    "number": 3448,
    "title": "ray nsys profile support",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-17T07:40:37Z",
    "closed_at": "2025-05-12T03:43:23Z",
    "merged_at": "2025-05-12T03:43:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3448"
  },
  {
    "number": 3446,
    "title": "update qwen2.5-vl-32b docs",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-17T04:32:50Z",
    "closed_at": "2025-04-17T04:58:34Z",
    "merged_at": "2025-04-17T04:58:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3446"
  },
  {
    "number": 3443,
    "title": "ray async forward execute",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-16T13:29:23Z",
    "closed_at": "2025-04-17T07:04:48Z",
    "merged_at": "2025-04-17T07:04:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3443"
  },
  {
    "number": 3442,
    "title": "fix linting error by upgrade to ubuntu-latest",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-16T10:56:22Z",
    "closed_at": "2025-04-16T12:10:38Z",
    "merged_at": "2025-04-16T12:10:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3442"
  },
  {
    "number": 3436,
    "title": "Add ascend env variables to dockerfile",
    "user": "DoorKickers",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-15T11:52:54Z",
    "closed_at": "2025-04-16T07:30:59Z",
    "merged_at": "2025-04-16T07:30:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3436"
  },
  {
    "number": 3435,
    "title": "fix awq tp for pytorch engine",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-15T07:33:36Z",
    "closed_at": "2025-04-17T04:54:51Z",
    "merged_at": "2025-04-17T04:54:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3435"
  },
  {
    "number": 3433,
    "title": "optimize internvit",
    "user": "caikun-pjlab",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-15T01:13:58Z",
    "closed_at": "2025-04-17T03:46:41Z",
    "merged_at": "2025-04-17T03:46:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3433"
  },
  {
    "number": 3432,
    "title": "bump version to v0.8.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-14T11:34:08Z",
    "closed_at": "2025-05-04T03:16:34Z",
    "merged_at": "2025-05-04T03:16:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3432"
  },
  {
    "number": 3430,
    "title": "Zmz/prefill without permute by dlblas",
    "user": "hellozmz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-14T07:02:50Z",
    "closed_at": "2025-07-07T08:27:31Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3430"
  },
  {
    "number": 3429,
    "title": "find port",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-14T06:37:02Z",
    "closed_at": "2025-04-14T09:38:02Z",
    "merged_at": "2025-04-14T09:38:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3429"
  },
  {
    "number": 3426,
    "title": "[Dlinfer][Ascend] 310P device support",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-14T04:36:59Z",
    "closed_at": "2025-05-07T01:05:16Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3426"
  },
  {
    "number": 3425,
    "title": "Wt/310 tp2 good",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-14T01:30:10Z",
    "closed_at": "2025-04-14T01:30:36Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3425"
  },
  {
    "number": 3423,
    "title": "Refactor turbomind (low-level abstractions)",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-11T12:03:30Z",
    "closed_at": "2025-04-22T14:19:51Z",
    "merged_at": "2025-04-22T14:19:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3423"
  },
  {
    "number": 3420,
    "title": "update ascend doc",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-11T07:18:50Z",
    "closed_at": "2025-04-11T11:21:21Z",
    "merged_at": "2025-04-11T11:21:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3420"
  },
  {
    "number": 3419,
    "title": "optimize fp8 moe kernel",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-11T03:03:01Z",
    "closed_at": "2025-04-11T07:48:29Z",
    "merged_at": "2025-04-11T07:48:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3419"
  },
  {
    "number": 3417,
    "title": "fix tensor dispatch in dynamo",
    "user": "wanfengcxz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-10T13:29:17Z",
    "closed_at": "2025-04-11T03:32:20Z",
    "merged_at": "2025-04-11T03:32:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3417"
  },
  {
    "number": 3416,
    "title": "bump version to v0.7.3",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-10T09:18:17Z",
    "closed_at": "2025-04-14T09:58:44Z",
    "merged_at": "2025-04-14T09:58:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3416"
  },
  {
    "number": 3415,
    "title": "add Hopper GPU dockerfile",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-10T06:22:20Z",
    "closed_at": "2025-04-14T11:30:38Z",
    "merged_at": "2025-04-14T11:30:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3415"
  },
  {
    "number": 3414,
    "title": "Launch multiple api servers for dp > 1",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-10T06:17:12Z",
    "closed_at": "2025-05-19T13:50:25Z",
    "merged_at": "2025-05-19T13:50:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3414"
  },
  {
    "number": 3408,
    "title": "support Llama4",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-09T03:51:27Z",
    "closed_at": "2025-04-10T14:12:50Z",
    "merged_at": "2025-04-10T14:12:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3408"
  },
  {
    "number": 3407,
    "title": "Default `enable_prefix_caching` True",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T13:54:14Z",
    "closed_at": "2025-04-11T07:02:20Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3407"
  },
  {
    "number": 3406,
    "title": "Revert \"opt experts memory and permute\"",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T11:06:24Z",
    "closed_at": "2025-04-08T11:31:49Z",
    "merged_at": "2025-04-08T11:31:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3406"
  },
  {
    "number": 3405,
    "title": "update fp8 weight loader",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T07:40:01Z",
    "closed_at": "2025-05-09T08:24:44Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3405"
  },
  {
    "number": 3403,
    "title": "add rayexecutor release timeout",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T07:10:04Z",
    "closed_at": "2025-04-10T07:10:38Z",
    "merged_at": "2025-04-10T07:10:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3403"
  },
  {
    "number": 3402,
    "title": "fix ep bug",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-08T06:44:39Z",
    "closed_at": "2025-04-08T11:07:14Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3402"
  },
  {
    "number": 3400,
    "title": "merge dev to main",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-07T08:03:24Z",
    "closed_at": "2025-04-11T04:01:41Z",
    "merged_at": "2025-04-11T04:01:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3400"
  },
  {
    "number": 3392,
    "title": "remove ep eager check",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-03T13:01:24Z",
    "closed_at": "2025-04-04T12:45:17Z",
    "merged_at": "2025-04-04T12:45:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3392"
  },
  {
    "number": 3390,
    "title": "opt experts memory and permute",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-03T09:30:21Z",
    "closed_at": "2025-04-07T12:44:12Z",
    "merged_at": "2025-04-07T12:44:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3390"
  },
  {
    "number": 3389,
    "title": "[WIP]: vl prefix caching",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-03T07:51:33Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3389"
  },
  {
    "number": 3387,
    "title": "Warmup deepgemm",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-02T12:17:55Z",
    "closed_at": "2025-04-09T03:24:29Z",
    "merged_at": "2025-04-09T03:24:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3387"
  },
  {
    "number": 3386,
    "title": "Add string before hash tokens in blocktrie",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-02T10:52:53Z",
    "closed_at": "2025-04-02T12:08:53Z",
    "merged_at": "2025-04-02T12:08:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3386"
  },
  {
    "number": 3385,
    "title": "support List[dict] prompt input without do_preprocess",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-02T08:36:52Z",
    "closed_at": "2025-04-07T08:02:53Z",
    "merged_at": "2025-04-07T08:02:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3385"
  },
  {
    "number": 3384,
    "title": "fix stopping criteria",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-02T04:13:26Z",
    "closed_at": "2025-04-04T03:50:41Z",
    "merged_at": "2025-04-04T03:50:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3384"
  },
  {
    "number": 3383,
    "title": "optimize ep in decoding stage",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-02T03:37:18Z",
    "closed_at": "2025-04-02T15:03:42Z",
    "merged_at": "2025-04-02T15:03:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3383"
  },
  {
    "number": 3382,
    "title": "disable sync batch on dp eager mode",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-01T13:55:05Z",
    "closed_at": "2025-04-02T06:19:02Z",
    "merged_at": "2025-04-02T06:19:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3382"
  },
  {
    "number": 3381,
    "title": "add twomicrobatch support",
    "user": "SHshenhao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-01T11:33:55Z",
    "closed_at": "2025-04-16T10:47:37Z",
    "merged_at": "2025-04-16T10:47:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3381"
  },
  {
    "number": 3380,
    "title": "fix for deepgemm update",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-01T08:42:24Z",
    "closed_at": "2025-04-02T10:44:19Z",
    "merged_at": "2025-04-02T10:44:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3380"
  },
  {
    "number": 3378,
    "title": "merge dev to main branch",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-04-01T03:54:26Z",
    "closed_at": "2025-04-01T11:58:02Z",
    "merged_at": "2025-04-01T11:58:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3378"
  },
  {
    "number": 3376,
    "title": "set cmake policy minimum version as 3.5",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-31T13:55:06Z",
    "closed_at": "2025-03-31T16:39:44Z",
    "merged_at": "2025-03-31T16:39:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3376"
  },
  {
    "number": 3375,
    "title": "fix flashmla eagermode",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-31T12:28:38Z",
    "closed_at": "2025-04-01T04:15:18Z",
    "merged_at": "2025-04-01T04:15:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3375"
  },
  {
    "number": 3374,
    "title": "[ci] add vl models into pipeline interface testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-31T10:18:22Z",
    "closed_at": "2025-04-01T08:05:27Z",
    "merged_at": "2025-04-01T08:05:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3374"
  },
  {
    "number": 3372,
    "title": "fix dp cudagraph",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-31T07:50:00Z",
    "closed_at": "2025-04-01T03:55:36Z",
    "merged_at": "2025-04-01T03:55:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3372"
  },
  {
    "number": 3371,
    "title": "set cmake policy minimum version as 3.5",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-31T03:48:39Z",
    "closed_at": "2025-03-31T13:48:07Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3371"
  },
  {
    "number": 3370,
    "title": "support all2all ep",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-31T02:33:35Z",
    "closed_at": "2025-04-01T07:16:51Z",
    "merged_at": "2025-04-01T07:16:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3370"
  },
  {
    "number": 3367,
    "title": "enable qwenvl2.5 graph mode on ascend",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-29T16:19:07Z",
    "closed_at": "2025-04-01T03:49:31Z",
    "merged_at": "2025-04-01T03:49:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3367"
  },
  {
    "number": 3366,
    "title": "enable qwenvl2.5 graph mode on ascend",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-29T16:06:11Z",
    "closed_at": "2025-03-29T16:13:21Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3366"
  },
  {
    "number": 3364,
    "title": "Optimize ascend moe",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-28T08:42:42Z",
    "closed_at": "2025-04-10T03:39:14Z",
    "merged_at": "2025-04-10T03:39:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3364"
  },
  {
    "number": 3362,
    "title": "Add Gloo communication to turobmind",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-28T03:47:40Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3362"
  },
  {
    "number": 3358,
    "title": "[Fix] fix `image_token_id` error of qwen2-vl and deepseek",
    "user": "ao-zz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-27T14:26:11Z",
    "closed_at": "2025-04-02T07:34:36Z",
    "merged_at": "2025-04-02T07:34:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3358"
  },
  {
    "number": 3356,
    "title": "optimize moe get sorted idx",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-27T12:12:54Z",
    "closed_at": "2025-04-03T09:32:42Z",
    "merged_at": "2025-04-03T09:32:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3356"
  },
  {
    "number": 3355,
    "title": "Add AIOHTTP_TIMEOUT env var for proxy server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-27T09:37:22Z",
    "closed_at": "2025-04-01T03:53:15Z",
    "merged_at": "2025-04-01T03:53:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3355"
  },
  {
    "number": 3353,
    "title": "Update block_trie.py",
    "user": "kexinoh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-27T03:18:09Z",
    "closed_at": "2025-04-02T12:09:07Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3353"
  },
  {
    "number": 3350,
    "title": "Fix the finish_reason",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-26T12:03:46Z",
    "closed_at": "2025-03-27T06:09:23Z",
    "merged_at": "2025-03-27T06:09:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3350"
  },
  {
    "number": 3348,
    "title": "merge dev into main",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-26T10:17:25Z",
    "closed_at": "2025-03-26T15:55:19Z",
    "merged_at": "2025-03-26T15:55:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3348"
  },
  {
    "number": 3346,
    "title": "merge dev branch to main branch",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-26T07:35:37Z",
    "closed_at": "2025-03-26T10:17:44Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3346"
  },
  {
    "number": 3345,
    "title": "optimize quant-fp8 kernel",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-26T07:17:37Z",
    "closed_at": "2025-03-27T02:37:41Z",
    "merged_at": "2025-03-27T02:37:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3345"
  },
  {
    "number": 3340,
    "title": "[maca] support multinode for maca.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-26T02:21:25Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3340"
  },
  {
    "number": 3338,
    "title": "Fix finish reasons",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-26T01:14:48Z",
    "closed_at": "2025-03-26T04:09:17Z",
    "merged_at": "2025-03-26T04:09:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3338"
  },
  {
    "number": 3336,
    "title": "Fix Qwen3MoE config parsing",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-25T13:50:09Z",
    "closed_at": "2025-03-25T15:51:22Z",
    "merged_at": "2025-03-25T15:51:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3336"
  },
  {
    "number": 3335,
    "title": "no attn_bias in qwen3moe",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-25T13:29:25Z",
    "closed_at": "2025-03-25T13:53:57Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3335"
  },
  {
    "number": 3334,
    "title": "optimize mla, remove load `v`",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-25T11:05:45Z",
    "closed_at": "2025-03-26T03:46:45Z",
    "merged_at": "2025-03-26T03:46:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3334"
  },
  {
    "number": 3333,
    "title": "Create SECURITY.md",
    "user": "ybdesire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-25T09:51:38Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3333"
  },
  {
    "number": 3332,
    "title": "Improve turbomind's  prefix cache",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-25T09:33:21Z",
    "closed_at": "2025-08-13T09:13:28Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3332"
  },
  {
    "number": 3329,
    "title": "Verbose log",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-24T12:21:46Z",
    "closed_at": "2025-03-24T14:04:06Z",
    "merged_at": "2025-03-24T14:04:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3329"
  },
  {
    "number": 3327,
    "title": "remove think_end_token_id in streaming content",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-24T11:43:09Z",
    "closed_at": "2025-03-26T07:21:08Z",
    "merged_at": "2025-03-26T07:21:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3327"
  },
  {
    "number": 3326,
    "title": "refactor dlinfer rope",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-24T11:30:01Z",
    "closed_at": "2025-03-27T08:42:39Z",
    "merged_at": "2025-03-27T08:42:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3326"
  },
  {
    "number": 3316,
    "title": "Optimize internvit",
    "user": "caikun-pjlab",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-24T09:27:03Z",
    "closed_at": "2025-04-11T07:00:01Z",
    "merged_at": "2025-04-11T07:00:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3316"
  },
  {
    "number": 3315,
    "title": "[Feature] support qwen3 and qwen3-moe for pytorch engine",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-24T09:05:57Z",
    "closed_at": "2025-03-25T11:15:51Z",
    "merged_at": "2025-03-25T11:15:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3315"
  },
  {
    "number": 3313,
    "title": "add deepep",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-24T06:42:19Z",
    "closed_at": "2025-03-28T12:34:27Z",
    "merged_at": "2025-03-28T12:34:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3313"
  },
  {
    "number": 3311,
    "title": "support dp decoding with cudagraph",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-24T03:56:47Z",
    "closed_at": "2025-03-26T09:41:11Z",
    "merged_at": "2025-03-26T09:41:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3311"
  },
  {
    "number": 3307,
    "title": "add `v` check",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-23T07:34:08Z",
    "closed_at": "2025-03-25T14:38:12Z",
    "merged_at": "2025-03-25T14:38:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3307"
  },
  {
    "number": 3305,
    "title": "Add Qwen3 and Qwen3MoE",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-22T14:33:27Z",
    "closed_at": "2025-03-25T01:29:08Z",
    "merged_at": "2025-03-25T01:29:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3305"
  },
  {
    "number": 3304,
    "title": "LMDeploy Distserve",
    "user": "JimyMa",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-22T13:42:40Z",
    "closed_at": "2025-05-08T10:46:46Z",
    "merged_at": "2025-05-08T10:46:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3304"
  },
  {
    "number": 3302,
    "title": "fix sliding window multi chat",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-21T12:17:06Z",
    "closed_at": "2025-03-22T05:40:16Z",
    "merged_at": "2025-03-22T05:40:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3302"
  },
  {
    "number": 3299,
    "title": "[ci] add think function testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-21T07:15:13Z",
    "closed_at": "2025-03-24T09:23:13Z",
    "merged_at": "2025-03-24T09:23:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3299"
  },
  {
    "number": 3298,
    "title": "bump version to v0.7.2.post1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-21T06:33:05Z",
    "closed_at": "2025-03-21T06:37:37Z",
    "merged_at": "2025-03-21T06:37:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3298"
  },
  {
    "number": 3295,
    "title": "Set ensure_ascii=False for tool calling",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-21T02:34:12Z",
    "closed_at": "2025-03-21T06:27:34Z",
    "merged_at": "2025-03-21T06:27:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3295"
  },
  {
    "number": 3291,
    "title": "add env var to control timeout",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-20T06:50:24Z",
    "closed_at": "2025-03-21T03:54:07Z",
    "merged_at": "2025-03-21T03:54:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3291"
  },
  {
    "number": 3287,
    "title": "Add deep gemm with tma pre allocated",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-19T13:39:02Z",
    "closed_at": "2025-03-22T05:32:24Z",
    "merged_at": "2025-03-22T05:32:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3287"
  },
  {
    "number": 3283,
    "title": "Add spaces_between_special_tokens to /v1/interactive and make compatible with empty text",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-19T10:28:25Z",
    "closed_at": "2025-03-20T13:17:20Z",
    "merged_at": "2025-03-20T13:17:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3283"
  },
  {
    "number": 3282,
    "title": "fix activation grid oversize",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-19T09:30:22Z",
    "closed_at": "2025-03-20T05:28:20Z",
    "merged_at": "2025-03-20T05:28:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3282"
  },
  {
    "number": 3273,
    "title": "[maca] support multinode for maca.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-18T05:48:04Z",
    "closed_at": "2025-03-26T02:21:48Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3273"
  },
  {
    "number": 3272,
    "title": "Add gemma3 implementation",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-18T03:39:01Z",
    "closed_at": "2025-03-18T09:52:09Z",
    "merged_at": "2025-03-18T09:52:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3272"
  },
  {
    "number": 3271,
    "title": "disable flashmla warning on sm<90",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-18T03:03:09Z",
    "closed_at": "2025-03-18T03:36:18Z",
    "merged_at": "2025-03-18T03:36:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3271"
  },
  {
    "number": 3270,
    "title": "Base yqdp add deepep",
    "user": "zhaochaoxing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-18T02:59:59Z",
    "closed_at": "2025-03-25T11:39:09Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3270"
  },
  {
    "number": 3269,
    "title": " close engine after each benchmark-generation iter ",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-17T12:50:31Z",
    "closed_at": "2025-04-01T04:32:24Z",
    "merged_at": "2025-04-01T04:32:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3269"
  },
  {
    "number": 3268,
    "title": "Fix get ppl",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-17T10:35:19Z",
    "closed_at": "2025-03-18T05:44:25Z",
    "merged_at": "2025-03-18T05:44:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3268"
  },
  {
    "number": 3267,
    "title": "support ascend w8a8 graph_mode",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-17T09:13:46Z",
    "closed_at": "2025-04-01T04:14:10Z",
    "merged_at": "2025-04-01T04:14:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3267"
  },
  {
    "number": 3266,
    "title": "docs: update ascend docs for docker running",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-17T09:09:17Z",
    "closed_at": "2025-03-18T02:59:38Z",
    "merged_at": "2025-03-18T02:59:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3266"
  },
  {
    "number": 3265,
    "title": "add deepseekv3 doc",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-17T09:04:13Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3265"
  },
  {
    "number": 3263,
    "title": "fix dsv3 gate scaling",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-17T06:25:55Z",
    "closed_at": "2025-03-17T10:26:32Z",
    "merged_at": "2025-03-17T10:26:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3263"
  },
  {
    "number": 3262,
    "title": "add rdma dependencies into docker file",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-17T04:15:20Z",
    "closed_at": "2025-03-17T07:44:29Z",
    "merged_at": "2025-03-17T07:44:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3262"
  },
  {
    "number": 3260,
    "title": "[ascend] support multi nodes on ascend device",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-15T08:15:35Z",
    "closed_at": "2025-03-25T10:17:20Z",
    "merged_at": "2025-03-25T10:17:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3260"
  },
  {
    "number": 3257,
    "title": "[Fix] failed to update the tokenizer's eos_token_id into stop_word list",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-14T07:43:50Z",
    "closed_at": "2025-03-14T13:39:07Z",
    "merged_at": "2025-03-14T13:39:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3257"
  },
  {
    "number": 3256,
    "title": "Fix stop words",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-14T06:39:01Z",
    "closed_at": "2025-04-14T08:42:13Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3256"
  },
  {
    "number": 3253,
    "title": "[ci] remove v100 testconfig",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-13T11:55:10Z",
    "closed_at": "2025-03-14T03:16:36Z",
    "merged_at": "2025-03-14T03:16:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3253"
  },
  {
    "number": 3252,
    "title": "bump version to v0.7.2",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-13T08:56:32Z",
    "closed_at": "2025-03-19T08:35:24Z",
    "merged_at": "2025-03-19T08:35:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3252"
  },
  {
    "number": 3251,
    "title": "change ascend&camb default_batch_size to 256",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-13T06:36:19Z",
    "closed_at": "2025-03-13T07:57:01Z",
    "merged_at": "2025-03-13T07:57:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3251"
  },
  {
    "number": 3247,
    "title": "fix qwen2.5 pytorch engine dtype error on NPU",
    "user": "tcye",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-13T01:49:47Z",
    "closed_at": "2025-03-13T15:29:05Z",
    "merged_at": "2025-03-13T15:29:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3247"
  },
  {
    "number": 3242,
    "title": "remove torchelastic flag",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-11T07:42:34Z",
    "closed_at": "2025-03-13T09:09:36Z",
    "merged_at": "2025-03-13T09:09:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3242"
  },
  {
    "number": 3240,
    "title": "[ci] add volc evaluation testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-11T06:18:35Z",
    "closed_at": "2025-03-12T03:04:34Z",
    "merged_at": "2025-03-12T03:04:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3240"
  },
  {
    "number": 3239,
    "title": "[ascend] add Ascend docker image",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-11T03:07:31Z",
    "closed_at": "2025-03-11T03:45:52Z",
    "merged_at": "2025-03-11T03:45:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3239"
  },
  {
    "number": 3235,
    "title": "[dlinfer] fix glm-4v graph mode on ascend",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-09T13:19:05Z",
    "closed_at": "2025-03-10T06:30:40Z",
    "merged_at": "2025-03-10T06:30:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3235"
  },
  {
    "number": 3229,
    "title": "Add mixed DP + TP",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-07T13:02:30Z",
    "closed_at": "2025-03-24T11:42:28Z",
    "merged_at": "2025-03-24T11:42:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3229"
  },
  {
    "number": 3221,
    "title": "fix for small cache-max-entry-count",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-05T13:16:04Z",
    "closed_at": "2025-03-10T04:01:24Z",
    "merged_at": "2025-03-10T04:01:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3221"
  },
  {
    "number": 3220,
    "title": "[ci] add cluster evaluation test case workflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-05T13:05:29Z",
    "closed_at": "2025-03-06T01:51:26Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3220"
  },
  {
    "number": 3218,
    "title": "Add flash mla",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-05T09:33:18Z",
    "closed_at": "2025-03-10T13:29:24Z",
    "merged_at": "2025-03-10T13:29:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3218"
  },
  {
    "number": 3217,
    "title": "[ci] add testcase for native communicator",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-05T09:15:09Z",
    "closed_at": "2025-03-06T03:44:25Z",
    "merged_at": "2025-03-06T03:44:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3217"
  },
  {
    "number": 3216,
    "title": "Specifiy lmdeploy version in benchmark guide ",
    "user": "lyj0309",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-05T08:57:59Z",
    "closed_at": "2025-03-07T04:58:21Z",
    "merged_at": "2025-03-07T04:58:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3216"
  },
  {
    "number": 3215,
    "title": "[ascend] fix multi-card distributed inference failures",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-05T08:25:12Z",
    "closed_at": "2025-03-09T05:05:00Z",
    "merged_at": "2025-03-09T05:05:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3215"
  },
  {
    "number": 3213,
    "title": "use half/bf16 lm_head output",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-05T03:32:20Z",
    "closed_at": "2025-04-03T16:52:05Z",
    "merged_at": "2025-04-03T16:52:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3213"
  },
  {
    "number": 3210,
    "title": "defaullt executor ray",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-04T10:12:45Z",
    "closed_at": "2025-03-04T13:37:30Z",
    "merged_at": "2025-03-04T13:37:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3210"
  },
  {
    "number": 3209,
    "title": "Fix missing cli chat option",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-04T07:49:52Z",
    "closed_at": "2025-03-04T08:14:19Z",
    "merged_at": "2025-03-04T08:14:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3209"
  },
  {
    "number": 3208,
    "title": "[ci] test LMDEPLOY_EXECUTOR_BACKEND for hang",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-04T06:44:19Z",
    "closed_at": "2025-03-07T10:08:56Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3208"
  },
  {
    "number": 3207,
    "title": "Torch dp support",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-04T06:43:56Z",
    "closed_at": "2025-03-22T04:27:40Z",
    "merged_at": "2025-03-22T04:27:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3207"
  },
  {
    "number": 3206,
    "title": "[ascend]support deepseekv2",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-04T05:25:00Z",
    "closed_at": "2025-03-26T04:32:07Z",
    "merged_at": "2025-03-26T04:32:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3206"
  },
  {
    "number": 3204,
    "title": "support loading model with user input params (turbomind)",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-03T09:55:13Z",
    "closed_at": "2025-07-07T08:28:37Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3204"
  },
  {
    "number": 3203,
    "title": "support setting devices for turbomind backend",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-03-03T09:48:04Z",
    "closed_at": "2025-09-08T04:33:33Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3203"
  },
  {
    "number": 3198,
    "title": "Tool reasoning parsers and streaming function call",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-28T11:17:59Z",
    "closed_at": "2025-03-13T09:09:13Z",
    "merged_at": "2025-03-13T09:09:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3198"
  },
  {
    "number": 3196,
    "title": "Fix the bug for reading dict error",
    "user": "GxjGit",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-27T16:23:04Z",
    "closed_at": "2025-03-17T10:38:39Z",
    "merged_at": "2025-03-17T10:38:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3196"
  },
  {
    "number": 3194,
    "title": "[Feature] support qwen2.5-vl for pytorch engine",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-27T07:24:54Z",
    "closed_at": "2025-03-03T07:11:09Z",
    "merged_at": "2025-03-03T07:11:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3194"
  },
  {
    "number": 3192,
    "title": "Support reward models",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-26T11:57:35Z",
    "closed_at": "2025-03-03T09:16:21Z",
    "merged_at": "2025-03-03T09:16:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3192"
  },
  {
    "number": 3189,
    "title": "fix unstoppable chat",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-26T04:59:37Z",
    "closed_at": "2025-02-26T11:05:41Z",
    "merged_at": "2025-02-26T11:05:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3189"
  },
  {
    "number": 3188,
    "title": "fix deepseekv2 has no attribute use_mla error",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-25T08:52:44Z",
    "closed_at": "2025-02-25T13:03:33Z",
    "merged_at": "2025-02-25T13:03:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3188"
  },
  {
    "number": 3183,
    "title": "remove update badwords",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-25T03:32:38Z",
    "closed_at": "2025-02-27T04:16:32Z",
    "merged_at": "2025-02-27T04:16:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3183"
  },
  {
    "number": 3181,
    "title": "fix blocked fp8 moe",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-24T10:33:56Z",
    "closed_at": "2025-02-24T13:00:35Z",
    "merged_at": "2025-02-24T13:00:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3181"
  },
  {
    "number": 3180,
    "title": "[maca] opt data sync.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-24T10:31:06Z",
    "closed_at": "2025-03-18T08:22:32Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3180"
  },
  {
    "number": 3178,
    "title": "Bump version to v0.7.1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-24T04:21:19Z",
    "closed_at": "2025-02-27T02:18:34Z",
    "merged_at": "2025-02-27T02:18:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3178"
  },
  {
    "number": 3177,
    "title": "Make turbomind support embedding inputs on GPU",
    "user": "chengyuma",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-24T02:51:52Z",
    "closed_at": "2025-02-24T09:15:51Z",
    "merged_at": "2025-02-24T09:15:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3177"
  },
  {
    "number": 3176,
    "title": "fix temperature=0",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-24T02:50:42Z",
    "closed_at": "2025-02-24T08:43:18Z",
    "merged_at": "2025-02-24T08:43:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3176"
  },
  {
    "number": 3174,
    "title": "Update qwen2.py",
    "user": "GxjGit",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-22T09:16:53Z",
    "closed_at": "2025-02-24T04:35:57Z",
    "merged_at": "2025-02-24T04:35:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3174"
  },
  {
    "number": 3166,
    "title": "fix default temperature value",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-20T13:15:16Z",
    "closed_at": "2025-02-20T15:14:20Z",
    "merged_at": "2025-02-20T15:14:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3166"
  },
  {
    "number": 3164,
    "title": "refactor attn param",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-20T10:40:56Z",
    "closed_at": "2025-03-21T10:08:58Z",
    "merged_at": "2025-03-21T10:08:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3164"
  },
  {
    "number": 3163,
    "title": "Add collective communication kernels",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-20T10:22:27Z",
    "closed_at": "2025-03-03T10:29:18Z",
    "merged_at": "2025-03-03T10:29:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3163"
  },
  {
    "number": 3161,
    "title": "fix async forward",
    "user": "lz1998",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-19T17:51:05Z",
    "closed_at": "2025-02-27T02:21:24Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3161"
  },
  {
    "number": 3158,
    "title": "Use pad_token_id as image_token_id for vl models",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-19T09:14:23Z",
    "closed_at": "2025-02-21T09:30:18Z",
    "merged_at": "2025-02-21T09:30:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3158"
  },
  {
    "number": 3156,
    "title": "Fix tool call prompt for InternLM and Qwen",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-19T08:15:16Z",
    "closed_at": "2025-02-21T10:47:12Z",
    "merged_at": "2025-02-21T10:47:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3156"
  },
  {
    "number": 3155,
    "title": "Optimized: Eliminate redundant variable re-assignments for better run",
    "user": "fyh2001",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-19T07:52:52Z",
    "closed_at": "2025-02-20T06:58:07Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3155"
  },
  {
    "number": 3153,
    "title": "fix typing",
    "user": "lz1998",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-18T19:07:48Z",
    "closed_at": "2025-02-19T04:50:05Z",
    "merged_at": "2025-02-19T04:50:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3153"
  },
  {
    "number": 3151,
    "title": "[ci] testcase refactoring",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-18T10:58:56Z",
    "closed_at": "2025-02-27T05:35:17Z",
    "merged_at": "2025-02-27T05:35:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3151"
  },
  {
    "number": 3150,
    "title": "fix min length penalty",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-18T10:29:57Z",
    "closed_at": "2025-02-20T15:08:35Z",
    "merged_at": "2025-02-20T15:08:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3150"
  },
  {
    "number": 3149,
    "title": "[Feature] support deepseek-vl2 for pytorch engine",
    "user": "CUHKSZzxy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-17T13:09:21Z",
    "closed_at": "2025-02-24T10:55:06Z",
    "merged_at": "2025-02-24T10:55:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3149"
  },
  {
    "number": 3148,
    "title": "fix the issue that stop_token may be less than defined in model.py",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-17T09:54:00Z",
    "closed_at": "2025-02-17T12:22:25Z",
    "merged_at": "2025-02-17T12:22:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3148"
  },
  {
    "number": 3147,
    "title": "PytorchEngine multi-node support v2",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-17T08:54:16Z",
    "closed_at": "2025-03-03T10:30:48Z",
    "merged_at": "2025-03-03T10:30:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3147"
  },
  {
    "number": 3146,
    "title": "Support GRPO",
    "user": "tastelikefeet",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-16T05:10:08Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3146"
  },
  {
    "number": 3142,
    "title": "Update runtime package dependencies",
    "user": "zgjja",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-14T05:38:32Z",
    "closed_at": "2025-02-19T10:56:43Z",
    "merged_at": "2025-02-19T10:56:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3142"
  },
  {
    "number": 3137,
    "title": "Fix cogvlm and phi3vision",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-12T12:37:59Z",
    "closed_at": "2025-02-13T04:05:34Z",
    "merged_at": "2025-02-13T04:05:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3137"
  },
  {
    "number": 3136,
    "title": "[fix] fix vl gradio, use pipeline api and remove interactive chat",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-12T08:54:44Z",
    "closed_at": "2025-02-17T09:14:05Z",
    "merged_at": "2025-02-17T09:14:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3136"
  },
  {
    "number": 3134,
    "title": "[ci] fix some fail in daily testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-12T05:44:07Z",
    "closed_at": "2025-02-12T13:26:37Z",
    "merged_at": "2025-02-12T13:26:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3134"
  },
  {
    "number": 3126,
    "title": "Mutual exclusion for vision encoder & LLM",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-10T08:20:15Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3126"
  },
  {
    "number": 3125,
    "title": "Fix UT of deepseek chat template",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-10T07:51:13Z",
    "closed_at": "2025-02-10T11:56:52Z",
    "merged_at": "2025-02-10T11:56:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3125"
  },
  {
    "number": 3123,
    "title": "Correct PYTHON_VERSION syntax",
    "user": "yoonghm",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-09T04:00:41Z",
    "closed_at": "2025-02-09T04:06:58Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3123"
  },
  {
    "number": 3122,
    "title": "Fix internvl2.5 error after eviction",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-08T12:33:45Z",
    "closed_at": "2025-02-11T07:07:35Z",
    "merged_at": "2025-02-11T07:07:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3122"
  },
  {
    "number": 3115,
    "title": "bump version to v0.7.0.post3",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-07T06:44:47Z",
    "closed_at": "2025-02-10T05:59:34Z",
    "merged_at": "2025-02-10T05:59:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3115"
  },
  {
    "number": 3110,
    "title": "Update benchmark script and user guide",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-06T06:30:34Z",
    "closed_at": "2025-02-10T07:51:52Z",
    "merged_at": "2025-02-10T07:51:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3110"
  },
  {
    "number": 3109,
    "title": "remove logitswarper",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-02-06T03:27:55Z",
    "closed_at": "2025-02-06T16:10:05Z",
    "merged_at": "2025-02-06T16:10:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3109"
  },
  {
    "number": 3103,
    "title": "[Fix] fix the URL judgment problem in Windows",
    "user": "Lychee-acaca",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-30T00:00:06Z",
    "closed_at": "2025-02-06T03:46:13Z",
    "merged_at": "2025-02-06T03:46:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3103"
  },
  {
    "number": 3094,
    "title": "bump version to v0.7.0.post2",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-27T10:27:59Z",
    "closed_at": "2025-01-27T15:56:41Z",
    "merged_at": "2025-01-27T15:56:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3094"
  },
  {
    "number": 3088,
    "title": "fix user guide about cogvlm deployment",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-24T06:52:16Z",
    "closed_at": "2025-02-06T03:42:35Z",
    "merged_at": "2025-02-06T03:42:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3088"
  },
  {
    "number": 3087,
    "title": "Fix xcomposer2d5",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-24T06:23:16Z",
    "closed_at": "2025-01-27T14:51:04Z",
    "merged_at": "2025-01-27T14:51:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3087"
  },
  {
    "number": 3086,
    "title": "fix postional argument",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-24T06:11:00Z",
    "closed_at": "2025-02-07T08:12:03Z",
    "merged_at": "2025-02-07T08:12:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3086"
  },
  {
    "number": 3085,
    "title": "support ascend 310P",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-24T05:59:27Z",
    "closed_at": "2025-04-16T02:15:07Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3085"
  },
  {
    "number": 3077,
    "title": "More arguments in api_client, update docstrings",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-23T03:01:38Z",
    "closed_at": "2025-01-23T06:25:40Z",
    "merged_at": "2025-01-23T06:25:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3077"
  },
  {
    "number": 3076,
    "title": "bump version to v0.7.0.post1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-22T12:39:02Z",
    "closed_at": "2025-01-25T10:42:35Z",
    "merged_at": "2025-01-25T10:42:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3076"
  },
  {
    "number": 3074,
    "title": "fix error in interactive api",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-22T10:40:13Z",
    "closed_at": "2025-01-23T02:43:56Z",
    "merged_at": "2025-01-23T02:43:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3074"
  },
  {
    "number": 3072,
    "title": "Add deepseek-r1 chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-22T03:29:35Z",
    "closed_at": "2025-01-27T07:11:57Z",
    "merged_at": "2025-01-27T07:11:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3072"
  },
  {
    "number": 3069,
    "title": "support release pipeline",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-21T12:58:32Z",
    "closed_at": "2025-02-13T04:00:20Z",
    "merged_at": "2025-02-13T04:00:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3069"
  },
  {
    "number": 3068,
    "title": "fix sliding window mgr",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-21T10:44:40Z",
    "closed_at": "2025-01-23T05:59:50Z",
    "merged_at": "2025-01-23T05:59:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3068"
  },
  {
    "number": 3067,
    "title": "[feat][dlinfer] camb w8a8 support ",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-21T10:40:59Z",
    "closed_at": "2025-02-28T02:58:17Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3067"
  },
  {
    "number": 3061,
    "title": "Update tokenizer",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-21T06:39:56Z",
    "closed_at": "2025-01-27T07:12:23Z",
    "merged_at": "2025-01-27T07:12:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3061"
  },
  {
    "number": 3059,
    "title": "fix: replace inf with max or min finite value, then do softmax",
    "user": "KenForever1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-21T04:17:26Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3059"
  },
  {
    "number": 3052,
    "title": "optimize safetensors weight loading",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-20T06:03:45Z",
    "closed_at": "2025-01-20T08:30:55Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3052"
  },
  {
    "number": 3051,
    "title": "Torch multinode",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-20T03:05:21Z",
    "closed_at": "2025-02-17T08:54:50Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3051"
  },
  {
    "number": 3045,
    "title": "[dlinfer] fix ascend qwen2_vl graph_mode",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-16T11:55:10Z",
    "closed_at": "2025-01-22T12:14:46Z",
    "merged_at": "2025-01-22T12:14:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3045"
  },
  {
    "number": 3044,
    "title": "support eos_token list in turbomind",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-16T11:53:13Z",
    "closed_at": "2025-02-17T06:00:17Z",
    "merged_at": "2025-02-17T06:00:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3044"
  },
  {
    "number": 3041,
    "title": "add internlm3 to supported models",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-16T10:44:23Z",
    "closed_at": "2025-01-16T10:51:27Z",
    "merged_at": "2025-01-16T10:51:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3041"
  },
  {
    "number": 3039,
    "title": "remove watchdog daemon",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-16T02:37:06Z",
    "closed_at": "2025-04-01T07:47:05Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3039"
  },
  {
    "number": 3038,
    "title": "[ci] add internlm3 into testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-15T11:08:30Z",
    "closed_at": "2025-01-16T05:49:41Z",
    "merged_at": "2025-01-16T05:49:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3038"
  },
  {
    "number": 3034,
    "title": "Fix empty response for pipeline",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-15T06:43:56Z",
    "closed_at": "2025-01-15T06:45:57Z",
    "merged_at": "2025-01-15T06:45:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3034"
  },
  {
    "number": 3033,
    "title": "Fix potential hang during TP model initialization",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-15T05:41:38Z",
    "closed_at": "2025-01-15T06:47:53Z",
    "merged_at": "2025-01-15T06:47:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3033"
  },
  {
    "number": 3031,
    "title": "Add system role to deepseek chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-15T02:34:15Z",
    "closed_at": "2025-01-27T07:13:06Z",
    "merged_at": "2025-01-27T07:13:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3031"
  },
  {
    "number": 3030,
    "title": "Fix MoE gating for DeepSeek V2",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-14T09:00:06Z",
    "closed_at": "2025-01-15T02:59:18Z",
    "merged_at": "2025-01-15T02:59:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3030"
  },
  {
    "number": 3029,
    "title": "Fix async engine",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-14T08:58:40Z",
    "closed_at": "2025-01-14T09:11:51Z",
    "merged_at": "2025-01-14T09:11:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3029"
  },
  {
    "number": 3027,
    "title": "Support internlm3 quantization",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-14T08:44:31Z",
    "closed_at": "2025-01-14T15:55:47Z",
    "merged_at": "2025-01-14T15:55:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3027"
  },
  {
    "number": 3026,
    "title": "support internlm3 on pt",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-14T07:51:01Z",
    "closed_at": "2025-01-14T11:42:10Z",
    "merged_at": "2025-01-14T11:42:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3026"
  },
  {
    "number": 3024,
    "title": "add internlm3-dense(turbomind) & chat template",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-14T07:45:35Z",
    "closed_at": "2025-01-14T10:28:19Z",
    "merged_at": "2025-01-14T10:28:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3024"
  },
  {
    "number": 3023,
    "title": "[hotfix] Fix get_ppl",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-14T07:21:34Z",
    "closed_at": "2025-01-14T10:07:50Z",
    "merged_at": "2025-01-14T10:07:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3023"
  },
  {
    "number": 3020,
    "title": "Use aiohttp inside proxy server && add --disable-cache-status argument",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-13T10:09:53Z",
    "closed_at": "2025-02-17T06:05:25Z",
    "merged_at": "2025-02-17T06:05:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3020"
  },
  {
    "number": 3018,
    "title": "Fix typo in w4a16 guide",
    "user": "Yan-Xiangjun",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-13T07:56:15Z",
    "closed_at": "2025-01-13T09:02:54Z",
    "merged_at": "2025-01-13T09:02:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3018"
  },
  {
    "number": 3016,
    "title": "remove decoding",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-13T06:01:01Z",
    "closed_at": "2025-01-14T04:26:32Z",
    "merged_at": "2025-01-14T04:26:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3016"
  },
  {
    "number": 3011,
    "title": "Update w4a16.md",
    "user": "Yan-Xiangjun",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-12T10:48:35Z",
    "closed_at": "2025-01-13T09:03:22Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3011"
  },
  {
    "number": 3010,
    "title": "bump version to v0.7.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-12T08:53:53Z",
    "closed_at": "2025-01-15T10:03:51Z",
    "merged_at": "2025-01-15T10:03:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3010"
  },
  {
    "number": 3009,
    "title": "fix blocked fp8 moe kernel",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-10T13:30:53Z",
    "closed_at": "2025-01-13T09:46:14Z",
    "merged_at": "2025-01-13T09:46:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3009"
  },
  {
    "number": 3008,
    "title": "Fix get_ppl & get_logits",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-09T13:12:33Z",
    "closed_at": "2025-01-13T08:53:15Z",
    "merged_at": "2025-01-13T08:53:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3008"
  },
  {
    "number": 3007,
    "title": "support-moe-fp8",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-09T08:10:38Z",
    "closed_at": "2025-01-13T10:17:58Z",
    "merged_at": "2025-01-13T10:17:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3007"
  },
  {
    "number": 3002,
    "title": "support new backend cambricon",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-09T03:30:08Z",
    "closed_at": "2025-01-13T08:54:35Z",
    "merged_at": "2025-01-13T08:54:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3002"
  },
  {
    "number": 3001,
    "title": "fix xcomposer2 when transformers is upgraded greater than 4.46 ",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-08T13:03:48Z",
    "closed_at": "2025-01-11T04:38:27Z",
    "merged_at": "2025-01-11T04:38:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3001"
  },
  {
    "number": 2998,
    "title": "[CI] add daily testcase on 4090",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-08T08:48:04Z",
    "closed_at": "2025-01-16T04:01:48Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2998"
  },
  {
    "number": 2994,
    "title": "logit bias to lmdeploy",
    "user": "sunny3",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-07T21:38:13Z",
    "closed_at": "2025-01-07T21:38:29Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2994"
  },
  {
    "number": 2992,
    "title": "Wt/camb/good",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-07T08:11:13Z",
    "closed_at": "2025-01-07T08:11:25Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2992"
  },
  {
    "number": 2991,
    "title": "Expose spaces_between_special_tokens",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-07T02:34:35Z",
    "closed_at": "2025-01-12T09:33:48Z",
    "merged_at": "2025-01-12T09:33:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2991"
  },
  {
    "number": 2989,
    "title": "Fix ascend dockerfile",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-05T15:37:59Z",
    "closed_at": "2025-01-06T07:18:35Z",
    "merged_at": "2025-01-06T07:18:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2989"
  },
  {
    "number": 2988,
    "title": "[feature] add dlinfer w8a8 support.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-04T08:22:40Z",
    "closed_at": "2025-02-17T07:58:51Z",
    "merged_at": "2025-02-17T07:58:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2988"
  },
  {
    "number": 2987,
    "title": "fix internvl2 qk norm",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-03T11:24:08Z",
    "closed_at": "2025-01-07T12:55:29Z",
    "merged_at": "2025-01-07T12:55:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2987"
  },
  {
    "number": 2986,
    "title": "add block_size arg to chat api",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-03T09:41:49Z",
    "closed_at": "2025-01-13T09:33:05Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2986"
  },
  {
    "number": 2984,
    "title": "[dlinfer]rope refine",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-02T10:58:40Z",
    "closed_at": "2025-01-12T09:21:07Z",
    "merged_at": "2025-01-12T09:21:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2984"
  },
  {
    "number": 2981,
    "title": "Update request logger",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-31T10:49:35Z",
    "closed_at": "2025-01-14T03:02:17Z",
    "merged_at": "2025-01-14T03:02:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2981"
  },
  {
    "number": 2980,
    "title": "add internvl2.5-78b mmmu evaluation for testing",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-31T10:29:11Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2980"
  },
  {
    "number": 2979,
    "title": "add tool role in BaseChatTemplate as tool response in messages",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-31T09:45:44Z",
    "closed_at": "2025-01-02T04:56:51Z",
    "merged_at": "2025-01-02T04:56:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2979"
  },
  {
    "number": 2978,
    "title": "[dlinfer]rope refine",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-31T03:36:24Z",
    "closed_at": "2025-01-06T08:37:40Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2978"
  },
  {
    "number": 2977,
    "title": "[dlinfer]change llm op interface of paged_prefill_attention.",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-31T03:31:33Z",
    "closed_at": "2025-01-13T08:53:49Z",
    "merged_at": "2025-01-13T08:53:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2977"
  },
  {
    "number": 2976,
    "title": "[side-effect] fix gradio demo error",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-30T08:41:51Z",
    "closed_at": "2024-12-30T10:13:08Z",
    "merged_at": "2024-12-30T10:13:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2976"
  },
  {
    "number": 2975,
    "title": "Optimize lora kernel",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-30T08:19:17Z",
    "closed_at": "2025-01-03T11:34:38Z",
    "merged_at": "2025-01-03T11:34:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2975"
  },
  {
    "number": 2972,
    "title": "[dlinfer]add camb support",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-30T03:21:15Z",
    "closed_at": "2024-12-30T03:21:21Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2972"
  },
  {
    "number": 2970,
    "title": "add a thread pool executor to control the vl engine traffic",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-28T13:45:50Z",
    "closed_at": "2024-12-29T09:14:31Z",
    "merged_at": "2024-12-29T09:14:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2970"
  },
  {
    "number": 2968,
    "title": "Refactor async engine & turbomind IO",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-27T11:34:23Z",
    "closed_at": "2025-01-10T17:00:49Z",
    "merged_at": "2025-01-10T17:00:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2968"
  },
  {
    "number": 2967,
    "title": "Support DeepseekV3 fp8",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-27T11:16:07Z",
    "closed_at": "2025-01-08T03:54:34Z",
    "merged_at": "2025-01-08T03:54:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2967"
  },
  {
    "number": 2965,
    "title": "Optimize awq kernel in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-27T09:41:20Z",
    "closed_at": "2024-12-31T10:50:22Z",
    "merged_at": "2024-12-31T10:50:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2965"
  },
  {
    "number": 2964,
    "title": "Fix build crash in nvcr.io/nvidia/pytorch:24.06-py3 image",
    "user": "zgjja",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-27T06:34:55Z",
    "closed_at": "2024-12-30T13:33:46Z",
    "merged_at": "2024-12-30T13:33:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2964"
  },
  {
    "number": 2961,
    "title": "Set max concurrent requests",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-26T09:40:10Z",
    "closed_at": "2025-02-02T13:58:01Z",
    "merged_at": "2025-02-02T13:58:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2961"
  },
  {
    "number": 2959,
    "title": "Support fp8 w8a8 for pt backend",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-26T07:27:41Z",
    "closed_at": "2025-01-03T05:33:22Z",
    "merged_at": "2025-01-03T05:33:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2959"
  },
  {
    "number": 2956,
    "title": "Fix torch_dtype in lite",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-25T13:54:49Z",
    "closed_at": "2024-12-26T06:42:47Z",
    "merged_at": "2024-12-26T06:42:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2956"
  },
  {
    "number": 2955,
    "title": "Bump version to v0.6.5",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-25T11:55:32Z",
    "closed_at": "2024-12-30T10:14:28Z",
    "merged_at": "2024-12-30T10:14:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2955"
  },
  {
    "number": 2954,
    "title": "[side-effect] bring back quantization of qwen2-vl, glm4v and etc.",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-25T11:17:26Z",
    "closed_at": "2024-12-26T12:55:20Z",
    "merged_at": "2024-12-26T12:55:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2954"
  },
  {
    "number": 2953,
    "title": "Fallback to pytorch engine when the model is quantized by smooth quant",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-25T08:13:20Z",
    "closed_at": "2024-12-26T03:16:45Z",
    "merged_at": "2024-12-26T03:16:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2953"
  },
  {
    "number": 2952,
    "title": "[dlinfer] feat: add DlinferFlashAttention to support qwen vl.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-25T08:13:17Z",
    "closed_at": "2024-12-26T03:39:17Z",
    "merged_at": "2024-12-26T03:39:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2952"
  },
  {
    "number": 2949,
    "title": "[ci] add w8a8 and internvl2.5 models into testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-24T11:58:48Z",
    "closed_at": "2024-12-31T09:16:54Z",
    "merged_at": "2024-12-31T09:16:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2949"
  },
  {
    "number": 2947,
    "title": "fix mllama inference without image",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-24T10:38:31Z",
    "closed_at": "2024-12-25T02:29:22Z",
    "merged_at": "2024-12-25T02:29:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2947"
  },
  {
    "number": 2944,
    "title": "fix mllama inference without image",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-24T06:43:53Z",
    "closed_at": "2024-12-24T10:59:07Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2944"
  },
  {
    "number": 2943,
    "title": "[qwen2]fix build rotary_params",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-24T02:45:22Z",
    "closed_at": "2024-12-24T04:25:54Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2943"
  },
  {
    "number": 2933,
    "title": "fix torch_dtype",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-20T11:31:48Z",
    "closed_at": "2024-12-23T06:06:11Z",
    "merged_at": "2024-12-23T06:06:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2933"
  },
  {
    "number": 2930,
    "title": "support unaligned qkv heads",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-20T03:15:16Z",
    "closed_at": "2024-12-23T12:50:10Z",
    "merged_at": "2024-12-23T12:50:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2930"
  },
  {
    "number": 2928,
    "title": "fix: Incorrect stats size during inference of throughput benchmark when concurrency > num_prompts",
    "user": "pancak3",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-19T08:44:51Z",
    "closed_at": "2024-12-19T14:06:10Z",
    "merged_at": "2024-12-19T14:06:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2928"
  },
  {
    "number": 2922,
    "title": "Wt/camb/good",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-18T10:32:11Z",
    "closed_at": "2024-12-18T10:38:30Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2922"
  },
  {
    "number": 2918,
    "title": "[maca] support deepseekv2 for maca backend.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-18T02:40:47Z",
    "closed_at": "2025-02-19T04:09:01Z",
    "merged_at": "2025-02-19T04:09:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2918"
  },
  {
    "number": 2917,
    "title": "[dlinfer] fix moe op for dlinfer.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-18T02:32:05Z",
    "closed_at": "2024-12-20T11:24:34Z",
    "merged_at": "2024-12-20T11:24:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2917"
  },
  {
    "number": 2916,
    "title": "Fix typo",
    "user": "Juniper1021",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-17T16:21:29Z",
    "closed_at": "2024-12-18T08:26:58Z",
    "merged_at": "2024-12-18T08:26:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2916"
  },
  {
    "number": 2914,
    "title": "[side effect] fix vlm quant failed",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-17T13:35:32Z",
    "closed_at": "2024-12-22T03:56:13Z",
    "merged_at": "2024-12-22T03:56:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2914"
  },
  {
    "number": 2912,
    "title": "fix lora name and rearange wqkv for internlm2",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-17T13:09:51Z",
    "closed_at": "2024-12-20T03:19:47Z",
    "merged_at": "2024-12-20T03:19:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2912"
  },
  {
    "number": 2910,
    "title": "[ci] update triton version",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-17T11:57:59Z",
    "closed_at": "2024-12-19T08:29:34Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2910"
  },
  {
    "number": 2907,
    "title": "Remove threadsafe",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-17T08:58:31Z",
    "closed_at": "2025-01-03T15:26:46Z",
    "merged_at": "2025-01-03T15:26:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2907"
  },
  {
    "number": 2906,
    "title": "unfeeze torch version in dockerfile",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-17T07:53:16Z",
    "closed_at": "2024-12-18T03:52:41Z",
    "merged_at": "2024-12-18T03:52:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2906"
  },
  {
    "number": 2901,
    "title": "Fix exception handler for proxy server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-16T06:16:22Z",
    "closed_at": "2024-12-26T02:59:15Z",
    "merged_at": "2024-12-26T02:59:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2901"
  },
  {
    "number": 2898,
    "title": "Support torch_dtype modification and update FAQs for AWQ quantization",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-16T03:26:23Z",
    "closed_at": "2024-12-25T04:21:01Z",
    "merged_at": "2024-12-25T04:21:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2898"
  },
  {
    "number": 2894,
    "title": "Support moe w8a8 in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-13T13:32:31Z",
    "closed_at": "2024-12-31T06:10:43Z",
    "merged_at": "2024-12-31T06:10:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2894"
  },
  {
    "number": 2893,
    "title": "[dlinfer] only compile the language model in vl models",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-13T10:09:44Z",
    "closed_at": "2024-12-16T07:46:27Z",
    "merged_at": "2024-12-16T07:46:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2893"
  },
  {
    "number": 2891,
    "title": "[dlinfer] fix engine checker",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-13T06:00:05Z",
    "closed_at": "2024-12-13T06:50:22Z",
    "merged_at": "2024-12-13T06:50:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2891"
  },
  {
    "number": 2889,
    "title": "Optimize tp broadcast",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-12T11:05:04Z",
    "closed_at": "2024-12-17T13:40:09Z",
    "merged_at": "2024-12-17T13:40:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2889"
  },
  {
    "number": 2888,
    "title": "Fix args type in docstring",
    "user": "Galaxy-Husky",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-12T09:31:54Z",
    "closed_at": "2024-12-13T03:26:33Z",
    "merged_at": "2024-12-13T03:26:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2888"
  },
  {
    "number": 2886,
    "title": "use weights iterator while loading",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-12T07:41:10Z",
    "closed_at": "2025-01-20T14:08:31Z",
    "merged_at": "2025-01-20T14:08:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2886"
  },
  {
    "number": 2883,
    "title": "support Turbomind ep",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-12T02:38:23Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2883"
  },
  {
    "number": 2881,
    "title": "fix cpu cache",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-11T06:05:14Z",
    "closed_at": "2024-12-12T04:17:59Z",
    "merged_at": "2024-12-12T04:17:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2881"
  },
  {
    "number": 2880,
    "title": "refine multi-backend setup.py",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-10T14:13:58Z",
    "closed_at": "2024-12-13T03:32:58Z",
    "merged_at": "2024-12-13T03:32:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2880"
  },
  {
    "number": 2879,
    "title": "Fix VLM batch inference error",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-10T11:19:25Z",
    "closed_at": "2024-12-10T11:20:33Z",
    "merged_at": "2024-12-10T11:20:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2879"
  },
  {
    "number": 2874,
    "title": "replicate kv for some models when tp is divisble by kv_head_num",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-09T12:58:47Z",
    "closed_at": "2024-12-18T12:48:12Z",
    "merged_at": "2024-12-18T12:48:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2874"
  },
  {
    "number": 2872,
    "title": "support tp > n_kv_heads for pt engine",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-09T08:27:04Z",
    "closed_at": "2024-12-18T11:56:04Z",
    "merged_at": "2024-12-18T11:56:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2872"
  },
  {
    "number": 2870,
    "title": "refactor PyTorchEngine check env",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-09T06:35:28Z",
    "closed_at": "2024-12-12T09:45:14Z",
    "merged_at": "2024-12-12T09:45:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2870"
  },
  {
    "number": 2868,
    "title": "Fix vision model batch inference",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-09T03:44:16Z",
    "closed_at": "2024-12-09T03:45:05Z",
    "merged_at": "2024-12-09T03:45:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2868"
  },
  {
    "number": 2865,
    "title": "Update dlinfer-ascend version in runtime_ascend.txt",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-06T10:50:44Z",
    "closed_at": "2024-12-09T03:39:39Z",
    "merged_at": "2024-12-09T03:39:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2865"
  },
  {
    "number": 2864,
    "title": "bump version to v0.6.4",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-06T10:40:09Z",
    "closed_at": "2024-12-09T12:07:44Z",
    "merged_at": "2024-12-09T12:07:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2864"
  },
  {
    "number": 2862,
    "title": "Fix llama3.1 chat template",
    "user": "fzyzcjy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-06T03:29:12Z",
    "closed_at": "2024-12-16T04:14:40Z",
    "merged_at": "2024-12-16T04:14:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2862"
  },
  {
    "number": 2860,
    "title": "[Feature] Support for loading lora adapter weights in safetensors format",
    "user": "Galaxy-Husky",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-05T10:23:08Z",
    "closed_at": "2024-12-09T13:43:07Z",
    "merged_at": "2024-12-09T13:43:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2860"
  },
  {
    "number": 2859,
    "title": "Support Medusa speculative decoding",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-05T06:29:38Z",
    "closed_at": "2025-09-08T04:11:59Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2859"
  },
  {
    "number": 2854,
    "title": "Update pytorch engine w8a8 supported model list",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-04T07:00:05Z",
    "closed_at": "2024-12-04T07:13:37Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2854"
  },
  {
    "number": 2853,
    "title": "[ascend] convert kv cache to nd format in ascend graph mode",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-04T06:38:21Z",
    "closed_at": "2024-12-04T11:48:31Z",
    "merged_at": "2024-12-04T11:48:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2853"
  },
  {
    "number": 2850,
    "title": "Supports W8A8 quantization for more models",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-03T07:34:44Z",
    "closed_at": "2024-12-04T05:39:05Z",
    "merged_at": "2024-12-04T05:39:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2850"
  },
  {
    "number": 2849,
    "title": "update supported models",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-03T06:43:26Z",
    "closed_at": "2024-12-06T10:39:01Z",
    "merged_at": "2024-12-06T10:39:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2849"
  },
  {
    "number": 2848,
    "title": "check whether backend_config is None or not before accessing its attr",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-03T03:50:22Z",
    "closed_at": "2024-12-03T06:45:58Z",
    "merged_at": "2024-12-03T06:45:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2848"
  },
  {
    "number": 2847,
    "title": "[dlinfer] change dlinfer kv_cache layout and ajust paged_prefill_attention api.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-03T02:37:13Z",
    "closed_at": "2024-12-03T08:44:36Z",
    "merged_at": "2024-12-03T08:44:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2847"
  },
  {
    "number": 2845,
    "title": "fix accessing before initialization",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-02T07:02:38Z",
    "closed_at": "2024-12-02T08:09:00Z",
    "merged_at": "2024-12-02T08:09:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2845"
  },
  {
    "number": 2844,
    "title": "fix the logic to verify whether AutoAWQ has been successfully installed",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-02T06:26:04Z",
    "closed_at": "2024-12-03T06:44:22Z",
    "merged_at": "2024-12-03T06:44:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2844"
  },
  {
    "number": 2842,
    "title": "Fix gemma2 accuracy through the correct softcapping logic",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-02T03:35:57Z",
    "closed_at": "2024-12-02T07:26:29Z",
    "merged_at": "2024-12-02T07:26:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2842"
  },
  {
    "number": 2836,
    "title": "Add version restrictions in runtime_ascend.txt to ensure functionality",
    "user": "zhabuye",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-30T03:01:34Z",
    "closed_at": "2024-12-02T06:01:05Z",
    "merged_at": "2024-12-02T06:01:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2836"
  },
  {
    "number": 2835,
    "title": "[maca] add env to support different mm layout on maca.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-29T08:17:28Z",
    "closed_at": "2024-12-03T08:45:35Z",
    "merged_at": "2024-12-03T08:45:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2835"
  },
  {
    "number": 2834,
    "title": "[maca] add cudagraph support on maca backend.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-29T08:16:28Z",
    "closed_at": "2025-01-22T09:26:34Z",
    "merged_at": "2025-01-22T09:26:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2834"
  },
  {
    "number": 2833,
    "title": "[maca] opt update_step_ctx on maca.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-29T08:13:52Z",
    "closed_at": "2024-11-29T10:14:23Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2833"
  },
  {
    "number": 2832,
    "title": "Update internvl chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-29T07:06:32Z",
    "closed_at": "2024-12-02T11:22:01Z",
    "merged_at": "2024-12-02T11:22:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2832"
  },
  {
    "number": 2830,
    "title": "add openssh-server installation in dockerfile",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-28T07:08:08Z",
    "closed_at": "2024-12-02T05:58:28Z",
    "merged_at": "2024-12-02T05:58:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2830"
  },
  {
    "number": 2826,
    "title": "profile throughput without new threads",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-28T02:18:42Z",
    "closed_at": "2024-12-03T03:14:35Z",
    "merged_at": "2024-12-03T03:14:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2826"
  },
  {
    "number": 2825,
    "title": "disable prefix-caching for vl model",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-27T08:12:52Z",
    "closed_at": "2024-11-27T11:17:17Z",
    "merged_at": "2024-11-27T11:17:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2825"
  },
  {
    "number": 2818,
    "title": "Refactor turbomind (2/N)",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-26T09:15:27Z",
    "closed_at": "2024-11-29T10:43:47Z",
    "merged_at": "2024-11-29T10:43:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2818"
  },
  {
    "number": 2817,
    "title": "Add Ascend installation adapter",
    "user": "zhabuye",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-26T08:15:18Z",
    "closed_at": "2024-11-29T08:37:29Z",
    "merged_at": "2024-11-29T08:37:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2817"
  },
  {
    "number": 2814,
    "title": "better kv allocate",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-26T05:17:21Z",
    "closed_at": "2024-12-02T08:18:44Z",
    "merged_at": "2024-12-02T08:18:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2814"
  },
  {
    "number": 2813,
    "title": "minor-fix",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-25T14:04:31Z",
    "closed_at": "2024-11-25T14:04:44Z",
    "merged_at": "2024-11-25T14:04:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2813"
  },
  {
    "number": 2812,
    "title": "Resolve conflicts",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-25T13:31:43Z",
    "closed_at": "2024-11-25T13:33:08Z",
    "merged_at": "2024-11-25T13:33:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2812"
  },
  {
    "number": 2811,
    "title": "Resolve conflicts",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-25T13:25:46Z",
    "closed_at": "2024-11-25T13:26:26Z",
    "merged_at": "2024-11-25T13:26:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2811"
  },
  {
    "number": 2810,
    "title": "Refactor VLM modules",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-25T13:09:57Z",
    "closed_at": "2024-12-13T11:05:24Z",
    "merged_at": "2024-12-13T11:05:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2810"
  },
  {
    "number": 2809,
    "title": "Remove vl template",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-25T13:06:27Z",
    "closed_at": "2024-11-25T13:06:55Z",
    "merged_at": "2024-11-25T13:06:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2809"
  },
  {
    "number": 2806,
    "title": "Refactor VLM modules v2",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-25T10:41:55Z",
    "closed_at": "2024-11-25T10:51:31Z",
    "merged_at": "2024-11-25T10:51:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2806"
  },
  {
    "number": 2804,
    "title": "Optimize update_step_ctx on Ascend",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-25T07:55:23Z",
    "closed_at": "2024-11-25T12:30:59Z",
    "merged_at": "2024-11-25T12:30:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2804"
  },
  {
    "number": 2801,
    "title": "Refactor turbomind attention by precomputing rotary embed",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-25T03:34:58Z",
    "closed_at": "2025-07-17T11:52:21Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2801"
  },
  {
    "number": 2797,
    "title": "Refactor VLM modules for internvl-llava",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-22T10:52:08Z",
    "closed_at": "2024-11-22T10:52:33Z",
    "merged_at": "2024-11-22T10:52:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2797"
  },
  {
    "number": 2796,
    "title": "Refactor VLM modules for xcomposer series",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-22T10:01:44Z",
    "closed_at": "2024-11-22T10:01:56Z",
    "merged_at": "2024-11-22T10:01:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2796"
  },
  {
    "number": 2795,
    "title": "[dlinfer] Fix qwenvl rope error for dlinfer backend",
    "user": "JackWeiw",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-22T08:45:06Z",
    "closed_at": "2024-11-25T10:33:24Z",
    "merged_at": "2024-11-25T10:33:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2795"
  },
  {
    "number": 2794,
    "title": "Refactor VLM module for minicpm and molmo",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-22T07:21:00Z",
    "closed_at": "2024-11-22T07:43:49Z",
    "merged_at": "2024-11-22T07:43:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2794"
  },
  {
    "number": 2791,
    "title": "[CI] add more testcase for mllm models",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-22T02:23:07Z",
    "closed_at": "2024-11-29T09:54:46Z",
    "merged_at": "2024-11-29T09:54:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2791"
  },
  {
    "number": 2787,
    "title": "Support qwen2-vl AWQ quantization",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-21T06:28:30Z",
    "closed_at": "2024-11-25T10:21:13Z",
    "merged_at": "2024-11-25T10:21:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2787"
  },
  {
    "number": 2783,
    "title": "[Feature] Support llava onevision",
    "user": "deepindeed2022",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-21T03:06:45Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2783"
  },
  {
    "number": 2781,
    "title": "Refactor VL modules for mllama and yi-vl",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-20T09:57:58Z",
    "closed_at": "2024-11-20T09:58:17Z",
    "merged_at": "2024-11-20T09:58:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2781"
  },
  {
    "number": 2779,
    "title": "Refactor VL modules for phi3-vision",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-20T08:56:35Z",
    "closed_at": "2024-11-20T09:55:21Z",
    "merged_at": "2024-11-20T09:55:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2779"
  },
  {
    "number": 2778,
    "title": "Fix side-effect to internvl",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-20T08:32:25Z",
    "closed_at": "2024-11-20T08:32:41Z",
    "merged_at": "2024-11-20T08:32:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2778"
  },
  {
    "number": 2777,
    "title": "Refactor VL modules for qwen2-vl",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-20T08:00:52Z",
    "closed_at": "2024-11-20T08:01:24Z",
    "merged_at": "2024-11-20T08:01:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2777"
  },
  {
    "number": 2773,
    "title": "Refactor VL modules for qwen-vl, llava and llava_next",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-19T12:49:07Z",
    "closed_at": "2024-11-20T07:33:31Z",
    "merged_at": "2024-11-20T07:33:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2773"
  },
  {
    "number": 2772,
    "title": "Refactor VL modules for glm4v, deepseek-vl, llava-hf, cogvlm",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-19T08:50:22Z",
    "closed_at": "2024-11-19T11:51:55Z",
    "merged_at": "2024-11-19T11:51:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2772"
  },
  {
    "number": 2767,
    "title": "[Feature] support minicpm-v_2_6 for pytorch engine.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-18T02:49:13Z",
    "closed_at": "2024-11-21T11:01:12Z",
    "merged_at": "2024-11-21T11:01:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2767"
  },
  {
    "number": 2765,
    "title": "Update supported models & Ascend doc",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-17T15:58:39Z",
    "closed_at": "2024-11-19T09:58:25Z",
    "merged_at": "2024-11-19T09:58:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2765"
  },
  {
    "number": 2764,
    "title": "refactor VL modules for internvl and qwen2-vl",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-17T15:29:19Z",
    "closed_at": "2024-11-18T13:28:43Z",
    "merged_at": "2024-11-18T13:28:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2764"
  },
  {
    "number": 2763,
    "title": "Add DeepSeek-V2 support",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-17T15:04:46Z",
    "closed_at": "2024-11-29T02:37:42Z",
    "merged_at": "2024-11-29T02:37:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2763"
  },
  {
    "number": 2761,
    "title": "set wrong head_dim for mistral-nemo",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-15T10:10:41Z",
    "closed_at": "2024-11-15T11:19:23Z",
    "merged_at": "2024-11-15T11:19:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2761"
  },
  {
    "number": 2758,
    "title": "Remove use_fast=True when loading tokenizer for lite auto_awq",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-14T11:59:46Z",
    "closed_at": "2024-11-14T16:42:28Z",
    "merged_at": "2024-11-14T16:42:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2758"
  },
  {
    "number": 2756,
    "title": "Update ascend readme",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-14T02:45:37Z",
    "closed_at": "2024-11-14T05:12:40Z",
    "merged_at": "2024-11-14T05:12:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2756"
  },
  {
    "number": 2755,
    "title": "feat: support multi cards in ascend graph mode",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-14T01:05:55Z",
    "closed_at": "2024-11-14T06:29:59Z",
    "merged_at": "2024-11-14T06:29:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2755"
  },
  {
    "number": 2754,
    "title": "bump version to v0.6.3",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-13T16:21:15Z",
    "closed_at": "2024-11-16T04:29:24Z",
    "merged_at": "2024-11-16T04:29:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2754"
  },
  {
    "number": 2751,
    "title": "[CI] Split vl testcases into turbomind and pytorch backend",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-13T10:26:14Z",
    "closed_at": "2024-11-19T10:04:40Z",
    "merged_at": "2024-11-19T10:04:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2751"
  },
  {
    "number": 2744,
    "title": "fix issue that mono-internvl failed to fallback pytorch engine",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-13T04:24:14Z",
    "closed_at": "2024-11-13T09:38:47Z",
    "merged_at": "2024-11-13T09:38:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2744"
  },
  {
    "number": 2742,
    "title": "PytorchEngine refactor multimodal",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-12T10:16:24Z",
    "closed_at": "2024-11-25T13:48:34Z",
    "merged_at": "2024-11-25T13:48:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2742"
  },
  {
    "number": 2741,
    "title": "optimize dlinfer moe",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-12T08:48:26Z",
    "closed_at": "2024-11-13T10:39:59Z",
    "merged_at": "2024-11-13T10:39:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2741"
  },
  {
    "number": 2740,
    "title": "fix assert pad >= 0 failed when inter_size is not a multiple of group",
    "user": "Vinkle-hzt",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-12T06:40:10Z",
    "closed_at": "2024-11-12T13:15:09Z",
    "merged_at": "2024-11-12T13:15:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2740"
  },
  {
    "number": 2738,
    "title": "Support chemvlm",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-11T10:58:04Z",
    "closed_at": "2024-11-14T03:34:13Z",
    "merged_at": "2024-11-14T03:34:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2738"
  },
  {
    "number": 2737,
    "title": "feature: support qwen2.5 function_call",
    "user": "akai-shuuichi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-11T07:33:22Z",
    "closed_at": "2024-11-19T03:21:58Z",
    "merged_at": "2024-11-19T03:21:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2737"
  },
  {
    "number": 2736,
    "title": "[ascend]feat: support kv int8",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-11T07:10:14Z",
    "closed_at": "2024-12-06T02:49:57Z",
    "merged_at": "2024-12-06T02:49:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2736"
  },
  {
    "number": 2727,
    "title": "Support Mono-InternVL with PyTorch backend",
    "user": "wzk1015",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-07T16:20:06Z",
    "closed_at": "2024-11-11T03:09:44Z",
    "merged_at": "2024-11-11T03:09:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2727"
  },
  {
    "number": 2725,
    "title": "Support mixtral moe AWQ quantization.",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-07T10:37:50Z",
    "closed_at": "2024-11-13T04:21:29Z",
    "merged_at": "2024-11-13T04:21:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2725"
  },
  {
    "number": 2723,
    "title": "Support Qwen2-MoE models",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-07T07:37:23Z",
    "closed_at": "2024-11-13T03:27:26Z",
    "merged_at": "2024-11-13T03:27:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2723"
  },
  {
    "number": 2721,
    "title": "[ci] add more testcase into evaluation and daily test",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-06T06:48:59Z",
    "closed_at": "2024-11-11T07:19:59Z",
    "merged_at": "2024-11-11T07:19:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2721"
  },
  {
    "number": 2720,
    "title": "support qwen2-vl with turbomind backend",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-06T03:19:13Z",
    "closed_at": "2025-09-08T04:13:56Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2720"
  },
  {
    "number": 2719,
    "title": "Check server input",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-06T03:17:47Z",
    "closed_at": "2024-11-13T07:37:54Z",
    "merged_at": "2024-11-13T07:37:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2719"
  },
  {
    "number": 2718,
    "title": "fix tp exit code for pytorch engine",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-06T02:37:39Z",
    "closed_at": "2024-11-07T03:21:45Z",
    "merged_at": "2024-11-07T03:21:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2718"
  },
  {
    "number": 2717,
    "title": "bump version to 0.6.2.post1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-05T10:00:27Z",
    "closed_at": "2024-11-07T07:40:56Z",
    "merged_at": "2024-11-07T07:40:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2717"
  },
  {
    "number": 2716,
    "title": "Support molmo in turbomind",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-05T09:12:48Z",
    "closed_at": "2024-11-14T05:07:01Z",
    "merged_at": "2024-11-14T05:07:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2716"
  },
  {
    "number": 2715,
    "title": "support turbomind head_dim 64",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-05T07:17:31Z",
    "closed_at": "2024-11-06T07:27:46Z",
    "merged_at": "2024-11-06T07:27:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2715"
  },
  {
    "number": 2713,
    "title": "Fix turbomind TP for v0.6.2",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-05T06:42:42Z",
    "closed_at": "2024-11-05T09:32:35Z",
    "merged_at": "2024-11-05T09:32:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2713"
  },
  {
    "number": 2710,
    "title": "[Feature]: support LlavaForConditionalGeneration with turbomind inference",
    "user": "deepindeed2022",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-05T02:33:33Z",
    "closed_at": "2024-11-08T11:31:35Z",
    "merged_at": "2024-11-08T11:31:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2710"
  },
  {
    "number": 2708,
    "title": "Remove one of the duplicate bos tokens",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-04T11:34:59Z",
    "closed_at": "2024-11-12T08:40:17Z",
    "merged_at": "2024-11-12T08:40:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2708"
  },
  {
    "number": 2707,
    "title": "Add ensure_ascii = False for json.dumps",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-04T08:56:59Z",
    "closed_at": "2024-11-06T03:07:56Z",
    "merged_at": "2024-11-06T03:07:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2707"
  },
  {
    "number": 2706,
    "title": "Fix turbomind TP",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-04T08:49:20Z",
    "closed_at": "2024-11-05T06:32:18Z",
    "merged_at": "2024-11-05T06:32:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2706"
  },
  {
    "number": 2703,
    "title": "Fix llama3.2 VL vision in \"Supported Modals\" documents",
    "user": "blankanswer",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-04T06:06:00Z",
    "closed_at": "2024-11-04T08:55:35Z",
    "merged_at": "2024-11-04T08:55:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2703"
  },
  {
    "number": 2701,
    "title": "Run loop.run_until_complete in another thread",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-04T03:39:32Z",
    "closed_at": "2025-07-07T08:38:10Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2701"
  },
  {
    "number": 2698,
    "title": "miss to read moe_ffn weights from converted tm model",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-01T11:15:10Z",
    "closed_at": "2024-11-04T08:55:16Z",
    "merged_at": "2024-11-04T08:55:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2698"
  },
  {
    "number": 2697,
    "title": "fix index error when computing ppl on long-text prompt",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-01T07:57:13Z",
    "closed_at": "2024-11-01T12:06:03Z",
    "merged_at": "2024-11-01T12:06:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2697"
  },
  {
    "number": 2696,
    "title": "fix ascend get_started.md link",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-01T03:45:07Z",
    "closed_at": "2024-11-01T05:48:13Z",
    "merged_at": "2024-11-01T05:48:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2696"
  },
  {
    "number": 2690,
    "title": "Support ep, column major moe kernel.",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-31T10:03:33Z",
    "closed_at": "2024-11-11T13:11:31Z",
    "merged_at": "2024-11-11T13:11:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2690"
  },
  {
    "number": 2688,
    "title": "fix decoding kernel for deepseekv2",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-31T09:46:23Z",
    "closed_at": "2024-11-06T06:53:04Z",
    "merged_at": "2024-11-06T06:53:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2688"
  },
  {
    "number": 2683,
    "title": "update pre-commit config",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-30T06:45:40Z",
    "closed_at": "2025-01-21T05:35:16Z",
    "merged_at": "2025-01-21T05:35:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2683"
  },
  {
    "number": 2681,
    "title": "Support min_tokens, min_p parameters for api_server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-29T10:25:56Z",
    "closed_at": "2024-11-01T12:05:38Z",
    "merged_at": "2024-11-01T12:05:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2681"
  },
  {
    "number": 2677,
    "title": "Better tp exit log.",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-29T07:01:46Z",
    "closed_at": "2024-11-04T08:29:53Z",
    "merged_at": "2024-11-04T08:29:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2677"
  },
  {
    "number": 2676,
    "title": "Flatten cache and add flashattention",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-29T04:27:55Z",
    "closed_at": "2024-11-08T03:51:35Z",
    "merged_at": "2024-11-08T03:51:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2676"
  },
  {
    "number": 2672,
    "title": "remove dlinfer version",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T11:02:58Z",
    "closed_at": "2024-10-28T11:06:54Z",
    "merged_at": "2024-10-28T11:06:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2672"
  },
  {
    "number": 2671,
    "title": "Call cuda empty_cache to prevent OOM when quantizing model",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T08:56:34Z",
    "closed_at": "2024-10-31T06:39:08Z",
    "merged_at": "2024-10-31T06:39:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2671"
  },
  {
    "number": 2670,
    "title": "feat: support dynamic/llama3 rotary embedding in ascend graph mode",
    "user": "tangzhiyi11",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T08:36:49Z",
    "closed_at": "2024-11-05T11:39:55Z",
    "merged_at": "2024-11-05T11:39:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2670"
  },
  {
    "number": 2669,
    "title": "fix supported model list in ascend graph mode",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T07:29:43Z",
    "closed_at": "2024-10-28T09:10:01Z",
    "merged_at": "2024-10-28T09:10:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2669"
  },
  {
    "number": 2668,
    "title": "fix inference mode error for qwen2-vl",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T06:40:43Z",
    "closed_at": "2024-10-28T07:18:11Z",
    "merged_at": "2024-10-28T07:18:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2668"
  },
  {
    "number": 2667,
    "title": "fix build error in ascend dockerfile",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T05:03:41Z",
    "closed_at": "2024-10-28T06:13:07Z",
    "merged_at": "2024-10-28T06:13:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2667"
  },
  {
    "number": 2666,
    "title": "Set history_cross_kv_seqlens to 0 by default",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-28T03:55:45Z",
    "closed_at": "2024-10-28T04:32:12Z",
    "merged_at": "2024-10-28T04:32:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2666"
  },
  {
    "number": 2665,
    "title": "[ci] support v100 dailytest ",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T11:26:41Z",
    "closed_at": "2024-10-30T04:15:32Z",
    "merged_at": "2024-10-30T04:15:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2665"
  },
  {
    "number": 2664,
    "title": "fix syntax in Dockerfile_aarch64_ascend",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T11:08:18Z",
    "closed_at": "2024-10-25T11:12:48Z",
    "merged_at": "2024-10-25T11:12:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2664"
  },
  {
    "number": 2663,
    "title": "miss device_type when checking is_bf16_supported on ascend platform",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T09:22:56Z",
    "closed_at": "2024-10-25T11:03:49Z",
    "merged_at": "2024-10-25T11:03:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2663"
  },
  {
    "number": 2662,
    "title": "Update ascend get_started tutorial about installing nnal",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T08:55:23Z",
    "closed_at": "2024-10-25T09:46:57Z",
    "merged_at": "2024-10-25T09:46:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2662"
  },
  {
    "number": 2661,
    "title": "update ascend dockerfile",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T08:41:59Z",
    "closed_at": "2024-10-25T09:46:12Z",
    "merged_at": "2024-10-25T09:46:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2661"
  },
  {
    "number": 2659,
    "title": "Bump version to v0.6.2",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T07:24:47Z",
    "closed_at": "2024-10-29T06:40:39Z",
    "merged_at": "2024-10-29T06:40:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2659"
  },
  {
    "number": 2657,
    "title": "bugfix: llava-hf/llava-interleave-qwen-7b-hf (#2497)",
    "user": "deepindeed2022",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T03:26:53Z",
    "closed_at": "2024-10-28T06:20:26Z",
    "merged_at": "2024-10-28T06:20:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2657"
  },
  {
    "number": 2656,
    "title": "adding the package install prerequisites section to installation doc",
    "user": "jianliao",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-25T00:41:44Z",
    "closed_at": "2024-10-25T08:11:47Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2656"
  },
  {
    "number": 2655,
    "title": "Update get_started tutorial about deploying on ascend platform",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T15:11:09Z",
    "closed_at": "2024-10-25T06:45:00Z",
    "merged_at": "2024-10-25T06:45:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2655"
  },
  {
    "number": 2654,
    "title": "Add warning message about `do_sample` to alert BC",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T13:12:32Z",
    "closed_at": "2024-10-25T07:24:07Z",
    "merged_at": "2024-10-25T07:24:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2654"
  },
  {
    "number": 2653,
    "title": "Check whether device support bfloat16",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T12:11:37Z",
    "closed_at": "2024-10-25T06:19:18Z",
    "merged_at": "2024-10-25T06:19:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2653"
  },
  {
    "number": 2649,
    "title": "match torch and torch_vision version",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T09:15:52Z",
    "closed_at": "2024-10-24T13:36:49Z",
    "merged_at": "2024-10-24T13:36:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2649"
  },
  {
    "number": 2648,
    "title": "[ascend] make compatibility for Ascend310P",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T07:36:12Z",
    "closed_at": "2024-10-24T08:36:10Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2648"
  },
  {
    "number": 2647,
    "title": "[ascend] add ascend graph mode",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T06:56:23Z",
    "closed_at": "2024-10-25T08:32:59Z",
    "merged_at": "2024-10-25T08:32:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2647"
  },
  {
    "number": 2646,
    "title": "Fix error in python3.8.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T06:16:18Z",
    "closed_at": "2024-10-24T09:33:07Z",
    "merged_at": "2024-10-24T09:33:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2646"
  },
  {
    "number": 2645,
    "title": "add --eager-mode to cli",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T06:02:01Z",
    "closed_at": "2024-10-24T11:44:37Z",
    "merged_at": "2024-10-24T11:44:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2645"
  },
  {
    "number": 2644,
    "title": "Align UT with triton fill_kv_cache_quant kernel",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T05:36:47Z",
    "closed_at": "2024-10-25T06:26:26Z",
    "merged_at": "2024-10-25T06:26:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2644"
  },
  {
    "number": 2641,
    "title": "update check for triton",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T03:28:18Z",
    "closed_at": "2024-10-24T04:59:02Z",
    "merged_at": "2024-10-24T04:59:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2641"
  },
  {
    "number": 2640,
    "title": "Ccy/add ascend graph mode",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-24T02:06:14Z",
    "closed_at": "2024-10-24T02:06:38Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2640"
  },
  {
    "number": 2636,
    "title": "[maca] add maca backend support.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-23T05:54:07Z",
    "closed_at": "2024-10-24T03:17:09Z",
    "merged_at": "2024-10-24T03:17:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2636"
  },
  {
    "number": 2635,
    "title": "[ci] fix restful script",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-23T05:46:30Z",
    "closed_at": "2024-10-23T07:57:25Z",
    "merged_at": "2024-10-23T07:57:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2635"
  },
  {
    "number": 2634,
    "title": "[ci] add v100 testworkflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-23T03:08:51Z",
    "closed_at": "2024-10-23T06:21:34Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2634"
  },
  {
    "number": 2632,
    "title": "refine pre-post-process",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-22T02:41:55Z",
    "closed_at": "2024-10-23T03:53:17Z",
    "merged_at": "2024-10-23T03:53:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2632"
  },
  {
    "number": 2631,
    "title": "[ci] add internlm2_5_7b_batch_1 into evaluation testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-22T01:46:48Z",
    "closed_at": "2024-10-23T08:01:03Z",
    "merged_at": "2024-10-23T08:01:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2631"
  },
  {
    "number": 2627,
    "title": "add linear op on dlinfer platform",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-21T11:20:33Z",
    "closed_at": "2024-11-05T11:41:20Z",
    "merged_at": "2024-11-05T11:41:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2627"
  },
  {
    "number": 2626,
    "title": "small block_m for sm7.x",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-21T06:01:14Z",
    "closed_at": "2024-10-23T07:51:52Z",
    "merged_at": "2024-10-23T07:51:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2626"
  },
  {
    "number": 2621,
    "title": "MoE support for turbomind",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-18T08:19:29Z",
    "closed_at": "2024-10-25T10:43:31Z",
    "merged_at": "2024-10-25T10:43:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2621"
  },
  {
    "number": 2620,
    "title": "Copy sglang/bench_serving.py to lmdeploy as serving benchmark script",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-18T07:40:41Z",
    "closed_at": "2024-10-20T03:17:36Z",
    "merged_at": "2024-10-20T03:17:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2620"
  },
  {
    "number": 2619,
    "title": "refactor for multi backends in dlinfer",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-18T06:47:26Z",
    "closed_at": "2024-10-18T09:16:49Z",
    "merged_at": "2024-10-18T09:16:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2619"
  },
  {
    "number": 2618,
    "title": "Raise an error for the wrong chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-18T04:05:33Z",
    "closed_at": "2024-10-22T10:38:52Z",
    "merged_at": "2024-10-22T10:38:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2618"
  },
  {
    "number": 2617,
    "title": "[ci] React dailytest workflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-18T03:14:29Z",
    "closed_at": "2024-10-23T05:44:43Z",
    "merged_at": "2024-10-23T05:44:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2617"
  },
  {
    "number": 2615,
    "title": "Add distributed context in pytorch engine to support torchrun",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-18T02:05:18Z",
    "closed_at": "2024-10-23T07:52:58Z",
    "merged_at": "2024-10-23T07:52:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2615"
  },
  {
    "number": 2613,
    "title": "[ascend] refactor fused_moe on ascend platform",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-17T08:56:14Z",
    "closed_at": "2024-10-21T03:03:56Z",
    "merged_at": "2024-10-21T03:03:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2613"
  },
  {
    "number": 2612,
    "title": "[ascend] support paged_prefill_attn when batch > 1",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-17T07:11:06Z",
    "closed_at": "2024-10-22T09:04:17Z",
    "merged_at": "2024-10-22T09:04:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2612"
  },
  {
    "number": 2607,
    "title": "Add barrier to prevent TP nccl kernel waiting.",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-16T07:29:40Z",
    "closed_at": "2024-10-21T02:59:32Z",
    "merged_at": "2024-10-21T02:59:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2607"
  },
  {
    "number": 2605,
    "title": "Support mllama for pytorch engine",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-15T09:45:11Z",
    "closed_at": "2024-10-24T03:17:44Z",
    "merged_at": "2024-10-24T03:17:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2605"
  },
  {
    "number": 2601,
    "title": "Fix spacing in ascend user guide",
    "user": "Superskyyy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-14T20:05:27Z",
    "closed_at": "2024-10-15T03:30:22Z",
    "merged_at": "2024-10-15T03:30:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2601"
  },
  {
    "number": 2596,
    "title": "Support llama3.2 LLM models in turbomind engine",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-12T09:39:35Z",
    "closed_at": "2024-10-24T10:32:37Z",
    "merged_at": "2024-10-24T10:32:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2596"
  },
  {
    "number": 2594,
    "title": "[Doc]: Lock sphinx version",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-12T03:28:28Z",
    "closed_at": "2024-10-12T06:45:57Z",
    "merged_at": "2024-10-12T06:45:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2594"
  },
  {
    "number": 2591,
    "title": "support cross-cache",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-12T01:19:36Z",
    "closed_at": "2024-10-28T11:24:10Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2591"
  },
  {
    "number": 2588,
    "title": "fix: make exit_flag verification for ascend more general",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-11T09:28:48Z",
    "closed_at": "2024-10-14T03:35:59Z",
    "merged_at": "2024-10-14T03:35:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2588"
  },
  {
    "number": 2587,
    "title": "feat(ascend): support w4a16",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-11T09:11:02Z",
    "closed_at": "2024-10-23T03:57:43Z",
    "merged_at": "2024-10-23T03:57:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2587"
  },
  {
    "number": 2584,
    "title": "[ci] add pytorch kvint testcase into function regresstion",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-11T07:39:52Z",
    "closed_at": "2024-10-16T09:28:08Z",
    "merged_at": "2024-10-16T09:28:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2584"
  },
  {
    "number": 2583,
    "title": "Add a workaround for saving internvl2 with latest transformers",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-11T06:54:53Z",
    "closed_at": "2024-10-17T07:22:21Z",
    "merged_at": "2024-10-17T07:22:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2583"
  },
  {
    "number": 2581,
    "title": "support release pipeline",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-11T03:01:57Z",
    "closed_at": "2025-01-21T12:59:06Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2581"
  },
  {
    "number": 2579,
    "title": "update copyright",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-10T12:50:00Z",
    "closed_at": "2024-10-10T12:51:59Z",
    "merged_at": "2024-10-10T12:51:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2579"
  },
  {
    "number": 2578,
    "title": "Update Dockerfile_aarch64_ascend",
    "user": "WangVertex",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-10T10:17:22Z",
    "closed_at": "2024-10-14T03:46:12Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2578"
  },
  {
    "number": 2577,
    "title": "Add instruction for downloading models from openmind hub",
    "user": "cookieyyds",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-10T07:49:09Z",
    "closed_at": "2024-10-11T03:07:49Z",
    "merged_at": "2024-10-11T03:07:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2577"
  },
  {
    "number": 2576,
    "title": "Support glm-4v-9b.",
    "user": "pdx1989",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-10T07:39:53Z",
    "closed_at": "2024-10-10T07:40:12Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2576"
  },
  {
    "number": 2569,
    "title": "[ci] use local requirements for test workflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-10T03:00:46Z",
    "closed_at": "2024-10-12T09:06:19Z",
    "merged_at": "2024-10-12T09:06:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2569"
  },
  {
    "number": 2568,
    "title": "Fix llama3.2-1b inference error by handling tie_word_embedding",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-09T10:26:53Z",
    "closed_at": "2024-10-09T11:23:15Z",
    "merged_at": "2024-10-09T11:23:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2568"
  },
  {
    "number": 2563,
    "title": "support downloading models from openmind_hub",
    "user": "cookieyyds",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-09T02:46:09Z",
    "closed_at": "2024-10-09T03:15:40Z",
    "merged_at": "2024-10-09T03:15:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2563"
  },
  {
    "number": 2560,
    "title": "set capture mode thread_local",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-08T11:56:47Z",
    "closed_at": "2024-10-21T02:20:30Z",
    "merged_at": "2024-10-21T02:20:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2560"
  },
  {
    "number": 2559,
    "title": "set outlines<0.1.0",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-08T11:44:48Z",
    "closed_at": "2024-10-09T02:55:40Z",
    "merged_at": "2024-10-09T02:55:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2559"
  },
  {
    "number": 2558,
    "title": "Add tool role for langchain usage",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-08T10:40:33Z",
    "closed_at": "2024-10-09T09:41:43Z",
    "merged_at": "2024-10-09T09:41:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2558"
  },
  {
    "number": 2553,
    "title": "optimize paged attention on triton3",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-08T03:03:50Z",
    "closed_at": "2024-10-18T04:31:34Z",
    "merged_at": "2024-10-18T04:31:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2553"
  },
  {
    "number": 2540,
    "title": "[Feature] Add argument to disable FastAPI docs",
    "user": "mouweng",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-30T14:03:19Z",
    "closed_at": "2024-10-08T11:33:44Z",
    "merged_at": "2024-10-08T11:33:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2540"
  },
  {
    "number": 2539,
    "title": "[Feature] Add argument to disable FastAPI docs",
    "user": "mouweng",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-30T13:34:30Z",
    "closed_at": "2024-09-30T13:56:28Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2539"
  },
  {
    "number": 2535,
    "title": "add check for device with cap 7.x",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-30T03:49:38Z",
    "closed_at": "2024-10-09T03:53:04Z",
    "merged_at": "2024-10-09T03:53:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2535"
  },
  {
    "number": 2527,
    "title": "fix vl gradio",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-27T07:25:43Z",
    "closed_at": "2024-09-27T12:11:56Z",
    "merged_at": "2024-09-27T12:11:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2527"
  },
  {
    "number": 2523,
    "title": "[ci] add oc infer test in stable test",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-26T12:10:31Z",
    "closed_at": "2024-10-08T12:31:38Z",
    "merged_at": "2024-10-08T12:31:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2523"
  },
  {
    "number": 2521,
    "title": "optimize performance of ascend backend's update_step_context() by calculating kv_start_indices in a new way",
    "user": "jiajie-yang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-26T07:15:55Z",
    "closed_at": "2024-09-26T09:30:10Z",
    "merged_at": "2024-09-26T09:30:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2521"
  },
  {
    "number": 2520,
    "title": "Fix chatglm tokenizer failed when transformers>=4.45.0",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-26T07:04:18Z",
    "closed_at": "2024-09-26T11:31:08Z",
    "merged_at": "2024-09-26T11:31:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2520"
  },
  {
    "number": 2519,
    "title": "support yarn in turbomind backend",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-26T05:45:58Z",
    "closed_at": "2024-11-04T08:30:38Z",
    "merged_at": "2024-11-04T08:30:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2519"
  },
  {
    "number": 2514,
    "title": "push released docker image to aliyun hub",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-25T09:54:51Z",
    "closed_at": "2024-09-25T14:22:00Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2514"
  },
  {
    "number": 2513,
    "title": "bump version to v0.6.1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-25T07:31:27Z",
    "closed_at": "2024-09-28T07:13:30Z",
    "merged_at": "2024-09-28T07:13:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2513"
  },
  {
    "number": 2506,
    "title": "support noaligned silu_and_mul",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-24T04:00:53Z",
    "closed_at": "2024-09-25T09:05:57Z",
    "merged_at": "2024-09-25T09:05:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2506"
  },
  {
    "number": 2502,
    "title": "Catch exceptions thrown by turbomind inference thread",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-23T11:19:16Z",
    "closed_at": "2024-09-24T13:56:31Z",
    "merged_at": "2024-09-24T13:56:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2502"
  },
  {
    "number": 2499,
    "title": "The `get_ppl` missed the last token of each iteration during multi-iter prefill",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-23T10:17:22Z",
    "closed_at": "2024-09-26T12:00:30Z",
    "merged_at": "2024-09-26T12:00:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2499"
  },
  {
    "number": 2494,
    "title": "set served model name being repo_id from hub before it is downloaded",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-22T11:27:34Z",
    "closed_at": "2024-09-23T04:30:24Z",
    "merged_at": "2024-09-23T04:30:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2494"
  },
  {
    "number": 2490,
    "title": "[CI] add base model evaluation",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-20T10:19:17Z",
    "closed_at": "2024-09-25T09:06:30Z",
    "merged_at": "2024-09-25T09:06:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2490"
  },
  {
    "number": 2488,
    "title": "Improve proxy server usage",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-20T05:36:35Z",
    "closed_at": "2024-09-23T07:48:12Z",
    "merged_at": "2024-09-23T07:48:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2488"
  },
  {
    "number": 2487,
    "title": "pytorch engine add get_logits",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-20T03:34:40Z",
    "closed_at": "2024-09-24T06:30:07Z",
    "merged_at": "2024-09-24T06:30:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2487"
  },
  {
    "number": 2485,
    "title": "CudaGraph mixin",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-19T06:30:14Z",
    "closed_at": "2024-09-23T10:36:01Z",
    "merged_at": "2024-09-23T10:36:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2485"
  },
  {
    "number": 2484,
    "title": "[maca] Add maca support.",
    "user": "Reinerzhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-19T06:26:49Z",
    "closed_at": "2024-10-21T16:13:19Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2484"
  },
  {
    "number": 2483,
    "title": "fix ascend atten_mask",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-19T03:11:55Z",
    "closed_at": "2024-09-19T08:52:44Z",
    "merged_at": "2024-09-19T08:52:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2483"
  },
  {
    "number": 2478,
    "title": "Add max_log_len option to control length of printed log",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-18T12:23:12Z",
    "closed_at": "2024-09-20T03:50:58Z",
    "merged_at": "2024-09-20T03:50:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2478"
  },
  {
    "number": 2477,
    "title": "adjust schedule to improve TTFT in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-18T10:15:57Z",
    "closed_at": "2024-09-20T03:50:36Z",
    "merged_at": "2024-09-20T03:50:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2477"
  },
  {
    "number": 2473,
    "title": "Support user-sepcified data type",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-16T10:44:33Z",
    "closed_at": "2024-09-18T06:33:33Z",
    "merged_at": "2024-09-18T06:33:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2473"
  },
  {
    "number": 2472,
    "title": "Fix \"TypeError: Got unsupported ScalarType BFloat16\"",
    "user": "SeitaroShinagawa",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-16T02:21:59Z",
    "closed_at": "2024-09-18T13:14:28Z",
    "merged_at": "2024-09-18T13:14:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2472"
  },
  {
    "number": 2469,
    "title": "Add silu mul kernel",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-14T11:52:50Z",
    "closed_at": "2024-09-19T08:53:58Z",
    "merged_at": "2024-09-19T08:53:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2469"
  },
  {
    "number": 2466,
    "title": "Refactor lora",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-13T12:04:22Z",
    "closed_at": "2024-09-24T07:31:40Z",
    "merged_at": "2024-09-24T07:31:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2466"
  },
  {
    "number": 2465,
    "title": "Support minicpm3-4b",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-13T10:10:59Z",
    "closed_at": "2024-09-23T03:36:59Z",
    "merged_at": "2024-09-23T03:36:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2465"
  },
  {
    "number": 2461,
    "title": "Fix initialization of runtime_min_p",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-12T12:44:19Z",
    "closed_at": "2024-09-12T13:36:21Z",
    "merged_at": "2024-09-12T13:36:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2461"
  },
  {
    "number": 2460,
    "title": "fix MultinomialSampling operator builder",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-12T12:26:05Z",
    "closed_at": "2024-09-12T13:35:42Z",
    "merged_at": "2024-09-12T13:35:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2460"
  },
  {
    "number": 2454,
    "title": "fix tensors on different devices when deploying MiniCPM-V-2_6 with tensor parallelism",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-12T05:59:31Z",
    "closed_at": "2024-09-12T09:28:39Z",
    "merged_at": "2024-09-12T09:28:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2454"
  },
  {
    "number": 2449,
    "title": "support Qwen2-VL with pytorch backend",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-11T13:08:54Z",
    "closed_at": "2024-09-23T07:18:43Z",
    "merged_at": "2024-09-23T07:18:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2449"
  },
  {
    "number": 2447,
    "title": "add docs about ascend",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-11T11:30:31Z",
    "closed_at": "2024-09-11T13:05:00Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2447"
  },
  {
    "number": 2446,
    "title": "Fix ascend readme",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-11T10:31:09Z",
    "closed_at": "2024-09-11T13:04:18Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2446"
  },
  {
    "number": 2445,
    "title": "bump version to v0.6.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-11T08:05:45Z",
    "closed_at": "2024-09-13T03:11:07Z",
    "merged_at": "2024-09-13T03:11:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2445"
  },
  {
    "number": 2444,
    "title": "fix llama3 rotary in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-11T05:33:25Z",
    "closed_at": "2024-09-11T09:14:29Z",
    "merged_at": "2024-09-11T09:14:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2444"
  },
  {
    "number": 2440,
    "title": "refactor pytorch engine(ascend)",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-10T10:13:59Z",
    "closed_at": "2024-09-11T06:41:03Z",
    "merged_at": "2024-09-11T06:41:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2440"
  },
  {
    "number": 2438,
    "title": "Support pytorch engine kv int4/int8 quantization",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-10T06:40:23Z",
    "closed_at": "2024-10-14T12:40:40Z",
    "merged_at": "2024-10-14T12:40:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2438"
  },
  {
    "number": 2434,
    "title": "automatically set max_batch_size according to the device when it is not specified",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-07T12:58:49Z",
    "closed_at": "2024-09-09T12:50:47Z",
    "merged_at": "2024-09-09T12:50:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2434"
  },
  {
    "number": 2433,
    "title": "build nccl in dockerfile for cuda11.8",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-06T12:51:04Z",
    "closed_at": "2024-09-07T12:18:48Z",
    "merged_at": "2024-09-07T12:18:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2433"
  },
  {
    "number": 2431,
    "title": "[ci] regular update",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-06T06:29:25Z",
    "closed_at": "2024-09-18T11:42:59Z",
    "merged_at": "2024-09-18T11:42:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2431"
  },
  {
    "number": 2428,
    "title": "Fix some issues encountered by modelscope and community",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-05T07:11:16Z",
    "closed_at": "2024-09-07T13:55:56Z",
    "merged_at": "2024-09-07T13:55:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2428"
  },
  {
    "number": 2427,
    "title": "inplace logits process as default",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-05T06:21:52Z",
    "closed_at": "2024-09-05T07:19:37Z",
    "merged_at": "2024-09-05T07:19:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2427"
  },
  {
    "number": 2426,
    "title": "ignore *.pth when download model from model hub",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-05T03:48:47Z",
    "closed_at": "2024-09-05T06:34:06Z",
    "merged_at": "2024-09-05T06:34:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2426"
  },
  {
    "number": 2421,
    "title": "build: update ascend dockerfile",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T08:48:09Z",
    "closed_at": "2024-09-06T10:14:44Z",
    "merged_at": "2024-09-06T10:14:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2421"
  },
  {
    "number": 2420,
    "title": "support min_p sampling parameter",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T03:17:47Z",
    "closed_at": "2024-09-09T10:01:50Z",
    "merged_at": "2024-09-09T10:01:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2420"
  },
  {
    "number": 2419,
    "title": "update actions/download-artifact to v4 to fix security issue",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T02:55:02Z",
    "closed_at": "2024-09-04T11:59:35Z",
    "merged_at": "2024-09-04T11:59:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2419"
  },
  {
    "number": 2417,
    "title": "add Ascend get_started",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-04T01:59:51Z",
    "closed_at": "2024-09-04T06:02:55Z",
    "merged_at": "2024-09-04T06:02:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2417"
  },
  {
    "number": 2413,
    "title": "import dlinfer before imageencoding",
    "user": "jinminxi104",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-02T10:45:11Z",
    "closed_at": "2024-09-03T14:06:23Z",
    "merged_at": "2024-09-03T14:06:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2413"
  },
  {
    "number": 2410,
    "title": "fix get_started user guide unaccessible",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-02T04:53:27Z",
    "closed_at": "2024-09-02T06:21:31Z",
    "merged_at": "2024-09-02T06:21:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2410"
  },
  {
    "number": 2403,
    "title": "rename the ascend dockerfile",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-30T09:33:07Z",
    "closed_at": "2024-08-30T09:39:09Z",
    "merged_at": "2024-08-30T09:39:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2403"
  },
  {
    "number": 2402,
    "title": "Torchrun launching multiple api_server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-30T08:15:31Z",
    "closed_at": "2024-12-26T10:33:42Z",
    "merged_at": "2024-12-26T10:33:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2402"
  },
  {
    "number": 2401,
    "title": "[ci] add daily test's coverage report ",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-30T06:45:51Z",
    "closed_at": "2024-08-30T09:26:27Z",
    "merged_at": "2024-08-30T09:26:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2401"
  },
  {
    "number": 2396,
    "title": "fix: make main process exit properly when tp>1 on ascend backend",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-29T06:51:52Z",
    "closed_at": "2024-09-04T12:58:39Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2396"
  },
  {
    "number": 2395,
    "title": "Fix /v1/completions batch order wrong",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-29T06:06:46Z",
    "closed_at": "2024-08-30T02:57:26Z",
    "merged_at": "2024-08-30T02:57:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2395"
  },
  {
    "number": 2388,
    "title": "fix cache position for pytorch engine",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-27T11:07:19Z",
    "closed_at": "2024-08-27T12:45:15Z",
    "merged_at": "2024-08-27T12:45:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2388"
  },
  {
    "number": 2378,
    "title": "Reorganize the table of content of get_started",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-26T12:57:30Z",
    "closed_at": "2024-08-28T10:09:55Z",
    "merged_at": "2024-08-28T10:09:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2378"
  },
  {
    "number": 2375,
    "title": "support do_sample parameter",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-26T10:35:25Z",
    "closed_at": "2024-09-02T06:21:48Z",
    "merged_at": "2024-09-02T06:21:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2375"
  },
  {
    "number": 2373,
    "title": "More w8a8 models",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-26T08:57:12Z",
    "closed_at": "2024-12-03T07:06:10Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2373"
  },
  {
    "number": 2372,
    "title": "Add auto_gptq to lmdeploy lite",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-26T07:59:46Z",
    "closed_at": "2024-08-28T09:44:09Z",
    "merged_at": "2024-08-28T09:44:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2372"
  },
  {
    "number": 2371,
    "title": "bump version to v0.6.0a0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-26T06:41:36Z",
    "closed_at": "2024-08-26T09:09:55Z",
    "merged_at": "2024-08-26T09:09:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2371"
  },
  {
    "number": 2364,
    "title": "refactor TurbomindModelConfig",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-23T10:55:19Z",
    "closed_at": "2024-09-02T09:02:27Z",
    "merged_at": "2024-09-02T09:02:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2364"
  },
  {
    "number": 2362,
    "title": "Fix the logic of update engine_config to TurbomindModelConfig for both tm model and hf model",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-23T05:28:27Z",
    "closed_at": "2024-08-23T13:05:59Z",
    "merged_at": "2024-08-23T13:05:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2362"
  },
  {
    "number": 2361,
    "title": "Support phi3.5 for pytorch engine",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-23T04:06:55Z",
    "closed_at": "2024-08-23T12:20:45Z",
    "merged_at": "2024-08-23T12:20:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2361"
  },
  {
    "number": 2358,
    "title": "Default rope_scaling_factor of TurbomindEngineConfig to None",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-22T10:00:12Z",
    "closed_at": "2024-08-22T11:41:02Z",
    "merged_at": "2024-08-22T11:41:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2358"
  },
  {
    "number": 2357,
    "title": "feat: support ascend qwen",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-22T09:47:48Z",
    "closed_at": "2024-09-10T10:18:44Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2357"
  },
  {
    "number": 2356,
    "title": "feat: support ascend mixtral",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-22T09:33:47Z",
    "closed_at": "2024-09-10T10:18:35Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2356"
  },
  {
    "number": 2355,
    "title": "refactor ascend kernels",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-22T09:04:05Z",
    "closed_at": "2024-08-30T09:45:48Z",
    "merged_at": "2024-08-30T09:45:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2355"
  },
  {
    "number": 2353,
    "title": "feat(server): enable `seed` parameter for openai compatible server.",
    "user": "DearPlanet",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-22T07:51:50Z",
    "closed_at": "2024-08-23T08:28:02Z",
    "merged_at": "2024-08-23T08:28:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2353"
  },
  {
    "number": 2352,
    "title": "Refactor turbomind (1/N)",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-21T13:01:08Z",
    "closed_at": "2024-08-22T11:44:20Z",
    "merged_at": "2024-08-22T11:44:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2352"
  },
  {
    "number": 2351,
    "title": "support openbmb/MiniCPM-V-2_6",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-21T12:45:26Z",
    "closed_at": "2024-08-22T14:07:18Z",
    "merged_at": "2024-08-22T14:07:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2351"
  },
  {
    "number": 2345,
    "title": "add max_prefill_token_num argument in CLI",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-20T07:55:26Z",
    "closed_at": "2024-08-20T10:16:25Z",
    "merged_at": "2024-08-20T10:16:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2345"
  },
  {
    "number": 2344,
    "title": "add cache to speed up docker building",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-20T06:31:43Z",
    "closed_at": "2024-08-20T10:15:19Z",
    "merged_at": "2024-08-20T10:15:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2344"
  },
  {
    "number": 2343,
    "title": "Add environment variable to control SILU fusion",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-20T06:19:52Z",
    "closed_at": "2024-08-20T08:18:28Z",
    "merged_at": "2024-08-20T08:18:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2343"
  },
  {
    "number": 2342,
    "title": "Add GEMM test utils",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-20T05:39:25Z",
    "closed_at": "2024-08-20T08:17:06Z",
    "merged_at": "2024-08-20T08:17:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2342"
  },
  {
    "number": 2341,
    "title": "feat: support npu device on Ascend platform with 'torch_npu' package",
    "user": "jiajie-yang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-20T04:40:35Z",
    "closed_at": "2024-09-11T13:17:36Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2341"
  },
  {
    "number": 2339,
    "title": "Use single thread per model instance",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-19T14:23:57Z",
    "closed_at": "2024-08-20T10:13:29Z",
    "merged_at": "2024-08-20T10:13:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2339"
  },
  {
    "number": 2337,
    "title": "Change to use device instead of device-type in cli",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-19T11:08:15Z",
    "closed_at": "2024-08-20T06:36:03Z",
    "merged_at": "2024-08-20T06:36:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2337"
  },
  {
    "number": 2333,
    "title": "Update error status_code to raise error in openai client",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-19T07:49:45Z",
    "closed_at": "2024-08-20T06:26:29Z",
    "merged_at": "2024-08-20T06:26:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2333"
  },
  {
    "number": 2329,
    "title": "Support custom logits processors",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-19T04:48:24Z",
    "closed_at": "2024-08-22T05:40:07Z",
    "merged_at": "2024-08-22T05:40:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2329"
  },
  {
    "number": 2328,
    "title": "fix(ascend): fix import error of pt engine in cli",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-19T03:52:23Z",
    "closed_at": "2024-08-20T09:43:45Z",
    "merged_at": "2024-08-20T09:43:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2328"
  },
  {
    "number": 2325,
    "title": "Fix the way to get \"quantization_config\" from model's coniguration",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-17T09:22:27Z",
    "closed_at": "2024-08-20T09:43:03Z",
    "merged_at": "2024-08-20T09:43:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2325"
  },
  {
    "number": 2324,
    "title": "feat: add device_type param to cli",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-16T11:21:42Z",
    "closed_at": "2024-08-19T03:32:51Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2324"
  },
  {
    "number": 2321,
    "title": "add device type for pytorch engine in cli",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-16T03:21:49Z",
    "closed_at": "2024-08-19T03:57:22Z",
    "merged_at": "2024-08-19T03:57:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2321"
  },
  {
    "number": 2313,
    "title": "Add stream options to control usage",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-15T06:01:52Z",
    "closed_at": "2024-08-16T07:14:23Z",
    "merged_at": "2024-08-16T07:14:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2313"
  },
  {
    "number": 2312,
    "title": "handle invalid images",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-15T05:53:03Z",
    "closed_at": "2024-09-05T09:55:14Z",
    "merged_at": "2024-09-05T09:55:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2312"
  },
  {
    "number": 2308,
    "title": "[Feature] Support vision module w8a8 inference",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-14T09:11:41Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2308"
  },
  {
    "number": 2307,
    "title": "fix: follow up #2303",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-14T03:53:45Z",
    "closed_at": "2024-08-14T08:01:32Z",
    "merged_at": "2024-08-14T08:01:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2307"
  },
  {
    "number": 2303,
    "title": "fix Windows compile error",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-14T02:29:25Z",
    "closed_at": "2024-08-14T03:28:30Z",
    "merged_at": "2024-08-14T03:28:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2303"
  },
  {
    "number": 2294,
    "title": "Remove QoS serving",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-13T07:38:40Z",
    "closed_at": "2024-08-13T13:42:28Z",
    "merged_at": "2024-08-13T13:42:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2294"
  },
  {
    "number": 2292,
    "title": "Fix internvl2 template and update docs",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-13T03:41:28Z",
    "closed_at": "2024-08-15T06:18:36Z",
    "merged_at": "2024-08-15T06:18:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2292"
  },
  {
    "number": 2290,
    "title": "Update python support version ",
    "user": "wuhongsheng",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-13T00:18:05Z",
    "closed_at": "2024-08-13T08:15:28Z",
    "merged_at": "2024-08-13T08:15:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2290"
  },
  {
    "number": 2289,
    "title": "better formatted table of 'lmdeploy list'",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-12T12:14:00Z",
    "closed_at": "2025-01-21T02:52:56Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2289"
  },
  {
    "number": 2285,
    "title": "remove eviction param",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-12T06:12:33Z",
    "closed_at": "2024-08-12T07:37:26Z",
    "merged_at": "2024-08-12T07:37:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2285"
  },
  {
    "number": 2278,
    "title": "build(ascend): add Dockerfile for ascend aarch64 910B",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-09T11:31:26Z",
    "closed_at": "2024-08-28T10:54:27Z",
    "merged_at": "2024-08-28T10:54:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2278"
  },
  {
    "number": 2277,
    "title": "[WIP] Support cogvlm model",
    "user": "pdx1989",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-09T10:49:36Z",
    "closed_at": "2024-08-09T11:54:11Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2277"
  },
  {
    "number": 2275,
    "title": "fix side-effect: failed to update tm model config with tm engine config",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-09T06:33:27Z",
    "closed_at": "2024-08-12T08:38:07Z",
    "merged_at": "2024-08-12T08:38:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2275"
  },
  {
    "number": 2274,
    "title": "[Feature] support qqq(w4a8) for lmdeploy",
    "user": "HandH1998",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-09T06:12:05Z",
    "closed_at": "2025-09-08T04:12:22Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2274"
  },
  {
    "number": 2256,
    "title": "enable run vlm with pytorch engine in gradio",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-07T11:22:07Z",
    "closed_at": "2024-08-09T06:48:30Z",
    "merged_at": "2024-08-09T06:48:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2256"
  },
  {
    "number": 2252,
    "title": "Split token_embs and lm_head weights",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-07T07:42:58Z",
    "closed_at": "2024-09-05T11:45:51Z",
    "merged_at": "2024-09-05T11:45:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2252"
  },
  {
    "number": 2251,
    "title": "debug",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-07T07:28:14Z",
    "closed_at": "2024-08-07T07:40:37Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2251"
  },
  {
    "number": 2246,
    "title": "cancel support baichuan2 7b awq in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T11:22:56Z",
    "closed_at": "2024-08-07T08:33:04Z",
    "merged_at": "2024-08-07T08:33:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2246"
  },
  {
    "number": 2245,
    "title": "support vlm custom image process parameters in openai input format",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T07:59:43Z",
    "closed_at": "2024-08-12T07:38:47Z",
    "merged_at": "2024-08-12T07:38:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2245"
  },
  {
    "number": 2242,
    "title": "bump version to v0.5.3",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T06:26:29Z",
    "closed_at": "2024-08-07T03:34:22Z",
    "merged_at": "2024-08-07T03:34:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2242"
  },
  {
    "number": 2240,
    "title": "fix the issue missing dependencies in the Dockerfile and pip",
    "user": "ColorfulDick",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T04:00:47Z",
    "closed_at": "2024-08-19T03:05:20Z",
    "merged_at": "2024-08-19T03:05:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2240"
  },
  {
    "number": 2237,
    "title": "docs: add Japanese README",
    "user": "eltociear",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-05T18:13:45Z",
    "closed_at": "2024-08-06T03:36:58Z",
    "merged_at": "2024-08-06T03:36:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2237"
  },
  {
    "number": 2233,
    "title": "Fix typos in profile_generation.py",
    "user": "jiajie-yang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-05T09:10:13Z",
    "closed_at": "2024-08-06T03:37:31Z",
    "merged_at": "2024-08-06T03:37:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2233"
  },
  {
    "number": 2218,
    "title": "Add peer-access-enabled allocator",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-01T13:43:25Z",
    "closed_at": "2024-08-06T06:10:26Z",
    "merged_at": "2024-08-06T06:10:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2218"
  },
  {
    "number": 2215,
    "title": "Fix hidden size and support mistral nemo",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-01T10:37:06Z",
    "closed_at": "2024-08-21T04:46:48Z",
    "merged_at": "2024-08-21T04:46:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2215"
  },
  {
    "number": 2212,
    "title": "fix runtime error when using dynamic scale rotary embed for InternLM2",
    "user": "CyCle1024",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-01T07:07:30Z",
    "closed_at": "2024-08-02T03:35:21Z",
    "merged_at": "2024-08-02T03:35:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2212"
  },
  {
    "number": 2209,
    "title": "clearify the model type LLM or MLLM in supported model matrix",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-01T04:46:28Z",
    "closed_at": "2024-08-01T07:31:30Z",
    "merged_at": "2024-08-01T07:31:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2209"
  },
  {
    "number": 2207,
    "title": "support VLMs with Qwen as the language model",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-01T02:53:55Z",
    "closed_at": "2024-08-01T07:30:57Z",
    "merged_at": "2024-08-01T07:30:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2207"
  },
  {
    "number": 2206,
    "title": "Check errors for attention kernels",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-31T14:25:53Z",
    "closed_at": "2024-08-01T06:14:15Z",
    "merged_at": "2024-08-01T06:14:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2206"
  },
  {
    "number": 2202,
    "title": "Stop synchronizing for `length_criterion`",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-31T11:49:32Z",
    "closed_at": "2024-08-02T10:42:53Z",
    "merged_at": "2024-08-02T10:42:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2202"
  },
  {
    "number": 2201,
    "title": "Fix chunked prefill",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-31T10:48:12Z",
    "closed_at": "2024-08-01T03:14:21Z",
    "merged_at": "2024-08-01T03:14:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2201"
  },
  {
    "number": 2200,
    "title": "update news about cooperation with modelscope/swift",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-31T10:10:04Z",
    "closed_at": "2024-07-31T14:00:33Z",
    "merged_at": "2024-07-31T14:00:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2200"
  },
  {
    "number": 2192,
    "title": "test prtest image update",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-31T03:39:16Z",
    "closed_at": "2024-08-07T09:22:23Z",
    "merged_at": "2024-08-07T09:22:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2192"
  },
  {
    "number": 2191,
    "title": "[Feature] Support XTuner Lite Llava",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-31T02:42:50Z",
    "closed_at": "2025-07-17T11:53:04Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2191"
  },
  {
    "number": 2187,
    "title": "use real max_prefill_token_num",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-30T10:11:43Z",
    "closed_at": "2024-07-31T14:04:30Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2187"
  },
  {
    "number": 2183,
    "title": "[ci] benchmark react",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-30T07:48:14Z",
    "closed_at": "2024-08-26T09:09:38Z",
    "merged_at": "2024-08-26T09:09:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2183"
  },
  {
    "number": 2182,
    "title": "update base image to support cuda12.4 in dockerfile",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-30T07:27:07Z",
    "closed_at": "2024-08-02T09:33:55Z",
    "merged_at": "2024-08-02T09:33:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2182"
  },
  {
    "number": 2172,
    "title": "Support specifying a prefix of assistant response",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-29T05:29:13Z",
    "closed_at": "2024-07-31T06:31:37Z",
    "merged_at": "2024-07-31T06:31:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2172"
  },
  {
    "number": 2165,
    "title": "wrong expression",
    "user": "ArtificialZeng",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-27T12:22:31Z",
    "closed_at": "2024-07-29T08:04:21Z",
    "merged_at": "2024-07-29T08:04:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2165"
  },
  {
    "number": 2159,
    "title": "bump version to 0.5.2.post1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-26T12:20:31Z",
    "closed_at": "2024-07-26T12:20:47Z",
    "merged_at": "2024-07-26T12:20:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2159"
  },
  {
    "number": 2158,
    "title": "support logit softcap",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-26T11:48:20Z",
    "closed_at": "2024-07-29T13:04:58Z",
    "merged_at": "2024-07-29T13:04:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2158"
  },
  {
    "number": 2157,
    "title": "[Hotfix] miss parentheses when calcuating the coef of llama3 rope",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-26T11:12:46Z",
    "closed_at": "2024-07-26T11:26:10Z",
    "merged_at": "2024-07-26T11:26:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2157"
  },
  {
    "number": 2156,
    "title": "Strict check for `name_map` in `InternLM2Chat7B`",
    "user": "l1cacheDell",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-26T10:39:43Z",
    "closed_at": "2024-07-31T07:05:30Z",
    "merged_at": "2024-07-31T07:05:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2156"
  },
  {
    "number": 2147,
    "title": "Support send tool_calls back to internlm2",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-26T03:22:19Z",
    "closed_at": "2024-08-14T13:55:44Z",
    "merged_at": "2024-08-14T13:55:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2147"
  },
  {
    "number": 2143,
    "title": "bump version to v0.5.2",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-25T12:30:33Z",
    "closed_at": "2024-07-26T05:55:39Z",
    "merged_at": "2024-07-26T05:55:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2143"
  },
  {
    "number": 2139,
    "title": "adapt MiniCPM-Llama3-V-2_5 new code",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-25T09:08:06Z",
    "closed_at": "2024-08-05T09:42:09Z",
    "merged_at": "2024-08-05T09:42:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2139"
  },
  {
    "number": 2136,
    "title": "docs: fix Qwen typo",
    "user": "ArtificialZeng",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-25T08:15:19Z",
    "closed_at": "2024-07-28T04:02:43Z",
    "merged_at": "2024-07-28T04:02:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2136"
  },
  {
    "number": 2134,
    "title": "Fix duplicated session_id when pipeline is used by multithreads",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-25T03:50:36Z",
    "closed_at": "2024-08-08T06:51:47Z",
    "merged_at": "2024-08-08T06:51:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2134"
  },
  {
    "number": 2133,
    "title": "Remove duplicate code",
    "user": "cmpute",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-25T03:30:08Z",
    "closed_at": "2024-08-06T06:12:18Z",
    "merged_at": "2024-08-06T06:12:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2133"
  },
  {
    "number": 2131,
    "title": "Fix gradio serve using a wrong chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-25T02:07:26Z",
    "closed_at": "2024-08-02T03:03:50Z",
    "merged_at": "2024-08-02T03:03:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2131"
  },
  {
    "number": 2123,
    "title": "Support Llama3.1 tool calling",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-24T07:00:25Z",
    "closed_at": "2024-07-25T07:01:50Z",
    "merged_at": "2024-07-25T07:01:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2123"
  },
  {
    "number": 2122,
    "title": "Support llama3.1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-24T06:41:10Z",
    "closed_at": "2024-07-24T16:24:19Z",
    "merged_at": "2024-07-24T16:24:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2122"
  },
  {
    "number": 2111,
    "title": "Fix gmem to smem WAW conflict in awq gemm kernel",
    "user": "foreverrookie",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-23T07:33:06Z",
    "closed_at": "2024-07-30T05:58:42Z",
    "merged_at": "2024-07-30T05:58:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2111"
  },
  {
    "number": 2108,
    "title": "clarify \"n>1\" in GenerationConfig hasn't been supported yet",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-23T04:45:28Z",
    "closed_at": "2024-07-23T09:24:20Z",
    "merged_at": "2024-07-23T09:24:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2108"
  },
  {
    "number": 2105,
    "title": "Remove `session_len` and deprecated short names of the chat templates",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-22T15:46:49Z",
    "closed_at": "2024-07-23T09:20:25Z",
    "merged_at": "2024-07-23T09:20:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2105"
  },
  {
    "number": 2104,
    "title": "Refactor pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-22T13:05:21Z",
    "closed_at": "2024-09-10T08:27:43Z",
    "merged_at": "2024-09-10T08:27:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2104"
  },
  {
    "number": 2103,
    "title": "Renew a session for reset button",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-22T10:13:11Z",
    "closed_at": "2024-08-28T01:53:27Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2103"
  },
  {
    "number": 2097,
    "title": "Remove kv cache offline quantization",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-22T03:09:17Z",
    "closed_at": "2024-07-22T08:57:51Z",
    "merged_at": "2024-07-22T08:57:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2097"
  },
  {
    "number": 2090,
    "title": "New GEMM kernels for weight-only quantization",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T18:44:38Z",
    "closed_at": "2024-08-19T06:15:36Z",
    "merged_at": "2024-08-19T06:15:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2090"
  },
  {
    "number": 2086,
    "title": "set log level ERROR in benchmark scripts",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T08:43:01Z",
    "closed_at": "2024-07-19T09:13:58Z",
    "merged_at": "2024-07-19T09:13:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2086"
  },
  {
    "number": 2085,
    "title": "Add nest_asyncio to requirements",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T08:40:02Z",
    "closed_at": "2024-07-23T09:18:28Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2085"
  },
  {
    "number": 2084,
    "title": "Add user guide about slora serving ",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T08:37:31Z",
    "closed_at": "2024-08-08T03:48:25Z",
    "merged_at": "2024-08-08T03:48:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2084"
  },
  {
    "number": 2083,
    "title": "misc: update bug issue template",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T08:12:27Z",
    "closed_at": "2024-07-19T08:24:53Z",
    "merged_at": "2024-07-19T08:24:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2083"
  },
  {
    "number": 2082,
    "title": "Disable peer access code",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T08:05:45Z",
    "closed_at": "2024-07-19T08:23:36Z",
    "merged_at": "2024-07-19T08:23:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2082"
  },
  {
    "number": 2081,
    "title": "add try except for request thread",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T06:47:28Z",
    "closed_at": "2024-07-19T06:59:25Z",
    "merged_at": "2024-07-19T06:59:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2081"
  },
  {
    "number": 2080,
    "title": "add debug log for topk",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T04:17:59Z",
    "closed_at": "2024-07-19T06:40:21Z",
    "merged_at": "2024-07-19T06:40:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2080"
  },
  {
    "number": 2071,
    "title": "raise thread exception",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-18T07:31:21Z",
    "closed_at": "2024-07-22T07:47:11Z",
    "merged_at": "2024-07-22T07:47:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2071"
  },
  {
    "number": 2065,
    "title": "misc: replace slow Jimver/cuda-toolkit",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-17T17:23:41Z",
    "closed_at": "2024-07-19T03:16:20Z",
    "merged_at": "2024-07-19T03:16:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2065"
  },
  {
    "number": 2059,
    "title": "InternLM Summer Camp3",
    "user": "boshallen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-17T07:59:50Z",
    "closed_at": "2024-07-23T09:22:15Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2059"
  },
  {
    "number": 2046,
    "title": "Support custom attention backend",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-16T12:07:52Z",
    "closed_at": "2024-08-21T05:55:44Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2046"
  },
  {
    "number": 2044,
    "title": "fix stop words for glm4",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-16T11:04:46Z",
    "closed_at": "2024-07-16T15:39:09Z",
    "merged_at": "2024-07-16T15:39:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2044"
  },
  {
    "number": 2038,
    "title": "Reorganize the user guide and update the get_started section",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-16T06:54:46Z",
    "closed_at": "2024-08-07T07:42:48Z",
    "merged_at": "2024-08-07T07:42:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2038"
  },
  {
    "number": 2037,
    "title": "update xcomposer2d5 docs",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-16T05:57:32Z",
    "closed_at": "2024-07-16T06:19:33Z",
    "merged_at": "2024-07-16T06:19:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2037"
  },
  {
    "number": 2035,
    "title": "update daily testcase new",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-16T03:39:58Z",
    "closed_at": "2024-07-21T12:16:06Z",
    "merged_at": "2024-07-21T12:16:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2035"
  },
  {
    "number": 2033,
    "title": "Fix side effect of #1995",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-16T02:26:02Z",
    "closed_at": "2024-07-16T03:19:31Z",
    "merged_at": "2024-07-16T03:19:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2033"
  },
  {
    "number": 2023,
    "title": "Fix internvl2-40b awq inference",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-15T07:53:46Z",
    "closed_at": "2024-07-15T10:05:55Z",
    "merged_at": "2024-07-15T10:05:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2023"
  },
  {
    "number": 2022,
    "title": "bump version to v0.5.1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-15T07:33:09Z",
    "closed_at": "2024-07-16T10:04:37Z",
    "merged_at": "2024-07-16T10:04:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2022"
  },
  {
    "number": 2018,
    "title": "Add prefix cache stats to usage",
    "user": "ispobock",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-13T09:50:28Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2018"
  },
  {
    "number": 2016,
    "title": "docs: fix Ada compatibility",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-13T03:30:52Z",
    "closed_at": "2024-07-13T04:19:58Z",
    "merged_at": "2024-07-13T04:19:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2016"
  },
  {
    "number": 2013,
    "title": "add chat template for codegeex4",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-12T12:16:27Z",
    "closed_at": "2024-07-15T07:02:46Z",
    "merged_at": "2024-07-15T07:02:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2013"
  },
  {
    "number": 2011,
    "title": "feat: support llama2 and internlm2 on 910B",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-12T07:19:19Z",
    "closed_at": "2024-07-12T09:25:21Z",
    "merged_at": "2024-07-12T09:25:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2011"
  },
  {
    "number": 2010,
    "title": "Add exception handler to imge encoder",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-12T06:37:28Z",
    "closed_at": "2024-07-13T13:03:28Z",
    "merged_at": "2024-07-13T13:03:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2010"
  },
  {
    "number": 2007,
    "title": "Fix the session_len assignment logic",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-12T04:59:50Z",
    "closed_at": "2024-07-12T07:54:49Z",
    "merged_at": "2024-07-12T07:54:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2007"
  },
  {
    "number": 1998,
    "title": "Fix table rendering for readthedocs",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-11T10:24:38Z",
    "closed_at": "2024-07-12T03:18:39Z",
    "merged_at": "2024-07-12T03:18:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1998"
  },
  {
    "number": 1995,
    "title": "Avoid the same session id for openai endpoint",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-11T09:09:48Z",
    "closed_at": "2024-07-15T07:05:46Z",
    "merged_at": "2024-07-15T07:05:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1995"
  },
  {
    "number": 1993,
    "title": "Support glm4 awq",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-11T07:59:35Z",
    "closed_at": "2024-07-19T07:27:32Z",
    "merged_at": "2024-07-19T07:27:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1993"
  },
  {
    "number": 1988,
    "title": "docs: sync the core features in README to index.rst",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-10T13:51:55Z",
    "closed_at": "2024-07-11T06:29:07Z",
    "merged_at": "2024-07-11T06:29:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1988"
  },
  {
    "number": 1986,
    "title": "Remove the triton inference server backend \"turbomind_backend\"",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-10T12:32:31Z",
    "closed_at": "2024-07-17T12:51:53Z",
    "merged_at": "2024-07-17T12:51:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1986"
  },
  {
    "number": 1985,
    "title": "Fix logprobs openai api",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-10T11:47:29Z",
    "closed_at": "2024-07-12T07:55:37Z",
    "merged_at": "2024-07-12T07:55:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1985"
  },
  {
    "number": 1984,
    "title": "Phi3 awq",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-10T10:30:12Z",
    "closed_at": "2024-07-31T09:18:21Z",
    "merged_at": "2024-07-31T09:18:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1984"
  },
  {
    "number": 1983,
    "title": "support internvl2-1b",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-10T08:46:29Z",
    "closed_at": "2024-07-11T05:50:32Z",
    "merged_at": "2024-07-11T05:50:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1983"
  },
  {
    "number": 1982,
    "title": "fix unexpected argument error when deploying \"cogvlm-chat-hf\"",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-10T08:13:04Z",
    "closed_at": "2024-07-10T09:51:38Z",
    "merged_at": "2024-07-10T09:51:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1982"
  },
  {
    "number": 1979,
    "title": "Fix internvl2-40b model export",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-10T06:04:44Z",
    "closed_at": "2024-07-10T08:23:41Z",
    "merged_at": "2024-07-10T08:23:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1979"
  },
  {
    "number": 1977,
    "title": "docs: update kv quant doc",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-10T02:40:50Z",
    "closed_at": "2024-07-10T02:56:08Z",
    "merged_at": "2024-07-10T02:56:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1977"
  },
  {
    "number": 1972,
    "title": "feat: support llama2 and internlm2 on 910B (#1889)",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T11:13:47Z",
    "closed_at": "2024-07-12T06:53:54Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1972"
  },
  {
    "number": 1971,
    "title": "fix: set PYTHONIOENCODING to UTF-8 before start tritonserver",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T09:42:15Z",
    "closed_at": "2024-07-09T09:49:05Z",
    "merged_at": "2024-07-09T09:49:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1971"
  },
  {
    "number": 1968,
    "title": "fix logprobs",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T07:52:56Z",
    "closed_at": "2024-07-10T09:01:48Z",
    "merged_at": "2024-07-10T09:01:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1968"
  },
  {
    "number": 1966,
    "title": "support min_p sampling & do_sample setting",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T07:31:20Z",
    "closed_at": "2024-08-26T10:23:05Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1966"
  },
  {
    "number": 1962,
    "title": "torch engine optimize prefill for long context",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T03:53:32Z",
    "closed_at": "2024-08-22T07:06:10Z",
    "merged_at": "2024-08-22T07:06:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1962"
  },
  {
    "number": 1956,
    "title": "fix llama3 chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T01:47:36Z",
    "closed_at": "2024-07-09T03:07:17Z",
    "merged_at": "2024-07-09T03:07:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1956"
  },
  {
    "number": 1952,
    "title": "fix transformers version check for InternVL2",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-08T09:54:29Z",
    "closed_at": "2024-07-09T03:12:51Z",
    "merged_at": "2024-07-09T03:12:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1952"
  },
  {
    "number": 1947,
    "title": "Support glm 4v",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-08T07:13:44Z",
    "closed_at": "2024-07-12T11:53:09Z",
    "merged_at": "2024-07-12T11:53:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1947"
  },
  {
    "number": 1946,
    "title": "docs: update compatibility section in README",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-08T06:39:00Z",
    "closed_at": "2024-07-08T09:43:43Z",
    "merged_at": "2024-07-08T09:43:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1946"
  },
  {
    "number": 1944,
    "title": "feat: add gpu topo for check_env",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-08T03:46:10Z",
    "closed_at": "2024-07-08T13:28:50Z",
    "merged_at": "2024-07-08T13:28:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1944"
  },
  {
    "number": 1941,
    "title": "fix mixtral and mistral cache_position",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-07T11:10:21Z",
    "closed_at": "2024-07-11T06:27:27Z",
    "merged_at": "2024-07-11T06:27:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1941"
  },
  {
    "number": 1940,
    "title": "refactor: update awq linear and rm legacy",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-07T10:38:12Z",
    "closed_at": "2024-07-08T13:22:01Z",
    "merged_at": "2024-07-08T13:22:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1940"
  },
  {
    "number": 1932,
    "title": "support internlm-xcomposer2d5-7b",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-05T09:26:30Z",
    "closed_at": "2024-07-15T04:22:07Z",
    "merged_at": "2024-07-15T04:22:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1932"
  },
  {
    "number": 1931,
    "title": "Remove deprecated arguments from API and clarify model_name and chat_template_name",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-05T08:39:14Z",
    "closed_at": "2024-08-08T03:46:59Z",
    "merged_at": "2024-08-08T03:46:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1931"
  },
  {
    "number": 1930,
    "title": "Upgrade gradio",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-05T08:29:16Z",
    "closed_at": "2024-07-09T06:51:00Z",
    "merged_at": "2024-07-09T06:51:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1930"
  },
  {
    "number": 1928,
    "title": "[ci] add internlm2.5 models into testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-05T06:13:15Z",
    "closed_at": "2024-07-09T08:06:18Z",
    "merged_at": "2024-07-09T08:06:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1928"
  },
  {
    "number": 1926,
    "title": "fix: tcp port can not change",
    "user": "Desein-Yang",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-05T03:52:42Z",
    "closed_at": "2024-07-05T03:55:29Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1926"
  },
  {
    "number": 1924,
    "title": "support gemma2 in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-05T03:25:40Z",
    "closed_at": "2024-07-05T12:16:22Z",
    "merged_at": "2024-07-05T12:16:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1924"
  },
  {
    "number": 1922,
    "title": "misc: add default api_server_url for api_client",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-04T12:02:33Z",
    "closed_at": "2024-07-05T06:41:36Z",
    "merged_at": "2024-07-05T06:41:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1922"
  },
  {
    "number": 1917,
    "title": "misc: add transformers version check for TurboMind Tokenizer",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-04T05:28:23Z",
    "closed_at": "2024-07-05T08:54:00Z",
    "merged_at": "2024-07-05T08:54:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1917"
  },
  {
    "number": 1913,
    "title": "PyTorch Engine AWQ support",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-03T12:57:51Z",
    "closed_at": "2024-07-29T13:04:11Z",
    "merged_at": "2024-07-29T13:04:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1913"
  },
  {
    "number": 1912,
    "title": "refactor sampling layer setup",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-03T12:56:14Z",
    "closed_at": "2024-07-10T08:32:25Z",
    "merged_at": "2024-07-10T08:32:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1912"
  },
  {
    "number": 1911,
    "title": "Support internvl2 chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-03T10:12:19Z",
    "closed_at": "2024-07-05T06:59:17Z",
    "merged_at": "2024-07-05T06:59:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1911"
  },
  {
    "number": 1909,
    "title": "Fix smem size for fused split-kv reduction",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-03T09:32:46Z",
    "closed_at": "2024-07-04T09:59:33Z",
    "merged_at": "2024-07-04T09:59:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1909"
  },
  {
    "number": 1899,
    "title": "Remove deprecated chat cli and vl examples",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-02T09:00:44Z",
    "closed_at": "2024-07-04T08:07:26Z",
    "merged_at": "2024-07-04T08:07:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1899"
  },
  {
    "number": 1898,
    "title": "Fix index error when profiling token generation with `-ct 1` ",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-02T07:36:46Z",
    "closed_at": "2024-07-22T08:08:30Z",
    "merged_at": "2024-07-22T08:08:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1898"
  },
  {
    "number": 1897,
    "title": "add internlm2.5 models into testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-02T05:19:15Z",
    "closed_at": "2024-07-03T05:32:37Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1897"
  },
  {
    "number": 1892,
    "title": "docs: update cache-max-entry-count help message",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-01T06:21:06Z",
    "closed_at": "2024-07-01T06:28:27Z",
    "merged_at": "2024-07-01T06:28:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1892"
  },
  {
    "number": 1890,
    "title": "Fix internlm-xcomposer2-vl awq search scale",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-01T04:54:25Z",
    "closed_at": "2024-07-01T08:36:39Z",
    "merged_at": "2024-07-01T08:36:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1890"
  },
  {
    "number": 1889,
    "title": "feat: support llama2 and internlm2 on 910B",
    "user": "yao-fengchen",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-01T04:40:00Z",
    "closed_at": "2024-07-09T11:13:15Z",
    "merged_at": "2024-07-09T11:13:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1889"
  },
  {
    "number": 1887,
    "title": "[Doc]: Update docs for internlm2.5",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-29T13:21:26Z",
    "closed_at": "2024-07-01T05:41:12Z",
    "merged_at": "2024-07-01T05:41:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1887"
  },
  {
    "number": 1886,
    "title": "fix qwen2 cache_position for PyTorch Engine when transformers>4.41.2",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-29T09:47:30Z",
    "closed_at": "2024-07-01T03:44:30Z",
    "merged_at": "2024-07-01T03:44:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1886"
  },
  {
    "number": 1881,
    "title": " Fix error link reference",
    "user": "zihaomu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-28T07:47:15Z",
    "closed_at": "2024-07-01T07:40:31Z",
    "merged_at": "2024-07-01T07:40:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1881"
  },
  {
    "number": 1880,
    "title": "[Doc]: Change to sphinx-book-theme in readthedocs",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-28T07:27:14Z",
    "closed_at": "2024-07-04T07:15:40Z",
    "merged_at": "2024-07-04T07:15:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1880"
  },
  {
    "number": 1877,
    "title": "docs: update faq for turbomind so not found",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-27T15:19:10Z",
    "closed_at": "2024-07-02T02:46:37Z",
    "merged_at": "2024-07-02T02:46:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1877"
  },
  {
    "number": 1876,
    "title": "Add usage in stream response",
    "user": "fbzhong",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-27T14:44:43Z",
    "closed_at": "2024-07-02T04:21:04Z",
    "merged_at": "2024-07-02T04:21:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1876"
  },
  {
    "number": 1875,
    "title": "misc: rm unnecessary files",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-27T12:35:36Z",
    "closed_at": "2024-07-01T07:35:04Z",
    "merged_at": "2024-07-01T07:35:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1875"
  },
  {
    "number": 1874,
    "title": "fix SamplingDecodeTest and SamplingDecodeTest2 unittest failure",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-27T09:49:07Z",
    "closed_at": "2024-07-01T10:14:05Z",
    "merged_at": "2024-07-01T10:14:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1874"
  },
  {
    "number": 1873,
    "title": "fix gradio vl \"stop_words\"",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-27T09:14:40Z",
    "closed_at": "2024-06-27T11:17:29Z",
    "merged_at": "2024-06-27T11:17:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1873"
  },
  {
    "number": 1867,
    "title": "fix model name matching for internvl",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-27T02:39:47Z",
    "closed_at": "2024-06-27T07:14:18Z",
    "merged_at": "2024-06-27T07:14:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1867"
  },
  {
    "number": 1861,
    "title": "react test evaluation config",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-26T08:12:36Z",
    "closed_at": "2024-06-26T08:49:41Z",
    "merged_at": "2024-06-26T08:49:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1861"
  },
  {
    "number": 1860,
    "title": "Fix vl session-len",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-26T07:23:06Z",
    "closed_at": "2024-06-26T12:44:39Z",
    "merged_at": "2024-06-26T12:44:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1860"
  },
  {
    "number": 1859,
    "title": "[side-effect] bring back \"--cap\" argument in chat cli",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-26T06:54:06Z",
    "closed_at": "2024-06-26T10:34:33Z",
    "merged_at": "2024-06-26T10:34:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1859"
  },
  {
    "number": 1858,
    "title": "misc: update torch version range to 2.3.0",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-26T05:57:26Z",
    "closed_at": "2024-07-01T05:36:36Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1858"
  },
  {
    "number": 1856,
    "title": "Support guided decoding for pytorch backend",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-26T03:49:50Z",
    "closed_at": "2024-09-02T11:40:09Z",
    "merged_at": "2024-09-02T11:40:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1856"
  },
  {
    "number": 1855,
    "title": "feat: decouple input_ids and output_ids",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-25T15:59:52Z",
    "closed_at": "2024-11-26T17:09:18Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1855"
  },
  {
    "number": 1854,
    "title": "vision model use tp number of gpu",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-25T15:55:23Z",
    "closed_at": "2024-07-05T04:13:17Z",
    "merged_at": "2024-07-05T04:13:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1854"
  },
  {
    "number": 1853,
    "title": "Optimize sampling on pytorch engine.",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-25T12:33:26Z",
    "closed_at": "2024-07-03T13:43:03Z",
    "merged_at": "2024-07-03T13:43:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1853"
  },
  {
    "number": 1852,
    "title": "bump version to v0.5.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-25T10:24:25Z",
    "closed_at": "2024-07-01T07:19:40Z",
    "merged_at": "2024-07-01T07:19:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1852"
  },
  {
    "number": 1850,
    "title": "misc: align PyTorch Engine temprature with TurboMind",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-25T09:29:23Z",
    "closed_at": "2024-06-26T06:08:28Z",
    "merged_at": "2024-06-26T06:08:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1850"
  },
  {
    "number": 1845,
    "title": "Support phi3-vision",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-25T06:21:49Z",
    "closed_at": "2024-07-02T04:21:26Z",
    "merged_at": "2024-07-02T04:21:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1845"
  },
  {
    "number": 1844,
    "title": "Maybe a workaround for qwen2 quantization Nan error",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-25T05:23:46Z",
    "closed_at": "2024-09-05T07:15:51Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1844"
  },
  {
    "number": 1842,
    "title": "fix cogvlm vl template",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-25T03:00:35Z",
    "closed_at": "2024-06-25T04:50:58Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1842"
  },
  {
    "number": 1838,
    "title": "Harden stream callback",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-24T09:59:11Z",
    "closed_at": "2024-06-24T11:41:09Z",
    "merged_at": "2024-06-24T11:41:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1838"
  },
  {
    "number": 1837,
    "title": "fix image encoder request queue ",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-24T08:56:30Z",
    "closed_at": "2024-06-24T09:10:11Z",
    "merged_at": "2024-06-24T09:10:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1837"
  },
  {
    "number": 1832,
    "title": "",
    "user": "Nianqitongs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-23T09:38:01Z",
    "closed_at": "2024-06-23T09:38:54Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1832"
  },
  {
    "number": 1829,
    "title": "Update engine.py to fix small typos",
    "user": "WANGSSSSSSS",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-23T06:36:43Z",
    "closed_at": "2024-06-24T03:07:58Z",
    "merged_at": "2024-06-24T03:07:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1829"
  },
  {
    "number": 1825,
    "title": "compat internlm2 for pytorch engine",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T11:17:20Z",
    "closed_at": "2024-06-24T08:21:43Z",
    "merged_at": "2024-06-24T08:21:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1825"
  },
  {
    "number": 1824,
    "title": "fix qwen-vl-chat hung",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T10:37:37Z",
    "closed_at": "2024-06-21T14:01:08Z",
    "merged_at": "2024-06-21T14:01:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1824"
  },
  {
    "number": 1823,
    "title": "drop stop words",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T09:04:28Z",
    "closed_at": "2024-07-01T10:09:21Z",
    "merged_at": "2024-07-01T10:09:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1823"
  },
  {
    "number": 1821,
    "title": "Fix Request completed log",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T06:08:47Z",
    "closed_at": "2024-06-21T12:39:54Z",
    "merged_at": "2024-06-21T12:39:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1821"
  },
  {
    "number": 1820,
    "title": "Add Jetson platform support (by docker)",
    "user": "BestAnHongjun",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T04:14:59Z",
    "closed_at": "2025-07-13T11:59:51Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1820"
  },
  {
    "number": 1814,
    "title": "Add model revision & download_dir to cli",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-20T07:45:51Z",
    "closed_at": "2024-06-24T08:24:22Z",
    "merged_at": "2024-06-24T08:24:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1814"
  },
  {
    "number": 1812,
    "title": "fix best_match_model",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-20T06:04:37Z",
    "closed_at": "2024-06-20T20:40:51Z",
    "merged_at": "2024-06-20T20:40:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1812"
  },
  {
    "number": 1811,
    "title": "check driver mismatch",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-20T03:43:26Z",
    "closed_at": "2024-06-20T12:51:22Z",
    "merged_at": "2024-06-20T12:51:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1811"
  },
  {
    "number": 1809,
    "title": "fix: append _stats when size > 0",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-19T15:14:54Z",
    "closed_at": "2024-07-05T09:12:10Z",
    "merged_at": "2024-07-05T09:12:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1809"
  },
  {
    "number": 1807,
    "title": "AsyncEngine create cancel task in exception.",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-19T09:10:56Z",
    "closed_at": "2024-06-21T13:46:08Z",
    "merged_at": "2024-06-21T13:46:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1807"
  },
  {
    "number": 1806,
    "title": "fix pr test for newest internlm2 model",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-19T08:47:34Z",
    "closed_at": "2024-06-20T08:20:59Z",
    "merged_at": "2024-06-20T08:20:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1806"
  },
  {
    "number": 1799,
    "title": "feat: auto set awq model_format from hf",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-18T16:15:17Z",
    "closed_at": "2024-06-19T08:23:40Z",
    "merged_at": "2024-06-19T08:23:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1799"
  },
  {
    "number": 1798,
    "title": "PyTorchEngine adapts to the latest internlm2 modeling.",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-18T12:35:18Z",
    "closed_at": "2024-06-21T09:23:25Z",
    "merged_at": "2024-06-21T09:23:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1798"
  },
  {
    "number": 1797,
    "title": "Support internvl-chat for pytorch engine",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-18T10:51:14Z",
    "closed_at": "2024-06-24T09:02:03Z",
    "merged_at": "2024-06-24T09:02:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1797"
  },
  {
    "number": 1795,
    "title": "[side-effect] fix weight_type caused by PR #1702",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-18T05:26:27Z",
    "closed_at": "2024-06-18T05:41:53Z",
    "merged_at": "2024-06-18T05:41:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1795"
  },
  {
    "number": 1793,
    "title": "Support Qwen2-1.5b awq",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-18T02:55:07Z",
    "closed_at": "2024-06-24T11:42:21Z",
    "merged_at": "2024-06-24T11:42:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1793"
  },
  {
    "number": 1791,
    "title": "fix: prevent numpy breakage",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-17T13:27:04Z",
    "closed_at": "2024-06-18T05:29:51Z",
    "merged_at": "2024-06-18T05:29:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1791"
  },
  {
    "number": 1789,
    "title": "Refine AsyncEngine exception handler",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-17T08:18:18Z",
    "closed_at": "2024-06-18T03:36:10Z",
    "merged_at": "2024-06-18T03:36:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1789"
  },
  {
    "number": 1782,
    "title": "support qwen2 1.5b",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-14T14:05:39Z",
    "closed_at": "2024-06-17T09:32:25Z",
    "merged_at": "2024-06-17T09:32:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1782"
  },
  {
    "number": 1780,
    "title": "Add anomaly handler",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-14T11:20:41Z",
    "closed_at": "2024-06-17T09:10:44Z",
    "merged_at": "2024-06-17T09:10:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1780"
  },
  {
    "number": 1778,
    "title": "[side-effect]Fix param `--cache-max-entry-count` is not taking effect (#1758)",
    "user": "QwertyJack",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-14T06:33:16Z",
    "closed_at": "2024-06-14T11:46:47Z",
    "merged_at": "2024-06-14T11:46:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1778"
  },
  {
    "number": 1775,
    "title": "Device dispatcher",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T09:35:19Z",
    "closed_at": "2024-06-21T08:49:47Z",
    "merged_at": "2024-06-21T08:49:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1775"
  },
  {
    "number": 1773,
    "title": "Encode raw image file to base64",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T06:30:53Z",
    "closed_at": "2024-06-17T14:36:41Z",
    "merged_at": "2024-06-17T14:36:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1773"
  },
  {
    "number": 1772,
    "title": "add qwen2 model into testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T05:42:07Z",
    "closed_at": "2024-06-14T03:21:53Z",
    "merged_at": "2024-06-14T03:21:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1772"
  },
  {
    "number": 1770,
    "title": "lock setuptools version in dockerfile",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T04:31:09Z",
    "closed_at": "2024-06-13T04:45:18Z",
    "merged_at": "2024-06-13T04:45:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1770"
  },
  {
    "number": 1769,
    "title": "skip inference for oversized inputs",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T03:56:21Z",
    "closed_at": "2024-06-18T03:18:28Z",
    "merged_at": "2024-06-18T03:18:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1769"
  },
  {
    "number": 1768,
    "title": "Fix finish_reason",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T02:37:05Z",
    "closed_at": "2024-06-13T07:34:01Z",
    "merged_at": "2024-06-13T07:34:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1768"
  },
  {
    "number": 1765,
    "title": "More accurate time logging for ImageEncoder and fix concurrent image processing corruption",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-12T09:04:12Z",
    "closed_at": "2024-06-18T08:17:40Z",
    "merged_at": "2024-06-18T08:17:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1765"
  },
  {
    "number": 1763,
    "title": "Add tools to api_server for InternLM2 model",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-12T07:02:45Z",
    "closed_at": "2024-07-09T06:15:22Z",
    "merged_at": "2024-07-09T06:15:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1763"
  },
  {
    "number": 1761,
    "title": "fix falcon attention",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-12T04:10:27Z",
    "closed_at": "2024-06-17T09:37:52Z",
    "merged_at": "2024-06-17T09:37:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1761"
  },
  {
    "number": 1754,
    "title": "fix uncached stop words",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-11T07:19:36Z",
    "closed_at": "2024-06-13T09:04:52Z",
    "merged_at": "2024-06-13T09:04:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1754"
  },
  {
    "number": 1753,
    "title": "Detokenize with prompt token ids",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-11T07:03:30Z",
    "closed_at": "2024-06-22T10:44:23Z",
    "merged_at": "2024-06-22T10:44:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1753"
  },
  {
    "number": 1751,
    "title": "refactor config",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-11T05:03:26Z",
    "closed_at": "2024-06-14T03:49:38Z",
    "merged_at": "2024-06-14T03:49:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1751"
  },
  {
    "number": 1741,
    "title": "[Bugfix] fix internvl-1.5-chat vision model preprocess and freeze weights",
    "user": "DefTruth",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-08T08:59:05Z",
    "closed_at": "2024-06-13T04:24:14Z",
    "merged_at": "2024-06-13T04:24:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1741"
  },
  {
    "number": 1736,
    "title": "docs: add BentoLMDeploy in README",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-07T15:27:31Z",
    "closed_at": "2024-06-08T14:23:32Z",
    "merged_at": "2024-06-08T14:23:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1736"
  },
  {
    "number": 1734,
    "title": "feat: align with OpenAI temperature range in api server",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-07T06:36:55Z",
    "closed_at": "2024-06-07T07:24:21Z",
    "merged_at": "2024-06-07T07:24:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1734"
  },
  {
    "number": 1733,
    "title": "feat: align with OpenAI temperature range",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-07T06:09:41Z",
    "closed_at": "2024-06-07T06:23:51Z",
    "merged_at": "2024-06-07T06:23:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1733"
  },
  {
    "number": 1724,
    "title": "Add GLM-4-9B-Chat",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-06T11:58:42Z",
    "closed_at": "2024-06-21T11:15:21Z",
    "merged_at": "2024-06-21T11:15:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1724"
  },
  {
    "number": 1716,
    "title": "Bugfix: ../generate.sh: 5: [: unexpected operator.",
    "user": "thelongestusernameofall",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T11:27:57Z",
    "closed_at": "2024-06-08T13:16:05Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1716"
  },
  {
    "number": 1715,
    "title": "update dockerfile and docs",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T08:45:37Z",
    "closed_at": "2024-06-06T04:12:28Z",
    "merged_at": "2024-06-06T04:12:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1715"
  },
  {
    "number": 1714,
    "title": "lazy import VLAsyncEngine to avoid bringing in VLMs dependencies when deploying LLMs",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T06:54:11Z",
    "closed_at": "2024-06-06T06:32:48Z",
    "merged_at": "2024-06-06T06:32:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1714"
  },
  {
    "number": 1708,
    "title": "support MiniCPM-Llama3-V 2.5 ",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-04T13:15:18Z",
    "closed_at": "2024-06-11T11:49:12Z",
    "merged_at": "2024-06-11T11:49:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1708"
  },
  {
    "number": 1705,
    "title": "Refine max_new_tokens logic to improve user experience",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-04T05:05:23Z",
    "closed_at": "2024-06-11T11:02:34Z",
    "merged_at": "2024-06-11T11:02:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1705"
  },
  {
    "number": 1702,
    "title": "Refactor converter about get_input_model_registered_name and get_output_model_registered_name_and_config",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-03T08:32:05Z",
    "closed_at": "2024-06-08T13:14:06Z",
    "merged_at": "2024-06-08T13:14:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1702"
  },
  {
    "number": 1694,
    "title": "add longtext generation benchmark",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-31T07:56:53Z",
    "closed_at": "2024-06-11T11:56:01Z",
    "merged_at": "2024-06-11T11:56:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1694"
  },
  {
    "number": 1692,
    "title": "Fix openai package can not use proxy stream mode",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-31T03:24:26Z",
    "closed_at": "2024-06-13T07:29:12Z",
    "merged_at": "2024-06-13T07:29:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1692"
  },
  {
    "number": 1690,
    "title": "fix typos",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-30T09:55:24Z",
    "closed_at": "2024-05-30T10:13:41Z",
    "merged_at": "2024-05-30T10:13:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1690"
  },
  {
    "number": 1687,
    "title": "upgrade the version of the dependency package peft",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-30T03:55:26Z",
    "closed_at": "2024-05-30T11:57:42Z",
    "merged_at": "2024-05-30T11:57:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1687"
  },
  {
    "number": 1684,
    "title": "API Image URL fetch timeout ",
    "user": "vody-am",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-29T14:40:46Z",
    "closed_at": "2024-05-31T13:49:12Z",
    "merged_at": "2024-05-31T13:49:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1684"
  },
  {
    "number": 1683,
    "title": "feat: skip invokeFlattenKV_v2_ when fp16 and bf16 with CacheType::kBlock",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-29T10:45:50Z",
    "closed_at": "2024-08-02T16:56:51Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1683"
  },
  {
    "number": 1679,
    "title": "Add health endpoint",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-29T06:18:22Z",
    "closed_at": "2024-05-30T05:47:49Z",
    "merged_at": "2024-05-30T05:47:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1679"
  },
  {
    "number": 1677,
    "title": "Follow the conventional model_name",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-29T04:50:05Z",
    "closed_at": "2024-05-31T06:57:49Z",
    "merged_at": "2024-05-31T06:57:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1677"
  },
  {
    "number": 1666,
    "title": "Support internlm-xcomposer2-4khd-7b awq",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-28T03:18:09Z",
    "closed_at": "2024-06-06T04:11:51Z",
    "merged_at": "2024-06-06T04:11:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1666"
  },
  {
    "number": 1662,
    "title": "support vl benchmark",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-27T11:00:27Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1662"
  },
  {
    "number": 1661,
    "title": "[side-effect] fix UnboundLocalError for internlm-xcomposer2-4khd-7b",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-27T07:13:31Z",
    "closed_at": "2024-05-27T07:34:44Z",
    "merged_at": "2024-05-27T07:34:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1661"
  },
  {
    "number": 1658,
    "title": "remove paged attention prefill autotune",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-27T06:05:12Z",
    "closed_at": "2024-05-27T08:52:27Z",
    "merged_at": "2024-05-27T08:52:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1658"
  },
  {
    "number": 1657,
    "title": "Update VL document",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-27T03:57:33Z",
    "closed_at": "2024-05-27T04:16:38Z",
    "merged_at": "2024-05-27T04:16:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1657"
  },
  {
    "number": 1654,
    "title": "fix fused-moe in triton2.2.0",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T03:39:11Z",
    "closed_at": "2024-05-24T08:00:36Z",
    "merged_at": "2024-05-24T08:00:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1654"
  },
  {
    "number": 1652,
    "title": "Add interfaces to the pipeline to obtain logits and ppl",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T02:43:21Z",
    "closed_at": "2024-06-25T04:18:26Z",
    "merged_at": "2024-06-25T04:18:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1652"
  },
  {
    "number": 1650,
    "title": "Align tokenizers in pipeline and api_server benchmark scripts",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T02:14:28Z",
    "closed_at": "2024-05-24T09:14:51Z",
    "merged_at": "2024-05-24T09:14:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1650"
  },
  {
    "number": 1649,
    "title": "Optimize GQA/MQA",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-23T11:44:51Z",
    "closed_at": "2024-05-24T10:38:56Z",
    "merged_at": "2024-05-24T10:38:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1649"
  },
  {
    "number": 1648,
    "title": "[side-effect] fix deepseek-vl when tp is 1",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-23T11:15:59Z",
    "closed_at": "2024-05-23T13:43:36Z",
    "merged_at": "2024-05-23T13:43:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1648"
  },
  {
    "number": 1644,
    "title": "bump version to v0.4.2",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-23T07:51:59Z",
    "closed_at": "2024-05-27T08:55:10Z",
    "merged_at": "2024-05-27T08:55:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1644"
  },
  {
    "number": 1641,
    "title": "[Feature]: Support llava for pytorch engine",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-23T03:56:06Z",
    "closed_at": "2024-06-19T06:32:42Z",
    "merged_at": "2024-06-19T06:32:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1641"
  },
  {
    "number": 1640,
    "title": "Fix xcomposer2 vision model process",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-22T12:46:02Z",
    "closed_at": "2024-05-22T12:49:54Z",
    "merged_at": "2024-05-22T12:49:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1640"
  },
  {
    "number": 1636,
    "title": "Fix NTK scaling",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-22T08:54:30Z",
    "closed_at": "2024-05-22T13:24:24Z",
    "merged_at": "2024-05-22T13:24:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1636"
  },
  {
    "number": 1630,
    "title": "add vl awq testcase and refactor pipeline testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-21T12:01:11Z",
    "closed_at": "2024-05-24T11:15:56Z",
    "merged_at": "2024-05-24T11:15:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1630"
  },
  {
    "number": 1627,
    "title": "Support user-specified IMAGE_TOKEN position for deepseek-vl model",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-21T08:28:43Z",
    "closed_at": "2024-05-24T10:10:37Z",
    "merged_at": "2024-05-24T10:10:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1627"
  },
  {
    "number": 1621,
    "title": "Torch deepseek v2",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T13:24:35Z",
    "closed_at": "2024-06-24T03:52:03Z",
    "merged_at": "2024-06-24T03:52:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1621"
  },
  {
    "number": 1620,
    "title": "Fix llava vl template",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T11:58:44Z",
    "closed_at": "2024-05-23T10:13:02Z",
    "merged_at": "2024-05-23T10:13:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1620"
  },
  {
    "number": 1617,
    "title": "Fix transformers 4.41.0 prompt may differ after encode decode",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T07:37:54Z",
    "closed_at": "2024-05-21T06:24:59Z",
    "merged_at": "2024-05-21T06:24:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1617"
  },
  {
    "number": 1616,
    "title": "Fix illegal memory access when seq_len < 64",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T05:29:18Z",
    "closed_at": "2024-05-23T06:37:31Z",
    "merged_at": "2024-05-23T06:37:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1616"
  },
  {
    "number": 1615,
    "title": "Check base64 image validation",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T05:20:25Z",
    "closed_at": "2024-09-05T09:07:48Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1615"
  },
  {
    "number": 1607,
    "title": "[benchmark] optimize benchmark: counting tokenlizer tokens and error requests",
    "user": "NiuBlibing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T04:08:18Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1607"
  },
  {
    "number": 1606,
    "title": "Enable split-kv for attention",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-16T18:53:09Z",
    "closed_at": "2024-05-18T04:07:27Z",
    "merged_at": "2024-05-18T04:07:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1606"
  },
  {
    "number": 1605,
    "title": "support python 3.12",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-16T11:23:37Z",
    "closed_at": "2024-05-16T12:53:27Z",
    "merged_at": "2024-05-16T12:53:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1605"
  },
  {
    "number": 1603,
    "title": "Refactor loading weights",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-16T09:24:51Z",
    "closed_at": "2024-06-12T03:22:34Z",
    "merged_at": "2024-06-12T03:22:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1603"
  },
  {
    "number": 1598,
    "title": "fix logger init",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-16T02:57:03Z",
    "closed_at": "2024-05-16T07:36:47Z",
    "merged_at": "2024-05-16T07:36:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1598"
  },
  {
    "number": 1597,
    "title": "Update doc for prefix caching",
    "user": "ispobock",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-16T02:10:07Z",
    "closed_at": "2024-05-24T14:24:17Z",
    "merged_at": "2024-05-24T14:24:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1597"
  },
  {
    "number": 1594,
    "title": "Bugfix: wrongly assign gen_config with True ",
    "user": "thelongestusernameofall",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-15T06:04:25Z",
    "closed_at": "2024-05-16T12:04:59Z",
    "merged_at": "2024-05-16T12:04:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1594"
  },
  {
    "number": 1591,
    "title": "Balance vision model weights on multi gpus",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-14T07:41:30Z",
    "closed_at": "2024-05-23T07:43:57Z",
    "merged_at": "2024-05-23T07:43:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1591"
  },
  {
    "number": 1579,
    "title": "support mistral and llava_mistral in turbomind",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-10T08:24:44Z",
    "closed_at": "2024-05-27T09:40:45Z",
    "merged_at": "2024-05-27T09:40:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1579"
  },
  {
    "number": 1575,
    "title": "Use a faster format for images in VLMs",
    "user": "isidentical",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-10T01:50:17Z",
    "closed_at": "2024-05-10T03:29:32Z",
    "merged_at": "2024-05-10T03:29:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1575"
  },
  {
    "number": 1568,
    "title": "Fix typo in w8a8.md ",
    "user": "chg0901",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-09T12:57:19Z",
    "closed_at": "2024-05-10T03:29:58Z",
    "merged_at": "2024-05-10T03:29:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1568"
  },
  {
    "number": 1566,
    "title": "add chat-template args to chat cli",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-09T07:13:43Z",
    "closed_at": "2024-05-10T03:30:58Z",
    "merged_at": "2024-05-10T03:30:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1566"
  },
  {
    "number": 1565,
    "title": "add more model into benchmark and evaluate workflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-09T06:17:44Z",
    "closed_at": "2024-05-13T06:36:14Z",
    "merged_at": "2024-05-13T06:36:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1565"
  },
  {
    "number": 1561,
    "title": "fix logprobs output",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-08T08:23:16Z",
    "closed_at": "2024-05-24T06:55:23Z",
    "merged_at": "2024-05-24T06:55:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1561"
  },
  {
    "number": 1559,
    "title": "Add tritonserver testcase",
    "user": "ZhoujhZoe",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-08T06:10:21Z",
    "closed_at": "2024-07-16T17:38:03Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1559"
  },
  {
    "number": 1553,
    "title": "[Feature] Support vl models quantization",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-07T10:07:28Z",
    "closed_at": "2024-05-24T07:55:05Z",
    "merged_at": "2024-05-24T07:55:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1553"
  },
  {
    "number": 1552,
    "title": "support AI4Chem/ChemLLM-7B-Chat-1_5-SFT",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-07T06:45:42Z",
    "closed_at": "2024-12-02T09:00:12Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1552"
  },
  {
    "number": 1550,
    "title": "Get the max session len from config.json",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-07T03:10:07Z",
    "closed_at": "2024-05-15T07:04:41Z",
    "merged_at": "2024-05-15T07:04:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1550"
  },
  {
    "number": 1549,
    "title": "remove first empty token check and add input validation testcase ",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-06T10:44:53Z",
    "closed_at": "2024-05-08T07:00:39Z",
    "merged_at": "2024-05-08T07:00:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1549"
  },
  {
    "number": 1546,
    "title": "Fix convert qwen2 to turbomind",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-06T08:52:02Z",
    "closed_at": "2024-05-06T10:29:38Z",
    "merged_at": "2024-05-06T10:29:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1546"
  },
  {
    "number": 1545,
    "title": "Enable search scale for awq",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-06T08:17:54Z",
    "closed_at": "2024-05-17T11:07:29Z",
    "merged_at": "2024-05-17T11:07:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1545"
  },
  {
    "number": 1544,
    "title": "bump version to v0.4.1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-06T03:00:36Z",
    "closed_at": "2024-05-07T08:19:39Z",
    "merged_at": "2024-05-07T08:19:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1544"
  },
  {
    "number": 1541,
    "title": "fix: update api_server_backend.py to adapt latest gradio",
    "user": "kv-chiu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-03T17:49:21Z",
    "closed_at": "2025-09-08T04:14:44Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1541"
  },
  {
    "number": 1534,
    "title": "Update docker docs for VL api",
    "user": "vody-am",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-30T15:28:17Z",
    "closed_at": "2024-05-06T02:28:55Z",
    "merged_at": "2024-05-06T02:28:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1534"
  },
  {
    "number": 1533,
    "title": "Fix turbomind import in windows",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-30T11:16:11Z",
    "closed_at": "2024-05-05T06:55:24Z",
    "merged_at": "2024-05-05T06:55:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1533"
  },
  {
    "number": 1531,
    "title": "fix installation requirements for windows",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-30T08:54:11Z",
    "closed_at": "2024-04-30T10:01:24Z",
    "merged_at": "2024-04-30T10:01:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1531"
  },
  {
    "number": 1529,
    "title": "update readme wechat qrcode",
    "user": "vansin",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-30T06:18:57Z",
    "closed_at": "2024-04-30T09:28:38Z",
    "merged_at": "2024-04-30T09:28:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1529"
  },
  {
    "number": 1528,
    "title": "add benchmark script to profile pipeline APIs",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-30T05:44:29Z",
    "closed_at": "2024-05-06T06:10:26Z",
    "merged_at": "2024-05-06T06:10:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1528"
  },
  {
    "number": 1527,
    "title": "Remove first empty chunck for api_server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-30T05:29:17Z",
    "closed_at": "2024-05-06T05:30:46Z",
    "merged_at": "2024-05-06T05:30:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1527"
  },
  {
    "number": 1525,
    "title": "Add input validation",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-30T02:39:56Z",
    "closed_at": "2024-05-06T07:19:09Z",
    "merged_at": "2024-05-06T07:19:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1525"
  },
  {
    "number": 1523,
    "title": "Fix typo in w8a8.md",
    "user": "Infinity4B",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-29T13:40:52Z",
    "closed_at": "2024-04-29T14:01:44Z",
    "merged_at": "2024-04-29T14:01:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1523"
  },
  {
    "number": 1520,
    "title": "Optimize moe",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-29T10:15:10Z",
    "closed_at": "2024-05-22T08:01:35Z",
    "merged_at": "2024-05-22T08:01:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1520"
  },
  {
    "number": 1518,
    "title": "make Qwen compatible with Slora when TP > 1",
    "user": "jjjjohnson",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-29T06:06:42Z",
    "closed_at": "2024-05-07T10:37:19Z",
    "merged_at": "2024-05-07T10:37:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1518"
  },
  {
    "number": 1515,
    "title": "Optimize mixtral",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-29T02:39:44Z",
    "closed_at": "2024-05-14T12:28:24Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1515"
  },
  {
    "number": 1513,
    "title": "fix local variable 'response' referenced before assignment in async_engine.generate",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-28T05:30:50Z",
    "closed_at": "2024-04-28T06:06:42Z",
    "merged_at": "2024-04-28T06:06:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1513"
  },
  {
    "number": 1508,
    "title": "complete build.md",
    "user": "YanxingLiu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-27T01:45:44Z",
    "closed_at": "2024-04-30T08:06:55Z",
    "merged_at": "2024-04-30T08:06:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1508"
  },
  {
    "number": 1507,
    "title": "Remove split batch inside pipline inference function",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T12:18:49Z",
    "closed_at": "2024-05-02T02:18:16Z",
    "merged_at": "2024-05-02T02:18:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1507"
  },
  {
    "number": 1506,
    "title": "add modelscope and lora testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T10:22:39Z",
    "closed_at": "2024-04-30T16:46:52Z",
    "merged_at": "2024-04-30T16:46:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1506"
  },
  {
    "number": 1502,
    "title": "[Feature]: Support cogvlm-chat",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T03:40:01Z",
    "closed_at": "2024-06-04T06:44:09Z",
    "merged_at": "2024-06-04T06:44:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1502"
  },
  {
    "number": 1499,
    "title": "Optimize kernel launch for triton2.2.0 and triton2.3.0",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T12:24:26Z",
    "closed_at": "2024-06-19T06:38:40Z",
    "merged_at": "2024-06-19T06:38:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1499"
  },
  {
    "number": 1497,
    "title": "support phi3",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T08:36:06Z",
    "closed_at": "2024-05-13T03:02:22Z",
    "merged_at": "2024-05-13T03:02:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1497"
  },
  {
    "number": 1493,
    "title": "Format supported model table using html syntax",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T03:40:38Z",
    "closed_at": "2024-05-06T05:26:36Z",
    "merged_at": "2024-05-06T05:26:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1493"
  },
  {
    "number": 1491,
    "title": "variable `CTA_H` & fix qkv bias",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T18:24:48Z",
    "closed_at": "2024-04-28T06:07:14Z",
    "merged_at": "2024-04-28T06:07:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1491"
  },
  {
    "number": 1490,
    "title": "support OpenGVLab/InternVL-Chat-V1-5",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T12:15:26Z",
    "closed_at": "2024-04-29T10:18:40Z",
    "merged_at": "2024-04-29T10:18:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1490"
  },
  {
    "number": 1488,
    "title": "doc: add example of deploying api server to Kubernetes",
    "user": "uzuku",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T11:19:15Z",
    "closed_at": "2024-05-06T07:35:09Z",
    "merged_at": "2024-05-06T07:35:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1488"
  },
  {
    "number": 1486,
    "title": "Add tritonserver testcase",
    "user": "ZhoujhZoe",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T06:25:16Z",
    "closed_at": "2024-05-06T06:25:09Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1486"
  },
  {
    "number": 1485,
    "title": "update supported models for Baichuan",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T06:08:53Z",
    "closed_at": "2024-04-24T09:20:24Z",
    "merged_at": "2024-04-24T09:20:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1485"
  },
  {
    "number": 1482,
    "title": "refactor vision model loading",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-23T10:31:03Z",
    "closed_at": "2024-04-29T12:20:51Z",
    "merged_at": "2024-04-29T12:20:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1482"
  },
  {
    "number": 1480,
    "title": "Fix the side effect in engine_intance brought by #1391",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-23T09:30:26Z",
    "closed_at": "2024-04-23T09:52:07Z",
    "merged_at": "2024-04-23T09:52:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1480"
  },
  {
    "number": 1478,
    "title": "Adding api_key and model_name parameters to the restful benchmark",
    "user": "NiuBlibing",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-23T06:39:09Z",
    "closed_at": "2024-04-25T08:48:45Z",
    "merged_at": "2024-04-25T08:48:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1478"
  },
  {
    "number": 1476,
    "title": "fix adapter failure when tp>1",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-23T03:20:20Z",
    "closed_at": "2024-04-23T06:22:03Z",
    "merged_at": "2024-04-23T06:22:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1476"
  },
  {
    "number": 1473,
    "title": "get model in advance to fix downloading from modelscope error",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-22T12:56:47Z",
    "closed_at": "2024-04-23T06:32:03Z",
    "merged_at": "2024-04-23T06:32:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1473"
  },
  {
    "number": 1470,
    "title": "Add qwen1.5 awq quantization",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-22T09:13:19Z",
    "closed_at": "2024-04-22T10:39:38Z",
    "merged_at": "2024-04-22T10:39:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1470"
  },
  {
    "number": 1469,
    "title": "bump version to v0.4.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-22T05:11:23Z",
    "closed_at": "2024-04-23T11:17:54Z",
    "merged_at": "2024-04-23T11:17:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1469"
  },
  {
    "number": 1468,
    "title": "support starcoder2",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-22T04:27:32Z",
    "closed_at": "2024-04-25T09:05:08Z",
    "merged_at": "2024-04-25T09:05:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1468"
  },
  {
    "number": 1467,
    "title": "fix free repetition_penalty_workspace_ buffer",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-22T03:28:20Z",
    "closed_at": "2024-04-22T03:48:45Z",
    "merged_at": "2024-04-22T03:48:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1467"
  },
  {
    "number": 1465,
    "title": "set infinity timeout to nccl",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-19T11:09:16Z",
    "closed_at": "2024-04-21T09:09:28Z",
    "merged_at": "2024-04-21T09:09:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1465"
  },
  {
    "number": 1464,
    "title": "change cutlass url in ut",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-19T06:03:40Z",
    "closed_at": "2024-04-19T11:57:06Z",
    "merged_at": "2024-04-19T11:57:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1464"
  },
  {
    "number": 1462,
    "title": "update doc for llama3",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-19T04:04:00Z",
    "closed_at": "2024-04-19T05:49:35Z",
    "merged_at": "2024-04-19T05:49:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1462"
  },
  {
    "number": 1461,
    "title": "Add llama3 chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-19T03:50:00Z",
    "closed_at": "2024-04-19T05:24:52Z",
    "merged_at": "2024-04-19T05:24:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1461"
  },
  {
    "number": 1458,
    "title": "support internlm-xcomposer2-7b & internlm-xcomposer2-4khd-7b",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-18T16:41:40Z",
    "closed_at": "2024-04-22T10:21:21Z",
    "merged_at": "2024-04-22T10:21:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1458"
  },
  {
    "number": 1457,
    "title": "Optimize apply_rotary kernel and remove useless inference_mode",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-18T13:36:16Z",
    "closed_at": "2024-04-20T08:36:00Z",
    "merged_at": "2024-04-20T08:36:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1457"
  },
  {
    "number": 1456,
    "title": "Feat: format internlm2 chat template",
    "user": "liujiangning30",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-18T11:36:13Z",
    "closed_at": "2024-04-22T07:02:29Z",
    "merged_at": "2024-04-22T07:02:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1456"
  },
  {
    "number": 1453,
    "title": "warning transformers version",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-18T09:59:43Z",
    "closed_at": "2024-04-19T05:04:34Z",
    "merged_at": "2024-04-19T05:04:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1453"
  },
  {
    "number": 1451,
    "title": "impove rotary embedding of qwen in torch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-18T04:37:16Z",
    "closed_at": "2024-04-19T06:09:19Z",
    "merged_at": "2024-04-19T06:09:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1451"
  },
  {
    "number": 1450,
    "title": "Turbomind prefix caching",
    "user": "ispobock",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-18T04:03:58Z",
    "closed_at": "2024-05-15T09:44:41Z",
    "merged_at": "2024-05-15T09:44:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1450"
  },
  {
    "number": 1448,
    "title": "Add kvint4/8 ete testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-18T01:15:38Z",
    "closed_at": "2024-04-18T12:58:42Z",
    "merged_at": "2024-04-18T12:58:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1448"
  },
  {
    "number": 1447,
    "title": "Optimize slora",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-17T12:12:51Z",
    "closed_at": "2024-05-08T12:22:52Z",
    "merged_at": "2024-05-08T12:22:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1447"
  },
  {
    "number": 1444,
    "title": "add interactive api in service for VL models",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-17T07:18:37Z",
    "closed_at": "2024-04-19T11:58:25Z",
    "merged_at": "2024-04-19T11:58:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1444"
  },
  {
    "number": 1441,
    "title": "remove space in deepseek template",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-17T02:39:09Z",
    "closed_at": "2024-04-18T03:36:12Z",
    "merged_at": "2024-04-18T03:36:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1441"
  },
  {
    "number": 1438,
    "title": "Support mini gemini llama",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-16T10:32:40Z",
    "closed_at": "2024-04-19T09:08:27Z",
    "merged_at": "2024-04-19T09:08:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1438"
  },
  {
    "number": 1436,
    "title": "add the recommendation version for Python Backend",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-16T07:39:13Z",
    "closed_at": "2024-04-16T07:54:39Z",
    "merged_at": "2024-04-16T07:54:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1436"
  },
  {
    "number": 1434,
    "title": "Initialize vl encoder first to avoid OOM",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-15T09:50:47Z",
    "closed_at": "2024-04-16T03:32:23Z",
    "merged_at": "2024-04-16T03:32:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1434"
  },
  {
    "number": 1433,
    "title": "Expose dynamic split&fuse parameters",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-15T03:04:49Z",
    "closed_at": "2024-04-16T11:30:35Z",
    "merged_at": "2024-04-16T11:30:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1433"
  },
  {
    "number": 1430,
    "title": "Support qwen1.5-*-AWQ model inference in turbomind",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-12T09:50:42Z",
    "closed_at": "2024-04-15T02:59:30Z",
    "merged_at": "2024-04-15T02:59:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1430"
  },
  {
    "number": 1429,
    "title": "PyTorch Engine hash table based prefix caching",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-12T07:33:03Z",
    "closed_at": "2024-05-07T10:22:36Z",
    "merged_at": "2024-05-07T10:22:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1429"
  },
  {
    "number": 1428,
    "title": "Add colab demo",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-12T04:48:30Z",
    "closed_at": "2024-04-24T03:17:23Z",
    "merged_at": "2024-04-24T03:17:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1428"
  },
  {
    "number": 1427,
    "title": "Fix loading single safetensor file error",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-12T02:27:42Z",
    "closed_at": "2024-04-12T05:52:13Z",
    "merged_at": "2024-04-12T05:52:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1427"
  },
  {
    "number": 1426,
    "title": "support Internvl chat llava",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-11T12:50:07Z",
    "closed_at": "2024-04-17T06:40:06Z",
    "merged_at": "2024-04-17T06:40:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1426"
  },
  {
    "number": 1425,
    "title": "support Internvl chat v1.1, v1.2 and v1.2-plus",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-11T12:45:11Z",
    "closed_at": "2024-04-16T02:54:13Z",
    "merged_at": "2024-04-16T02:54:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1425"
  },
  {
    "number": 1423,
    "title": "Add metrics endpoint",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-11T07:29:18Z",
    "closed_at": "2025-07-07T08:36:53Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1423"
  },
  {
    "number": 1420,
    "title": "miss --trust-remote-code in converter, which is side effect brought by pr #1406",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T12:12:10Z",
    "closed_at": "2024-04-11T03:07:43Z",
    "merged_at": "2024-04-11T03:07:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1420"
  },
  {
    "number": 1419,
    "title": "Add benchmark report generated in summary",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T11:28:31Z",
    "closed_at": "2024-04-15T06:28:08Z",
    "merged_at": "2024-04-15T06:28:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1419"
  },
  {
    "number": 1417,
    "title": "fix sampling kernel",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T04:51:31Z",
    "closed_at": "2024-04-12T03:46:16Z",
    "merged_at": "2024-04-12T03:46:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1417"
  },
  {
    "number": 1416,
    "title": "add restful completions v1 test case",
    "user": "ZhoujhZoe",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T02:11:14Z",
    "closed_at": "2024-04-16T10:29:27Z",
    "merged_at": "2024-04-16T10:29:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1416"
  },
  {
    "number": 1415,
    "title": "Add triton server chatbot testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-09T05:51:12Z",
    "closed_at": "2024-04-24T08:27:21Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1415"
  },
  {
    "number": 1414,
    "title": "Fix llama_triton_example",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-09T04:57:46Z",
    "closed_at": "2024-04-09T12:12:06Z",
    "merged_at": "2024-04-09T12:12:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1414"
  },
  {
    "number": 1412,
    "title": "Update kv quantization and inference guide",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-08T12:16:32Z",
    "closed_at": "2024-04-16T08:40:46Z",
    "merged_at": "2024-04-16T08:40:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1412"
  },
  {
    "number": 1411,
    "title": "fix typo in get_started guide",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-08T09:05:48Z",
    "closed_at": "2024-04-08T12:18:48Z",
    "merged_at": "2024-04-08T12:18:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1411"
  },
  {
    "number": 1410,
    "title": "[WIP]: checkout cutlass explicitly",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-08T08:43:13Z",
    "closed_at": "2024-04-08T09:08:59Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1410"
  },
  {
    "number": 1409,
    "title": "Add async openai demo for api_server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-08T08:17:40Z",
    "closed_at": "2024-04-11T03:14:43Z",
    "merged_at": "2024-04-11T03:14:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1409"
  },
  {
    "number": 1408,
    "title": "add llava-v1.6-34b template",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-08T06:39:52Z",
    "closed_at": "2024-04-10T10:10:33Z",
    "merged_at": "2024-04-10T10:10:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1408"
  },
  {
    "number": 1406,
    "title": "Support qwen1.5 in turbomind engine",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T11:48:51Z",
    "closed_at": "2024-04-09T05:56:27Z",
    "merged_at": "2024-04-09T05:56:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1406"
  },
  {
    "number": 1405,
    "title": "hack cmakelist.txt in pr_test workflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T10:46:51Z",
    "closed_at": "2024-04-08T10:02:50Z",
    "merged_at": "2024-04-08T10:02:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1405"
  },
  {
    "number": 1403,
    "title": "Support model_name  customization for api_server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T07:18:10Z",
    "closed_at": "2024-04-16T06:08:09Z",
    "merged_at": "2024-04-16T06:08:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1403"
  },
  {
    "number": 1401,
    "title": "fix chat cli `ArgumentError` error happened in python 3.11",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T03:07:51Z",
    "closed_at": "2024-04-07T10:36:00Z",
    "merged_at": "2024-04-07T10:36:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1401"
  },
  {
    "number": 1400,
    "title": "Add model name corresponding to the test data in the doc",
    "user": "wykvictor",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-07T03:02:27Z",
    "closed_at": "2024-04-07T10:54:46Z",
    "merged_at": "2024-04-07T10:54:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1400"
  },
  {
    "number": 1397,
    "title": "Optimize inference of pytorch engine with tensor parallelism",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-05T05:24:12Z",
    "closed_at": "2024-04-05T09:38:42Z",
    "merged_at": "2024-04-05T09:38:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1397"
  },
  {
    "number": 1393,
    "title": "Torch engine prefix caching",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-04T04:40:09Z",
    "closed_at": "2024-05-07T12:01:41Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1393"
  },
  {
    "number": 1392,
    "title": "Optimize TP performance of pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-03T12:06:50Z",
    "closed_at": "2024-04-05T03:08:39Z",
    "merged_at": "2024-04-05T03:08:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1392"
  },
  {
    "number": 1391,
    "title": "support output logprobs with turbomind backend.",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-03T11:43:39Z",
    "closed_at": "2024-04-21T14:12:07Z",
    "merged_at": "2024-04-21T14:12:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1391"
  },
  {
    "number": 1389,
    "title": "handle SIGTERM",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-03T08:11:20Z",
    "closed_at": "2024-04-07T03:48:00Z",
    "merged_at": "2024-04-07T03:47:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1389"
  },
  {
    "number": 1387,
    "title": "bump version to v0.3.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-03T01:48:15Z",
    "closed_at": "2024-04-03T01:55:16Z",
    "merged_at": "2024-04-03T01:55:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1387"
  },
  {
    "number": 1383,
    "title": "Reduce binary size, add `sm_89` and `sm_90` targets",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-02T08:02:16Z",
    "closed_at": "2024-04-04T06:16:45Z",
    "merged_at": "2024-04-04T06:16:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1383"
  },
  {
    "number": 1382,
    "title": "[Fix] fix the unit test of model name deduce",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-02T07:42:42Z",
    "closed_at": "2024-04-02T07:59:16Z",
    "merged_at": "2024-04-02T07:59:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1382"
  },
  {
    "number": 1380,
    "title": "bump version to v0.3.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-02T03:39:40Z",
    "closed_at": "2024-04-02T15:48:29Z",
    "merged_at": "2024-04-02T15:48:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1380"
  },
  {
    "number": 1377,
    "title": "Online 8/4-bit KV-cache quantization",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-01T10:54:09Z",
    "closed_at": "2024-04-11T06:21:12Z",
    "merged_at": "2024-04-11T06:21:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1377"
  },
  {
    "number": 1373,
    "title": "update `max_prefill_token_num` for low gpu memory",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-29T09:38:39Z",
    "closed_at": "2024-04-01T07:28:25Z",
    "merged_at": "2024-04-01T07:28:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1373"
  },
  {
    "number": 1372,
    "title": "Support qwen2 moe for pytorch engine",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-29T08:28:35Z",
    "closed_at": "2024-04-01T07:48:03Z",
    "merged_at": "2024-04-01T07:48:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1372"
  },
  {
    "number": 1371,
    "title": "update triton server version to r24.03",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-29T08:23:16Z",
    "closed_at": "2024-04-16T07:41:02Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1371"
  },
  {
    "number": 1369,
    "title": "add protobuf to runtime.txt",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-29T08:21:56Z",
    "closed_at": "2024-04-01T10:25:45Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1369"
  },
  {
    "number": 1368,
    "title": "update lmdeploy pypi packages deps to cuda12",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-29T07:34:19Z",
    "closed_at": "2024-03-29T08:16:19Z",
    "merged_at": "2024-03-29T08:16:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1368"
  },
  {
    "number": 1367,
    "title": "torch engine support dbrx",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-29T06:48:02Z",
    "closed_at": "2024-04-01T04:08:42Z",
    "merged_at": "2024-04-01T04:08:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1367"
  },
  {
    "number": 1364,
    "title": "Add benchmark test workflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-28T08:55:13Z",
    "closed_at": "2024-04-02T04:14:08Z",
    "merged_at": "2024-04-02T04:14:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1364"
  },
  {
    "number": 1361,
    "title": "Fix memory leak of DLManagedTensor",
    "user": "ispobock",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-28T00:55:36Z",
    "closed_at": "2024-03-28T06:58:03Z",
    "merged_at": "2024-03-28T06:58:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1361"
  },
  {
    "number": 1360,
    "title": "Set deleter to dl_managed_tensor when building it",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T10:50:46Z",
    "closed_at": "2024-03-27T11:54:59Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1360"
  },
  {
    "number": 1359,
    "title": "lazy import accelerate.init_empty_weights for vl async engine",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T10:30:44Z",
    "closed_at": "2024-03-28T09:35:43Z",
    "merged_at": "2024-03-28T09:35:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1359"
  },
  {
    "number": 1358,
    "title": "fix batchApplyRepetitionPenalty",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T10:05:32Z",
    "closed_at": "2024-03-28T06:42:46Z",
    "merged_at": "2024-03-28T06:42:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1358"
  },
  {
    "number": 1354,
    "title": "Fix invalid context for Internstudio platform",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T08:52:37Z",
    "closed_at": "2024-03-27T10:40:22Z",
    "merged_at": "2024-03-27T10:40:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1354"
  },
  {
    "number": 1353,
    "title": "Optimize w8a8 kernel",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T07:24:25Z",
    "closed_at": "2024-05-16T11:39:08Z",
    "merged_at": "2024-05-16T11:39:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1353"
  },
  {
    "number": 1352,
    "title": "Use new event loop instead of the current loop for pipeline",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T06:49:59Z",
    "closed_at": "2024-04-05T05:26:27Z",
    "merged_at": "2024-04-05T05:26:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1352"
  },
  {
    "number": 1351,
    "title": "Update rewritings for qwen",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-27T02:58:10Z",
    "closed_at": "2024-03-28T07:07:37Z",
    "merged_at": "2024-03-28T07:07:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1351"
  },
  {
    "number": 1349,
    "title": "fix benchmark generation",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-26T09:34:22Z",
    "closed_at": "2024-03-28T03:51:30Z",
    "merged_at": "2024-03-28T03:51:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1349"
  },
  {
    "number": 1348,
    "title": "remove unused flash_attention folder",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-26T08:38:07Z",
    "closed_at": "2024-03-28T06:01:02Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1348"
  },
  {
    "number": 1345,
    "title": "custom master addr and port",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-26T03:12:50Z",
    "closed_at": "2024-04-07T02:25:47Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1345"
  },
  {
    "number": 1344,
    "title": "Fix dlpack memory leak",
    "user": "ispobock",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-26T03:08:32Z",
    "closed_at": "2024-03-26T04:34:14Z",
    "merged_at": "2024-03-26T04:34:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1344"
  },
  {
    "number": 1343,
    "title": "Add slora example for pipeline",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-26T03:01:48Z",
    "closed_at": "2024-04-02T03:43:58Z",
    "merged_at": "2024-04-02T03:43:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1343"
  },
  {
    "number": 1341,
    "title": "fix window attention",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-25T13:25:54Z",
    "closed_at": "2024-03-28T06:04:53Z",
    "merged_at": "2024-03-28T06:04:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1341"
  },
  {
    "number": 1339,
    "title": "workflow bugfix and add llava-v1.5-13b testcase",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-25T12:08:03Z",
    "closed_at": "2024-03-26T11:07:45Z",
    "merged_at": "2024-03-26T11:07:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1339"
  },
  {
    "number": 1336,
    "title": "fix vlm inference hung with tp",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-25T08:36:22Z",
    "closed_at": "2024-03-29T11:43:51Z",
    "merged_at": "2024-03-29T11:43:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1336"
  },
  {
    "number": 1335,
    "title": "Add deepseek vl",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-25T06:48:31Z",
    "closed_at": "2024-04-02T07:21:44Z",
    "merged_at": "2024-04-02T07:21:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1335"
  },
  {
    "number": 1332,
    "title": "Add docs of support new vl model",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-22T08:56:07Z",
    "closed_at": "2024-09-05T09:44:54Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1332"
  },
  {
    "number": 1329,
    "title": "Support Triton inference server python backend",
    "user": "ispobock",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T12:05:56Z",
    "closed_at": "2024-03-28T07:08:22Z",
    "merged_at": "2024-03-28T07:08:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1329"
  },
  {
    "number": 1328,
    "title": "Optimize pipeline of pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T10:55:16Z",
    "closed_at": "2024-04-02T05:56:01Z",
    "merged_at": "2024-04-02T05:56:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1328"
  },
  {
    "number": 1326,
    "title": "Pytorch engine set device.",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T07:08:28Z",
    "closed_at": "2024-04-09T07:59:36Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1326"
  },
  {
    "number": 1325,
    "title": "remove cuda cache after loading vison model",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T03:09:00Z",
    "closed_at": "2024-03-22T06:35:24Z",
    "merged_at": "2024-03-22T06:35:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1325"
  },
  {
    "number": 1323,
    "title": "Add more log info for api_server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-21T02:40:36Z",
    "closed_at": "2024-03-22T03:13:26Z",
    "merged_at": "2024-03-22T03:13:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1323"
  },
  {
    "number": 1318,
    "title": "Add offline mode for testcase workflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-20T12:02:45Z",
    "closed_at": "2024-03-22T03:16:12Z",
    "merged_at": "2024-03-22T03:16:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1318"
  },
  {
    "number": 1317,
    "title": "add missed argument",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-20T09:54:16Z",
    "closed_at": "2024-03-21T12:22:04Z",
    "merged_at": "2024-03-21T12:22:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1317"
  },
  {
    "number": 1310,
    "title": "add chat template for deepseek coder model",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-19T12:37:38Z",
    "closed_at": "2024-03-20T07:02:16Z",
    "merged_at": "2024-03-20T07:02:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1310"
  },
  {
    "number": 1308,
    "title": "add citation in readme",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-19T02:48:22Z",
    "closed_at": "2024-03-19T02:53:14Z",
    "merged_at": "2024-03-19T02:53:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1308"
  },
  {
    "number": 1307,
    "title": "upgrade turbomind to v2.1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-19T02:47:59Z",
    "closed_at": "2024-03-19T07:24:38Z",
    "merged_at": "2024-03-19T07:24:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1307"
  },
  {
    "number": 1304,
    "title": "Fix crash when api_server loads a turbomind model",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-18T11:38:04Z",
    "closed_at": "2024-03-18T12:06:21Z",
    "merged_at": "2024-03-18T12:06:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1304"
  },
  {
    "number": 1302,
    "title": "Add restful interface regrssion daily test workflow.",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-18T07:15:51Z",
    "closed_at": "2024-03-19T10:04:57Z",
    "merged_at": "2024-03-19T10:04:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1302"
  },
  {
    "number": 1300,
    "title": "fix torch tp lora adapter",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-18T05:09:35Z",
    "closed_at": "2024-03-18T06:56:27Z",
    "merged_at": "2024-03-18T06:56:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1300"
  },
  {
    "number": 1299,
    "title": "bump version to v0.2.6",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-18T04:55:02Z",
    "closed_at": "2024-03-19T02:42:29Z",
    "merged_at": "2024-03-19T02:42:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1299"
  },
  {
    "number": 1295,
    "title": "Fix performance issue of chatbot",
    "user": "ispobock",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-16T07:20:48Z",
    "closed_at": "2024-03-20T04:42:11Z",
    "merged_at": "2024-03-20T04:42:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1295"
  },
  {
    "number": 1294,
    "title": "Fall back to base template if there is no chat_template in tokenizer_config.json",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-15T09:58:14Z",
    "closed_at": "2024-03-15T10:39:00Z",
    "merged_at": "2024-03-15T10:39:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1294"
  },
  {
    "number": 1293,
    "title": "Serve VLM by gradio",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-15T07:53:45Z",
    "closed_at": "2024-03-18T04:56:59Z",
    "merged_at": "2024-03-18T04:56:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1293"
  },
  {
    "number": 1292,
    "title": "Add pipeline.chat api for easy use",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-15T06:33:24Z",
    "closed_at": "2024-03-18T06:47:06Z",
    "merged_at": "2024-03-18T06:47:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1292"
  },
  {
    "number": 1288,
    "title": "Update readthedocs index",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-14T07:35:00Z",
    "closed_at": "2024-03-15T04:09:41Z",
    "merged_at": "2024-03-15T04:09:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1288"
  },
  {
    "number": 1287,
    "title": "rename restful_api.md to api_server.md",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-14T07:27:06Z",
    "closed_at": "2024-03-15T03:07:56Z",
    "merged_at": "2024-03-15T03:07:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1287"
  },
  {
    "number": 1286,
    "title": "Support slora to pipeline",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-14T07:04:05Z",
    "closed_at": "2024-03-20T04:41:37Z",
    "merged_at": "2024-03-20T04:41:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1286"
  },
  {
    "number": 1285,
    "title": "Support serving VLMs",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-14T06:55:48Z",
    "closed_at": "2024-03-15T10:38:17Z",
    "merged_at": "2024-03-15T10:38:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1285"
  },
  {
    "number": 1284,
    "title": "upgrade peft and check adapters",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-14T03:56:11Z",
    "closed_at": "2024-03-14T09:11:53Z",
    "merged_at": "2024-03-14T09:11:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1284"
  },
  {
    "number": 1282,
    "title": "Fix concatenate issue in profile serving",
    "user": "ispobock",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-13T09:17:19Z",
    "closed_at": "2024-03-14T06:48:26Z",
    "merged_at": "2024-03-14T06:48:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1282"
  },
  {
    "number": 1281,
    "title": "fix bf16 check",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-13T08:48:47Z",
    "closed_at": "2024-03-13T09:00:07Z",
    "merged_at": "2024-03-13T09:00:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1281"
  },
  {
    "number": 1279,
    "title": "remove evaluate workflow reviewer approval.",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-13T03:21:52Z",
    "closed_at": "2024-03-13T03:56:20Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1279"
  },
  {
    "number": 1278,
    "title": "[Fix] fix triton server chatbot init error",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-13T02:11:24Z",
    "closed_at": "2024-03-14T03:09:32Z",
    "merged_at": "2024-03-14T03:09:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1278"
  },
  {
    "number": 1277,
    "title": "[BUG] fix the case when num_used_blocks < 0 ",
    "user": "jjjjohnson",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-12T08:27:58Z",
    "closed_at": "2024-03-13T05:58:36Z",
    "merged_at": "2024-03-13T05:58:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1277"
  },
  {
    "number": 1276,
    "title": "Add new chat cli with auto backend feature",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-12T07:14:02Z",
    "closed_at": "2024-03-26T04:24:46Z",
    "merged_at": "2024-03-26T04:24:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1276"
  },
  {
    "number": 1275,
    "title": " when num_required_blocks > num_drop_blocks, num_used_blocks < 0",
    "user": "jjjjohnson",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-12T06:58:26Z",
    "closed_at": "2024-03-12T08:26:58Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1275"
  },
  {
    "number": 1272,
    "title": "better cache allocation in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-11T08:09:50Z",
    "closed_at": "2024-03-14T09:12:45Z",
    "merged_at": "2024-03-14T09:12:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1272"
  },
  {
    "number": 1271,
    "title": " Test case bugfix and add restful interface testcases.",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-11T07:06:26Z",
    "closed_at": "2024-03-13T03:12:26Z",
    "merged_at": "2024-03-13T03:12:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1271"
  },
  {
    "number": 1270,
    "title": "Check bf16 model in torch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-11T03:52:14Z",
    "closed_at": "2024-03-13T08:04:12Z",
    "merged_at": "2024-03-13T08:04:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1270"
  },
  {
    "number": 1265,
    "title": "Support qwen for pytorch engine",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-08T11:57:47Z",
    "closed_at": "2024-03-21T06:21:26Z",
    "merged_at": "2024-03-21T06:21:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1265"
  },
  {
    "number": 1264,
    "title": "Accelerate sample request in benchmark script",
    "user": "ispobock",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-08T07:38:25Z",
    "closed_at": "2024-03-11T02:18:29Z",
    "merged_at": "2024-03-11T02:18:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1264"
  },
  {
    "number": 1260,
    "title": "Add pipeline.chat api for easy use",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-07T07:33:07Z",
    "closed_at": "2024-03-15T06:33:50Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1260"
  },
  {
    "number": 1259,
    "title": "Update eval ci cfg",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-06T11:43:45Z",
    "closed_at": "2024-03-11T12:14:24Z",
    "merged_at": "2024-03-11T12:14:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1259"
  },
  {
    "number": 1258,
    "title": "Add tensor core GQA dispatch for `[4,5,6,8]`",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-06T10:40:42Z",
    "closed_at": "2024-03-11T09:17:16Z",
    "merged_at": "2024-03-11T09:17:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1258"
  },
  {
    "number": 1256,
    "title": "rm unused var",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-06T08:33:49Z",
    "closed_at": "2024-03-06T14:03:47Z",
    "merged_at": "2024-03-06T14:03:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1256"
  },
  {
    "number": 1254,
    "title": "Parallelize testcase and refactor test workflow",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-06T06:51:25Z",
    "closed_at": "2024-03-06T13:51:36Z",
    "merged_at": "2024-03-06T13:51:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1254"
  },
  {
    "number": 1253,
    "title": "lazy load convert_pv jit function",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-06T03:23:02Z",
    "closed_at": "2024-03-11T12:16:07Z",
    "merged_at": "2024-03-11T12:16:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1253"
  },
  {
    "number": 1251,
    "title": "optimize filling kv cache kernel in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-06T02:10:10Z",
    "closed_at": "2024-03-11T12:15:23Z",
    "merged_at": "2024-03-11T12:15:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1251"
  },
  {
    "number": 1248,
    "title": "Update serving guide including api_server and gradio",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-05T09:25:44Z",
    "closed_at": "2024-03-06T03:57:22Z",
    "merged_at": "2024-03-06T03:57:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1248"
  },
  {
    "number": 1247,
    "title": "Color log formatter",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-05T07:46:43Z",
    "closed_at": "2024-03-11T05:58:50Z",
    "merged_at": "2024-03-11T05:58:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1247"
  },
  {
    "number": 1246,
    "title": "fix different stop/bad words length in batch",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-05T06:31:56Z",
    "closed_at": "2024-03-06T06:59:15Z",
    "merged_at": "2024-03-06T06:59:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1246"
  },
  {
    "number": 1245,
    "title": "fix config for readthedocs",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-05T05:58:36Z",
    "closed_at": "2024-03-05T12:12:25Z",
    "merged_at": "2024-03-05T12:12:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1245"
  },
  {
    "number": 1243,
    "title": "update badges in README",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-05T05:02:12Z",
    "closed_at": "2024-03-06T03:06:15Z",
    "merged_at": "2024-03-06T03:06:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1243"
  },
  {
    "number": 1241,
    "title": "update doc index",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-05T02:05:20Z",
    "closed_at": "2024-03-05T03:10:54Z",
    "merged_at": "2024-03-05T03:10:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1241"
  },
  {
    "number": 1240,
    "title": "reduce torchengine prefill mem usage",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T13:46:02Z",
    "closed_at": "2024-03-05T03:56:57Z",
    "merged_at": "2024-03-05T03:56:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1240"
  },
  {
    "number": 1239,
    "title": "fix bf16 multinomial sampling",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T11:06:26Z",
    "closed_at": "2024-03-05T01:55:16Z",
    "merged_at": "2024-03-05T01:55:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1239"
  },
  {
    "number": 1238,
    "title": "Hide qos functions from swagger UI if not applied",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T08:57:56Z",
    "closed_at": "2024-03-06T03:07:21Z",
    "merged_at": "2024-03-06T03:07:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1238"
  },
  {
    "number": 1237,
    "title": "remove unused kernel in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T07:32:42Z",
    "closed_at": "2024-03-05T03:36:29Z",
    "merged_at": "2024-03-05T03:36:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1237"
  },
  {
    "number": 1236,
    "title": "fix pytest version",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T04:03:27Z",
    "closed_at": "2024-03-04T05:09:05Z",
    "merged_at": "2024-03-04T05:09:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1236"
  },
  {
    "number": 1235,
    "title": "bump version to v0.2.5",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T03:40:03Z",
    "closed_at": "2024-03-05T08:38:51Z",
    "merged_at": "2024-03-05T08:38:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1235"
  },
  {
    "number": 1234,
    "title": "optimize pytorch engine inference with falcon model",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-04T02:49:16Z",
    "closed_at": "2024-03-04T05:44:09Z",
    "merged_at": "2024-03-04T05:44:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1234"
  },
  {
    "number": 1231,
    "title": "[WIP] support Medusa",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-03T04:58:36Z",
    "closed_at": "2024-07-07T14:20:41Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1231"
  },
  {
    "number": 1230,
    "title": "Fix `None` session_len",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-02T11:37:25Z",
    "closed_at": "2024-03-02T12:34:49Z",
    "merged_at": "2024-03-02T12:34:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1230"
  },
  {
    "number": 1228,
    "title": "fix multinomial sampling",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-02T06:17:37Z",
    "closed_at": "2024-03-03T13:07:11Z",
    "merged_at": "2024-03-03T13:07:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1228"
  },
  {
    "number": 1226,
    "title": "[WIP] porting Medusa",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-01T15:18:45Z",
    "closed_at": "2024-03-03T04:47:59Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1226"
  },
  {
    "number": 1223,
    "title": "optmize baichuan in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-03-01T04:27:45Z",
    "closed_at": "2024-03-01T07:50:54Z",
    "merged_at": "2024-03-01T07:50:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1223"
  },
  {
    "number": 1220,
    "title": "check model required transformers version",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-29T11:10:11Z",
    "closed_at": "2024-03-01T08:04:21Z",
    "merged_at": "2024-03-01T08:04:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1220"
  },
  {
    "number": 1219,
    "title": "[Fix] Avoid AsyncEngine running the same session id",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-29T10:12:43Z",
    "closed_at": "2024-03-01T08:00:10Z",
    "merged_at": "2024-03-01T08:00:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1219"
  },
  {
    "number": 1218,
    "title": "Expose cache_block_seq_len to API",
    "user": "ispobock",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-29T08:33:26Z",
    "closed_at": "2024-03-19T07:21:36Z",
    "merged_at": "2024-03-19T07:21:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1218"
  },
  {
    "number": 1216,
    "title": "Refactor chat template and support accurate name matching.",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-29T07:39:02Z",
    "closed_at": "2024-03-12T04:35:40Z",
    "merged_at": "2024-03-12T04:35:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1216"
  },
  {
    "number": 1215,
    "title": "torch optmize chatglm3",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-29T07:11:31Z",
    "closed_at": "2024-03-01T10:50:15Z",
    "merged_at": "2024-03-01T10:50:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1215"
  },
  {
    "number": 1214,
    "title": "Add inference pipeline for VL models",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-29T01:56:17Z",
    "closed_at": "2024-03-14T13:09:52Z",
    "merged_at": "2024-03-14T13:09:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1214"
  },
  {
    "number": 1213,
    "title": "[WIP] porting Medusa",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-28T16:12:15Z",
    "closed_at": "2024-03-01T15:19:05Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1213"
  },
  {
    "number": 1211,
    "title": "Auto backend for pipeline and serve when backend is not set to pytorch explicitly",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-28T10:54:58Z",
    "closed_at": "2024-03-04T06:56:37Z",
    "merged_at": "2024-03-04T06:56:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1211"
  },
  {
    "number": 1210,
    "title": "[Fix] Use distinct session id instead of random",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-28T10:20:28Z",
    "closed_at": "2024-02-29T09:17:25Z",
    "merged_at": "2024-02-29T09:17:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1210"
  },
  {
    "number": 1209,
    "title": "fix returning logits in prefill phase of pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-28T10:11:04Z",
    "closed_at": "2024-03-04T04:20:10Z",
    "merged_at": "2024-03-04T04:20:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1209"
  },
  {
    "number": 1208,
    "title": "Add PR test workflow and check-in more testcases",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-28T10:09:31Z",
    "closed_at": "2024-03-01T10:04:36Z",
    "merged_at": "2024-03-01T10:04:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1208"
  },
  {
    "number": 1207,
    "title": "[Fix] Correct session length warning",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-28T07:55:12Z",
    "closed_at": "2024-02-28T11:12:08Z",
    "merged_at": "2024-02-28T11:12:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1207"
  },
  {
    "number": 1206,
    "title": "Async torch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-28T07:28:50Z",
    "closed_at": "2024-03-03T14:42:41Z",
    "merged_at": "2024-03-03T14:42:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1206"
  },
  {
    "number": 1205,
    "title": "fix module map",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-28T06:33:56Z",
    "closed_at": "2024-02-28T06:36:10Z",
    "merged_at": "2024-02-28T06:36:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1205"
  },
  {
    "number": 1203,
    "title": "Add parameter `max_prefill_token_num`",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-27T13:18:19Z",
    "closed_at": "2024-03-01T07:35:34Z",
    "merged_at": "2024-03-01T07:35:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1203"
  },
  {
    "number": 1200,
    "title": "Support passing json file to chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-27T07:52:06Z",
    "closed_at": "2024-03-13T06:09:15Z",
    "merged_at": "2024-03-13T06:09:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1200"
  },
  {
    "number": 1199,
    "title": "feat: support fused_bias_residual_activation for medusa",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-27T06:18:55Z",
    "closed_at": "2024-02-28T16:48:04Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1199"
  },
  {
    "number": 1197,
    "title": "Batched sampling",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-26T13:03:27Z",
    "closed_at": "2024-03-01T04:25:39Z",
    "merged_at": "2024-03-01T04:25:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1197"
  },
  {
    "number": 1196,
    "title": "Add parameter `max_prefill_token_num`",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-26T10:38:38Z",
    "closed_at": "2024-02-27T06:32:54Z",
    "merged_at": "2024-02-27T06:32:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1196"
  },
  {
    "number": 1193,
    "title": "Fix argument error",
    "user": "ispobock",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-26T02:10:35Z",
    "closed_at": "2024-02-26T07:23:11Z",
    "merged_at": "2024-02-26T07:23:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1193"
  },
  {
    "number": 1192,
    "title": "Added tutorial document for deploying lmdeploy on Jetson series boards. ",
    "user": "BestAnHongjun",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-24T17:47:10Z",
    "closed_at": "2024-02-26T10:40:55Z",
    "merged_at": "2024-02-26T10:40:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1192"
  },
  {
    "number": 1188,
    "title": "refactor the logic of getting `model_name`",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-23T10:36:12Z",
    "closed_at": "2024-03-01T05:53:05Z",
    "merged_at": "2024-03-01T05:53:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1188"
  },
  {
    "number": 1186,
    "title": "auto generate pipeline api for readthedocs",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-23T05:07:32Z",
    "closed_at": "2024-02-23T07:25:38Z",
    "merged_at": "2024-02-23T07:25:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1186"
  },
  {
    "number": 1185,
    "title": "fix torch engine infer",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-22T12:26:46Z",
    "closed_at": "2024-02-23T03:11:35Z",
    "merged_at": "2024-02-23T03:11:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1185"
  },
  {
    "number": 1184,
    "title": "Support gemma model in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-22T11:09:57Z",
    "closed_at": "2024-02-29T04:51:53Z",
    "merged_at": "2024-02-29T04:51:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1184"
  },
  {
    "number": 1181,
    "title": "Fix session length for profile generation",
    "user": "ispobock",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-22T08:59:09Z",
    "closed_at": "2024-02-22T10:58:04Z",
    "merged_at": "2024-02-22T10:58:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1181"
  },
  {
    "number": 1179,
    "title": "Use LifoQueue for turbomind async_stream_infer",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-22T05:04:35Z",
    "closed_at": "2024-02-27T04:15:11Z",
    "merged_at": "2024-02-27T04:15:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1179"
  },
  {
    "number": 1175,
    "title": "minor fix benchmark generation guide and script",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-21T09:45:49Z",
    "closed_at": "2024-02-21T11:25:32Z",
    "merged_at": "2024-02-21T11:25:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1175"
  },
  {
    "number": 1174,
    "title": "Add `top_k` in ChatCompletionRequest",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-21T09:33:50Z",
    "closed_at": "2024-02-21T10:39:27Z",
    "merged_at": "2024-02-21T10:39:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1174"
  },
  {
    "number": 1172,
    "title": "Fix all devices occupation when applying tp to torch engine by updating device map",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-21T06:23:43Z",
    "closed_at": "2024-02-28T11:15:44Z",
    "merged_at": "2024-02-28T11:15:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1172"
  },
  {
    "number": 1171,
    "title": "bump version to v0.2.4",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-21T03:47:38Z",
    "closed_at": "2024-02-21T12:54:02Z",
    "merged_at": "2024-02-21T12:54:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1171"
  },
  {
    "number": 1168,
    "title": "Fix falcon chatglm2 template",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-20T09:56:57Z",
    "closed_at": "2024-03-01T03:23:05Z",
    "merged_at": "2024-03-01T03:23:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1168"
  },
  {
    "number": 1166,
    "title": "Support torch cache_max_entry_count",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-20T08:34:37Z",
    "closed_at": "2024-02-20T14:01:00Z",
    "merged_at": "2024-02-20T14:01:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1166"
  },
  {
    "number": 1164,
    "title": "Update interactive output len strategy and response",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-20T06:24:34Z",
    "closed_at": "2024-02-29T06:57:10Z",
    "merged_at": "2024-02-29T06:57:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1164"
  },
  {
    "number": 1163,
    "title": "Support torch deepseek moe",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-20T04:49:06Z",
    "closed_at": "2024-02-28T03:23:34Z",
    "merged_at": "2024-02-28T03:23:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1163"
  },
  {
    "number": 1162,
    "title": "Update Dockerfile order to launch the http service by `docker run` directly",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-20T04:06:35Z",
    "closed_at": "2024-02-20T08:12:04Z",
    "merged_at": "2024-02-20T08:12:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1162"
  },
  {
    "number": 1161,
    "title": "remove chat template config in turbomind engine",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-20T03:54:51Z",
    "closed_at": "2024-06-25T09:04:26Z",
    "merged_at": "2024-06-25T09:04:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1161"
  },
  {
    "number": 1160,
    "title": "Support qwen1.5 in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-20T02:27:49Z",
    "closed_at": "2024-02-23T11:06:41Z",
    "merged_at": "2024-02-23T11:06:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1160"
  },
  {
    "number": 1159,
    "title": "torch engine support chatglm3",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-19T12:15:17Z",
    "closed_at": "2024-02-23T08:06:27Z",
    "merged_at": "2024-02-23T08:06:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1159"
  },
  {
    "number": 1156,
    "title": "set log level default warning for serve and add `block` argument",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-19T09:06:18Z",
    "closed_at": "2024-02-27T07:59:03Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1156"
  },
  {
    "number": 1155,
    "title": "TorchEngine support repetition_penalty",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-19T06:58:49Z",
    "closed_at": "2024-02-27T02:27:45Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1155"
  },
  {
    "number": 1153,
    "title": "update llama triton example",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-19T06:41:44Z",
    "closed_at": "2024-02-21T09:46:40Z",
    "merged_at": "2024-02-21T09:46:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1153"
  },
  {
    "number": 1149,
    "title": "Update api_server.py",
    "user": "909254",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-17T11:04:44Z",
    "closed_at": "2024-02-21T09:32:51Z",
    "merged_at": "2024-02-21T09:32:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1149"
  },
  {
    "number": 1148,
    "title": "Update protocol.py",
    "user": "909254",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-17T11:04:26Z",
    "closed_at": "2024-02-21T10:15:24Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1148"
  },
  {
    "number": 1140,
    "title": "fix export turbomind weight bug",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-07T08:48:54Z",
    "closed_at": "2024-02-07T10:59:48Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1140"
  },
  {
    "number": 1139,
    "title": "Support environment role for internlm2",
    "user": "arkohut",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-07T06:20:46Z",
    "closed_at": "2024-02-17T07:09:26Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1139"
  },
  {
    "number": 1138,
    "title": "Use asyncio.Lifoque for turbomind async_stream_infer",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-07T05:18:53Z",
    "closed_at": "2024-02-21T04:21:09Z",
    "merged_at": "2024-02-21T04:21:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1138"
  },
  {
    "number": 1137,
    "title": "support triton2.2",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-07T04:37:26Z",
    "closed_at": "2024-02-20T13:04:00Z",
    "merged_at": "2024-02-20T13:04:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1137"
  },
  {
    "number": 1136,
    "title": "chore workflows support python 3.12",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-07T03:09:25Z",
    "closed_at": "2024-03-01T15:21:36Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1136"
  },
  {
    "number": 1133,
    "title": "Support mixtral for pytorch engine",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-06T11:09:50Z",
    "closed_at": "2024-02-27T04:42:31Z",
    "merged_at": "2024-02-27T04:42:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1133"
  },
  {
    "number": 1132,
    "title": "Fix win ci",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-06T08:59:55Z",
    "closed_at": "2024-02-20T08:14:02Z",
    "merged_at": "2024-02-20T08:14:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1132"
  },
  {
    "number": 1129,
    "title": "[Fix] configuration_internlm.py -> configuration_internlm2.py",
    "user": "HIT-cwh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-06T04:06:27Z",
    "closed_at": "2024-02-06T04:37:03Z",
    "merged_at": "2024-02-06T04:37:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1129"
  },
  {
    "number": 1126,
    "title": "fix pipeline init turbomind from workspace",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-05T08:15:14Z",
    "closed_at": "2024-02-05T10:02:12Z",
    "merged_at": "2024-02-05T10:02:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1126"
  },
  {
    "number": 1125,
    "title": "fix model_name exception for turbomind",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-05T08:10:26Z",
    "closed_at": "2024-02-05T08:23:12Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1125"
  },
  {
    "number": 1123,
    "title": "bump version to v0.2.3",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-05T07:24:08Z",
    "closed_at": "2024-02-06T05:55:25Z",
    "merged_at": "2024-02-06T05:55:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1123"
  },
  {
    "number": 1122,
    "title": "fix pytorch engine with peft==0.8.2",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-05T06:39:03Z",
    "closed_at": "2024-02-19T03:32:30Z",
    "merged_at": "2024-02-19T03:32:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1122"
  },
  {
    "number": 1121,
    "title": "docs add debug turbomind guide",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-05T06:31:22Z",
    "closed_at": "2024-02-19T08:29:27Z",
    "merged_at": "2024-02-19T08:29:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1121"
  },
  {
    "number": 1120,
    "title": "update contribution guide",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-05T05:18:51Z",
    "closed_at": "2024-02-05T09:56:23Z",
    "merged_at": "2024-02-05T09:56:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1120"
  },
  {
    "number": 1119,
    "title": "use default stop words for turbomind backend in pipeline",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-05T03:24:53Z",
    "closed_at": "2024-02-05T03:47:49Z",
    "merged_at": "2024-02-05T03:47:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1119"
  },
  {
    "number": 1116,
    "title": "Refactor turbomind attention",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-04T12:37:47Z",
    "closed_at": "2024-03-06T06:57:38Z",
    "merged_at": "2024-03-06T06:57:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1116"
  },
  {
    "number": 1115,
    "title": "Add input_token_len to Response and update Response document",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-04T09:55:57Z",
    "closed_at": "2024-02-05T07:14:36Z",
    "merged_at": "2024-02-05T07:14:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1115"
  },
  {
    "number": 1107,
    "title": "check pytorch engine environment",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-02T09:18:10Z",
    "closed_at": "2024-02-20T07:33:36Z",
    "merged_at": "2024-02-20T07:33:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1107"
  },
  {
    "number": 1100,
    "title": "fix turbomind CUDA runtime error invalid argument",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-01T11:39:04Z",
    "closed_at": "2024-02-02T04:52:28Z",
    "merged_at": "2024-02-02T04:52:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1100"
  },
  {
    "number": 1099,
    "title": "dependency version check & fix `ignore_eos` logic",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-01T11:20:24Z",
    "closed_at": "2024-02-05T10:25:28Z",
    "merged_at": "2024-02-05T10:25:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1099"
  },
  {
    "number": 1098,
    "title": "Fix the side effect of pytorch engine",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-01T10:22:08Z",
    "closed_at": "2024-02-01T10:33:44Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1098"
  },
  {
    "number": 1097,
    "title": "remove owned_session",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-01T09:49:36Z",
    "closed_at": "2024-02-04T09:24:18Z",
    "merged_at": "2024-02-04T09:24:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1097"
  },
  {
    "number": 1096,
    "title": "Support `min_new_tokens` generation config in pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-01T09:28:20Z",
    "closed_at": "2024-02-29T13:03:11Z",
    "merged_at": "2024-02-29T13:03:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1096"
  },
  {
    "number": 1095,
    "title": "Support huggingface chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-01T06:52:44Z",
    "closed_at": "2024-02-27T07:52:20Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1095"
  },
  {
    "number": 1094,
    "title": "[Fix] Add safety check for incremental decode",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-01T06:50:03Z",
    "closed_at": "2024-02-02T06:59:58Z",
    "merged_at": "2024-02-02T06:59:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1094"
  },
  {
    "number": 1093,
    "title": "fix device for get_ppl",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-01T06:24:42Z",
    "closed_at": "2024-02-02T07:50:46Z",
    "merged_at": "2024-02-02T07:50:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1093"
  },
  {
    "number": 1092,
    "title": "make logging.logger's behavior consistent with MMLogger",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-01T06:00:19Z",
    "closed_at": "2024-02-02T07:46:06Z",
    "merged_at": "2024-02-02T07:46:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1092"
  },
  {
    "number": 1091,
    "title": "Add skip_special_tokens in GenerationConfig ",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-01T03:07:33Z",
    "closed_at": "2024-02-04T10:05:11Z",
    "merged_at": "2024-02-04T10:05:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1091"
  },
  {
    "number": 1090,
    "title": "Fix unable to set model format to qwen",
    "user": "mokeyish",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-02-01T02:49:00Z",
    "closed_at": "2024-02-01T10:35:56Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1090"
  },
  {
    "number": 1088,
    "title": "Speed up torch engine w8a8 model init",
    "user": "FlamingoPg",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-31T21:01:40Z",
    "closed_at": "2024-02-02T04:38:17Z",
    "merged_at": "2024-02-02T04:38:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1088"
  },
  {
    "number": 1087,
    "title": "Speed up torch engine w8a8 model init",
    "user": "FlamingoPg",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-31T20:54:01Z",
    "closed_at": "2024-01-31T20:54:30Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1087"
  },
  {
    "number": 1086,
    "title": "WIP feat replace blocking console log with async log file",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-31T15:15:21Z",
    "closed_at": "2024-02-05T05:07:13Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1086"
  },
  {
    "number": 1085,
    "title": "unify engine initialization in pipeline",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-31T11:34:32Z",
    "closed_at": "2024-02-04T10:01:30Z",
    "merged_at": "2024-02-04T10:01:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1085"
  },
  {
    "number": 1079,
    "title": "Update chat template for internlm2 base model",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-31T03:43:39Z",
    "closed_at": "2024-01-31T03:55:50Z",
    "merged_at": "2024-01-31T03:55:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1079"
  },
  {
    "number": 1077,
    "title": "Ete testcase add more models",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-31T03:28:30Z",
    "closed_at": "2024-02-17T06:50:21Z",
    "merged_at": "2024-02-17T06:50:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1077"
  },
  {
    "number": 1076,
    "title": "bump version to v0.2.2",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-31T03:22:38Z",
    "closed_at": "2024-01-31T09:56:08Z",
    "merged_at": "2024-01-31T09:56:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1076"
  },
  {
    "number": 1075,
    "title": "Support mistral and sliding window attention",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-31T03:10:13Z",
    "closed_at": "2024-02-23T03:12:06Z",
    "merged_at": "2024-02-23T03:12:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1075"
  },
  {
    "number": 1074,
    "title": "Remove caching tokenizer.json",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-31T02:29:13Z",
    "closed_at": "2024-01-31T11:22:17Z",
    "merged_at": "2024-01-31T11:22:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1074"
  },
  {
    "number": 1073,
    "title": "support internlm2-1_8b",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-30T14:32:26Z",
    "closed_at": "2024-01-31T03:16:36Z",
    "merged_at": "2024-01-31T03:16:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1073"
  },
  {
    "number": 1072,
    "title": "[Fix] Support QLinear in rowwise_parallelize_linear_fn and colwise_parallelize_linear_fn",
    "user": "HIT-cwh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-30T14:29:09Z",
    "closed_at": "2024-01-31T03:21:03Z",
    "merged_at": "2024-01-31T03:21:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1072"
  },
  {
    "number": 1071,
    "title": "fix use TM_LOG_LEVEL environment variable first",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-30T13:15:29Z",
    "closed_at": "2024-02-01T04:54:22Z",
    "merged_at": "2024-02-01T04:54:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1071"
  },
  {
    "number": 1070,
    "title": "use stricter rules to get weight file ",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-30T12:50:29Z",
    "closed_at": "2024-02-18T06:21:18Z",
    "merged_at": "2024-02-18T06:21:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1070"
  },
  {
    "number": 1069,
    "title": "Support loading model from modelscope",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-30T11:49:17Z",
    "closed_at": "2024-02-05T07:34:01Z",
    "merged_at": "2024-02-05T07:34:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1069"
  },
  {
    "number": 1068,
    "title": "Change install prefix from ./install to /opt/tritonserver in daily build script",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-30T11:02:44Z",
    "closed_at": "2024-01-30T11:06:13Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1068"
  },
  {
    "number": 1067,
    "title": "docs update cache_max_entry_count for turbomind config",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-30T08:48:51Z",
    "closed_at": "2024-01-30T09:41:05Z",
    "merged_at": "2024-01-30T09:41:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1067"
  },
  {
    "number": 1064,
    "title": "fix and change all logger using get_logger",
    "user": "FlamingoPg",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-29T13:02:10Z",
    "closed_at": "2024-01-31T11:23:41Z",
    "merged_at": "2024-01-31T11:23:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1064"
  },
  {
    "number": 1062,
    "title": "fix and change all logger using get_logger",
    "user": "FlamingoPg",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-29T10:45:50Z",
    "closed_at": "2024-01-29T12:51:46Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1062"
  },
  {
    "number": 1061,
    "title": "Fix serve api by moving logger inside process for turbomind",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-29T09:01:14Z",
    "closed_at": "2024-01-30T02:44:20Z",
    "merged_at": "2024-01-30T02:44:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1061"
  },
  {
    "number": 1060,
    "title": "Add eval ci",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-29T06:55:25Z",
    "closed_at": "2024-02-10T01:31:48Z",
    "merged_at": "2024-02-10T01:31:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1060"
  },
  {
    "number": 1057,
    "title": "fix use engine_config.tp when tp is None",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-28T07:21:57Z",
    "closed_at": "2024-01-29T11:17:22Z",
    "merged_at": "2024-01-29T11:17:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1057"
  },
  {
    "number": 1053,
    "title": "sync mem size for tp",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-26T08:51:13Z",
    "closed_at": "2024-01-29T08:32:42Z",
    "merged_at": "2024-01-29T08:32:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1053"
  },
  {
    "number": 1052,
    "title": "Fix modelconfig in pytorch engine, support YI.",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-26T08:47:04Z",
    "closed_at": "2024-01-29T02:26:28Z",
    "merged_at": "2024-01-29T02:26:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1052"
  },
  {
    "number": 1051,
    "title": "update pipeline guide and FAQ about OOM",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-26T08:26:51Z",
    "closed_at": "2024-01-30T05:53:12Z",
    "merged_at": "2024-01-30T05:53:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1051"
  },
  {
    "number": 1050,
    "title": "update indexes_containing_token function",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-26T07:00:08Z",
    "closed_at": "2024-01-26T08:31:31Z",
    "merged_at": "2024-01-26T08:31:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1050"
  },
  {
    "number": 1049,
    "title": "[doc] Introduce project OpenAOE",
    "user": "JiaYingLii",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-26T06:54:57Z",
    "closed_at": "2024-01-26T10:22:57Z",
    "merged_at": "2024-01-26T10:22:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1049"
  },
  {
    "number": 1048,
    "title": "[Feature] Add api key and ssl to http server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-26T04:58:40Z",
    "closed_at": "2024-01-30T12:08:56Z",
    "merged_at": "2024-01-30T12:08:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1048"
  },
  {
    "number": 1042,
    "title": "Fix baichuan2 lora",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-25T10:16:26Z",
    "closed_at": "2024-01-26T08:51:13Z",
    "merged_at": "2024-01-26T08:51:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1042"
  },
  {
    "number": 1040,
    "title": "Update restful_api.md fix OOM starting serve api",
    "user": "G4mot",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-25T04:19:46Z",
    "closed_at": "2024-02-04T10:57:07Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1040"
  },
  {
    "number": 1039,
    "title": "Update adapters cli argument",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-25T04:09:58Z",
    "closed_at": "2024-01-25T06:10:55Z",
    "merged_at": "2024-01-25T06:10:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1039"
  },
  {
    "number": 1037,
    "title": "Fix repetition penalty for long context",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-24T17:12:30Z",
    "closed_at": "2024-01-29T03:22:44Z",
    "merged_at": "2024-01-29T03:22:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1037"
  },
  {
    "number": 1036,
    "title": "fix embedding copy size",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-24T11:37:02Z",
    "closed_at": "2024-02-18T06:19:14Z",
    "merged_at": "2024-02-18T06:19:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1036"
  },
  {
    "number": 1035,
    "title": "Compatible with Gradio 4.x",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-24T10:48:56Z",
    "closed_at": "2024-09-05T09:44:47Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1035"
  },
  {
    "number": 1034,
    "title": "optimize sleep",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-24T10:39:21Z",
    "closed_at": "2024-01-25T04:04:44Z",
    "merged_at": "2024-01-25T04:04:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1034"
  },
  {
    "number": 1027,
    "title": "fix flash kernel on sm 70",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-23T10:19:13Z",
    "closed_at": "2024-01-26T08:36:04Z",
    "merged_at": "2024-01-26T08:36:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1027"
  },
  {
    "number": 1026,
    "title": "update docs for kvint8",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-23T10:11:02Z",
    "closed_at": "2024-01-25T09:42:24Z",
    "merged_at": "2024-01-25T09:42:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1026"
  },
  {
    "number": 1025,
    "title": "Support linking the custom built mpi",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-23T09:05:21Z",
    "closed_at": "2024-01-26T08:20:42Z",
    "merged_at": "2024-01-26T08:20:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1025"
  },
  {
    "number": 1024,
    "title": "update ut ci to new server node",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-23T03:07:08Z",
    "closed_at": "2024-01-25T03:10:47Z",
    "merged_at": "2024-01-25T03:10:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1024"
  },
  {
    "number": 1023,
    "title": "Ete testcase update",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-22T11:24:03Z",
    "closed_at": "2024-01-26T07:30:22Z",
    "merged_at": "2024-01-26T07:30:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1023"
  },
  {
    "number": 1022,
    "title": "Remove model name when loading hf model",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-22T08:54:52Z",
    "closed_at": "2024-01-30T10:18:50Z",
    "merged_at": "2024-01-30T10:18:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1022"
  },
  {
    "number": 1017,
    "title": "Fix turbomind end session bug. Add huggingface demo document",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-22T07:24:48Z",
    "closed_at": "2024-01-25T11:46:07Z",
    "merged_at": "2024-01-25T11:46:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1017"
  },
  {
    "number": 1013,
    "title": "fix missing init file in modules",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-22T04:13:48Z",
    "closed_at": "2024-01-25T03:07:09Z",
    "merged_at": "2024-01-25T03:07:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1013"
  },
  {
    "number": 1005,
    "title": "bump version to v0.2.1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-19T10:33:25Z",
    "closed_at": "2024-01-19T10:35:40Z",
    "merged_at": "2024-01-19T10:35:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1005"
  },
  {
    "number": 1004,
    "title": "add alignment tools",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-19T10:11:47Z",
    "closed_at": "2024-01-25T06:50:03Z",
    "merged_at": "2024-01-25T06:50:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1004"
  },
  {
    "number": 1003,
    "title": "[Fix] interlm messages2prompt",
    "user": "Harold-lkk",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-19T10:01:13Z",
    "closed_at": "2024-01-19T10:08:10Z",
    "merged_at": "2024-01-19T10:08:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1003"
  },
  {
    "number": 1002,
    "title": "[Fix] interlm2 chat format",
    "user": "Harold-lkk",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-19T08:04:41Z",
    "closed_at": "2024-01-19T10:26:31Z",
    "merged_at": "2024-01-19T10:26:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1002"
  },
  {
    "number": 996,
    "title": "fix qwen-vl example",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-19T03:22:43Z",
    "closed_at": "2024-01-22T06:37:32Z",
    "merged_at": "2024-01-22T06:37:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/996"
  },
  {
    "number": 995,
    "title": "add docs for evaluation with opencompass",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-19T02:37:21Z",
    "closed_at": "2024-01-23T09:42:34Z",
    "merged_at": "2024-01-23T09:42:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/995"
  },
  {
    "number": 992,
    "title": "Fix fast tokenizer swallows prefix space when there are too many white spaces",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-18T10:41:58Z",
    "closed_at": "2024-01-31T11:34:39Z",
    "merged_at": "2024-01-31T11:34:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/992"
  },
  {
    "number": 991,
    "title": "hide stop-words in output text",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-18T10:25:45Z",
    "closed_at": "2024-01-22T13:55:00Z",
    "merged_at": "2024-01-22T13:55:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/991"
  },
  {
    "number": 988,
    "title": "add guide about installation on cuda 12+ platform",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-18T07:57:48Z",
    "closed_at": "2024-01-19T03:07:51Z",
    "merged_at": "2024-01-19T03:07:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/988"
  },
  {
    "number": 987,
    "title": "fix tp mem usage",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-18T07:53:13Z",
    "closed_at": "2024-01-25T05:10:32Z",
    "merged_at": "2024-01-25T05:10:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/987"
  },
  {
    "number": 985,
    "title": "fix import error for triton server",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-18T05:40:40Z",
    "closed_at": "2024-01-22T05:46:01Z",
    "merged_at": "2024-01-22T05:46:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/985"
  },
  {
    "number": 984,
    "title": "set example values to /v1/chat/completions in swagger UI",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-18T05:17:15Z",
    "closed_at": "2024-01-25T04:05:54Z",
    "merged_at": "2024-01-25T04:05:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/984"
  },
  {
    "number": 977,
    "title": "fix module mapping error of baichuan model",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-17T09:03:19Z",
    "closed_at": "2024-01-22T04:09:46Z",
    "merged_at": "2024-01-22T04:09:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/977"
  },
  {
    "number": 974,
    "title": "Add stream mode function to pipeline",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-17T05:11:44Z",
    "closed_at": "2024-01-29T05:56:02Z",
    "merged_at": "2024-01-29T05:56:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/974"
  },
  {
    "number": 973,
    "title": "fix OOM in BlockManager",
    "user": "zhyncs",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-17T04:56:37Z",
    "closed_at": "2024-01-26T08:41:21Z",
    "merged_at": "2024-01-26T08:41:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/973"
  },
  {
    "number": 972,
    "title": "fix baichuan2 conversion",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-17T02:18:30Z",
    "closed_at": "2024-01-17T10:17:02Z",
    "merged_at": "2024-01-17T10:17:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/972"
  },
  {
    "number": 970,
    "title": "update long context doc",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T15:23:48Z",
    "closed_at": "2024-01-16T15:30:20Z",
    "merged_at": "2024-01-16T15:30:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/970"
  },
  {
    "number": 969,
    "title": "bump version to v0.2.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T15:10:36Z",
    "closed_at": "2024-01-17T01:59:17Z",
    "merged_at": "2024-01-17T01:59:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/969"
  },
  {
    "number": 968,
    "title": "skip resume logic for pytorch backend",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T12:44:22Z",
    "closed_at": "2024-01-16T14:51:26Z",
    "merged_at": "2024-01-16T14:51:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/968"
  },
  {
    "number": 967,
    "title": "[Fix] Fix `calibrate` bug when `transformers>4.36`",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T12:25:40Z",
    "closed_at": "2024-01-16T17:04:35Z",
    "merged_at": "2024-01-16T17:04:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/967"
  },
  {
    "number": 966,
    "title": "Add ci for ut",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T11:55:20Z",
    "closed_at": "2024-01-16T15:08:34Z",
    "merged_at": "2024-01-16T15:08:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/966"
  },
  {
    "number": 965,
    "title": "Add more docstring to api_server and proxy_server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T11:48:19Z",
    "closed_at": "2024-01-16T12:10:39Z",
    "merged_at": "2024-01-16T12:10:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/965"
  },
  {
    "number": 963,
    "title": "Support internlm2",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T11:24:19Z",
    "closed_at": "2024-01-16T16:51:45Z",
    "merged_at": "2024-01-16T16:51:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/963"
  },
  {
    "number": 962,
    "title": "fix pytorch backend can not properly stop",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T10:28:16Z",
    "closed_at": "2024-01-16T11:09:20Z",
    "merged_at": "2024-01-16T11:09:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/962"
  },
  {
    "number": 961,
    "title": "support min_length for turbomind backend",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T10:10:34Z",
    "closed_at": "2024-01-26T11:00:44Z",
    "merged_at": "2024-01-26T11:00:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/961"
  },
  {
    "number": 960,
    "title": "fix logger in tokenizer",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T09:57:08Z",
    "closed_at": "2024-01-16T10:07:51Z",
    "merged_at": "2024-01-16T10:07:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/960"
  },
  {
    "number": 959,
    "title": "fix cli with special arg names",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T05:22:38Z",
    "closed_at": "2024-01-16T08:06:53Z",
    "merged_at": "2024-01-16T08:06:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/959"
  },
  {
    "number": 958,
    "title": "set random seed when it is None",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T04:31:53Z",
    "closed_at": "2024-01-16T08:27:56Z",
    "merged_at": "2024-01-16T08:27:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/958"
  },
  {
    "number": 957,
    "title": "support mlp s-lora",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T03:55:58Z",
    "closed_at": "2024-01-16T10:22:55Z",
    "merged_at": "2024-01-16T10:22:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/957"
  },
  {
    "number": 956,
    "title": "avoid run get_logger when import lmdeploy",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T03:37:48Z",
    "closed_at": "2024-01-16T08:49:30Z",
    "merged_at": "2024-01-16T08:49:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/956"
  },
  {
    "number": 955,
    "title": "print help for cli in case of failure",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-16T03:19:08Z",
    "closed_at": "2024-01-16T04:10:21Z",
    "merged_at": "2024-01-16T04:10:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/955"
  },
  {
    "number": 953,
    "title": "Remove the manual model conversion during benchmark",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-15T14:44:46Z",
    "closed_at": "2024-02-21T02:54:06Z",
    "merged_at": "2024-02-21T02:54:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/953"
  },
  {
    "number": 952,
    "title": "return dataclass for pipeline",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-15T13:28:45Z",
    "closed_at": "2024-01-16T06:15:13Z",
    "merged_at": "2024-01-16T06:15:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/952"
  },
  {
    "number": 951,
    "title": "Miss __init__.py in modeling folder",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-15T10:52:59Z",
    "closed_at": "2024-01-15T13:07:50Z",
    "merged_at": "2024-01-15T13:07:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/951"
  },
  {
    "number": 949,
    "title": "set gradio default value the same as chat.py",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-15T10:02:12Z",
    "closed_at": "2024-01-15T13:07:38Z",
    "merged_at": "2024-01-15T13:07:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/949"
  },
  {
    "number": 948,
    "title": "E2e testcase v2",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-15T06:56:11Z",
    "closed_at": "2024-01-15T06:57:33Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/948"
  },
  {
    "number": 947,
    "title": "Remove `tp` from pipline argument list",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-14T09:22:23Z",
    "closed_at": "2024-01-15T04:44:04Z",
    "merged_at": "2024-01-15T04:44:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/947"
  },
  {
    "number": 946,
    "title": "accelerate pytorch benchmark",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-14T09:10:12Z",
    "closed_at": "2024-01-15T03:19:42Z",
    "merged_at": "2024-01-15T03:19:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/946"
  },
  {
    "number": 945,
    "title": "Update get_started and w4a16 tutorials",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-14T08:31:01Z",
    "closed_at": "2024-01-15T10:01:08Z",
    "merged_at": "2024-01-15T10:01:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/945"
  },
  {
    "number": 942,
    "title": "fix TorchEngine stuck when benchmarking with `tp>1`",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-12T06:41:51Z",
    "closed_at": "2024-01-22T04:07:44Z",
    "merged_at": "2024-01-22T04:07:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/942"
  },
  {
    "number": 941,
    "title": "Fix scripts in benchmark doc",
    "user": "panli889",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-12T06:26:22Z",
    "closed_at": "2024-01-12T06:57:35Z",
    "merged_at": "2024-01-12T06:57:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/941"
  },
  {
    "number": 939,
    "title": "Limit max tokens per iter",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-12T03:54:48Z",
    "closed_at": "2024-01-16T09:15:28Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/939"
  },
  {
    "number": 937,
    "title": "suppress turbomind chat warning",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-11T13:17:49Z",
    "closed_at": "2024-01-12T06:21:01Z",
    "merged_at": "2024-01-12T06:21:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/937"
  },
  {
    "number": 936,
    "title": "modify type hint of api to avoid import _turbomind",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-11T10:07:57Z",
    "closed_at": "2024-01-13T09:22:00Z",
    "merged_at": "2024-01-13T09:22:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/936"
  },
  {
    "number": 935,
    "title": "add try except when importing turbomind for lite",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-11T07:44:47Z",
    "closed_at": "2024-01-11T08:50:31Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/935"
  },
  {
    "number": 934,
    "title": "fix get_gpu_mem",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-11T04:41:18Z",
    "closed_at": "2024-01-11T06:35:34Z",
    "merged_at": "2024-01-11T06:35:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/934"
  },
  {
    "number": 933,
    "title": "fix profile generation multiprocessing error",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-11T03:48:42Z",
    "closed_at": "2024-01-13T08:03:10Z",
    "merged_at": "2024-01-13T08:03:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/933"
  },
  {
    "number": 931,
    "title": "remove instance_num argument",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-11T02:32:15Z",
    "closed_at": "2024-01-11T08:21:12Z",
    "merged_at": "2024-01-11T08:21:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/931"
  },
  {
    "number": 930,
    "title": "add pytorch random sampling",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-10T07:41:44Z",
    "closed_at": "2024-01-11T11:05:58Z",
    "merged_at": "2024-01-11T11:05:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/930"
  },
  {
    "number": 929,
    "title": "fix pipeline stop_words type error",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-10T07:08:35Z",
    "closed_at": "2024-01-10T11:28:15Z",
    "merged_at": "2024-01-10T11:28:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/929"
  },
  {
    "number": 928,
    "title": "Cleanup fixed attributes in turbomind engine config",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-10T06:19:25Z",
    "closed_at": "2024-01-10T07:08:09Z",
    "merged_at": "2024-01-10T07:08:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/928"
  },
  {
    "number": 927,
    "title": "Register deepseek model",
    "user": "demin-song",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-10T05:15:07Z",
    "closed_at": "2024-01-10T05:28:37Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/927"
  },
  {
    "number": 926,
    "title": "Update supported models and add quick start section in README",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-10T05:02:44Z",
    "closed_at": "2024-01-10T08:12:58Z",
    "merged_at": "2024-01-10T08:12:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/926"
  },
  {
    "number": 925,
    "title": "Fix matching results of several chat templates like llama2, solar, yi and so on",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-10T03:43:48Z",
    "closed_at": "2024-01-11T09:07:46Z",
    "merged_at": "2024-01-11T09:07:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/925"
  },
  {
    "number": 923,
    "title": "add init in adapters",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-09T10:03:51Z",
    "closed_at": "2024-01-09T10:15:03Z",
    "merged_at": "2024-01-09T10:15:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/923"
  },
  {
    "number": 922,
    "title": "Upgrade lmdeploy cli",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-09T09:41:33Z",
    "closed_at": "2024-01-15T04:41:10Z",
    "merged_at": "2024-01-15T04:41:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/922"
  },
  {
    "number": 921,
    "title": "remove unused settings in turbomind engine config",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-09T04:25:48Z",
    "closed_at": "2024-01-09T04:32:52Z",
    "merged_at": "2024-01-09T04:32:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/921"
  },
  {
    "number": 919,
    "title": "fix local variable 'output_ids' referenced before assignment",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-08T10:20:42Z",
    "closed_at": "2024-01-08T11:34:55Z",
    "merged_at": "2024-01-08T11:34:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/919"
  },
  {
    "number": 918,
    "title": "Refactor gradio and api_server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-08T09:33:41Z",
    "closed_at": "2024-01-10T08:13:16Z",
    "merged_at": "2024-01-10T08:13:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/918"
  },
  {
    "number": 917,
    "title": "Remove `flash-attn` dependency of lmdeploy lite module",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-08T04:45:07Z",
    "closed_at": "2024-01-08T08:09:51Z",
    "merged_at": "2024-01-08T08:09:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/917"
  },
  {
    "number": 916,
    "title": "Refactor LLM inference pipeline API",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-08T04:09:16Z",
    "closed_at": "2024-01-10T03:58:23Z",
    "merged_at": "2024-01-10T03:58:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/916"
  },
  {
    "number": 915,
    "title": "Add user guide about pytorch engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-08T03:32:53Z",
    "closed_at": "2024-01-10T06:44:07Z",
    "merged_at": "2024-01-10T06:44:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/915"
  },
  {
    "number": 914,
    "title": "fix pytorch llama2 with new transformers",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-05T08:57:33Z",
    "closed_at": "2024-01-05T12:01:07Z",
    "merged_at": "2024-01-05T12:01:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/914"
  },
  {
    "number": 912,
    "title": "Improve setup by removing pycuda dependency and adding cuda runtime and cublas to RPATH",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-04T07:57:36Z",
    "closed_at": "2024-01-08T13:14:26Z",
    "merged_at": "2024-01-08T13:14:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/912"
  },
  {
    "number": 911,
    "title": "[Fix] set scaling_factor 1 forcefully when sequence length is less than max_pos_emb",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-04T06:55:57Z",
    "closed_at": "2024-01-05T09:06:30Z",
    "merged_at": "2024-01-05T09:06:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/911"
  },
  {
    "number": 910,
    "title": "support accessing lmdeploy version by lmdeploy.version_info",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-04T03:18:07Z",
    "closed_at": "2024-01-04T13:15:26Z",
    "merged_at": "2024-01-04T13:15:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/910"
  },
  {
    "number": 909,
    "title": "Check-in turbomind engine config",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-04T02:58:56Z",
    "closed_at": "2024-01-08T03:53:22Z",
    "merged_at": "2024-01-08T03:53:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/909"
  },
  {
    "number": 908,
    "title": "pytorch engine config",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-04T02:20:05Z",
    "closed_at": "2024-01-08T03:52:55Z",
    "merged_at": "2024-01-08T03:52:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/908"
  },
  {
    "number": 907,
    "title": "check-in ModelConfig",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-03T07:22:13Z",
    "closed_at": "2024-01-04T06:34:30Z",
    "merged_at": "2024-01-04T06:34:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/907"
  },
  {
    "number": 906,
    "title": "Update",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-03T06:08:42Z",
    "closed_at": "2024-01-03T06:12:12Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/906"
  },
  {
    "number": 904,
    "title": "Fix context decoding stuck issue when tp > 1",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-02T10:41:41Z",
    "closed_at": "2024-01-04T04:44:08Z",
    "merged_at": "2024-01-04T04:44:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/904"
  },
  {
    "number": 903,
    "title": "Add request distributor server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-02T10:13:18Z",
    "closed_at": "2024-01-12T06:22:06Z",
    "merged_at": "2024-01-12T06:22:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/903"
  },
  {
    "number": 902,
    "title": "check-in generation config",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-01-02T09:31:20Z",
    "closed_at": "2024-01-03T09:26:51Z",
    "merged_at": "2024-01-03T09:26:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/902"
  },
  {
    "number": 900,
    "title": "Fix data offset",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-28T10:22:31Z",
    "closed_at": "2023-12-28T11:16:48Z",
    "merged_at": "2023-12-28T11:16:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/900"
  },
  {
    "number": 899,
    "title": "Improve user guide",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-28T10:17:29Z",
    "closed_at": "2024-01-03T09:26:33Z",
    "merged_at": "2024-01-03T09:26:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/899"
  },
  {
    "number": 897,
    "title": "Fix overflow",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-28T09:56:47Z",
    "closed_at": "2023-12-28T11:12:44Z",
    "merged_at": "2023-12-28T11:12:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/897"
  },
  {
    "number": 894,
    "title": "S-LoRA support",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-27T11:53:26Z",
    "closed_at": "2024-01-09T07:33:42Z",
    "merged_at": "2024-01-09T07:33:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/894"
  },
  {
    "number": 893,
    "title": "Update test triton CI",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-27T07:16:13Z",
    "closed_at": "2023-12-28T05:53:45Z",
    "merged_at": "2023-12-28T05:53:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/893"
  },
  {
    "number": 892,
    "title": "register deepseek model",
    "user": "demin-song",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-27T05:55:16Z",
    "closed_at": "2024-01-08T05:58:16Z",
    "merged_at": "2024-01-08T05:58:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/892"
  },
  {
    "number": 891,
    "title": "Update dockerfile",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-27T02:43:10Z",
    "closed_at": "2023-12-28T06:37:03Z",
    "merged_at": "2023-12-28T06:37:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/891"
  },
  {
    "number": 888,
    "title": "[Feature] Support w8a8 tp",
    "user": "HIT-cwh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-26T03:24:02Z",
    "closed_at": "2023-12-26T10:01:52Z",
    "merged_at": "2023-12-26T10:01:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/888"
  },
  {
    "number": 887,
    "title": "pass stop words to openai api",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-26T02:49:19Z",
    "closed_at": "2024-01-11T11:05:40Z",
    "merged_at": "2024-01-11T11:05:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/887"
  },
  {
    "number": 885,
    "title": "stable api_server benchmark result by a non-zero await",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-25T08:16:47Z",
    "closed_at": "2023-12-25T09:10:58Z",
    "merged_at": "2023-12-25T09:10:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/885"
  },
  {
    "number": 884,
    "title": "Refactor benchmark bash script",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-24T09:37:05Z",
    "closed_at": "2023-12-25T10:01:47Z",
    "merged_at": "2023-12-25T10:01:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/884"
  },
  {
    "number": 880,
    "title": "[WIP]: support evaluation turbomind models in github action",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-21T06:51:54Z",
    "closed_at": "2023-12-26T08:12:46Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/880"
  },
  {
    "number": 879,
    "title": "Move `api_server` dependencies from serve.txt to runtime.txt",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-21T06:41:09Z",
    "closed_at": "2023-12-21T12:55:59Z",
    "merged_at": "2023-12-21T12:55:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/879"
  },
  {
    "number": 878,
    "title": "[Fix] Fix conflicts in `lite`",
    "user": "HIT-cwh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-21T05:03:04Z",
    "closed_at": "2023-12-21T07:55:11Z",
    "merged_at": "2023-12-21T07:55:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/878"
  },
  {
    "number": 877,
    "title": "Support QoS in api_server",
    "user": "sallyjunjun",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-21T03:51:27Z",
    "closed_at": "2023-12-27T08:22:00Z",
    "merged_at": "2023-12-27T08:22:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/877"
  },
  {
    "number": 875,
    "title": "Fix uninitialized parameter",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-20T14:16:02Z",
    "closed_at": "2023-12-23T11:39:24Z",
    "merged_at": "2023-12-23T11:39:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/875"
  },
  {
    "number": 874,
    "title": "add image chat demo",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-20T12:52:36Z",
    "closed_at": "2023-12-29T11:12:17Z",
    "merged_at": "2023-12-29T11:12:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/874"
  },
  {
    "number": 872,
    "title": "add tritonclient req",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-19T08:59:00Z",
    "closed_at": "2023-12-19T11:38:27Z",
    "merged_at": "2023-12-19T11:38:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/872"
  },
  {
    "number": 871,
    "title": "Refactor torch inference engine",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-19T08:23:08Z",
    "closed_at": "2023-12-28T03:48:58Z",
    "merged_at": "2023-12-28T03:48:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/871"
  },
  {
    "number": 870,
    "title": "add top_k value for /v1/completions and update the documents",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-19T06:53:02Z",
    "closed_at": "2023-12-21T02:39:34Z",
    "merged_at": "2023-12-21T02:39:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/870"
  },
  {
    "number": 864,
    "title": "Return the iterator after erasing it from a map",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-18T09:38:53Z",
    "closed_at": "2023-12-18T10:37:42Z",
    "merged_at": "2023-12-18T10:37:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/864"
  },
  {
    "number": 863,
    "title": "[Fix] Adapt to the pyTorch poc branch",
    "user": "HIT-cwh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-18T09:11:14Z",
    "closed_at": "2023-12-19T08:20:49Z",
    "merged_at": "2023-12-19T08:20:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/863"
  },
  {
    "number": 862,
    "title": "Fix cuda reinitialization in a multiprocessing setting",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-18T08:57:58Z",
    "closed_at": "2023-12-18T09:19:07Z",
    "merged_at": "2023-12-18T09:19:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/862"
  },
  {
    "number": 860,
    "title": "Unified paging",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-18T08:03:59Z",
    "closed_at": "2023-12-18T08:24:20Z",
    "merged_at": "2023-12-18T08:24:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/860"
  },
  {
    "number": 859,
    "title": "[Docs] Fix typo in `restful_api ` user guide",
    "user": "maxchiron",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-18T07:25:36Z",
    "closed_at": "2023-12-18T08:07:44Z",
    "merged_at": "2023-12-18T08:07:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/859"
  },
  {
    "number": 858,
    "title": "[Docs] Fix typo in `restful_api ` user guide",
    "user": "maxchiron",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-18T07:04:49Z",
    "closed_at": "2023-12-18T07:37:35Z",
    "merged_at": "2023-12-18T07:37:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/858"
  },
  {
    "number": 856,
    "title": "launch gradio server directly with hf model",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-18T03:09:58Z",
    "closed_at": "2023-12-18T09:23:50Z",
    "merged_at": "2023-12-18T09:23:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/856"
  },
  {
    "number": 851,
    "title": "Support linear rope scale",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-16T08:16:31Z",
    "closed_at": "2024-03-06T07:41:53Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/851"
  },
  {
    "number": 850,
    "title": "Fix stop requests by await before turbomind queue.get()",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-16T07:39:19Z",
    "closed_at": "2023-12-18T06:20:17Z",
    "merged_at": "2023-12-18T06:20:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/850"
  },
  {
    "number": 849,
    "title": "[Feature]Merge `lmdeploy lite calibrate` and `lmdeploy lite auto_awq`",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-15T17:30:35Z",
    "closed_at": "2024-01-09T05:41:14Z",
    "merged_at": "2024-01-09T05:41:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/849"
  },
  {
    "number": 848,
    "title": "[Fix] Fix meta tensor error",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-15T17:12:22Z",
    "closed_at": "2023-12-18T06:50:33Z",
    "merged_at": "2023-12-18T06:50:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/848"
  },
  {
    "number": 847,
    "title": "fix turbomind awq",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-15T06:19:46Z",
    "closed_at": "2023-12-15T07:24:43Z",
    "merged_at": "2023-12-15T07:24:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/847"
  },
  {
    "number": 846,
    "title": "use rope_scaling_factor instead to enable Dynamic NTK",
    "user": "jjjjohnson",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-15T06:03:39Z",
    "closed_at": "2024-03-06T07:42:48Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/846"
  },
  {
    "number": 845,
    "title": "export \"num_tokens_per_iter\", \"max_prefill_iters\" and etc when converting a model",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-15T03:58:24Z",
    "closed_at": "2023-12-21T02:40:00Z",
    "merged_at": "2023-12-21T02:40:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/845"
  },
  {
    "number": 844,
    "title": "Add test case for function regression",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-15T03:28:10Z",
    "closed_at": "2023-12-25T10:27:23Z",
    "merged_at": "2023-12-25T10:27:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/844"
  },
  {
    "number": 839,
    "title": "Perform fuzzy matching on chat template according to model path",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-14T07:22:40Z",
    "closed_at": "2024-01-02T02:57:27Z",
    "merged_at": "2024-01-02T02:57:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/839"
  },
  {
    "number": 835,
    "title": "fix api_server stop_session and end_session",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-14T01:32:48Z",
    "closed_at": "2023-12-14T06:28:00Z",
    "merged_at": "2023-12-14T06:28:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/835"
  },
  {
    "number": 834,
    "title": "bump version to v0.1.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-13T12:17:17Z",
    "closed_at": "2023-12-18T12:05:20Z",
    "merged_at": "2023-12-18T12:05:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/834"
  },
  {
    "number": 830,
    "title": "Compute cross entropy loss given a list of input tokens",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-12T13:23:46Z",
    "closed_at": "2023-12-27T05:34:27Z",
    "merged_at": "2023-12-27T05:34:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/830"
  },
  {
    "number": 828,
    "title": "add encode for opencompass",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-12T08:48:25Z",
    "closed_at": "2023-12-13T12:22:10Z",
    "merged_at": "2023-12-13T12:22:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/828"
  },
  {
    "number": 825,
    "title": "Support building docker image manually in CI",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-12T06:39:38Z",
    "closed_at": "2023-12-13T09:22:40Z",
    "merged_at": "2023-12-13T09:22:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/825"
  },
  {
    "number": 822,
    "title": "Support building docker image manually in CI",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-12T03:59:06Z",
    "closed_at": "2023-12-12T06:41:28Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/822"
  },
  {
    "number": 821,
    "title": "Fix cache verification",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-11T16:58:06Z",
    "closed_at": "2023-12-12T02:56:11Z",
    "merged_at": "2023-12-12T02:56:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/821"
  },
  {
    "number": 820,
    "title": "simplify the header of the benchmark table",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-11T15:26:35Z",
    "closed_at": "2023-12-12T08:24:07Z",
    "merged_at": "2023-12-12T08:24:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/820"
  },
  {
    "number": 818,
    "title": "Set smem size for repetition penalty kernel",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-11T08:38:01Z",
    "closed_at": "2023-12-11T09:23:18Z",
    "merged_at": "2023-12-11T09:23:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/818"
  },
  {
    "number": 816,
    "title": "fix finish_reason",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-11T06:36:50Z",
    "closed_at": "2023-12-12T08:48:12Z",
    "merged_at": "2023-12-12T08:48:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/816"
  },
  {
    "number": 813,
    "title": "Disable attention mask when it is not needed",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-10T14:16:50Z",
    "closed_at": "2023-12-11T10:07:14Z",
    "merged_at": "2023-12-11T10:07:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/813"
  },
  {
    "number": 812,
    "title": "Simplify block manager",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-10T12:33:15Z",
    "closed_at": "2023-12-11T05:35:09Z",
    "merged_at": "2023-12-11T05:35:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/812"
  },
  {
    "number": 809,
    "title": "Fix out-of-bound access",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-07T08:08:09Z",
    "closed_at": "2023-12-07T09:58:54Z",
    "merged_at": "2023-12-07T09:58:54Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/809"
  },
  {
    "number": 807,
    "title": "bump version to v0.1.0a2",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-06T04:55:12Z",
    "closed_at": "2023-12-06T06:48:56Z",
    "merged_at": "2023-12-06T06:48:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/807"
  },
  {
    "number": 806,
    "title": "Fix local kv head num",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-06T03:39:22Z",
    "closed_at": "2023-12-06T04:55:35Z",
    "merged_at": "2023-12-06T04:55:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/806"
  },
  {
    "number": 805,
    "title": "Add api.py",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-06T02:25:31Z",
    "closed_at": "2023-12-13T06:09:21Z",
    "merged_at": "2023-12-13T06:09:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/805"
  },
  {
    "number": 803,
    "title": "Support turbomind bf16",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-05T10:07:08Z",
    "closed_at": "2023-12-15T04:44:14Z",
    "merged_at": "2023-12-15T04:44:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/803"
  },
  {
    "number": 802,
    "title": "profiling api server with text completion",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-05T09:51:42Z",
    "closed_at": "2023-12-06T02:23:42Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/802"
  },
  {
    "number": 799,
    "title": "support image_embs input",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-05T08:57:22Z",
    "closed_at": "2023-12-15T04:43:15Z",
    "merged_at": "2023-12-15T04:43:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/799"
  },
  {
    "number": 796,
    "title": "fix extra colon in InternLMChat7B template",
    "user": "C1rN09",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-04T09:31:05Z",
    "closed_at": "2023-12-05T03:47:33Z",
    "merged_at": "2023-12-05T03:47:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/796"
  },
  {
    "number": 795,
    "title": "FIFO pipe strategy for api_server",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-04T05:30:18Z",
    "closed_at": "2023-12-11T11:50:50Z",
    "merged_at": "2023-12-11T11:50:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/795"
  },
  {
    "number": 794,
    "title": "Report the inference benchmark of models with different size",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-04T04:15:34Z",
    "closed_at": "2023-12-06T06:48:38Z",
    "merged_at": "2023-12-06T06:48:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/794"
  },
  {
    "number": 793,
    "title": "fix: awq should save bin files",
    "user": "hscspring",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-03T06:16:15Z",
    "closed_at": "2023-12-15T17:00:07Z",
    "merged_at": "2023-12-15T17:00:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/793"
  },
  {
    "number": 788,
    "title": "Fix early-exit condition in attention kernel",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-01T12:30:45Z",
    "closed_at": "2023-12-02T08:40:32Z",
    "merged_at": "2023-12-02T08:40:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/788"
  },
  {
    "number": 787,
    "title": "Fix missed arguments when benchmark static inference performance",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-12-01T08:10:57Z",
    "closed_at": "2023-12-04T04:54:32Z",
    "merged_at": "2023-12-04T04:54:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/787"
  },
  {
    "number": 784,
    "title": "auto upload cuda12.1 python pkg to release when create new tag",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-30T15:44:58Z",
    "closed_at": "2023-12-05T03:46:43Z",
    "merged_at": "2023-12-05T03:46:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/784"
  },
  {
    "number": 782,
    "title": "add cuda12.1 build check ci",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-30T08:10:59Z",
    "closed_at": "2023-12-04T09:06:31Z",
    "merged_at": "2023-12-04T09:06:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/782"
  },
  {
    "number": 780,
    "title": "Add test case init",
    "user": "zhulinJulia24",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-30T05:30:32Z",
    "closed_at": "2023-12-15T02:58:22Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/780"
  },
  {
    "number": 779,
    "title": "Add chat template for Yi",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-30T03:25:33Z",
    "closed_at": "2023-12-04T03:42:05Z",
    "merged_at": "2023-12-04T03:42:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/779"
  },
  {
    "number": 776,
    "title": "bump version to 0.1.0a1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-29T13:49:19Z",
    "closed_at": "2023-11-29T13:49:37Z",
    "merged_at": "2023-11-29T13:49:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/776"
  },
  {
    "number": 775,
    "title": "Unify prefill & decode passes",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-29T12:46:53Z",
    "closed_at": "2023-12-04T06:39:21Z",
    "merged_at": "2023-12-04T06:39:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/775"
  },
  {
    "number": 774,
    "title": "convert model with hf repo_id",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-29T11:43:41Z",
    "closed_at": "2023-11-29T13:35:12Z",
    "merged_at": "2023-11-29T13:35:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/774"
  },
  {
    "number": 771,
    "title": "support qwen-vl-chat",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-29T03:20:55Z",
    "closed_at": "2023-12-04T07:45:45Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/771"
  },
  {
    "number": 769,
    "title": "fix typo",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-28T11:36:19Z",
    "closed_at": "2023-11-28T12:17:13Z",
    "merged_at": "2023-11-28T12:17:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/769"
  },
  {
    "number": 768,
    "title": "[Refactor & Doc] Improve w8a8 and add docstring",
    "user": "HIT-cwh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-28T09:49:18Z",
    "closed_at": "2023-11-29T09:25:49Z",
    "merged_at": "2023-11-29T09:25:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/768"
  },
  {
    "number": 767,
    "title": "improvement(build): enable ninja and gold linker",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-28T09:19:09Z",
    "closed_at": "2023-11-29T10:02:18Z",
    "merged_at": "2023-11-29T10:02:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/767"
  },
  {
    "number": 764,
    "title": "rename pytorch poc",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-27T10:01:26Z",
    "closed_at": "2023-12-11T03:10:08Z",
    "merged_at": "2023-12-11T03:10:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/764"
  },
  {
    "number": 763,
    "title": "Update benchmark user guide",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-27T09:27:11Z",
    "closed_at": "2023-11-29T14:21:14Z",
    "merged_at": "2023-11-29T14:21:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/763"
  },
  {
    "number": 761,
    "title": "Set the default value of `max_context_token_num` 1",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-27T06:46:37Z",
    "closed_at": "2023-11-27T06:54:53Z",
    "merged_at": "2023-11-27T06:54:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/761"
  },
  {
    "number": 760,
    "title": "add triton server test and workflow yml",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-27T02:46:59Z",
    "closed_at": "2023-11-29T05:16:23Z",
    "merged_at": "2023-11-29T05:16:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/760"
  },
  {
    "number": 758,
    "title": "[Fix] Rollback the data type of `input_ids` to `TYPE_UINT32` in preprocessor's proto",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-24T11:41:33Z",
    "closed_at": "2023-11-27T05:59:56Z",
    "merged_at": "2023-11-27T05:59:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/758"
  },
  {
    "number": 757,
    "title": "[Fix] Rollback the data type of `input_ids` to `TYPE_UINT32` in preprocessor's proto",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-24T11:36:15Z",
    "closed_at": "2023-11-24T11:36:32Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/757"
  },
  {
    "number": 754,
    "title": "fix turbomind build on sm<80",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-24T05:19:25Z",
    "closed_at": "2023-11-29T08:39:42Z",
    "merged_at": "2023-11-29T08:39:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/754"
  },
  {
    "number": 753,
    "title": "[Fix] build docker image failed since `packaging` is missing",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-24T03:10:16Z",
    "closed_at": "2023-11-24T03:27:45Z",
    "merged_at": "2023-11-24T03:27:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/753"
  },
  {
    "number": 747,
    "title": "[Fix] Skip empty batch",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-23T12:17:28Z",
    "closed_at": "2023-11-23T13:00:42Z",
    "merged_at": "2023-11-23T13:00:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/747"
  },
  {
    "number": 738,
    "title": "Fix cache/output length calculation",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-22T13:21:44Z",
    "closed_at": "2023-11-23T09:38:46Z",
    "merged_at": "2023-11-23T09:38:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/738"
  },
  {
    "number": 736,
    "title": "Report first-token-latency and token-latency percentiles",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-22T12:49:13Z",
    "closed_at": "2023-11-29T12:01:31Z",
    "merged_at": "2023-11-29T12:01:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/736"
  },
  {
    "number": 735,
    "title": "[Feature] Add params config for api server web_ui",
    "user": "amulil",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-22T11:21:40Z",
    "closed_at": "2023-12-20T11:37:21Z",
    "merged_at": "2023-12-20T11:37:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/735"
  },
  {
    "number": 729,
    "title": "Fix Qwen self.model.eos_token_id is None",
    "user": "jjjjohnson",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-22T03:46:39Z",
    "closed_at": "2023-11-22T06:53:40Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/729"
  },
  {
    "number": 718,
    "title": "feat(lmdeploy): add rerope quantization",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-21T03:24:08Z",
    "closed_at": "2023-11-27T06:49:07Z",
    "merged_at": "2023-11-27T06:49:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/718"
  },
  {
    "number": 717,
    "title": "Fix Qwen self.model.eos_token_id is None",
    "user": "jjjjohnson",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-21T03:11:02Z",
    "closed_at": "2023-11-22T03:23:15Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/717"
  },
  {
    "number": 715,
    "title": "Replace mmengine with mmengine-lite",
    "user": "zhouzaida",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-21T02:51:35Z",
    "closed_at": "2023-11-21T09:42:02Z",
    "merged_at": "2023-11-21T09:42:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/715"
  },
  {
    "number": 713,
    "title": "support frequency penalty",
    "user": "RytonLi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-20T10:22:48Z",
    "closed_at": "2025-09-08T04:18:38Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/713"
  },
  {
    "number": 709,
    "title": "bump version to v0.1.0a0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-19T08:37:13Z",
    "closed_at": "2023-11-23T10:30:25Z",
    "merged_at": "2023-11-23T10:30:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/709"
  },
  {
    "number": 701,
    "title": "Optimize for throughput",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-16T09:26:09Z",
    "closed_at": "2023-11-20T03:46:55Z",
    "merged_at": "2023-11-20T03:46:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/701"
  },
  {
    "number": 697,
    "title": "Update async_engine.py  checking",
    "user": "Spockhh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-16T05:47:54Z",
    "closed_at": "2023-11-21T12:55:58Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/697"
  },
  {
    "number": 690,
    "title": "[Fix] Fix load_checkpoint_in_model bug",
    "user": "HIT-cwh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-15T07:46:19Z",
    "closed_at": "2023-11-16T06:07:55Z",
    "merged_at": "2023-11-16T06:07:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/690"
  },
  {
    "number": 688,
    "title": "add first token latency",
    "user": "CokeDong",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-14T12:14:20Z",
    "closed_at": "2023-11-14T12:18:56Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/688"
  },
  {
    "number": 686,
    "title": "fix turbomind stream canceling",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-14T04:09:00Z",
    "closed_at": "2023-11-15T09:32:31Z",
    "merged_at": "2023-11-15T09:32:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/686"
  },
  {
    "number": 685,
    "title": "Support loading hf model directly",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-14T02:21:23Z",
    "closed_at": "2023-11-22T11:05:39Z",
    "merged_at": "2023-11-22T11:05:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/685"
  },
  {
    "number": 682,
    "title": "Fix init of batch state",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-13T09:22:52Z",
    "closed_at": "2023-11-14T11:37:15Z",
    "merged_at": "2023-11-14T11:37:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/682"
  },
  {
    "number": 681,
    "title": "[Docs] Update KV8 Docs",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-13T09:16:03Z",
    "closed_at": "2023-11-13T09:45:21Z",
    "merged_at": "2023-11-13T09:45:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/681"
  },
  {
    "number": 680,
    "title": "Check-in user guide about turbomind config",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-13T08:50:19Z",
    "closed_at": "2023-11-20T05:06:21Z",
    "merged_at": "2023-11-20T05:06:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/680"
  },
  {
    "number": 679,
    "title": "[Docs] Update Supported Matrix",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-13T04:09:37Z",
    "closed_at": "2023-11-13T07:24:20Z",
    "merged_at": "2023-11-13T07:24:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/679"
  },
  {
    "number": 674,
    "title": "Merge main branch to pytorch-poc branch",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-10T06:53:36Z",
    "closed_at": "2023-12-14T07:25:25Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/674"
  },
  {
    "number": 669,
    "title": "fix Tokenizer load error when the path of the being-converted model is not writable",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-09T03:36:20Z",
    "closed_at": "2023-11-09T03:58:53Z",
    "merged_at": "2023-11-09T03:58:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/669"
  },
  {
    "number": 665,
    "title": "Refactor chat template",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-08T11:09:32Z",
    "closed_at": "2024-02-18T04:09:05Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/665"
  },
  {
    "number": 663,
    "title": "bump version to v0.0.14",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-08T08:57:30Z",
    "closed_at": "2023-11-09T12:12:45Z",
    "merged_at": "2023-11-09T12:12:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/663"
  },
  {
    "number": 662,
    "title": "[Doc] Update restful api doc",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-08T08:38:43Z",
    "closed_at": "2023-11-19T08:38:47Z",
    "merged_at": "2023-11-19T08:38:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/662"
  },
  {
    "number": 661,
    "title": "fix tokenizer_info when convert the model",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-07T13:58:40Z",
    "closed_at": "2023-11-08T05:29:20Z",
    "merged_at": "2023-11-08T05:29:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/661"
  },
  {
    "number": 655,
    "title": "Decode by interval for TritonServer",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-07T07:31:45Z",
    "closed_at": "2024-03-21T06:21:50Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/655"
  },
  {
    "number": 654,
    "title": "Add check env sub command",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-07T07:07:02Z",
    "closed_at": "2023-11-08T06:11:43Z",
    "merged_at": "2023-11-08T06:11:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/654"
  },
  {
    "number": 648,
    "title": "Fix race condition & check for anormal values (#627)",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-05T11:32:02Z",
    "closed_at": "2023-11-05T11:43:08Z",
    "merged_at": "2023-11-05T11:43:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/648"
  },
  {
    "number": 645,
    "title": "Fix Tokenizer encode",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-03T09:29:59Z",
    "closed_at": "2023-11-19T08:55:10Z",
    "merged_at": "2023-11-19T08:55:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/645"
  },
  {
    "number": 644,
    "title": "Fix wrong eos_id and bos_id obtained through grpc api",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-03T07:29:57Z",
    "closed_at": "2023-11-20T03:06:05Z",
    "merged_at": "2023-11-20T03:06:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/644"
  },
  {
    "number": 639,
    "title": "add cli to list the supported model names",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-02T05:31:54Z",
    "closed_at": "2023-11-03T07:43:41Z",
    "merged_at": "2023-11-03T07:43:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/639"
  },
  {
    "number": 637,
    "title": "fix: gradio gr.Button.update deprecated after 4.0.0",
    "user": "hscspring",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-01T15:11:01Z",
    "closed_at": "2023-11-03T02:35:43Z",
    "merged_at": "2023-11-03T02:35:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/637"
  },
  {
    "number": 634,
    "title": "update turbomind session_len with model.session_len",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-01T08:29:59Z",
    "closed_at": "2023-11-03T09:01:16Z",
    "merged_at": "2023-11-03T09:01:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/634"
  },
  {
    "number": 633,
    "title": "Fix ip2id convertion error api_server.py",
    "user": "mokeyish",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-11-01T05:07:36Z",
    "closed_at": "2023-11-01T11:00:50Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/633"
  },
  {
    "number": 630,
    "title": "fix benchmark serving computation mistake",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-31T05:10:02Z",
    "closed_at": "2023-11-08T03:54:06Z",
    "merged_at": "2023-11-08T03:54:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/630"
  },
  {
    "number": 628,
    "title": "add mistral-7b-instruct-v0.1 template",
    "user": "maxchiron",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-30T16:06:09Z",
    "closed_at": "2023-11-06T11:59:04Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/628"
  },
  {
    "number": 627,
    "title": "Fix race condition & check for anormal values",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-30T14:01:38Z",
    "closed_at": "2023-10-31T09:09:51Z",
    "merged_at": "2023-10-31T09:09:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/627"
  },
  {
    "number": 625,
    "title": "feat(pytorch_poc): implement ReRoPE",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-30T09:29:35Z",
    "closed_at": "2023-11-08T06:17:43Z",
    "merged_at": "2023-11-08T06:17:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/625"
  },
  {
    "number": 623,
    "title": "Refactor engine",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-29T12:31:52Z",
    "closed_at": "2023-11-10T09:21:50Z",
    "merged_at": "2023-11-10T09:21:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/623"
  },
  {
    "number": 620,
    "title": "bump version to v0.0.13",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-27T09:34:41Z",
    "closed_at": "2023-10-30T06:34:49Z",
    "merged_at": "2023-10-30T06:34:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/620"
  },
  {
    "number": 615,
    "title": "support qwen-vl-chat",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-26T07:56:53Z",
    "closed_at": "2024-01-23T02:33:30Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/615"
  },
  {
    "number": 607,
    "title": "Visualize layer activations and weights to simplify the quantization process.",
    "user": "HIT-cwh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-24T13:45:14Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/607"
  },
  {
    "number": 606,
    "title": "fix(pytorch_poc): memory cal",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-24T10:34:56Z",
    "closed_at": "2023-10-30T09:30:45Z",
    "merged_at": "2023-10-30T09:30:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/606"
  },
  {
    "number": 605,
    "title": "[Fix] Qwen's quantization results are abnormal & Baichuan cannot be quantized",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-24T08:34:07Z",
    "closed_at": "2023-11-03T09:07:17Z",
    "merged_at": "2023-11-03T09:07:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/605"
  },
  {
    "number": 604,
    "title": "bump version to v0.0.12",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-24T04:18:26Z",
    "closed_at": "2023-10-24T04:21:42Z",
    "merged_at": "2023-10-24T04:21:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/604"
  },
  {
    "number": 602,
    "title": "Add \"build from docker\" section",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-23T12:34:41Z",
    "closed_at": "2023-10-25T07:04:33Z",
    "merged_at": "2023-10-25T07:04:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/602"
  },
  {
    "number": 599,
    "title": "Add UltraCM and WizardLM chat templates",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-23T03:23:22Z",
    "closed_at": "2023-11-09T07:09:47Z",
    "merged_at": "2023-11-09T07:09:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/599"
  },
  {
    "number": 597,
    "title": "Optimize attention",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-20T11:34:18Z",
    "closed_at": "2023-10-31T03:16:23Z",
    "merged_at": "2023-10-31T03:16:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/597"
  },
  {
    "number": 595,
    "title": "[Feature] w8a8 based on pytorch poc",
    "user": "HIT-cwh",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-20T07:42:37Z",
    "closed_at": "2023-11-10T09:49:04Z",
    "merged_at": "2023-11-10T09:49:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/595"
  },
  {
    "number": 591,
    "title": "Fix crash and remove `sys_instruct` from `chat.py` and `client.py`",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T13:21:36Z",
    "closed_at": "2023-10-24T03:15:28Z",
    "merged_at": "2023-10-24T03:15:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/591"
  },
  {
    "number": 590,
    "title": "TurboMind 2",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T13:20:33Z",
    "closed_at": "2023-11-10T12:27:44Z",
    "merged_at": "2023-11-10T12:27:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/590"
  },
  {
    "number": 587,
    "title": "update solar chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T08:30:08Z",
    "closed_at": "2023-10-23T07:52:44Z",
    "merged_at": "2023-10-23T07:52:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/587"
  },
  {
    "number": 586,
    "title": "Revert \"[Docs] Simplify `build.md`\"",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-19T05:07:25Z",
    "closed_at": "2023-10-23T10:10:25Z",
    "merged_at": "2023-10-23T10:10:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/586"
  },
  {
    "number": 582,
    "title": "Support Tensor parallel on Falcon models",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-18T12:49:43Z",
    "closed_at": "2023-10-25T06:22:26Z",
    "merged_at": "2023-10-25T06:22:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/582"
  },
  {
    "number": 581,
    "title": "robust incremental decode for leading space",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-18T10:23:51Z",
    "closed_at": "2023-10-19T07:54:58Z",
    "merged_at": "2023-10-19T07:54:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/581"
  },
  {
    "number": 580,
    "title": "Add extra_requires to reduce dependencies",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-18T08:52:23Z",
    "closed_at": "2023-11-10T03:26:47Z",
    "merged_at": "2023-11-10T03:26:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/580"
  },
  {
    "number": 578,
    "title": "FIX: fix stop_session func bug",
    "user": "yunzhongyan0",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-18T06:52:08Z",
    "closed_at": "2023-11-06T03:39:16Z",
    "merged_at": "2023-11-06T03:39:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/578"
  },
  {
    "number": 576,
    "title": "add solar chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-18T03:28:21Z",
    "closed_at": "2023-10-19T06:40:37Z",
    "merged_at": "2023-10-19T06:40:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/576"
  },
  {
    "number": 575,
    "title": "change `model_format` to `qwen` when `model_name` starts with `qwen`",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-18T03:21:11Z",
    "closed_at": "2023-10-18T04:43:41Z",
    "merged_at": "2023-10-18T04:43:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/575"
  },
  {
    "number": 572,
    "title": "Apply rotary kernel",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-18T02:16:32Z",
    "closed_at": "2023-10-27T05:57:28Z",
    "merged_at": "2023-10-27T05:57:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/572"
  },
  {
    "number": 567,
    "title": "bump version to v0.0.11",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-17T06:07:46Z",
    "closed_at": "2023-10-17T06:16:31Z",
    "merged_at": "2023-10-17T06:16:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/567"
  },
  {
    "number": 566,
    "title": "avoid splitting chinese characters during decoding",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-17T02:51:22Z",
    "closed_at": "2023-10-18T13:52:03Z",
    "merged_at": "2023-10-18T13:52:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/566"
  },
  {
    "number": 555,
    "title": "add tp hint for deployment",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-13T03:38:18Z",
    "closed_at": "2023-10-13T06:34:11Z",
    "merged_at": "2023-10-13T06:34:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/555"
  },
  {
    "number": 554,
    "title": "Fix typing of openai protocol.",
    "user": "mokeyish",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-13T02:43:23Z",
    "closed_at": "2023-10-13T03:46:29Z",
    "merged_at": "2023-10-13T03:46:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/554"
  },
  {
    "number": 553,
    "title": "Manage session id using random int for gradio local mode",
    "user": "aisensiy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-12T14:58:54Z",
    "closed_at": "2023-11-06T08:02:41Z",
    "merged_at": "2023-11-06T08:02:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/553"
  },
  {
    "number": 552,
    "title": "free runner disk",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-12T08:18:49Z",
    "closed_at": "2023-10-16T03:05:07Z",
    "merged_at": "2023-10-16T03:05:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/552"
  },
  {
    "number": 551,
    "title": "Refactor scheduler",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-12T06:51:49Z",
    "closed_at": "2023-10-19T05:59:27Z",
    "merged_at": "2023-10-19T05:59:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/551"
  },
  {
    "number": 549,
    "title": "Add `launch.py` to `<workspace>` when it created.",
    "user": "mokeyish",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-12T06:03:44Z",
    "closed_at": "2023-10-17T07:23:26Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/549"
  },
  {
    "number": 546,
    "title": "[Doc] update huggingface internlm-chat-7b model url",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-11T10:14:45Z",
    "closed_at": "2023-10-12T03:47:52Z",
    "merged_at": "2023-10-12T03:47:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/546"
  },
  {
    "number": 545,
    "title": "Fix  loading  of qwen safetensors",
    "user": "mokeyish",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-11T09:56:52Z",
    "closed_at": "2023-10-12T03:56:35Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/545"
  },
  {
    "number": 544,
    "title": "Improve api_server and webui usage",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-11T09:27:03Z",
    "closed_at": "2023-11-01T03:40:36Z",
    "merged_at": "2023-11-01T03:40:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/544"
  },
  {
    "number": 543,
    "title": "Move `tokenizer.py` to the folder of lmdeploy",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-11T08:19:03Z",
    "closed_at": "2023-10-16T05:57:35Z",
    "merged_at": "2023-10-16T05:57:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/543"
  },
  {
    "number": 541,
    "title": "Add more user-friendly CLI ",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-11T03:03:33Z",
    "closed_at": "2023-10-25T07:45:22Z",
    "merged_at": "2023-10-25T07:45:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/541"
  },
  {
    "number": 539,
    "title": "Fix typo in `docs/en/pytorch.md`",
    "user": "shahrukhx01",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-10T15:02:14Z",
    "closed_at": "2023-10-11T06:25:45Z",
    "merged_at": "2023-10-11T06:25:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/539"
  },
  {
    "number": 535,
    "title": "support deploy Mistral-7B-Instruct-v0.1",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-10T03:07:33Z",
    "closed_at": "2023-10-16T03:33:59Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/535"
  },
  {
    "number": 532,
    "title": "[Fix] Set the default value of `step` being 0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-09T10:49:44Z",
    "closed_at": "2023-10-09T17:56:52Z",
    "merged_at": "2023-10-09T17:56:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/532"
  },
  {
    "number": 523,
    "title": "optimize fill kv cache",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-10-07T08:52:22Z",
    "closed_at": "2023-10-09T10:27:26Z",
    "merged_at": "2023-10-09T10:27:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/523"
  },
  {
    "number": 517,
    "title": "[bug] fix mismatched shape for decoder output tensor",
    "user": "akhoroshev",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-29T20:43:31Z",
    "closed_at": "2023-10-11T06:32:52Z",
    "merged_at": "2023-10-11T06:32:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/517"
  },
  {
    "number": 507,
    "title": "Change `shared_instance` type from `weakptr` to `shared_ptr`",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-28T04:06:44Z",
    "closed_at": "2023-10-09T03:04:53Z",
    "merged_at": "2023-10-09T03:04:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/507"
  },
  {
    "number": 506,
    "title": "reset shared_state when previous AbstractTransformerModelInstance deconstruct",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-28T03:32:33Z",
    "closed_at": "2023-09-28T04:35:56Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/506"
  },
  {
    "number": 504,
    "title": "rename modules",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-27T10:11:08Z",
    "closed_at": "2023-10-09T02:58:08Z",
    "merged_at": "2023-10-09T02:58:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/504"
  },
  {
    "number": 500,
    "title": "[doc] Update benchmark command in w4a16.md",
    "user": "del-zhenwu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-27T08:33:28Z",
    "closed_at": "2023-10-13T09:08:35Z",
    "merged_at": "2023-10-13T09:08:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/500"
  },
  {
    "number": 499,
    "title": "[Enchance] internlm message to prompt",
    "user": "Harold-lkk",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-27T07:20:59Z",
    "closed_at": "2023-11-03T08:05:14Z",
    "merged_at": "2023-11-03T08:05:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/499"
  },
  {
    "number": 488,
    "title": "Fix memory leak",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-26T11:45:49Z",
    "closed_at": "2023-09-26T12:36:00Z",
    "merged_at": "2023-09-26T12:36:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/488"
  },
  {
    "number": 487,
    "title": "make IPv6 compatible, safe run for coroutine interrupting",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-26T11:37:33Z",
    "closed_at": "2023-10-11T02:22:20Z",
    "merged_at": "2023-10-11T02:22:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/487"
  },
  {
    "number": 482,
    "title": "support deploy qwen-14b-chat",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-26T08:19:18Z",
    "closed_at": "2023-10-12T12:21:00Z",
    "merged_at": "2023-10-12T12:21:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/482"
  },
  {
    "number": 481,
    "title": "Support CORS for openai api server",
    "user": "aisensiy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-26T07:40:53Z",
    "closed_at": "2023-10-09T02:59:22Z",
    "merged_at": "2023-10-09T02:59:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/481"
  },
  {
    "number": 474,
    "title": "bump version to v0.0.10",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-26T01:50:44Z",
    "closed_at": "2023-09-26T12:51:27Z",
    "merged_at": "2023-09-26T12:51:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/474"
  },
  {
    "number": 471,
    "title": "fix: build from source with MPI & NCCL in other directories",
    "user": "C1rN09",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-25T13:57:11Z",
    "closed_at": "2023-12-06T06:17:04Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/471"
  },
  {
    "number": 470,
    "title": "Miss meta instruction of internlm-chat model",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-25T12:54:13Z",
    "closed_at": "2023-09-25T13:15:10Z",
    "merged_at": "2023-09-25T13:15:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/470"
  },
  {
    "number": 467,
    "title": "support inference a batch of prompts",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-25T08:11:01Z",
    "closed_at": "2023-10-25T11:25:34Z",
    "merged_at": "2023-10-25T11:25:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/467"
  },
  {
    "number": 466,
    "title": "Fix side effect brought by supporting codellama: `sequence_start` is always true when calling `model.get_prompt`",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-25T07:40:33Z",
    "closed_at": "2023-09-25T12:30:43Z",
    "merged_at": "2023-09-25T12:30:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/466"
  },
  {
    "number": 465,
    "title": "Fix compatibility issues with Pydantic 2",
    "user": "aisensiy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-25T07:13:22Z",
    "closed_at": "2023-09-26T06:34:40Z",
    "merged_at": "2023-09-26T06:34:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/465"
  },
  {
    "number": 462,
    "title": "Fix typo in README.md",
    "user": "eltociear",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-24T04:40:00Z",
    "closed_at": "2023-09-25T03:14:45Z",
    "merged_at": "2023-09-25T03:14:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/462"
  },
  {
    "number": 460,
    "title": "[bug] Fix race condition",
    "user": "akhoroshev",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-23T12:32:13Z",
    "closed_at": "2023-09-26T04:45:02Z",
    "merged_at": "2023-09-26T04:45:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/460"
  },
  {
    "number": 458,
    "title": "[feature] Graceful termination of background threads in LlamaV2",
    "user": "akhoroshev",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-23T10:03:29Z",
    "closed_at": "2023-09-26T01:41:17Z",
    "merged_at": "2023-09-26T01:41:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/458"
  },
  {
    "number": 455,
    "title": "profile pytorch poc",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-22T10:16:06Z",
    "closed_at": "2023-10-20T11:56:58Z",
    "merged_at": "2023-10-20T11:56:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/455"
  },
  {
    "number": 445,
    "title": "add baichuan lint",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-20T09:44:44Z",
    "closed_at": "2023-09-20T11:58:10Z",
    "merged_at": "2023-09-20T11:58:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/445"
  },
  {
    "number": 443,
    "title": "fix benchmark serving cannot use Qwen tokenizer",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-20T07:40:16Z",
    "closed_at": "2023-09-26T07:26:59Z",
    "merged_at": "2023-09-26T07:26:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/443"
  },
  {
    "number": 440,
    "title": "Support InternLM 20B",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-20T06:11:38Z",
    "closed_at": "2023-09-20T08:09:06Z",
    "merged_at": "2023-09-20T08:09:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/440"
  },
  {
    "number": 435,
    "title": "reduce logic block",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-19T07:19:01Z",
    "closed_at": "2023-09-20T02:45:15Z",
    "merged_at": "2023-09-20T02:45:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/435"
  },
  {
    "number": 434,
    "title": "Make trust_remote_code as cli argument",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-19T07:16:10Z",
    "closed_at": "2023-10-09T10:51:43Z",
    "merged_at": "2023-10-09T10:51:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/434"
  },
  {
    "number": 429,
    "title": "rename readthedocs config file",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-19T02:16:56Z",
    "closed_at": "2023-09-19T02:47:40Z",
    "merged_at": "2023-09-19T02:47:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/429"
  },
  {
    "number": 428,
    "title": "bump version to v0.0.9",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-18T14:04:20Z",
    "closed_at": "2023-09-20T08:09:48Z",
    "merged_at": "2023-09-20T08:09:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/428"
  },
  {
    "number": 425,
    "title": "add internlm 20b chat template",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-18T09:14:09Z",
    "closed_at": "2023-09-18T09:15:01Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/425"
  },
  {
    "number": 418,
    "title": "[Fix] Support actual seqlen in flash-attention2",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-14T11:01:12Z",
    "closed_at": "2023-09-18T12:38:38Z",
    "merged_at": "2023-09-18T12:38:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/418"
  },
  {
    "number": 416,
    "title": "Fix token count bug",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-14T04:53:58Z",
    "closed_at": "2023-09-18T12:04:56Z",
    "merged_at": "2023-09-18T12:04:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/416"
  },
  {
    "number": 415,
    "title": "Fix memory leak",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-13T15:24:22Z",
    "closed_at": "2023-09-14T12:55:57Z",
    "merged_at": "2023-09-14T12:55:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/415"
  },
  {
    "number": 412,
    "title": "more general pypi ci",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-13T02:35:37Z",
    "closed_at": "2023-09-13T03:18:30Z",
    "merged_at": "2023-09-13T03:18:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/412"
  },
  {
    "number": 411,
    "title": "Fix build.md",
    "user": "pangsg",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-12T14:15:46Z",
    "closed_at": "2023-09-14T03:42:17Z",
    "merged_at": "2023-09-14T03:42:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/411"
  },
  {
    "number": 407,
    "title": "Reduce gil switching",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-12T07:58:18Z",
    "closed_at": "2023-09-18T12:03:44Z",
    "merged_at": "2023-09-18T12:03:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/407"
  },
  {
    "number": 406,
    "title": "Support Falcon models",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-12T07:58:08Z",
    "closed_at": "2023-10-18T06:26:39Z",
    "merged_at": "2023-10-18T06:26:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/406"
  },
  {
    "number": 405,
    "title": "[Fix] output[-1] when output is empty",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-12T07:07:17Z",
    "closed_at": "2023-09-13T06:33:20Z",
    "merged_at": "2023-09-13T06:33:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/405"
  },
  {
    "number": 404,
    "title": "Fix disk space limit for building docker image",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-12T04:55:24Z",
    "closed_at": "2023-09-12T06:16:34Z",
    "merged_at": "2023-09-12T06:16:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/404"
  },
  {
    "number": 401,
    "title": "bump version to v0.0.8",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-11T13:13:04Z",
    "closed_at": "2023-09-11T13:56:59Z",
    "merged_at": "2023-09-11T13:56:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/401"
  },
  {
    "number": 400,
    "title": "more general pypi ci",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-11T12:40:06Z",
    "closed_at": "2023-09-12T12:34:00Z",
    "merged_at": "2023-09-12T12:34:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/400"
  },
  {
    "number": 399,
    "title": "[Fix] update puyu model",
    "user": "Harold-lkk",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-11T07:23:32Z",
    "closed_at": "2023-09-11T08:18:39Z",
    "merged_at": "2023-09-11T08:18:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/399"
  },
  {
    "number": 398,
    "title": "Move `q_seq_info` into `context`",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-11T06:27:52Z",
    "closed_at": "2023-09-14T07:34:47Z",
    "merged_at": "2023-09-14T07:34:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/398"
  },
  {
    "number": 382,
    "title": "Support Baichuan",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-06T09:48:09Z",
    "closed_at": "2023-09-14T03:46:18Z",
    "merged_at": "2023-09-14T03:46:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/382"
  },
  {
    "number": 378,
    "title": "Support baichuan2-chat chat template",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-06T08:12:23Z",
    "closed_at": "2023-09-08T09:03:02Z",
    "merged_at": "2023-09-08T09:03:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/378"
  },
  {
    "number": 377,
    "title": "[Fix] Set max dynamic smem size for decoder MHA to support context length > 8k",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-06T07:45:44Z",
    "closed_at": "2023-09-07T10:38:32Z",
    "merged_at": "2023-09-07T10:38:32Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/377"
  },
  {
    "number": 372,
    "title": "Update lmdeploy logo",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-05T11:41:22Z",
    "closed_at": "2023-09-06T02:38:36Z",
    "merged_at": "2023-09-06T02:38:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/372"
  },
  {
    "number": 371,
    "title": "[Improve] Use 4d input in pytorch poc",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-05T10:31:26Z",
    "closed_at": "2023-09-05T12:58:08Z",
    "merged_at": "2023-09-05T12:58:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/371"
  },
  {
    "number": 370,
    "title": "[Docs] Simplify `build.md`",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-05T09:00:32Z",
    "closed_at": "2023-09-05T10:56:01Z",
    "merged_at": "2023-09-05T10:56:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/370"
  },
  {
    "number": 367,
    "title": "[Doc] Fix quantization docs link",
    "user": "LZHgrla",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-05T07:08:13Z",
    "closed_at": "2023-09-05T08:06:25Z",
    "merged_at": "2023-09-05T08:06:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/367"
  },
  {
    "number": 366,
    "title": "fix exceed session len core dump for chat and generate",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-05T06:24:49Z",
    "closed_at": "2023-09-07T10:38:55Z",
    "merged_at": "2023-09-07T10:38:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/366"
  },
  {
    "number": 364,
    "title": "Profile token generation with more settings",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-05T03:55:02Z",
    "closed_at": "2023-09-18T13:54:00Z",
    "merged_at": "2023-09-18T13:54:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/364"
  },
  {
    "number": 360,
    "title": "Support chatglm2 in pytorch_poc",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-04T12:00:36Z",
    "closed_at": "2023-09-25T07:01:40Z",
    "merged_at": "2023-09-25T07:01:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/360"
  },
  {
    "number": 359,
    "title": "Support codellama",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-04T04:01:28Z",
    "closed_at": "2023-09-11T05:09:51Z",
    "merged_at": "2023-09-11T05:09:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/359"
  },
  {
    "number": 358,
    "title": "bump version to v0.0.7",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-04T03:57:27Z",
    "closed_at": "2023-09-04T06:38:31Z",
    "merged_at": "2023-09-04T06:38:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/358"
  },
  {
    "number": 352,
    "title": "expose stop words and filter eoa",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-09-01T07:36:28Z",
    "closed_at": "2023-09-26T02:04:14Z",
    "merged_at": "2023-09-26T02:04:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/352"
  },
  {
    "number": 346,
    "title": "bug-fix: when using stream is False, continuous batching doesn't work",
    "user": "sleepwalker2017",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-31T12:25:00Z",
    "closed_at": "2023-09-07T09:42:02Z",
    "merged_at": "2023-09-07T09:42:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/346"
  },
  {
    "number": 345,
    "title": "bug-fix: when using stream is False, continuous batching doesn't work",
    "user": "sleepwalker2017",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-31T12:02:32Z",
    "closed_at": "2023-08-31T12:13:13Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/345"
  },
  {
    "number": 344,
    "title": "Fix profile_serving hung issue",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-31T11:20:26Z",
    "closed_at": "2023-09-04T03:07:52Z",
    "merged_at": "2023-09-04T03:07:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/344"
  },
  {
    "number": 321,
    "title": "Fix readthedocs building",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-28T10:13:56Z",
    "closed_at": "2023-08-29T02:28:26Z",
    "merged_at": "2023-08-29T02:28:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/321"
  },
  {
    "number": 320,
    "title": "add llama_gemm to wheel ",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-28T09:57:42Z",
    "closed_at": "2023-09-01T04:16:43Z",
    "merged_at": "2023-09-01T04:16:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/320"
  },
  {
    "number": 319,
    "title": "Update FAQ for restful api",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-28T09:13:02Z",
    "closed_at": "2023-08-30T03:11:35Z",
    "merged_at": "2023-08-30T03:11:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/319"
  },
  {
    "number": 316,
    "title": "Fix turbomind import error on windows",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-28T06:55:46Z",
    "closed_at": "2023-08-29T08:14:43Z",
    "merged_at": "2023-08-29T08:14:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/316"
  },
  {
    "number": 315,
    "title": "fix(kvint8): update doc",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-28T04:20:24Z",
    "closed_at": "2023-08-29T05:50:07Z",
    "merged_at": "2023-08-29T05:50:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/315"
  },
  {
    "number": 310,
    "title": "bump version to v0.0.6",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-25T13:24:37Z",
    "closed_at": "2023-08-25T13:25:03Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/310"
  },
  {
    "number": 309,
    "title": "Decode generated token_ids incrementally",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-25T10:40:37Z",
    "closed_at": "2023-09-01T08:39:09Z",
    "merged_at": "2023-09-01T08:39:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/309"
  },
  {
    "number": 307,
    "title": "Fix 4bit Qwen inference crash",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-25T09:44:34Z",
    "closed_at": "2023-10-25T07:09:49Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/307"
  },
  {
    "number": 303,
    "title": "fix import error",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-25T04:06:12Z",
    "closed_at": "2023-08-25T04:45:16Z",
    "merged_at": "2023-08-25T04:45:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/303"
  },
  {
    "number": 296,
    "title": "Refactor model conversion",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-24T06:52:42Z",
    "closed_at": "2023-11-03T08:04:48Z",
    "merged_at": "2023-11-03T08:04:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/296"
  },
  {
    "number": 295,
    "title": "Open the streaming output at the commencement of benchmarking the first token's latency.",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-24T03:34:13Z",
    "closed_at": "2023-11-22T12:44:58Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/295"
  },
  {
    "number": 291,
    "title": "Change to github-hosted runner for building docker image",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-23T04:01:52Z",
    "closed_at": "2023-08-23T13:07:43Z",
    "merged_at": "2023-08-23T13:07:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/291"
  },
  {
    "number": 287,
    "title": "app.py supports restful-api",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-22T10:06:09Z",
    "closed_at": "2023-08-24T11:35:26Z",
    "merged_at": "2023-08-24T11:35:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/287"
  },
  {
    "number": 285,
    "title": "Pad tok_embedding and output weights to make their shape divisible by TP",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-22T09:03:27Z",
    "closed_at": "2023-08-24T04:29:04Z",
    "merged_at": "2023-08-24T04:29:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/285"
  },
  {
    "number": 283,
    "title": "bump version to v0.0.6",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-22T06:28:56Z",
    "closed_at": "2023-08-25T13:27:09Z",
    "merged_at": "2023-08-25T13:27:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/283"
  },
  {
    "number": 282,
    "title": "Update workflow for building docker image",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-22T04:53:22Z",
    "closed_at": "2023-08-22T06:17:33Z",
    "merged_at": "2023-08-22T06:17:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/282"
  },
  {
    "number": 280,
    "title": "[Fix] Fix building with CUDA 11.3",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-21T11:25:56Z",
    "closed_at": "2023-08-22T12:51:51Z",
    "merged_at": "2023-08-22T12:51:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/280"
  },
  {
    "number": 273,
    "title": "[Fix] Fix llama2 70b & qwen quantization error",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-18T17:53:46Z",
    "closed_at": "2023-08-24T02:58:09Z",
    "merged_at": "2023-08-24T02:58:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/273"
  },
  {
    "number": 272,
    "title": "docs(quantization): update description",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-18T11:01:56Z",
    "closed_at": "2023-08-21T08:28:50Z",
    "merged_at": "2023-08-21T08:28:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/272"
  },
  {
    "number": 267,
    "title": "[Fix] Implement `movmatrix` using warp shuffling for CUDA < 11.8",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-17T10:46:23Z",
    "closed_at": "2023-08-17T12:31:28Z",
    "merged_at": "2023-08-17T12:31:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/267"
  },
  {
    "number": 262,
    "title": "[Feature] Support TP for W4A16",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-16T12:18:48Z",
    "closed_at": "2023-08-18T11:04:26Z",
    "merged_at": "2023-08-18T11:04:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/262"
  },
  {
    "number": 261,
    "title": "Add 'accelerate' to requirement list",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-16T11:46:13Z",
    "closed_at": "2023-08-18T04:05:12Z",
    "merged_at": "2023-08-18T04:05:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/261"
  },
  {
    "number": 256,
    "title": "Check-in FAQ",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-16T06:52:29Z",
    "closed_at": "2023-08-21T02:49:31Z",
    "merged_at": "2023-08-21T02:49:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/256"
  },
  {
    "number": 253,
    "title": "docs(quantzation): update description",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-16T03:55:41Z",
    "closed_at": "2023-08-17T07:36:38Z",
    "merged_at": "2023-08-17T07:36:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/253"
  },
  {
    "number": 252,
    "title": "Remove chat template",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-16T03:42:17Z",
    "closed_at": "2023-08-16T04:23:31Z",
    "merged_at": "2023-08-16T04:23:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/252"
  },
  {
    "number": 251,
    "title": "WIP: docs(quantization): update",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-16T03:39:09Z",
    "closed_at": "2023-08-16T03:54:17Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/251"
  },
  {
    "number": 241,
    "title": "Remove specified version in user guide",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-15T08:29:04Z",
    "closed_at": "2023-08-15T09:27:35Z",
    "merged_at": "2023-08-15T09:27:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/241"
  },
  {
    "number": 239,
    "title": "Fix wrong RPATH using the absolute path instead of relative one",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-15T06:48:04Z",
    "closed_at": "2023-08-15T07:04:23Z",
    "merged_at": "2023-08-15T07:04:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/239"
  },
  {
    "number": 236,
    "title": "adjust app.py dependency",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-15T03:13:07Z",
    "closed_at": "2023-08-16T04:40:47Z",
    "merged_at": "2023-08-16T04:40:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/236"
  },
  {
    "number": 231,
    "title": "Bump version to v0.0.4",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-14T09:41:48Z",
    "closed_at": "2023-08-14T11:26:37Z",
    "merged_at": "2023-08-14T11:26:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/231"
  },
  {
    "number": 230,
    "title": "[Feature] Qwen-7B, dynamic NTK scaling and logN scaling support in turbomind ",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-14T08:54:15Z",
    "closed_at": "2023-08-18T09:49:43Z",
    "merged_at": "2023-08-18T09:49:43Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/230"
  },
  {
    "number": 228,
    "title": "fix auto_awq readme",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-14T03:28:58Z",
    "closed_at": "2023-08-14T07:06:21Z",
    "merged_at": "2023-08-14T07:06:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/228"
  },
  {
    "number": 227,
    "title": "[Docs] Update W4A16 News",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-14T02:04:36Z",
    "closed_at": "2023-08-14T07:39:00Z",
    "merged_at": "2023-08-14T07:39:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/227"
  },
  {
    "number": 225,
    "title": "pass args including meta_prompt to model",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T09:08:42Z",
    "closed_at": "2023-08-21T13:20:39Z",
    "merged_at": "2023-08-21T13:20:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/225"
  },
  {
    "number": 224,
    "title": "Check-in user guide for w4a16 LLM deployment",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T08:27:58Z",
    "closed_at": "2023-08-14T09:23:44Z",
    "merged_at": "2023-08-14T09:23:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/224"
  },
  {
    "number": 223,
    "title": "Add Restful API",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T06:40:10Z",
    "closed_at": "2023-08-22T05:59:14Z",
    "merged_at": "2023-08-22T05:59:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/223"
  },
  {
    "number": 222,
    "title": "Fix TIS client got-no-space-result side effect brought by PR #197",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-11T04:21:13Z",
    "closed_at": "2023-08-14T08:34:25Z",
    "merged_at": "2023-08-14T08:34:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/222"
  },
  {
    "number": 218,
    "title": "feat(quantization): kv cache use asymmetric",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-10T09:44:10Z",
    "closed_at": "2023-08-14T03:53:05Z",
    "merged_at": "2023-08-14T03:53:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/218"
  },
  {
    "number": 217,
    "title": "support 0.2.x",
    "user": "Harold-lkk",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-10T07:33:55Z",
    "closed_at": "2023-08-10T07:33:58Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/217"
  },
  {
    "number": 212,
    "title": "[Fix] hot fix 029 get prompt",
    "user": "Harold-lkk",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-09T12:29:06Z",
    "closed_at": "2023-08-09T12:31:09Z",
    "merged_at": "2023-08-09T12:31:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/212"
  },
  {
    "number": 211,
    "title": "Add release note template",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-09T11:30:57Z",
    "closed_at": "2023-08-10T02:51:33Z",
    "merged_at": "2023-08-10T02:51:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/211"
  },
  {
    "number": 209,
    "title": "support windows build",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-08T07:07:22Z",
    "closed_at": "2023-08-17T03:22:33Z",
    "merged_at": "2023-08-17T03:22:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/209"
  },
  {
    "number": 208,
    "title": "add readthedocs",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-08T04:07:35Z",
    "closed_at": "2023-08-21T04:20:50Z",
    "merged_at": "2023-08-21T04:20:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/208"
  },
  {
    "number": 205,
    "title": "bump version to v0.0.3",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-07T13:31:07Z",
    "closed_at": "2023-08-07T13:48:16Z",
    "merged_at": "2023-08-07T13:48:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/205"
  },
  {
    "number": 202,
    "title": "[Feature] Blazing fast W4A16 inference",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-07T05:28:58Z",
    "closed_at": "2023-08-14T02:35:05Z",
    "merged_at": "2023-08-14T02:35:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/202"
  },
  {
    "number": 200,
    "title": "Add non-stream inference api for chatbot",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-04T09:48:14Z",
    "closed_at": "2023-08-07T10:26:46Z",
    "merged_at": "2023-08-07T10:26:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/200"
  },
  {
    "number": 199,
    "title": "[Feature] Add script to split HuggingFace model to the smallest sharded checkpoints",
    "user": "LZHgrla",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-04T09:47:45Z",
    "closed_at": "2023-08-07T04:48:58Z",
    "merged_at": "2023-08-07T04:48:58Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/199"
  },
  {
    "number": 197,
    "title": "Improve postprocessing in TIS serving by applying Incremental de-tokenizing",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-04T08:33:56Z",
    "closed_at": "2023-08-07T04:48:18Z",
    "merged_at": "2023-08-07T04:48:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/197"
  },
  {
    "number": 196,
    "title": "Add flashattention2",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-04T07:16:29Z",
    "closed_at": "2023-08-29T12:53:00Z",
    "merged_at": "2023-08-29T12:53:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/196"
  },
  {
    "number": 193,
    "title": "[Feature] Support decode with DP in pytorch",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-03T06:01:32Z",
    "closed_at": "2023-08-24T07:48:28Z",
    "merged_at": "2023-08-24T07:48:27Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/193"
  },
  {
    "number": 191,
    "title": "Fix launching client error by moving lmdeploy/turbomind/utils.py to lmdeploy/utils.py",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-02T08:21:33Z",
    "closed_at": "2023-08-03T06:07:17Z",
    "merged_at": "2023-08-03T06:07:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/191"
  },
  {
    "number": 188,
    "title": "Fix build test error and move turbmind csrc test cases to `tests/csrc`",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-01T09:39:15Z",
    "closed_at": "2023-08-03T06:06:40Z",
    "merged_at": "2023-08-03T06:06:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/188"
  },
  {
    "number": 187,
    "title": "Update README.md",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-08-01T07:35:49Z",
    "closed_at": "2023-08-01T09:59:15Z",
    "merged_at": "2023-08-01T09:59:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/187"
  },
  {
    "number": 184,
    "title": "add issue/pr templates",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-31T06:30:32Z",
    "closed_at": "2023-07-31T08:31:53Z",
    "merged_at": "2023-07-31T08:31:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/184"
  },
  {
    "number": 183,
    "title": "Update profile_serving.py: fix typo",
    "user": "del-zhenwu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-31T06:01:45Z",
    "closed_at": "2023-07-31T06:38:02Z",
    "merged_at": "2023-07-31T06:38:02Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/183"
  },
  {
    "number": 181,
    "title": "[Fix] Remove unused code to reduce binary size",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-31T05:54:21Z",
    "closed_at": "2023-07-31T08:36:09Z",
    "merged_at": "2023-07-31T08:36:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/181"
  },
  {
    "number": 178,
    "title": "[Refactor] Support multi-session chat",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-28T06:33:13Z",
    "closed_at": "2023-08-07T15:14:26Z",
    "merged_at": "2023-08-07T15:14:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/178"
  },
  {
    "number": 177,
    "title": "bump version to v0.0.2",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-28T05:43:23Z",
    "closed_at": "2023-07-28T07:10:21Z",
    "merged_at": "2023-07-28T07:10:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/177"
  },
  {
    "number": 175,
    "title": "Doc: add Twitter link",
    "user": "vansin",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-27T05:59:34Z",
    "closed_at": "2023-07-27T06:19:30Z",
    "merged_at": "2023-07-27T06:19:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/175"
  },
  {
    "number": 174,
    "title": "add model_name param for Chatbot",
    "user": "streamsunshine",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-26T17:17:48Z",
    "closed_at": "2023-07-27T03:40:11Z",
    "merged_at": "2023-07-27T03:40:11Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/174"
  },
  {
    "number": 173,
    "title": "[Docs] Translate turbomind.md",
    "user": "xin-li-67",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-26T09:57:25Z",
    "closed_at": "2023-08-03T06:06:17Z",
    "merged_at": "2023-08-03T06:06:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/173"
  },
  {
    "number": 172,
    "title": "ensemble mode of tritonserver",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-26T09:46:27Z",
    "closed_at": "2023-10-09T07:25:32Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/172"
  },
  {
    "number": 171,
    "title": "Add a chatbot example to call this deployment like a API",
    "user": "Kunlun-Zhu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-26T09:29:07Z",
    "closed_at": "2023-08-21T04:21:11Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/171"
  },
  {
    "number": 170,
    "title": "Add pypi ci",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-26T08:55:59Z",
    "closed_at": "2023-07-27T09:32:49Z",
    "merged_at": "2023-07-27T09:32:49Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/170"
  },
  {
    "number": 168,
    "title": "[WIP] Pytorch Inference Kernels",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-26T08:02:49Z",
    "closed_at": "2023-10-24T08:20:36Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/168"
  },
  {
    "number": 166,
    "title": "[Docs] Translate the quantization.md",
    "user": "xin-li-67",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-26T00:47:00Z",
    "closed_at": "2023-07-26T08:09:16Z",
    "merged_at": "2023-07-26T08:09:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/166"
  },
  {
    "number": 164,
    "title": "Add manylinux builder",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-25T11:24:39Z",
    "closed_at": "2023-07-27T03:10:14Z",
    "merged_at": "2023-07-27T03:10:14Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/164"
  },
  {
    "number": 163,
    "title": "Add triton_models to whl package",
    "user": "irexyc",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-25T11:11:06Z",
    "closed_at": "2023-07-26T06:06:18Z",
    "merged_at": "2023-07-26T06:06:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/163"
  },
  {
    "number": 162,
    "title": "app.py support local model",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-25T07:43:48Z",
    "closed_at": "2023-08-04T11:38:51Z",
    "merged_at": "2023-08-04T11:38:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/162"
  },
  {
    "number": 161,
    "title": "[Feature] Profiling tool for huggingface and deepspeed models",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-25T06:01:16Z",
    "closed_at": "2023-08-16T03:50:03Z",
    "merged_at": "2023-08-16T03:50:03Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/161"
  },
  {
    "number": 160,
    "title": "support fusedGQA",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-25T04:22:29Z",
    "closed_at": "2023-07-25T11:59:22Z",
    "merged_at": "2023-07-25T11:59:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/160"
  },
  {
    "number": 159,
    "title": "docs(README): disable ECC",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-25T04:06:48Z",
    "closed_at": "2023-07-26T07:04:13Z",
    "merged_at": "2023-07-26T07:04:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/159"
  },
  {
    "number": 158,
    "title": "Runtime TP",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-24T11:14:22Z",
    "closed_at": "2023-07-31T12:48:48Z",
    "merged_at": "2023-07-31T12:48:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/158"
  },
  {
    "number": 157,
    "title": "fix getting package root path error in python3.9",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-24T09:07:25Z",
    "closed_at": "2023-07-25T03:25:40Z",
    "merged_at": "2023-07-25T03:25:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/157"
  },
  {
    "number": 156,
    "title": "checkin benchmark on real conversation data",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-22T16:06:27Z",
    "closed_at": "2023-07-24T10:21:20Z",
    "merged_at": "2023-07-24T10:21:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/156"
  },
  {
    "number": 154,
    "title": "remove slicing reponse and add resume api",
    "user": "streamsunshine",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-21T09:47:19Z",
    "closed_at": "2023-07-21T13:22:05Z",
    "merged_at": "2023-07-21T13:22:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/154"
  },
  {
    "number": 153,
    "title": "[Feature] decode-only forward pass",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-21T09:02:33Z",
    "closed_at": "2023-07-24T06:56:25Z",
    "merged_at": "2023-07-24T06:56:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/153"
  },
  {
    "number": 150,
    "title": "Update CMakeLists.txt",
    "user": "alexw994",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-20T09:18:41Z",
    "closed_at": "2023-07-20T09:20:23Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/150"
  },
  {
    "number": 148,
    "title": "Add github action for publishing docker image ",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-20T02:40:06Z",
    "closed_at": "2023-07-21T01:32:20Z",
    "merged_at": "2023-07-21T01:32:20Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/148"
  },
  {
    "number": 147,
    "title": "[Feature] Support Llama-2 with GQA",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-19T14:24:22Z",
    "closed_at": "2023-07-21T02:46:41Z",
    "merged_at": "2023-07-21T02:46:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/147"
  },
  {
    "number": 146,
    "title": "add profile throughput benchmark",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-19T11:28:25Z",
    "closed_at": "2023-07-22T06:20:12Z",
    "merged_at": "2023-07-22T06:20:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/146"
  },
  {
    "number": 145,
    "title": "[Fix] Fix bug for issues #141",
    "user": "humu789",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-19T10:01:35Z",
    "closed_at": "2023-07-20T03:29:41Z",
    "merged_at": "2023-07-20T03:29:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/145"
  },
  {
    "number": 144,
    "title": "Refactor the chat template of supported models using factory pattern",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-19T09:15:02Z",
    "closed_at": "2023-07-23T11:35:28Z",
    "merged_at": "2023-07-23T11:35:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/144"
  },
  {
    "number": 143,
    "title": "[Fix] return carriage cause overwriting at the same line",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-19T07:18:14Z",
    "closed_at": "2023-07-20T07:50:29Z",
    "merged_at": "2023-07-20T07:50:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/143"
  },
  {
    "number": 142,
    "title": "fix the offset of output token ids array during streaming chat",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-19T07:14:48Z",
    "closed_at": "2023-07-19T08:34:53Z",
    "merged_at": "2023-07-19T08:34:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/142"
  },
  {
    "number": 140,
    "title": "add llama2 chat template",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-19T06:43:26Z",
    "closed_at": "2023-07-20T11:27:44Z",
    "merged_at": "2023-07-20T11:27:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/140"
  },
  {
    "number": 139,
    "title": "lmdeploy.serve.turbomind.deploy the value of input param model_format is confused",
    "user": "KevinNuNu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-19T06:11:42Z",
    "closed_at": "2024-04-06T10:37:41Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/139"
  },
  {
    "number": 138,
    "title": "[Fix] Support DeepSpeed on autoTP and kernel injection",
    "user": "KevinNuNu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-19T05:46:16Z",
    "closed_at": "2023-07-21T02:42:17Z",
    "merged_at": "2023-07-21T02:42:17Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/138"
  },
  {
    "number": 135,
    "title": "Fix tp with bias",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-18T11:39:50Z",
    "closed_at": "2023-07-19T04:21:50Z",
    "merged_at": "2023-07-19T04:21:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/135"
  },
  {
    "number": 134,
    "title": "Fix possible errors in benchmark script",
    "user": "rollroll90",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-18T08:25:10Z",
    "closed_at": "2023-07-19T03:14:26Z",
    "merged_at": "2023-07-19T03:14:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/134"
  },
  {
    "number": 133,
    "title": "print info copy-paste error",
    "user": "KevinNuNu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-18T07:08:36Z",
    "closed_at": "2023-07-18T08:44:31Z",
    "merged_at": "2023-07-18T08:44:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/133"
  },
  {
    "number": 131,
    "title": "update log info",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-17T12:38:23Z",
    "closed_at": "2023-07-17T13:01:15Z",
    "merged_at": "2023-07-17T13:01:15Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/131"
  },
  {
    "number": 125,
    "title": "[Fix] fix attempted_relative_import",
    "user": "KevinNuNu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-17T03:53:31Z",
    "closed_at": "2023-07-17T12:29:42Z",
    "merged_at": "2023-07-17T12:29:42Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/125"
  },
  {
    "number": 124,
    "title": "[doc] use internlm-chat-7b",
    "user": "del-zhenwu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-17T03:04:59Z",
    "closed_at": "2023-07-17T03:08:50Z",
    "merged_at": "2023-07-17T03:08:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/124"
  },
  {
    "number": 123,
    "title": "docs: fix typo",
    "user": "vansin",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-16T14:34:33Z",
    "closed_at": "2023-07-17T12:29:00Z",
    "merged_at": "2023-07-17T12:29:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/123"
  },
  {
    "number": 120,
    "title": "[Doc] update discord and wechat link",
    "user": "vansin",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-14T12:36:14Z",
    "closed_at": "2023-07-14T13:24:19Z",
    "merged_at": "2023-07-14T13:24:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/120"
  },
  {
    "number": 119,
    "title": "update doc and requirements.txt",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-14T08:27:03Z",
    "closed_at": "2023-07-18T08:49:53Z",
    "merged_at": "2023-07-18T08:49:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/119"
  },
  {
    "number": 118,
    "title": "move turbomind.md to docs/en",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-14T07:12:35Z",
    "closed_at": "2023-07-14T11:14:57Z",
    "merged_at": "2023-07-14T11:14:57Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/118"
  },
  {
    "number": 115,
    "title": "Update README.md: use internlm-chat-7b",
    "user": "del-zhenwu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-14T06:43:02Z",
    "closed_at": "2023-07-17T03:05:34Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/115"
  },
  {
    "number": 114,
    "title": "docs(architecture): add quantization en doc",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-14T04:41:13Z",
    "closed_at": "2023-07-19T09:40:49Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/114"
  },
  {
    "number": 113,
    "title": "[Fix] fix pylint",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-14T02:41:05Z",
    "closed_at": "2023-07-14T02:58:34Z",
    "merged_at": "2023-07-14T02:58:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/113"
  },
  {
    "number": 112,
    "title": "miss <bos> of InternLM chat template",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-13T13:42:42Z",
    "closed_at": "2023-07-14T03:25:34Z",
    "merged_at": "2023-07-14T03:25:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/112"
  },
  {
    "number": 111,
    "title": "fix warnings.warn of `lmdeploy/pytorch/chat.py` ",
    "user": "djkcyl",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-13T13:14:38Z",
    "closed_at": "2023-07-14T02:55:07Z",
    "merged_at": "2023-07-14T02:55:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/111"
  },
  {
    "number": 109,
    "title": "[bugfix] Fix some docs' bug in 'serving'",
    "user": "APX103",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-13T08:31:11Z",
    "closed_at": "2023-07-17T06:27:22Z",
    "merged_at": "2023-07-17T06:27:22Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/109"
  },
  {
    "number": 108,
    "title": "[Feature] Support AWQ ",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-13T07:25:38Z",
    "closed_at": "2023-08-11T06:01:26Z",
    "merged_at": "2023-08-11T06:01:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/108"
  },
  {
    "number": 106,
    "title": "Update serving.md",
    "user": "del-zhenwu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-13T06:29:11Z",
    "closed_at": "2023-07-13T07:06:51Z",
    "merged_at": "2023-07-13T07:06:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/106"
  },
  {
    "number": 105,
    "title": "add puyu model for internal use",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-13T02:54:04Z",
    "closed_at": "2023-07-14T07:08:51Z",
    "merged_at": "2023-07-14T07:08:51Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/105"
  },
  {
    "number": 101,
    "title": "[Improvement] Add architecture documentation",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-12T07:23:53Z",
    "closed_at": "2023-07-14T04:22:24Z",
    "merged_at": "2023-07-14T04:22:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/101"
  },
  {
    "number": 97,
    "title": "add docstring for turbomind",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-11T13:29:48Z",
    "closed_at": "2023-07-12T12:55:52Z",
    "merged_at": "2023-07-12T12:55:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/97"
  },
  {
    "number": 94,
    "title": "set chuk_size=1 and export tp to config.ini",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-11T09:52:08Z",
    "closed_at": "2023-07-11T12:25:41Z",
    "merged_at": "2023-07-11T12:25:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/94"
  },
  {
    "number": 93,
    "title": "[Improve] Add docstrings to pytorch submodule",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-11T09:22:14Z",
    "closed_at": "2023-07-12T12:40:35Z",
    "merged_at": "2023-07-12T12:40:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/93"
  },
  {
    "number": 92,
    "title": "docs(serving.md): typo",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-11T09:09:49Z",
    "closed_at": "2023-07-11T09:56:46Z",
    "merged_at": "2023-07-11T09:56:46Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/92"
  },
  {
    "number": 86,
    "title": "update contribution.md",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-10T08:18:34Z",
    "closed_at": "2023-07-11T09:05:05Z",
    "merged_at": "2023-07-11T09:05:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/86"
  },
  {
    "number": 84,
    "title": "feat(quantization): kv cache use asymmetric",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-10T04:39:27Z",
    "closed_at": "2023-08-10T09:45:02Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/84"
  },
  {
    "number": 83,
    "title": "feat(deploy.py): support w pack qkv",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-10T04:21:21Z",
    "closed_at": "2023-07-11T09:05:38Z",
    "merged_at": "2023-07-11T09:05:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/83"
  },
  {
    "number": 82,
    "title": "Tensor Parallel python api",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-07T11:26:40Z",
    "closed_at": "2023-07-18T08:43:10Z",
    "merged_at": "2023-07-18T08:43:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/82"
  },
  {
    "number": 77,
    "title": "update benchmark image",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-06T10:25:07Z",
    "closed_at": "2023-07-06T10:30:37Z",
    "merged_at": "2023-07-06T10:30:37Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/77"
  },
  {
    "number": 76,
    "title": "Update Python to 3.8 in lint.yml",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-06T09:03:21Z",
    "closed_at": "2023-07-10T06:00:36Z",
    "merged_at": "2023-07-10T06:00:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/76"
  },
  {
    "number": 75,
    "title": "[Fix] Remaining Issues in #19",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-06T07:24:41Z",
    "closed_at": "2023-07-11T08:59:23Z",
    "merged_at": "2023-07-11T08:59:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/75"
  },
  {
    "number": 74,
    "title": "update zh readme",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-06T06:37:43Z",
    "closed_at": "2023-07-06T06:44:12Z",
    "merged_at": "2023-07-06T06:44:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/74"
  },
  {
    "number": 73,
    "title": "[Fix] Remove unused cmake flags",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-06T06:37:16Z",
    "closed_at": "2023-07-11T08:59:52Z",
    "merged_at": "2023-07-11T08:59:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/73"
  },
  {
    "number": 72,
    "title": "[Fix] Update Image URL",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-06T05:30:44Z",
    "closed_at": "2023-07-06T05:31:25Z",
    "merged_at": "2023-07-06T05:31:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/72"
  },
  {
    "number": 71,
    "title": "Streaming output",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-06T05:29:06Z",
    "closed_at": "2023-07-06T06:26:41Z",
    "merged_at": "2023-07-06T06:26:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/71"
  },
  {
    "number": 70,
    "title": "Update .gitignore",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-06T05:25:04Z",
    "closed_at": "2023-07-06T05:35:24Z",
    "merged_at": "2023-07-06T05:35:24Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/70"
  },
  {
    "number": 69,
    "title": "fix(project): interlm run error",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-06T04:23:36Z",
    "closed_at": "2023-07-06T04:23:47Z",
    "merged_at": "2023-07-06T04:23:47Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/69"
  },
  {
    "number": 68,
    "title": "fix clang-format",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-06T04:06:22Z",
    "closed_at": "2023-07-06T06:21:29Z",
    "merged_at": "2023-07-06T06:21:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/68"
  },
  {
    "number": 67,
    "title": "Add InternLM Download Url",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-06T03:43:45Z",
    "closed_at": "2023-07-06T03:49:08Z",
    "merged_at": "2023-07-06T03:49:08Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/67"
  },
  {
    "number": 66,
    "title": "lower transformer version <4.30.0",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T15:17:42Z",
    "closed_at": "2023-07-05T15:17:48Z",
    "merged_at": "2023-07-05T15:17:48Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/66"
  },
  {
    "number": 65,
    "title": "Streaming output",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T13:33:50Z",
    "closed_at": "2023-07-06T05:18:33Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/65"
  },
  {
    "number": 64,
    "title": "[Fix] Fix building w/o Python FFI",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T13:12:59Z",
    "closed_at": "2023-07-05T13:20:52Z",
    "merged_at": "2023-07-05T13:20:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/64"
  },
  {
    "number": 63,
    "title": "add demo gif",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T12:45:15Z",
    "closed_at": "2023-07-05T13:12:16Z",
    "merged_at": "2023-07-05T13:12:16Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/63"
  },
  {
    "number": 61,
    "title": "Update setup for build python wheel",
    "user": "RunningLeon",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T09:57:30Z",
    "closed_at": "2023-07-05T13:32:30Z",
    "merged_at": "2023-07-05T13:32:30Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/61"
  },
  {
    "number": 60,
    "title": "WIP feat(quantization): kCacheKVInt8 use asymmetric quantization",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T09:45:31Z",
    "closed_at": "2023-07-10T04:05:05Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/60"
  },
  {
    "number": 59,
    "title": "fix(kv_qparams.py): zp use min",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T08:00:02Z",
    "closed_at": "2023-07-05T08:00:26Z",
    "merged_at": "2023-07-05T08:00:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/59"
  },
  {
    "number": 58,
    "title": "WIP fix(kv_qparams.py): zp use min",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T07:40:42Z",
    "closed_at": "2023-07-05T08:00:31Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/58"
  },
  {
    "number": 57,
    "title": "doc(README.md): fix badge link",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T06:59:19Z",
    "closed_at": "2023-07-05T06:59:25Z",
    "merged_at": "2023-07-05T06:59:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/57"
  },
  {
    "number": 56,
    "title": "docs(README): typo",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T06:21:21Z",
    "closed_at": "2023-07-05T06:21:26Z",
    "merged_at": "2023-07-05T06:21:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/56"
  },
  {
    "number": 55,
    "title": "rename chat_example",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T06:19:29Z",
    "closed_at": "2023-07-05T07:28:18Z",
    "merged_at": "2023-07-05T07:28:18Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/55"
  },
  {
    "number": 54,
    "title": "update internlms chat template",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T05:33:53Z",
    "closed_at": "2023-07-05T15:11:10Z",
    "merged_at": "2023-07-05T15:11:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/54"
  },
  {
    "number": 53,
    "title": "docs(quantization): add more test",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-05T03:37:34Z",
    "closed_at": "2023-07-05T03:45:55Z",
    "merged_at": "2023-07-05T03:45:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/53"
  },
  {
    "number": 52,
    "title": "improve readme",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-04T15:20:24Z",
    "closed_at": "2023-07-05T15:55:52Z",
    "merged_at": "2023-07-05T15:55:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/52"
  },
  {
    "number": 51,
    "title": "[Fix] Fix HF model conversion",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-04T12:38:04Z",
    "closed_at": "2023-07-04T13:07:01Z",
    "merged_at": "2023-07-04T13:07:01Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/51"
  },
  {
    "number": 50,
    "title": "docs(README): fix",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-04T11:47:34Z",
    "closed_at": "2023-07-04T11:47:53Z",
    "merged_at": "2023-07-04T11:47:53Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/50"
  },
  {
    "number": 49,
    "title": "support 'input_tokens' in triton_example",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-04T11:31:53Z",
    "closed_at": "2023-07-04T12:39:31Z",
    "merged_at": "2023-07-04T12:39:31Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/49"
  },
  {
    "number": 48,
    "title": "export attn_bias as int type into config",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-04T11:26:51Z",
    "closed_at": "2023-07-04T11:27:00Z",
    "merged_at": "2023-07-04T11:27:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/48"
  },
  {
    "number": 47,
    "title": "Update quantization.md",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-04T08:25:02Z",
    "closed_at": "2023-07-04T08:25:35Z",
    "merged_at": "2023-07-04T08:25:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/47"
  },
  {
    "number": 46,
    "title": "docs(project): add quantization test results",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-04T07:17:52Z",
    "closed_at": "2023-07-04T08:09:07Z",
    "merged_at": "2023-07-04T08:09:07Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/46"
  },
  {
    "number": 45,
    "title": "[Feature] Stats Quantization Parameters for KV Cache ",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-04T06:42:30Z",
    "closed_at": "2023-07-05T04:44:19Z",
    "merged_at": "2023-07-05T04:44:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/45"
  },
  {
    "number": 44,
    "title": "[Feature] Stats Quantization Parameters for KV Cache",
    "user": "pppppM",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-04T06:13:47Z",
    "closed_at": "2023-07-04T06:34:37Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/44"
  },
  {
    "number": 43,
    "title": "[Doc] add persistent batch inference GIF",
    "user": "vansin",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-03T14:49:03Z",
    "closed_at": "2023-07-03T15:24:33Z",
    "merged_at": "2023-07-03T15:24:33Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/43"
  },
  {
    "number": 41,
    "title": "fix(kernel): speed degrade",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-03T04:29:51Z",
    "closed_at": "2023-07-03T05:43:34Z",
    "merged_at": "2023-07-03T05:43:34Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/41"
  },
  {
    "number": 40,
    "title": "add build-lmdeploy command in dockerfile",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-03T04:00:40Z",
    "closed_at": "2023-07-06T03:23:26Z",
    "merged_at": "2023-07-06T03:23:26Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/40"
  },
  {
    "number": 39,
    "title": "install triton_example and TransformerTritonBackend to runtime and lib respectively",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-03T03:55:07Z",
    "closed_at": "2023-07-03T07:23:52Z",
    "merged_at": "2023-07-03T07:23:52Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/39"
  },
  {
    "number": 38,
    "title": "use format-11.1",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-03T03:22:13Z",
    "closed_at": "2023-07-04T13:47:39Z",
    "merged_at": "2023-07-04T13:47:39Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/38"
  },
  {
    "number": 37,
    "title": "change project(FasterTransformer) to project(TurboMind)",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-01T15:05:59Z",
    "closed_at": "2023-07-01T15:06:09Z",
    "merged_at": "2023-07-01T15:06:09Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/37"
  },
  {
    "number": 36,
    "title": "Change target tritonfastertransformerbackend to trtonturbomindbackend",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-01T14:12:10Z",
    "closed_at": "2023-07-01T14:12:23Z",
    "merged_at": "2023-07-01T14:12:23Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/36"
  },
  {
    "number": 35,
    "title": "build turbomind",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-01T09:12:19Z",
    "closed_at": "2023-07-01T09:13:28Z",
    "merged_at": "2023-07-01T09:13:28Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/35"
  },
  {
    "number": 34,
    "title": "Python ffi",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-01T08:39:55Z",
    "closed_at": "2023-07-05T03:38:06Z",
    "merged_at": "2023-07-05T03:38:06Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/34"
  },
  {
    "number": 33,
    "title": "rename src/fastertransformer to src/turbomind",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-07-01T07:38:57Z",
    "closed_at": "2023-07-01T07:39:45Z",
    "merged_at": "2023-07-01T07:39:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/33"
  },
  {
    "number": 32,
    "title": "Add lint action",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-30T07:34:33Z",
    "closed_at": "2023-07-01T07:35:56Z",
    "merged_at": "2023-07-01T07:35:56Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/32"
  },
  {
    "number": 31,
    "title": "rename serve/fastertransformer to serve/turbomind",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-30T06:53:54Z",
    "closed_at": "2023-06-30T11:26:42Z",
    "merged_at": "2023-06-30T11:26:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/31"
  },
  {
    "number": 30,
    "title": "rename llmdeploy to lmdeploy",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-30T05:07:06Z",
    "closed_at": "2023-06-30T06:34:50Z",
    "merged_at": "2023-06-30T06:34:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/30"
  },
  {
    "number": 29,
    "title": "Webui copyright",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-30T03:48:29Z",
    "closed_at": "2023-06-30T04:11:55Z",
    "merged_at": "2023-06-30T04:11:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/29"
  },
  {
    "number": 28,
    "title": "fix crash when conversation history out of limit",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-29T07:34:32Z",
    "closed_at": "2023-06-29T13:38:36Z",
    "merged_at": "2023-06-29T13:38:36Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/28"
  },
  {
    "number": 27,
    "title": "Add webui",
    "user": "AllentDan",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-28T10:18:18Z",
    "closed_at": "2023-06-29T06:09:51Z",
    "merged_at": "2023-06-29T06:09:50Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/27"
  },
  {
    "number": 26,
    "title": "Hf tokenizer",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-28T02:09:59Z",
    "closed_at": "2023-06-29T07:06:40Z",
    "merged_at": "2023-06-29T07:06:40Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/26"
  },
  {
    "number": 24,
    "title": "[Fix] Fix GEMM tuning",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-27T10:55:37Z",
    "closed_at": "2023-06-28T03:33:05Z",
    "merged_at": "2023-06-28T03:33:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/24"
  },
  {
    "number": 23,
    "title": "remove cuda architecture from build option",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-27T09:43:09Z",
    "closed_at": "2023-06-29T09:12:21Z",
    "merged_at": "2023-06-29T09:12:21Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/23"
  },
  {
    "number": 22,
    "title": "feat(src): add kv cache int8 quantization",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-27T03:24:48Z",
    "closed_at": "2023-06-28T13:04:41Z",
    "merged_at": "2023-06-28T13:04:41Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/22"
  },
  {
    "number": 19,
    "title": "[Feature] Add a torch client",
    "user": "wangruohui",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-25T14:19:19Z",
    "closed_at": "2023-07-06T07:15:25Z",
    "merged_at": "2023-07-06T07:15:25Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/19"
  },
  {
    "number": 18,
    "title": "Port GEMM tuning from FT",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-25T07:40:20Z",
    "closed_at": "2023-06-26T13:19:05Z",
    "merged_at": "2023-06-26T13:19:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/18"
  },
  {
    "number": 17,
    "title": "Update deploy.py",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-25T07:24:44Z",
    "closed_at": "2023-06-25T07:31:29Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/17"
  },
  {
    "number": 16,
    "title": "Update requirements.txt",
    "user": "tpoisonooo",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-25T06:51:44Z",
    "closed_at": "2023-06-25T06:54:21Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/16"
  },
  {
    "number": 15,
    "title": "Add profile",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-22T14:10:36Z",
    "closed_at": "2023-06-25T06:11:44Z",
    "merged_at": "2023-06-25T06:11:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/15"
  },
  {
    "number": 14,
    "title": "Support attention bias",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-22T05:51:13Z",
    "closed_at": "2023-06-24T13:17:10Z",
    "merged_at": "2023-06-24T13:17:10Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/14"
  },
  {
    "number": 13,
    "title": "remove duplicate model converter script",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-22T04:34:30Z",
    "closed_at": "2023-06-22T04:54:04Z",
    "merged_at": "2023-06-22T04:54:04Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/13"
  },
  {
    "number": 12,
    "title": "Fix fmha on sm 70",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-21T11:48:08Z",
    "closed_at": "2023-06-22T04:18:35Z",
    "merged_at": "2023-06-22T04:18:35Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/12"
  },
  {
    "number": 11,
    "title": "check-in build script",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-21T07:11:46Z",
    "closed_at": "2023-06-21T07:12:29Z",
    "merged_at": "2023-06-21T07:12:29Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/11"
  },
  {
    "number": 10,
    "title": "check-in `.clang-format`",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-21T04:38:46Z",
    "closed_at": "2023-06-21T04:38:59Z",
    "merged_at": "2023-06-21T04:38:59Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/10"
  },
  {
    "number": 9,
    "title": "support fmha",
    "user": "grimoire",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-20T12:40:05Z",
    "closed_at": "2023-06-21T07:04:38Z",
    "merged_at": "2023-06-21T07:04:38Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/9"
  },
  {
    "number": 8,
    "title": "check-in dockerfile",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-20T09:41:57Z",
    "closed_at": "2023-06-20T09:43:00Z",
    "merged_at": "2023-06-20T09:43:00Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/8"
  },
  {
    "number": 7,
    "title": "check-in fastertransformer",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-20T07:51:12Z",
    "closed_at": "2023-06-20T09:25:44Z",
    "merged_at": "2023-06-20T09:25:44Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/7"
  },
  {
    "number": 6,
    "title": "Add readme",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-20T07:43:52Z",
    "closed_at": "2023-06-20T07:44:13Z",
    "merged_at": "2023-06-20T07:44:13Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/6"
  },
  {
    "number": 5,
    "title": "check-in fastertransformer",
    "user": "lzhangzz",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-20T07:43:29Z",
    "closed_at": "2023-06-20T07:45:19Z",
    "merged_at": "2023-06-20T07:45:19Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/5"
  },
  {
    "number": 4,
    "title": "update scripts for deploying llama family model to fastertransformer triton models",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-20T04:53:36Z",
    "closed_at": "2023-06-20T04:55:05Z",
    "merged_at": "2023-06-20T04:55:05Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/4"
  },
  {
    "number": 3,
    "title": "check-in fastertransformer's triton models",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-18T13:19:36Z",
    "closed_at": "2023-06-18T13:19:45Z",
    "merged_at": "2023-06-18T13:19:45Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/3"
  },
  {
    "number": 2,
    "title": "Add chatbot for fastertransformer",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-18T07:59:07Z",
    "closed_at": "2023-06-18T08:02:55Z",
    "merged_at": "2023-06-18T08:02:55Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/2"
  },
  {
    "number": 1,
    "title": "check-in license",
    "user": "lvhan028",
    "user_type": "User",
    "is_human": true,
    "created_at": "2023-06-18T05:52:59Z",
    "closed_at": "2023-06-18T05:53:12Z",
    "merged_at": "2023-06-18T05:53:12Z",
    "state": "closed",
    "html_url": "https://github.com/InternLM/lmdeploy/pull/1"
  }
]