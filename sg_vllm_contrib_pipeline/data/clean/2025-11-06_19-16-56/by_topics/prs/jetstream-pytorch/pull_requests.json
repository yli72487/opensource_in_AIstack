[
  {
    "number": 209,
    "title": "Add 'model_name' label to metrics and add MetricsServerConfig",
    "user": "Bslabe123",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-22T23:51:25Z",
    "closed_at": "2025-03-27T20:55:55Z",
    "merged_at": "2025-03-27T20:55:55Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/209"
  },
  {
    "number": 208,
    "title": "Add deepseek distils as options",
    "user": "bluecoconut",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-21T23:29:38Z",
    "closed_at": "2025-09-15T03:23:19Z",
    "merged_at": "2025-09-15T03:23:19Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/208"
  },
  {
    "number": 207,
    "title": "Update README.md",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2025-01-08T17:49:50Z",
    "closed_at": "2025-01-13T22:13:53Z",
    "merged_at": "2025-01-13T22:13:53Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/207"
  },
  {
    "number": 206,
    "title": "Raise error if weights are not loaded",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-14T00:13:03Z",
    "closed_at": "2025-01-02T18:14:39Z",
    "merged_at": "2025-01-02T18:14:39Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/206"
  },
  {
    "number": 205,
    "title": "Llama 3.1 RoPE scaling",
    "user": "tengomucho",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-13T09:19:26Z",
    "closed_at": "2024-12-16T21:04:03Z",
    "merged_at": "2024-12-16T21:04:03Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/205"
  },
  {
    "number": 204,
    "title": "Update jax version to 0.4.37",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-13T04:55:25Z",
    "closed_at": "2024-12-13T19:39:05Z",
    "merged_at": "2024-12-13T19:39:05Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/204"
  },
  {
    "number": 203,
    "title": "Add Dockerfile and entrypoint script for the jetstream-pytorch-server",
    "user": "vivianrwu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-10T21:54:53Z",
    "closed_at": "2024-12-13T00:52:47Z",
    "merged_at": "2024-12-13T00:52:47Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/203"
  },
  {
    "number": 202,
    "title": "update branch tag in tutorial",
    "user": "sixiang-google",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-09T19:41:02Z",
    "closed_at": "2024-12-09T22:27:48Z",
    "merged_at": "2024-12-09T22:27:48Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/202"
  },
  {
    "number": 201,
    "title": "Add `prometheus_port` flag to CLI",
    "user": "Bslabe123",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-09T17:40:34Z",
    "closed_at": "2024-12-09T17:52:10Z",
    "merged_at": "2024-12-09T17:52:09Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/201"
  },
  {
    "number": 200,
    "title": "Support passing custom sampling function.",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-12-01T16:46:26Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/200"
  },
  {
    "number": 199,
    "title": "Enable jax compilation flags for jpt",
    "user": "vivianrwu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-07T22:37:21Z",
    "closed_at": "2024-11-07T22:44:07Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/199"
  },
  {
    "number": 198,
    "title": "Add jax compilation cache config",
    "user": "vivianrwu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-07T00:21:39Z",
    "closed_at": "2024-11-07T19:16:40Z",
    "merged_at": "2024-11-07T19:16:40Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/198"
  },
  {
    "number": 197,
    "title": "Add model warmup flag into cli",
    "user": "vivianrwu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-11-06T18:37:00Z",
    "closed_at": "2024-11-06T19:54:52Z",
    "merged_at": "2024-11-06T19:54:52Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/197"
  },
  {
    "number": 196,
    "title": "Fix: correct quantization name filtering",
    "user": "tengomucho",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-22T12:35:21Z",
    "closed_at": "2024-10-23T00:37:28Z",
    "merged_at": "2024-10-23T00:37:28Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/196"
  },
  {
    "number": 195,
    "title": "Add per request sampling support.",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-21T20:53:30Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/195"
  },
  {
    "number": 194,
    "title": "feat: add quantize exclude layer flag",
    "user": "tengomucho",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-16T20:46:33Z",
    "closed_at": "2024-10-17T17:48:00Z",
    "merged_at": "2024-10-17T17:48:00Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/194"
  },
  {
    "number": 193,
    "title": "fix: correct error message",
    "user": "tengomucho",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-15T21:01:58Z",
    "closed_at": "2024-12-13T18:26:40Z",
    "merged_at": "2024-12-13T18:26:40Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/193"
  },
  {
    "number": 192,
    "title": "add local tokenizer option for automated testing without hf token",
    "user": "sixiang-google",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-14T19:00:08Z",
    "closed_at": "2024-10-15T07:37:52Z",
    "merged_at": "2024-10-15T07:37:52Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/192"
  },
  {
    "number": 191,
    "title": "Add an option to not quantize embedding layer when doing quantization.",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-14T18:15:08Z",
    "closed_at": "2024-10-17T18:14:49Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/191"
  },
  {
    "number": 190,
    "title": "Delete convert_checkpoints and helper classmethods.",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-09T01:16:13Z",
    "closed_at": "2024-10-09T15:02:04Z",
    "merged_at": "2024-10-09T15:02:04Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/190"
  },
  {
    "number": 189,
    "title": "Fix ray recompilation and accuracy",
    "user": "sixiang-google",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-06T22:36:31Z",
    "closed_at": "2024-10-07T16:54:50Z",
    "merged_at": "2024-10-07T16:54:50Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/189"
  },
  {
    "number": 188,
    "title": "Make jpt the default cli - remove other entry point scripts",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-10-02T23:13:09Z",
    "closed_at": "2024-10-08T17:16:06Z",
    "merged_at": "2024-10-08T17:16:06Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/188"
  },
  {
    "number": 187,
    "title": "Add model warmup and jax compilation cache flags",
    "user": "vivianrwu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-27T19:55:05Z",
    "closed_at": "2024-10-02T00:11:06Z",
    "merged_at": "2024-10-02T00:11:06Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/187"
  },
  {
    "number": 186,
    "title": "Fix too many positional arguments lint error",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-27T02:00:49Z",
    "closed_at": "2024-09-28T00:34:45Z",
    "merged_at": "2024-09-28T00:34:45Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/186"
  },
  {
    "number": 184,
    "title": "Switch to NP from Jax to  improve attention manager performance",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-19T17:27:47Z",
    "closed_at": "2024-09-24T16:42:19Z",
    "merged_at": "2024-09-24T16:42:19Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/184"
  },
  {
    "number": 181,
    "title": "Add offline perf ci",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-06T22:08:58Z",
    "closed_at": "2024-09-13T00:25:24Z",
    "merged_at": "2024-09-13T00:25:24Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/181"
  },
  {
    "number": 180,
    "title": "Support End To End PagedAttention in JetStream",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-06T16:47:18Z",
    "closed_at": "2024-09-10T16:52:49Z",
    "merged_at": "2024-09-10T16:52:49Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/180"
  },
  {
    "number": 179,
    "title": "Pa decode checkin 1",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-09-06T02:23:09Z",
    "closed_at": "2024-09-06T16:47:32Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/179"
  },
  {
    "number": 178,
    "title": "Update README for new CLI",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-30T23:17:07Z",
    "closed_at": "2024-09-10T02:57:12Z",
    "merged_at": "2024-09-10T02:57:12Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/178"
  },
  {
    "number": 177,
    "title": "Update Jetstream, add optional sampler args.",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-30T00:45:33Z",
    "closed_at": "2024-08-30T19:08:02Z",
    "merged_at": "2024-08-30T19:08:02Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/177"
  },
  {
    "number": 176,
    "title": "Add gemma support in better cli",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-29T17:22:55Z",
    "closed_at": "2024-08-30T16:19:59Z",
    "merged_at": "2024-08-30T16:19:59Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/176"
  },
  {
    "number": 175,
    "title": "Use kwargs to simplify the call sites a bit",
    "user": "yixinshi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-27T20:08:49Z",
    "closed_at": "2024-08-27T23:06:57Z",
    "merged_at": "2024-08-27T23:06:57Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/175"
  },
  {
    "number": 174,
    "title": "Add mixtral support to new CLI",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-27T03:07:02Z",
    "closed_at": "2024-08-27T18:04:26Z",
    "merged_at": "2024-08-27T18:04:26Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/174"
  },
  {
    "number": 172,
    "title": "Fix the performance regression with ragged attention on for llama2 7b.",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-19T22:00:58Z",
    "closed_at": "2024-08-20T22:04:00Z",
    "merged_at": "2024-08-20T22:04:00Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/172"
  },
  {
    "number": 171,
    "title": "Replace repeat kv with proper GQA handling.",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-19T21:32:19Z",
    "closed_at": "2024-08-20T17:54:06Z",
    "merged_at": "2024-08-20T17:54:06Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/171"
  },
  {
    "number": 170,
    "title": "fix ray engine crashes on multihost",
    "user": "sixiang-google",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-19T18:32:02Z",
    "closed_at": "2024-08-20T17:55:27Z",
    "merged_at": "2024-08-20T17:55:27Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/170"
  },
  {
    "number": 168,
    "title": "Add a script to measure speed of basic ops",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T22:22:06Z",
    "closed_at": "2024-08-06T23:32:03Z",
    "merged_at": "2024-08-06T23:32:03Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/168"
  },
  {
    "number": 167,
    "title": "Add page attention manager and kvcache manager",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-06T21:05:25Z",
    "closed_at": "2024-08-06T22:48:04Z",
    "merged_at": "2024-08-06T22:48:04Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/167"
  },
  {
    "number": 166,
    "title": "Add page attention manager and kvcache manager",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-05T23:10:43Z",
    "closed_at": "2024-08-06T21:15:30Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/166"
  },
  {
    "number": 165,
    "title": "Fix TPU head resource name for v4 and v5e",
    "user": "richardsliu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-01T21:19:43Z",
    "closed_at": "2024-08-01T21:34:31Z",
    "merged_at": "2024-08-01T21:34:31Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/165"
  },
  {
    "number": 164,
    "title": "Fix Ray engine crash on multihost",
    "user": "richardsliu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-08-01T04:18:48Z",
    "closed_at": "2024-08-01T18:40:23Z",
    "merged_at": "2024-08-01T18:40:23Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/164"
  },
  {
    "number": 163,
    "title": "Fixed exhausted bug between head and workers",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-31T16:27:23Z",
    "closed_at": "2024-08-02T21:22:05Z",
    "merged_at": "2024-08-02T21:22:04Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/163"
  },
  {
    "number": 162,
    "title": "Handle v5e-8 in run_ray_serve_interleave",
    "user": "richardsliu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-31T02:55:04Z",
    "closed_at": "2024-07-31T17:19:48Z",
    "merged_at": "2024-07-31T17:19:48Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/162"
  },
  {
    "number": 161,
    "title": "Update Ray version in Dockerfile and add v5 configs",
    "user": "richardsliu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-30T23:37:02Z",
    "closed_at": "2024-07-31T00:04:48Z",
    "merged_at": "2024-07-31T00:04:48Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/161"
  },
  {
    "number": 160,
    "title": "Add newest llama-3 benchmarks",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-30T22:26:17Z",
    "closed_at": "2024-07-30T22:50:57Z",
    "merged_at": "2024-07-30T22:50:57Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/160"
  },
  {
    "number": 159,
    "title": "V5e8 ray",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-30T02:31:32Z",
    "closed_at": "2024-07-30T16:35:07Z",
    "merged_at": "2024-07-30T16:35:07Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/159"
  },
  {
    "number": 158,
    "title": "Return np instead of jax array for prefill result tokens",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-26T22:35:02Z",
    "closed_at": "2024-07-26T22:48:16Z",
    "merged_at": "2024-07-26T22:48:16Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/158"
  },
  {
    "number": 157,
    "title": "Correct typo enbedding -> embedding",
    "user": "tengomucho",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-26T09:47:49Z",
    "closed_at": "2024-07-29T23:46:33Z",
    "merged_at": "2024-07-29T23:46:33Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/157"
  },
  {
    "number": 156,
    "title": "commit act quant for conditional ffn",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-23T04:15:33Z",
    "closed_at": null,
    "merged_at": null,
    "state": "open",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/156"
  },
  {
    "number": 155,
    "title": "Stacked cache mixtral.",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-20T03:00:00Z",
    "closed_at": "2024-07-20T03:37:40Z",
    "merged_at": "2024-07-20T03:37:40Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/155"
  },
  {
    "number": 154,
    "title": "Stacked cache for MLPerf",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-20T01:46:33Z",
    "closed_at": "2024-07-20T02:44:43Z",
    "merged_at": "2024-07-20T02:44:43Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/154"
  },
  {
    "number": 153,
    "title": "Add mlperf benchmark for offline for mixtral",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T20:52:14Z",
    "closed_at": "2024-07-22T21:04:47Z",
    "merged_at": "2024-07-22T21:04:47Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/153"
  },
  {
    "number": 152,
    "title": "Set accumulate type to bf16 in activation quant",
    "user": "lsy323",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T02:34:32Z",
    "closed_at": "2024-07-19T04:45:48Z",
    "merged_at": "2024-07-19T04:45:48Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/152"
  },
  {
    "number": 151,
    "title": "Optimize cache update. ",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-19T00:11:24Z",
    "closed_at": "2024-08-06T19:37:49Z",
    "merged_at": "2024-08-06T19:37:49Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/151"
  },
  {
    "number": 149,
    "title": "Fix blockwise sharding",
    "user": "lsy323",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-16T02:25:25Z",
    "closed_at": "2025-02-04T07:27:58Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/149"
  },
  {
    "number": 148,
    "title": "Add mlperf benchmark scripts in-tree.",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-13T00:43:28Z",
    "closed_at": "2024-07-15T21:47:13Z",
    "merged_at": "2024-07-15T21:47:13Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/148"
  },
  {
    "number": 147,
    "title": "Make Ray engine and worker process prefill returning first token",
    "user": "richardsliu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-12T21:29:01Z",
    "closed_at": "2024-07-12T22:01:44Z",
    "merged_at": "2024-07-12T22:01:44Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/147"
  },
  {
    "number": 146,
    "title": "Jetstream + RayServe deployment for interleave mode",
    "user": "richardsliu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-10T23:19:16Z",
    "closed_at": "2024-07-11T04:04:30Z",
    "merged_at": "2024-07-11T04:04:30Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/146"
  },
  {
    "number": 145,
    "title": "Set JAX_PLATFORMS to \"tpu, cpu\" for ray worker",
    "user": "richardsliu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T17:33:54Z",
    "closed_at": "2024-07-09T18:22:47Z",
    "merged_at": "2024-07-09T18:22:47Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/145"
  },
  {
    "number": 144,
    "title": "Fix exception in ray_worker",
    "user": "richardsliu",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-09T17:25:12Z",
    "closed_at": "2024-07-09T20:02:25Z",
    "merged_at": "2024-07-09T20:02:25Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/144"
  },
  {
    "number": 143,
    "title": "Make prefilling return first token for loadgen integration",
    "user": "sixiang-google",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-08T18:38:21Z",
    "closed_at": "2024-07-10T20:21:46Z",
    "merged_at": "2024-07-10T20:21:46Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/143"
  },
  {
    "number": 142,
    "title": "Add server tests",
    "user": "bvrockwell",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-05T03:37:51Z",
    "closed_at": "2024-07-08T17:12:00Z",
    "merged_at": "2024-07-08T17:12:00Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/142"
  },
  {
    "number": 141,
    "title": "Update benchmark command in README.md",
    "user": "bhavya01",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-02T03:47:12Z",
    "closed_at": "2024-07-03T22:46:55Z",
    "merged_at": "2024-07-03T22:46:55Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/141"
  },
  {
    "number": 140,
    "title": "add enable jax profiler to run_server",
    "user": "bvrockwell",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-07-01T17:56:25Z",
    "closed_at": "2024-07-01T18:27:19Z",
    "merged_at": "2024-07-01T18:27:19Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/140"
  },
  {
    "number": 139,
    "title": "Update README.md to state the limitation of accessing GCS when converâ€¦",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-28T23:00:43Z",
    "closed_at": "2024-06-28T23:07:22Z",
    "merged_at": "2024-06-28T23:07:22Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/139"
  },
  {
    "number": 138,
    "title": "Minor fixes to README",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-28T21:46:45Z",
    "closed_at": "2024-06-28T21:48:17Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/138"
  },
  {
    "number": 136,
    "title": "Add layer id in scope for each TransformerBlock layer",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-26T20:46:04Z",
    "closed_at": "2024-06-26T21:12:07Z",
    "merged_at": "2024-06-26T21:12:07Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/136"
  },
  {
    "number": 134,
    "title": "prototyping better UX",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-22T00:59:51Z",
    "closed_at": "2024-07-15T17:53:03Z",
    "merged_at": "2024-07-15T17:53:03Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/134"
  },
  {
    "number": 133,
    "title": "Add left aligned cache support.",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-21T22:43:07Z",
    "closed_at": "2024-06-28T23:09:32Z",
    "merged_at": "2024-06-28T23:09:32Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/133"
  },
  {
    "number": 132,
    "title": "fix mixtral quantization scaler axis when dimension > 2",
    "user": "sixiang-google",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-20T18:02:23Z",
    "closed_at": "2024-06-20T18:30:12Z",
    "merged_at": "2024-06-20T18:30:12Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/132"
  },
  {
    "number": 131,
    "title": "Add test for Mixtral model.",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-19T23:36:20Z",
    "closed_at": "2024-06-20T17:40:33Z",
    "merged_at": "2024-06-20T17:40:33Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/131"
  },
  {
    "number": 130,
    "title": "make sure GPU works",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-18T20:25:44Z",
    "closed_at": "2024-06-19T04:09:56Z",
    "merged_at": "2024-06-19T04:09:56Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/130"
  },
  {
    "number": 129,
    "title": "Update README.md",
    "user": "bhavya01",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-17T17:25:26Z",
    "closed_at": "2024-06-17T18:17:29Z",
    "merged_at": "2024-06-17T18:17:29Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/129"
  },
  {
    "number": 128,
    "title": "Update README.md",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-14T18:29:52Z",
    "closed_at": "2024-06-15T17:40:07Z",
    "merged_at": "2024-06-15T17:40:07Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/128"
  },
  {
    "number": 127,
    "title": "Update submodules, prepare for leasing v0.2.4",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-14T05:01:23Z",
    "closed_at": "2024-06-14T18:25:26Z",
    "merged_at": "2024-06-14T18:25:26Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/127"
  },
  {
    "number": 126,
    "title": "Add lock in prefill and generate to prevent starvation",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T21:42:27Z",
    "closed_at": "2024-06-14T15:40:14Z",
    "merged_at": "2024-06-14T15:40:14Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/126"
  },
  {
    "number": 125,
    "title": "Update summary.md",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-13T17:44:16Z",
    "closed_at": "2024-06-17T17:21:41Z",
    "merged_at": "2024-06-17T17:21:41Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/125"
  },
  {
    "number": 124,
    "title": "Remove JSON config mangling for Gemma ckpt",
    "user": "lsy323",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-12T22:25:59Z",
    "closed_at": "2024-06-13T17:20:32Z",
    "merged_at": "2024-06-13T17:20:32Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/124"
  },
  {
    "number": 123,
    "title": "Add different token sampling algorithms to decoder.",
    "user": "bvrockwell",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-12T05:16:12Z",
    "closed_at": "2024-06-14T00:43:41Z",
    "merged_at": "2024-06-14T00:43:41Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/123"
  },
  {
    "number": 122,
    "title": "add script to isntall for GPU",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-11T21:02:25Z",
    "closed_at": "2024-06-12T00:11:21Z",
    "merged_at": "2024-06-12T00:11:21Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/122"
  },
  {
    "number": 121,
    "title": "Fix convert_checkpoint.py for hf and gemma",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-10T23:30:01Z",
    "closed_at": "2024-06-10T23:56:49Z",
    "merged_at": "2024-06-10T23:56:49Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/121"
  },
  {
    "number": 120,
    "title": "Mixtral enablement. ",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-10T21:38:57Z",
    "closed_at": "2024-06-11T02:56:18Z",
    "merged_at": "2024-06-11T02:56:18Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/120"
  },
  {
    "number": 119,
    "title": "Add guide on adding HF ckpt conversion support",
    "user": "lsy323",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-07T05:04:25Z",
    "closed_at": "2024-06-07T20:07:05Z",
    "merged_at": "2024-06-07T20:07:05Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/119"
  },
  {
    "number": 118,
    "title": "Support HF LLaMA ckpt conversion",
    "user": "lsy323",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-07T00:57:47Z",
    "closed_at": "2024-06-07T03:15:25Z",
    "merged_at": "2024-06-07T03:15:25Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/118"
  },
  {
    "number": 117,
    "title": "Integrate disaggregated serving with JetStream",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-05T23:32:53Z",
    "closed_at": "2024-06-06T14:21:36Z",
    "merged_at": "2024-06-06T14:21:36Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/117"
  },
  {
    "number": 116,
    "title": "Fix conversion bug",
    "user": "yeandy",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-04T23:00:48Z",
    "closed_at": "2024-06-04T23:41:53Z",
    "merged_at": "2024-06-04T23:41:53Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/116"
  },
  {
    "number": 114,
    "title": "Add for readme interleave multiple host with ray",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-04T20:29:04Z",
    "closed_at": "2024-06-04T21:33:41Z",
    "merged_at": "2024-06-04T21:33:41Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/114"
  },
  {
    "number": 113,
    "title": "Metrics bug: server_lib should be config_lib",
    "user": "Bslabe123",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-03T23:09:43Z",
    "closed_at": "2024-06-04T03:02:21Z",
    "merged_at": "2024-06-04T03:02:21Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/113"
  },
  {
    "number": 112,
    "title": "Enable jax profiler server in run with ray",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-06-03T20:25:27Z",
    "closed_at": "2024-06-04T15:43:28Z",
    "merged_at": "2024-06-04T15:43:28Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/112"
  },
  {
    "number": 111,
    "title": "Jetstream: 8128c8a -> v0.2.2",
    "user": "Bslabe123",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-31T21:23:39Z",
    "closed_at": "2024-05-31T21:34:00Z",
    "merged_at": "2024-05-31T21:34:00Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/111"
  },
  {
    "number": 110,
    "title": "Release JetStream v0.2.2",
    "user": "JoeZijunZhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-31T21:15:22Z",
    "closed_at": "2024-05-31T22:33:44Z",
    "merged_at": "2024-05-31T22:33:44Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/110"
  },
  {
    "number": 109,
    "title": "Add run_server with ray for interleave serving ",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-31T00:09:50Z",
    "closed_at": "2024-05-31T15:20:39Z",
    "merged_at": "2024-05-31T15:20:39Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/109"
  },
  {
    "number": 108,
    "title": "Update Jetstream commit id",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-29T23:33:43Z",
    "closed_at": "2024-05-30T16:27:32Z",
    "merged_at": "2024-05-30T16:27:32Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/108"
  },
  {
    "number": 106,
    "title": "Ray Disaggregated Serving MVP",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-29T01:25:12Z",
    "closed_at": "2024-05-29T22:19:08Z",
    "merged_at": "2024-05-29T22:19:08Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/106"
  },
  {
    "number": 105,
    "title": "Add activation quantization support to per-channel quantized linear layers",
    "user": "lsy323",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-25T02:09:56Z",
    "closed_at": "2024-06-12T22:29:27Z",
    "merged_at": "2024-06-12T22:29:27Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/105"
  },
  {
    "number": 104,
    "title": "Fix convert script cannot generate bf16 weights",
    "user": "lsy323",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-25T02:02:59Z",
    "closed_at": "2024-05-28T21:25:18Z",
    "merged_at": "2024-05-28T21:25:18Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/104"
  },
  {
    "number": 103,
    "title": "Update run_interactive.py with finer control of profiler.",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T22:31:46Z",
    "closed_at": "2024-05-29T22:32:13Z",
    "merged_at": "2024-05-29T22:32:13Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/103"
  },
  {
    "number": 102,
    "title": "Update run_server.py. metrics_server_config is not supported in JetStream[8128c8a] yet",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T22:26:53Z",
    "closed_at": "2024-06-03T17:01:06Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/102"
  },
  {
    "number": 101,
    "title": "Add support for Llama3-70b",
    "user": "bhavya01",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T01:43:09Z",
    "closed_at": "2024-06-10T18:52:30Z",
    "merged_at": "2024-06-10T18:52:30Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/101"
  },
  {
    "number": 100,
    "title": "Fix ray conflict changes ",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-24T00:53:58Z",
    "closed_at": "2024-05-28T17:23:09Z",
    "merged_at": "2024-05-28T17:23:09Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/100"
  },
  {
    "number": 99,
    "title": "Pass metrics client config through to Jetstream",
    "user": "Bslabe123",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-23T17:21:23Z",
    "closed_at": "2024-05-23T18:34:36Z",
    "merged_at": "2024-05-23T18:34:36Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/99"
  },
  {
    "number": 98,
    "title": "Fix gemma model, enable_weight_quantization is available through quant_config.",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-22T23:19:37Z",
    "closed_at": "2024-05-22T23:37:27Z",
    "merged_at": "2024-05-22T23:37:27Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/98"
  },
  {
    "number": 97,
    "title": "Update README.md, the quantize flag is no longer available, quantize_type assumes the role of the original flag.",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-22T23:19:13Z",
    "closed_at": "2024-05-22T23:37:05Z",
    "merged_at": "2024-05-22T23:37:05Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/97"
  },
  {
    "number": 96,
    "title": "Fix flax and ray dependencies",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-22T20:34:20Z",
    "closed_at": "2024-05-22T20:56:26Z",
    "merged_at": "2024-05-22T20:56:26Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/96"
  },
  {
    "number": 95,
    "title": "Fixes tests. Can now run on CPU by default. ",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-22T20:11:56Z",
    "closed_at": "2024-05-22T23:03:55Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/95"
  },
  {
    "number": 93,
    "title": "Integrates ragged attention to JetStream Pytorch",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-20T21:43:15Z",
    "closed_at": "2024-05-23T21:35:05Z",
    "merged_at": "2024-05-23T21:35:05Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/93"
  },
  {
    "number": 92,
    "title": "Move flags in scripts to a common function",
    "user": "lsy323",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T23:46:53Z",
    "closed_at": "2024-05-20T16:15:03Z",
    "merged_at": "2024-05-20T16:15:03Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/92"
  },
  {
    "number": 91,
    "title": "Update README.md",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T23:20:19Z",
    "closed_at": "2024-05-17T23:24:27Z",
    "merged_at": "2024-05-17T23:24:27Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/91"
  },
  {
    "number": 90,
    "title": "Leverage tokens_utils to process result tokens",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T23:18:09Z",
    "closed_at": "2024-05-17T23:38:41Z",
    "merged_at": "2024-05-17T23:38:41Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/90"
  },
  {
    "number": 89,
    "title": "Move deps to git submodule",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T20:41:37Z",
    "closed_at": "2024-05-17T22:38:33Z",
    "merged_at": "2024-05-17T22:38:33Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/89"
  },
  {
    "number": 88,
    "title": "Update version of jetstream; misc fixes",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T05:11:23Z",
    "closed_at": "2024-05-17T16:51:58Z",
    "merged_at": "2024-05-17T16:51:58Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/88"
  },
  {
    "number": 87,
    "title": "Update README.md",
    "user": "JackCaoG",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-17T00:32:13Z",
    "closed_at": "2024-05-17T01:09:18Z",
    "merged_at": "2024-05-17T01:09:18Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/87"
  },
  {
    "number": 86,
    "title": "Fix sharding config file name bug",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-16T19:21:18Z",
    "closed_at": "2024-05-16T22:18:42Z",
    "merged_at": "2024-05-16T22:18:42Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/86"
  },
  {
    "number": 85,
    "title": "Add Gemma 2b benchmark; fix a typo.",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-16T17:54:41Z",
    "closed_at": "2024-05-16T18:16:18Z",
    "merged_at": "2024-05-16T18:16:17Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/85"
  },
  {
    "number": 84,
    "title": "Enable Blockwise Int4 quantized linear layer",
    "user": "lsy323",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-16T17:44:03Z",
    "closed_at": "2024-05-22T20:44:53Z",
    "merged_at": "2024-05-22T20:44:53Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/84"
  },
  {
    "number": 81,
    "title": "Add Gemma 2b benchmark; fix a typo.",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-15T04:38:40Z",
    "closed_at": "2024-05-15T04:42:31Z",
    "merged_at": "2024-05-15T04:42:31Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/81"
  },
  {
    "number": 80,
    "title": "Add shard on batch mode. Als update version of torchxla2",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-13T23:20:15Z",
    "closed_at": "2024-05-14T22:58:42Z",
    "merged_at": "2024-05-14T22:58:42Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/80"
  },
  {
    "number": 79,
    "title": "Add llama-3 instructions to readme",
    "user": "bhavya01",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-13T18:11:31Z",
    "closed_at": "2024-05-13T22:33:38Z",
    "merged_at": "2024-05-13T22:33:38Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/79"
  },
  {
    "number": 78,
    "title": "Fix attention kernel of GQA use case",
    "user": "lsy323",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-10T21:21:00Z",
    "closed_at": "2024-05-10T21:24:04Z",
    "merged_at": "2024-05-10T21:24:04Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/78"
  },
  {
    "number": 77,
    "title": "Enable quantization for Gemma 7b",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-10T18:33:33Z",
    "closed_at": "2024-05-10T21:24:54Z",
    "merged_at": "2024-05-10T21:24:54Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/77"
  },
  {
    "number": 76,
    "title": "Add benchmark results",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-10T18:24:38Z",
    "closed_at": "2024-05-10T19:48:51Z",
    "merged_at": "2024-05-10T19:48:50Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/76"
  },
  {
    "number": 75,
    "title": "Enable Gemma 2B",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-10T00:09:05Z",
    "closed_at": "2024-05-10T16:13:38Z",
    "merged_at": "2024-05-10T16:13:37Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/75"
  },
  {
    "number": 74,
    "title": "Add gemma and update recent changes to  multiple host",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-09T22:28:29Z",
    "closed_at": "2024-05-09T22:52:48Z",
    "merged_at": "2024-05-09T22:52:48Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/74"
  },
  {
    "number": 73,
    "title": "Fix sharding config for quant",
    "user": "lsy323",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-09T19:47:48Z",
    "closed_at": "2024-05-09T22:52:36Z",
    "merged_at": "2024-05-09T22:52:36Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/73"
  },
  {
    "number": 72,
    "title": "Use GemmaAttention for Gemma",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-09T16:16:04Z",
    "closed_at": "2024-05-09T18:24:06Z",
    "merged_at": "2024-05-09T18:24:06Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/72"
  },
  {
    "number": 71,
    "title": "Support converting hf gemma weights",
    "user": "lsy323",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-08T18:17:49Z",
    "closed_at": "2024-05-09T12:12:02Z",
    "merged_at": "2024-05-09T12:12:02Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/71"
  },
  {
    "number": 70,
    "title": "Gemma sharding and test",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-07T01:44:53Z",
    "closed_at": "2024-05-08T00:09:01Z",
    "merged_at": "2024-05-08T00:09:01Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/70"
  },
  {
    "number": 69,
    "title": "Add gemma support",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-03T22:45:51Z",
    "closed_at": "2024-05-07T00:43:01Z",
    "merged_at": "2024-05-07T00:43:01Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/69"
  },
  {
    "number": 68,
    "title": "Add prefill only benchmark for different token length",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-03T03:50:50Z",
    "closed_at": "2024-05-03T15:57:08Z",
    "merged_at": "2024-05-03T15:57:08Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/68"
  },
  {
    "number": 67,
    "title": "Pick a slot from 0 to batch_size-1 during run_interactive.py",
    "user": "bhavya01",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-02T22:40:42Z",
    "closed_at": "2024-05-03T00:04:45Z",
    "merged_at": "2024-05-03T00:04:45Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/67"
  },
  {
    "number": 66,
    "title": "Add vscode to gitignore",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-02T21:47:22Z",
    "closed_at": "2024-05-02T22:06:39Z",
    "merged_at": "2024-05-02T22:06:39Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/66"
  },
  {
    "number": 65,
    "title": "Refactor so that environment and engine",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-02T01:54:01Z",
    "closed_at": "2024-05-02T18:17:10Z",
    "merged_at": "2024-05-02T18:17:10Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/65"
  },
  {
    "number": 64,
    "title": "Support llama3",
    "user": "bhavya01",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-05-02T00:12:52Z",
    "closed_at": "2024-05-03T23:36:35Z",
    "merged_at": "2024-05-03T23:36:35Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/64"
  },
  {
    "number": 63,
    "title": "Add ray multiple host support",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T23:47:43Z",
    "closed_at": "2024-04-30T21:47:05Z",
    "merged_at": "2024-04-30T21:47:05Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/63"
  },
  {
    "number": 62,
    "title": "Ignore duplicated lines check now",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T23:27:31Z",
    "closed_at": "2024-04-26T23:27:41Z",
    "merged_at": "2024-04-26T23:27:41Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/62"
  },
  {
    "number": 61,
    "title": "Output all token text",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-26T06:10:52Z",
    "closed_at": "2024-04-26T06:13:54Z",
    "merged_at": "2024-04-26T06:13:54Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/61"
  },
  {
    "number": 60,
    "title": "Comment broken function to unblock interactive run after JetStream api change",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T22:43:14Z",
    "closed_at": "2024-04-25T23:09:46Z",
    "merged_at": "2024-04-25T23:09:46Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/60"
  },
  {
    "number": 59,
    "title": "Use property instead of function",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T22:22:50Z",
    "closed_at": "2024-04-25T22:25:54Z",
    "merged_at": "2024-04-25T22:25:54Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/59"
  },
  {
    "number": 58,
    "title": "Enable pylint check",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T08:24:48Z",
    "closed_at": "2024-04-25T08:24:56Z",
    "merged_at": "2024-04-25T08:24:56Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/58"
  },
  {
    "number": 57,
    "title": "Fix run_server lint check",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T08:05:20Z",
    "closed_at": "2024-04-25T08:05:27Z",
    "merged_at": "2024-04-25T08:05:27Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/57"
  },
  {
    "number": 56,
    "title": "Fix run_interactive lint check",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T08:00:22Z",
    "closed_at": "2024-04-25T08:00:30Z",
    "merged_at": "2024-04-25T08:00:30Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/56"
  },
  {
    "number": 55,
    "title": "Fix convert checkpoint lint check",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T07:48:41Z",
    "closed_at": "2024-04-25T07:48:51Z",
    "merged_at": "2024-04-25T07:48:51Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/55"
  },
  {
    "number": 54,
    "title": "Add pylintrc and init in root dir",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T07:36:53Z",
    "closed_at": "2024-04-25T07:37:02Z",
    "merged_at": "2024-04-25T07:37:02Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/54"
  },
  {
    "number": 53,
    "title": "Fix quantizaiton, jax lint and llama e2e",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T07:31:29Z",
    "closed_at": "2024-04-25T07:31:51Z",
    "merged_at": "2024-04-25T07:31:51Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/53"
  },
  {
    "number": 52,
    "title": "Fix quantizaiton and jax lint check",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T07:22:06Z",
    "closed_at": "2024-04-25T07:22:17Z",
    "merged_at": "2024-04-25T07:22:17Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/52"
  },
  {
    "number": 51,
    "title": "Fix test quantization lint check",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T06:59:08Z",
    "closed_at": "2024-04-25T06:59:14Z",
    "merged_at": "2024-04-25T06:59:14Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/51"
  },
  {
    "number": 50,
    "title": "Fix test_model_impl lint",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T06:50:44Z",
    "closed_at": "2024-04-25T06:51:07Z",
    "merged_at": "2024-04-25T06:51:07Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/50"
  },
  {
    "number": 49,
    "title": "Clean up llama_e2e test",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T06:21:39Z",
    "closed_at": "2024-04-25T06:23:21Z",
    "merged_at": "2024-04-25T06:23:21Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/49"
  },
  {
    "number": 48,
    "title": "Cleanup test_jax_torch",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T05:44:41Z",
    "closed_at": "2024-04-25T05:44:48Z",
    "merged_at": "2024-04-25T05:44:47Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/48"
  },
  {
    "number": 47,
    "title": "Disable test_engine check for now",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T05:39:21Z",
    "closed_at": "2024-04-25T05:39:29Z",
    "merged_at": "2024-04-25T05:39:29Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/47"
  },
  {
    "number": 46,
    "title": "Add pylintrc to tests",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T05:35:39Z",
    "closed_at": "2024-04-25T05:35:49Z",
    "merged_at": "2024-04-25T05:35:48Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/46"
  },
  {
    "number": 45,
    "title": "Clean up config.py",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T05:28:55Z",
    "closed_at": "2024-04-25T05:29:06Z",
    "merged_at": "2024-04-25T05:29:06Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/45"
  },
  {
    "number": 44,
    "title": "Cleanup quantize",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T05:21:58Z",
    "closed_at": "2024-04-25T05:22:06Z",
    "merged_at": "2024-04-25T05:22:06Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/44"
  },
  {
    "number": 43,
    "title": "Cleanup environment",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T05:16:53Z",
    "closed_at": "2024-04-25T05:17:03Z",
    "merged_at": "2024-04-25T05:17:03Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/43"
  },
  {
    "number": 42,
    "title": "Clean up engine",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T04:24:33Z",
    "closed_at": "2024-04-25T04:27:21Z",
    "merged_at": "2024-04-25T04:27:21Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/42"
  },
  {
    "number": 41,
    "title": "Cleanup cache_manager",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T03:51:01Z",
    "closed_at": "2024-04-25T03:51:15Z",
    "merged_at": "2024-04-25T03:51:15Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/41"
  },
  {
    "number": 40,
    "title": "Add .pylintrc",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T03:41:26Z",
    "closed_at": "2024-04-25T03:41:36Z",
    "merged_at": "2024-04-25T03:41:36Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/40"
  },
  {
    "number": 39,
    "title": "Clean up benchmarks files",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T03:19:24Z",
    "closed_at": "2024-04-25T03:19:33Z",
    "merged_at": "2024-04-25T03:19:32Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/39"
  },
  {
    "number": 38,
    "title": "Cleanup run_offline",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T03:14:47Z",
    "closed_at": "2024-04-25T03:15:00Z",
    "merged_at": "2024-04-25T03:15:00Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/38"
  },
  {
    "number": 37,
    "title": "Remove duplicated test",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T02:49:09Z",
    "closed_at": "2024-04-25T02:49:17Z",
    "merged_at": "2024-04-25T02:49:17Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/37"
  },
  {
    "number": 36,
    "title": "Fix pylint for micro benchmark",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-25T00:55:45Z",
    "closed_at": "2024-04-25T00:55:52Z",
    "merged_at": "2024-04-25T00:55:52Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/36"
  },
  {
    "number": 35,
    "title": "Use 2 space as indentation",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T23:49:38Z",
    "closed_at": "2024-04-24T23:50:41Z",
    "merged_at": "2024-04-24T23:50:41Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/35"
  },
  {
    "number": 34,
    "title": "Enable pylint check",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T23:32:58Z",
    "closed_at": "2024-04-24T23:44:36Z",
    "merged_at": "2024-04-24T23:44:36Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/34"
  },
  {
    "number": 33,
    "title": "Enable pyink check",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T21:23:15Z",
    "closed_at": "2024-04-24T21:28:06Z",
    "merged_at": "2024-04-24T21:28:06Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/33"
  },
  {
    "number": 32,
    "title": "Cleanup and format main dir code",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T21:17:02Z",
    "closed_at": "2024-04-24T21:19:44Z",
    "merged_at": "2024-04-24T21:19:44Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/32"
  },
  {
    "number": 31,
    "title": "Cleanup and format benchmark code",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T21:07:52Z",
    "closed_at": "2024-04-24T21:12:42Z",
    "merged_at": "2024-04-24T21:12:42Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/31"
  },
  {
    "number": 30,
    "title": "Cleanup and format test code",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T21:06:28Z",
    "closed_at": "2024-04-24T21:12:57Z",
    "merged_at": "2024-04-24T21:12:57Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/30"
  },
  {
    "number": 29,
    "title": "Cleanup and format engine code",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T21:05:01Z",
    "closed_at": "2024-04-24T21:12:31Z",
    "merged_at": "2024-04-24T21:12:31Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/29"
  },
  {
    "number": 28,
    "title": "Cleanup and format third party code",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-24T20:57:38Z",
    "closed_at": "2024-04-24T21:00:50Z",
    "merged_at": "2024-04-24T21:00:50Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/28"
  },
  {
    "number": 26,
    "title": "llama3",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-23T18:04:45Z",
    "closed_at": "2024-05-09T15:44:55Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/26"
  },
  {
    "number": 25,
    "title": "Add original llama prefill and decode",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-23T05:44:04Z",
    "closed_at": "2024-04-23T20:25:26Z",
    "merged_at": "2024-04-23T20:25:26Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/25"
  },
  {
    "number": 24,
    "title": "update create TPU VM link",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-23T05:13:55Z",
    "closed_at": "2024-04-23T05:14:12Z",
    "merged_at": "2024-04-23T05:14:12Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/24"
  },
  {
    "number": 23,
    "title": "Add jetstream links",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-17T19:43:38Z",
    "closed_at": "2024-04-17T19:52:57Z",
    "merged_at": "2024-04-17T19:52:57Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/23"
  },
  {
    "number": 22,
    "title": "Unstall existing jax before install jax",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-16T20:04:06Z",
    "closed_at": "2024-04-16T22:09:15Z",
    "merged_at": "2024-04-16T22:09:15Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/22"
  },
  {
    "number": 21,
    "title": "Remove unused import",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-13T20:21:41Z",
    "closed_at": "2024-04-13T20:28:17Z",
    "merged_at": "2024-04-13T20:28:17Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/21"
  },
  {
    "number": 20,
    "title": "Pass all unit tests",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-13T19:41:53Z",
    "closed_at": "2024-04-13T20:05:29Z",
    "merged_at": "2024-04-13T20:05:29Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/20"
  },
  {
    "number": 19,
    "title": "Initial implementation",
    "user": "liurupeng",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-12T23:22:18Z",
    "closed_at": "2024-05-07T20:12:21Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/19"
  },
  {
    "number": 18,
    "title": "Fix KVCacheGenerate",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-12T03:14:04Z",
    "closed_at": "2024-04-12T15:52:31Z",
    "merged_at": "2024-04-12T15:52:31Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/18"
  },
  {
    "number": 17,
    "title": "Add Jax torch test",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-12T00:14:11Z",
    "closed_at": "2024-04-12T02:15:16Z",
    "merged_at": "2024-04-12T02:15:16Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/17"
  },
  {
    "number": 16,
    "title": "Add float32 support",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-11T21:48:03Z",
    "closed_at": "2024-04-13T18:35:08Z",
    "merged_at": "2024-04-13T18:35:08Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/16"
  },
  {
    "number": 15,
    "title": "Add copyright",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-11T00:16:30Z",
    "closed_at": "2024-04-11T00:27:50Z",
    "merged_at": "2024-04-11T00:27:50Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/15"
  },
  {
    "number": 14,
    "title": "Fix the 70B quantized model with correct kv head dimension for cache.",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T22:38:45Z",
    "closed_at": "2024-04-10T23:14:32Z",
    "merged_at": "2024-04-10T23:14:32Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/14"
  },
  {
    "number": 13,
    "title": "Fix unit tests CICD",
    "user": "JoeZijunZhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T21:55:47Z",
    "closed_at": "2024-04-10T23:41:56Z",
    "merged_at": "2024-04-10T23:41:56Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/13"
  },
  {
    "number": 12,
    "title": "Add CICD for jetstream_pt unit tests",
    "user": "JoeZijunZhou",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T20:07:22Z",
    "closed_at": "2024-04-10T21:50:32Z",
    "merged_at": "2024-04-10T21:50:32Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/12"
  },
  {
    "number": 11,
    "title": "Add llama end to end test with jetstream engine ",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-10T19:02:13Z",
    "closed_at": "2024-04-10T21:23:05Z",
    "merged_at": "2024-04-10T21:23:05Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/11"
  },
  {
    "number": 10,
    "title": "Updates the toml script to the release tag version; Removes the poetry related config from the toml script; Updates the engine to take checkpoint paths without .safetensors suffix for better user experience.",
    "user": "wang2yn84",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-09T00:03:57Z",
    "closed_at": "2024-04-09T17:03:37Z",
    "merged_at": "2024-04-09T17:03:37Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/10"
  },
  {
    "number": 9,
    "title": "Update readme",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-06T00:06:07Z",
    "closed_at": "2024-04-06T00:15:48Z",
    "merged_at": "2024-04-06T00:15:48Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/9"
  },
  {
    "number": 8,
    "title": "Add colorama",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-04T21:23:19Z",
    "closed_at": "2024-04-04T22:03:06Z",
    "merged_at": "2024-04-04T22:03:06Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/8"
  },
  {
    "number": 7,
    "title": "Move create_pytorch_engine to init.",
    "user": "qihqi",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-04T17:32:30Z",
    "closed_at": "2024-04-04T17:47:16Z",
    "merged_at": "2024-04-04T17:47:16Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/7"
  },
  {
    "number": 6,
    "title": "Refactor interactive",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-04T14:28:54Z",
    "closed_at": "2024-04-04T17:21:58Z",
    "merged_at": "2024-04-04T17:21:58Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/6"
  },
  {
    "number": 5,
    "title": "Fix install_everything",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-04T01:58:40Z",
    "closed_at": "2024-04-04T02:01:56Z",
    "merged_at": "2024-04-04T02:01:56Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/5"
  },
  {
    "number": 4,
    "title": "Remove personal information",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-04T01:16:52Z",
    "closed_at": "2024-04-04T01:27:40Z",
    "merged_at": "2024-04-04T01:27:40Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/4"
  },
  {
    "number": 3,
    "title": "Remove personal information ",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-04T01:11:11Z",
    "closed_at": "2024-04-04T01:15:26Z",
    "merged_at": null,
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/3"
  },
  {
    "number": 2,
    "title": "Update readme",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-04T01:01:29Z",
    "closed_at": "2024-04-04T01:28:43Z",
    "merged_at": "2024-04-04T01:28:43Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/2"
  },
  {
    "number": 1,
    "title": "mv run_interactive out of benchmarks",
    "user": "FanhaiLu1",
    "user_type": "User",
    "is_human": true,
    "created_at": "2024-04-04T00:44:56Z",
    "closed_at": "2024-04-04T01:27:02Z",
    "merged_at": "2024-04-04T01:27:02Z",
    "state": "closed",
    "html_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch/pull/1"
  }
]